{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import urllib.request, json \n",
    "with urllib.request.urlopen(\"http://statistik.easycredit-bbl.de/XML/exchange/540/Schedule.php?type=json&saison=2017&fixedGamesOnly=0\") as url:\n",
    "    games = json.loads(url.read().decode())\n",
    "\n",
    "    \n",
    "    \n",
    "arenakap = {486:6594,413:14500,433:4200,420:6150,415:6000,425:3300,430:6000,426:5002,540:3140,418:6200,421:4003,422:3603,483:3076,477:3447,428:3000,439:4200,517:3533,432:3132}\n",
    "\n",
    "dataset=[]\n",
    "\n",
    "for i in range(0,len(games['competition'][0]['spiel'])):\n",
    "    datasetrow=[]     \n",
    "    datasetrow.append(games['competition'][0]['spiel'][i]['home_id'])\n",
    "    datasetrow.append(games['competition'][0]['spiel'][i]['gast_id'])\n",
    "    datasetrow.append(int(games['competition'][0]['spiel'][i]['home_result']>games['competition'][0]['spiel'][i]['gast_result']))\n",
    "    datasetrow.append(int(games['competition'][0]['spiel'][i]['zuschauer']))\n",
    "    datasetrow.append(arenakap[int(games['competition'][0]['spiel'][i]['home_id'])])\n",
    "    \n",
    "    dataset.append(datasetrow)\n",
    "\n",
    "\n",
    "# Umwandlung des Datasets in ein Numpy Array \n",
    "import numpy as np\n",
    "# : bedeutet in diesem Fall auslesen aller zeilen\n",
    "dataset=np.asarray(dataset)\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "transformed_home_ids = encoder.fit_transform(dataset[:,0])\n",
    "\n",
    "\n",
    "#ohne fit, damit die Teams eindeutig bleiben, nur transformation notwendig\n",
    "transformed_gast_ids = encoder.transform(dataset[:,1])\n",
    "\n",
    "# Umformung der Zuschauer in eine Spalte (vorher war es nur eine Zeile)\n",
    "#print(np.reshape(dataset[:,3],(306,1)))\n",
    "\n",
    "# Featurescaling der Zuschaueranzahl & Hallenkapazit√§ten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "arenaKap_scaler=MinMaxScaler()\n",
    "arenaKap_scaler.fit([[0],[14500]]) #Maximum Berlin und 0 Minimum\n",
    "#reshaping\n",
    "transformed_zuschauer=arenaKap_scaler.transform(np.reshape(dataset[:,3],(306,1)))\n",
    "transformed_kap=arenaKap_scaler.transform(np.reshape(dataset[:,4],(306,1)))\n",
    "\n",
    "\n",
    "data=np.c_[transformed_home_ids,transformed_gast_ids,transformed_zuschauer,transformed_kap,dataset[:,2]]\n",
    "\n",
    "# Importing the Keras libraries and packages \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                1248      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                660       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,929\n",
      "Trainable params: 1,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 843us/step - loss: 0.2499 - acc: 0.5309 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.2490 - acc: 0.5418 - val_loss: 0.2488 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.2463 - acc: 0.5418 - val_loss: 0.2448 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.2375 - acc: 0.5600 - val_loss: 0.2362 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.2219 - acc: 0.6436 - val_loss: 0.2273 - val_acc: 0.5806\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.2083 - acc: 0.7018 - val_loss: 0.2212 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1952 - acc: 0.7273 - val_loss: 0.2176 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1839 - acc: 0.7673 - val_loss: 0.2125 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1745 - acc: 0.7782 - val_loss: 0.2154 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1688 - acc: 0.7709 - val_loss: 0.2198 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1652 - acc: 0.7636 - val_loss: 0.2138 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1587 - acc: 0.7891 - val_loss: 0.2121 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1554 - acc: 0.7891 - val_loss: 0.2169 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1526 - acc: 0.8036 - val_loss: 0.2179 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1498 - acc: 0.8145 - val_loss: 0.2173 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1479 - acc: 0.8109 - val_loss: 0.2199 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1460 - acc: 0.8182 - val_loss: 0.2244 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1437 - acc: 0.8218 - val_loss: 0.2211 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1421 - acc: 0.8182 - val_loss: 0.2197 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1400 - acc: 0.8255 - val_loss: 0.2190 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1386 - acc: 0.8218 - val_loss: 0.2191 - val_acc: 0.7419\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1368 - acc: 0.8291 - val_loss: 0.2260 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1345 - acc: 0.8436 - val_loss: 0.2191 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1339 - acc: 0.8291 - val_loss: 0.2160 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1311 - acc: 0.8327 - val_loss: 0.2189 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 139us/step - loss: 0.1280 - acc: 0.8436 - val_loss: 0.2191 - val_acc: 0.7419\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 140us/step - loss: 0.1273 - acc: 0.8436 - val_loss: 0.2241 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.1241 - acc: 0.8509 - val_loss: 0.2214 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1228 - acc: 0.8509 - val_loss: 0.2202 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1193 - acc: 0.8618 - val_loss: 0.2206 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1164 - acc: 0.8655 - val_loss: 0.2218 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1154 - acc: 0.8545 - val_loss: 0.2171 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1129 - acc: 0.8727 - val_loss: 0.2171 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1104 - acc: 0.8764 - val_loss: 0.2210 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1080 - acc: 0.8691 - val_loss: 0.2161 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.1048 - acc: 0.8836 - val_loss: 0.2158 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 140us/step - loss: 0.1020 - acc: 0.9018 - val_loss: 0.2178 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0993 - acc: 0.8945 - val_loss: 0.2178 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0961 - acc: 0.9055 - val_loss: 0.2178 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0932 - acc: 0.8982 - val_loss: 0.2148 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0898 - acc: 0.9091 - val_loss: 0.2177 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0862 - acc: 0.9164 - val_loss: 0.2203 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0833 - acc: 0.9200 - val_loss: 0.2151 - val_acc: 0.6452\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0795 - acc: 0.9345 - val_loss: 0.2160 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0742 - acc: 0.9382 - val_loss: 0.2199 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0712 - acc: 0.9418 - val_loss: 0.2113 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0674 - acc: 0.9527 - val_loss: 0.2110 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0641 - acc: 0.9491 - val_loss: 0.2163 - val_acc: 0.6452\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0622 - acc: 0.9600 - val_loss: 0.2179 - val_acc: 0.6452\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0577 - acc: 0.9564 - val_loss: 0.2179 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0556 - acc: 0.9636 - val_loss: 0.2104 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0533 - acc: 0.9636 - val_loss: 0.2098 - val_acc: 0.6452\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0489 - acc: 0.9636 - val_loss: 0.2058 - val_acc: 0.6452\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0466 - acc: 0.9636 - val_loss: 0.2045 - val_acc: 0.7097\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 143us/step - loss: 0.0455 - acc: 0.9673 - val_loss: 0.2089 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.0434 - acc: 0.9636 - val_loss: 0.2045 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0426 - acc: 0.9673 - val_loss: 0.2017 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.0401 - acc: 0.9673 - val_loss: 0.2109 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.0362 - acc: 0.9745 - val_loss: 0.2140 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0345 - acc: 0.9745 - val_loss: 0.2036 - val_acc: 0.7097\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0313 - acc: 0.9709 - val_loss: 0.2048 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0309 - acc: 0.9745 - val_loss: 0.2092 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0282 - acc: 0.9782 - val_loss: 0.2065 - val_acc: 0.6129\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 143us/step - loss: 0.0261 - acc: 0.9782 - val_loss: 0.2041 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.0241 - acc: 0.9818 - val_loss: 0.2040 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 136us/step - loss: 0.0211 - acc: 0.9855 - val_loss: 0.1973 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.0195 - acc: 0.9891 - val_loss: 0.1970 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0169 - acc: 0.9891 - val_loss: 0.1982 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0155 - acc: 0.9927 - val_loss: 0.1916 - val_acc: 0.7097\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0142 - acc: 0.9927 - val_loss: 0.1985 - val_acc: 0.7097\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 143us/step - loss: 0.0131 - acc: 0.9927 - val_loss: 0.1934 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.0118 - acc: 0.9964 - val_loss: 0.1981 - val_acc: 0.7097\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.0110 - acc: 0.9964 - val_loss: 0.1997 - val_acc: 0.7097\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0102 - acc: 0.9964 - val_loss: 0.1982 - val_acc: 0.7097\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.0097 - acc: 0.9964 - val_loss: 0.1918 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 140us/step - loss: 0.0091 - acc: 0.9964 - val_loss: 0.1946 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 138us/step - loss: 0.0085 - acc: 0.9964 - val_loss: 0.1949 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0081 - acc: 0.9964 - val_loss: 0.1951 - val_acc: 0.7097\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0080 - acc: 0.9964 - val_loss: 0.1942 - val_acc: 0.7097\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0081 - acc: 0.9964 - val_loss: 0.1995 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.0073 - acc: 0.9964 - val_loss: 0.1965 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0070 - acc: 0.9964 - val_loss: 0.1950 - val_acc: 0.7097\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0068 - acc: 0.9964 - val_loss: 0.1960 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0066 - acc: 0.9964 - val_loss: 0.1968 - val_acc: 0.7097\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.0063 - acc: 0.9964 - val_loss: 0.1959 - val_acc: 0.7097\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0062 - acc: 0.9964 - val_loss: 0.1958 - val_acc: 0.7097\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.0061 - acc: 0.9964 - val_loss: 0.1963 - val_acc: 0.7097\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.0059 - acc: 0.9964 - val_loss: 0.1972 - val_acc: 0.7097\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.0058 - acc: 0.9964 - val_loss: 0.1963 - val_acc: 0.7097\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0057 - acc: 0.9964 - val_loss: 0.1985 - val_acc: 0.7097\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0056 - acc: 0.9964 - val_loss: 0.1972 - val_acc: 0.7097\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.1964 - val_acc: 0.7097\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.0054 - acc: 0.9964 - val_loss: 0.1981 - val_acc: 0.7097\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.1998 - val_acc: 0.7097\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.1951 - val_acc: 0.7097\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.1998 - val_acc: 0.7097\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.1963 - val_acc: 0.7097\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.1982 - val_acc: 0.7419\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.1984 - val_acc: 0.7419\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.1985 - val_acc: 0.7419\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 40)                1560      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,981\n",
      "Trainable params: 1,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 881us/step - loss: 0.2500 - acc: 0.4800 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2495 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.2488 - acc: 0.5418 - val_loss: 0.2481 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.2459 - acc: 0.5636 - val_loss: 0.2440 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.2386 - acc: 0.6618 - val_loss: 0.2348 - val_acc: 0.7097\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.2265 - acc: 0.7200 - val_loss: 0.2199 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.2094 - acc: 0.7455 - val_loss: 0.2103 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1927 - acc: 0.7564 - val_loss: 0.1970 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1804 - acc: 0.7527 - val_loss: 0.1962 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1719 - acc: 0.7600 - val_loss: 0.1972 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1679 - acc: 0.7673 - val_loss: 0.2029 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1653 - acc: 0.7709 - val_loss: 0.2050 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1615 - acc: 0.7709 - val_loss: 0.2064 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1609 - acc: 0.7782 - val_loss: 0.2065 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1588 - acc: 0.7673 - val_loss: 0.2082 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1577 - acc: 0.8000 - val_loss: 0.2089 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1564 - acc: 0.7891 - val_loss: 0.2116 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1547 - acc: 0.7927 - val_loss: 0.2118 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1539 - acc: 0.8000 - val_loss: 0.2136 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1527 - acc: 0.7891 - val_loss: 0.2141 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1513 - acc: 0.8000 - val_loss: 0.2149 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1499 - acc: 0.7964 - val_loss: 0.2151 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1491 - acc: 0.8036 - val_loss: 0.2145 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1480 - acc: 0.8073 - val_loss: 0.2171 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1471 - acc: 0.8000 - val_loss: 0.2167 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1461 - acc: 0.8036 - val_loss: 0.2182 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1449 - acc: 0.8145 - val_loss: 0.2169 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1437 - acc: 0.8182 - val_loss: 0.2175 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1425 - acc: 0.8145 - val_loss: 0.2177 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1420 - acc: 0.8182 - val_loss: 0.2161 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1410 - acc: 0.8218 - val_loss: 0.2171 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1390 - acc: 0.8255 - val_loss: 0.2183 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1380 - acc: 0.8364 - val_loss: 0.2185 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1373 - acc: 0.8255 - val_loss: 0.2172 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1367 - acc: 0.8145 - val_loss: 0.2177 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1343 - acc: 0.8400 - val_loss: 0.2155 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1332 - acc: 0.8400 - val_loss: 0.2180 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1320 - acc: 0.8291 - val_loss: 0.2181 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1306 - acc: 0.8364 - val_loss: 0.2181 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.1288 - acc: 0.8473 - val_loss: 0.2152 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1276 - acc: 0.8436 - val_loss: 0.2151 - val_acc: 0.7419\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1252 - acc: 0.8582 - val_loss: 0.2175 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1256 - acc: 0.8618 - val_loss: 0.2154 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.1231 - acc: 0.8655 - val_loss: 0.2152 - val_acc: 0.7097\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1215 - acc: 0.8655 - val_loss: 0.2150 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1203 - acc: 0.8582 - val_loss: 0.2173 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1185 - acc: 0.8691 - val_loss: 0.2164 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1167 - acc: 0.8727 - val_loss: 0.2122 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1149 - acc: 0.8800 - val_loss: 0.2140 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1132 - acc: 0.8800 - val_loss: 0.2154 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1120 - acc: 0.8836 - val_loss: 0.2163 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1094 - acc: 0.8873 - val_loss: 0.2178 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1074 - acc: 0.8945 - val_loss: 0.2196 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1055 - acc: 0.8945 - val_loss: 0.2173 - val_acc: 0.7097\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1047 - acc: 0.8909 - val_loss: 0.2154 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1019 - acc: 0.8982 - val_loss: 0.2202 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1005 - acc: 0.9091 - val_loss: 0.2189 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0991 - acc: 0.9018 - val_loss: 0.2175 - val_acc: 0.7097\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0968 - acc: 0.9055 - val_loss: 0.2185 - val_acc: 0.7097\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0949 - acc: 0.9127 - val_loss: 0.2194 - val_acc: 0.7097\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0925 - acc: 0.9091 - val_loss: 0.2224 - val_acc: 0.7097\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0898 - acc: 0.9091 - val_loss: 0.2183 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0884 - acc: 0.9091 - val_loss: 0.2184 - val_acc: 0.7097\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0858 - acc: 0.9164 - val_loss: 0.2215 - val_acc: 0.7097\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0834 - acc: 0.9127 - val_loss: 0.2181 - val_acc: 0.7097\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0833 - acc: 0.9164 - val_loss: 0.2180 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0799 - acc: 0.9091 - val_loss: 0.2216 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0767 - acc: 0.9236 - val_loss: 0.2171 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0752 - acc: 0.9273 - val_loss: 0.2218 - val_acc: 0.7097\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 158us/step - loss: 0.0735 - acc: 0.9309 - val_loss: 0.2157 - val_acc: 0.7742\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0716 - acc: 0.9382 - val_loss: 0.2163 - val_acc: 0.7742\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0681 - acc: 0.9345 - val_loss: 0.2186 - val_acc: 0.7097\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0661 - acc: 0.9382 - val_loss: 0.2217 - val_acc: 0.7097\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0637 - acc: 0.9455 - val_loss: 0.2219 - val_acc: 0.7097\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0616 - acc: 0.9455 - val_loss: 0.2192 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0595 - acc: 0.9455 - val_loss: 0.2187 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0578 - acc: 0.9527 - val_loss: 0.2184 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0558 - acc: 0.9600 - val_loss: 0.2189 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0538 - acc: 0.9491 - val_loss: 0.2203 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0531 - acc: 0.9491 - val_loss: 0.2331 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0498 - acc: 0.9600 - val_loss: 0.2194 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0478 - acc: 0.9673 - val_loss: 0.2220 - val_acc: 0.7097\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0462 - acc: 0.9636 - val_loss: 0.2181 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0444 - acc: 0.9636 - val_loss: 0.2218 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0424 - acc: 0.9709 - val_loss: 0.2239 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0415 - acc: 0.9709 - val_loss: 0.2264 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0391 - acc: 0.9709 - val_loss: 0.2254 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0379 - acc: 0.9709 - val_loss: 0.2305 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0361 - acc: 0.9745 - val_loss: 0.2291 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0348 - acc: 0.9782 - val_loss: 0.2303 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0333 - acc: 0.9782 - val_loss: 0.2279 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0325 - acc: 0.9818 - val_loss: 0.2396 - val_acc: 0.6129\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0301 - acc: 0.9818 - val_loss: 0.2345 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0293 - acc: 0.9818 - val_loss: 0.2441 - val_acc: 0.5806\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0276 - acc: 0.9818 - val_loss: 0.2403 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0266 - acc: 0.9818 - val_loss: 0.2371 - val_acc: 0.6452\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0250 - acc: 0.9855 - val_loss: 0.2388 - val_acc: 0.5806\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0245 - acc: 0.9855 - val_loss: 0.2419 - val_acc: 0.6129\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.0221 - acc: 0.9855 - val_loss: 0.2347 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0212 - acc: 0.9891 - val_loss: 0.2385 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 13)                507       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 703\n",
      "Trainable params: 703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 1ms/step - loss: 0.2499 - acc: 0.5273 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.2490 - acc: 0.5418 - val_loss: 0.2487 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.2469 - acc: 0.5418 - val_loss: 0.2460 - val_acc: 0.5806\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.2420 - acc: 0.6473 - val_loss: 0.2398 - val_acc: 0.6129\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.2327 - acc: 0.6909 - val_loss: 0.2298 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.2185 - acc: 0.7273 - val_loss: 0.2180 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.2032 - acc: 0.7382 - val_loss: 0.2082 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1891 - acc: 0.7309 - val_loss: 0.2029 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.1785 - acc: 0.7455 - val_loss: 0.2018 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 138us/step - loss: 0.1729 - acc: 0.7564 - val_loss: 0.2031 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.1686 - acc: 0.7636 - val_loss: 0.2014 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 137us/step - loss: 0.1656 - acc: 0.7564 - val_loss: 0.2080 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1642 - acc: 0.7673 - val_loss: 0.2087 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1623 - acc: 0.7600 - val_loss: 0.2081 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1627 - acc: 0.7600 - val_loss: 0.2132 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 140us/step - loss: 0.1605 - acc: 0.7673 - val_loss: 0.2113 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 138us/step - loss: 0.1595 - acc: 0.7673 - val_loss: 0.2180 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.1583 - acc: 0.7818 - val_loss: 0.2185 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.1585 - acc: 0.7673 - val_loss: 0.2179 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1579 - acc: 0.7673 - val_loss: 0.2202 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1570 - acc: 0.7855 - val_loss: 0.2241 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1559 - acc: 0.7891 - val_loss: 0.2226 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1552 - acc: 0.7855 - val_loss: 0.2237 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1547 - acc: 0.7818 - val_loss: 0.2250 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1542 - acc: 0.7855 - val_loss: 0.2249 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1531 - acc: 0.7855 - val_loss: 0.2235 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1543 - acc: 0.7891 - val_loss: 0.2246 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1530 - acc: 0.7964 - val_loss: 0.2234 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1524 - acc: 0.7891 - val_loss: 0.2242 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1515 - acc: 0.7891 - val_loss: 0.2277 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1504 - acc: 0.7964 - val_loss: 0.2267 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1503 - acc: 0.8073 - val_loss: 0.2270 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.1514 - acc: 0.7964 - val_loss: 0.2261 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.1511 - acc: 0.7927 - val_loss: 0.2252 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.1483 - acc: 0.8036 - val_loss: 0.2253 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1485 - acc: 0.8000 - val_loss: 0.2269 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.1470 - acc: 0.8000 - val_loss: 0.2252 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 140us/step - loss: 0.1474 - acc: 0.8036 - val_loss: 0.2249 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 139us/step - loss: 0.1468 - acc: 0.8000 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 135us/step - loss: 0.1455 - acc: 0.8036 - val_loss: 0.2264 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1453 - acc: 0.8109 - val_loss: 0.2260 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1445 - acc: 0.8109 - val_loss: 0.2256 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1459 - acc: 0.8218 - val_loss: 0.2275 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1430 - acc: 0.8109 - val_loss: 0.2268 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1424 - acc: 0.8182 - val_loss: 0.2275 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 140us/step - loss: 0.1424 - acc: 0.8182 - val_loss: 0.2303 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 139us/step - loss: 0.1412 - acc: 0.8218 - val_loss: 0.2296 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 140us/step - loss: 0.1409 - acc: 0.8218 - val_loss: 0.2311 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1396 - acc: 0.8218 - val_loss: 0.2267 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1392 - acc: 0.8182 - val_loss: 0.2274 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.1386 - acc: 0.8255 - val_loss: 0.2296 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.1381 - acc: 0.8291 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 140us/step - loss: 0.1372 - acc: 0.8255 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1364 - acc: 0.8364 - val_loss: 0.2297 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1369 - acc: 0.8364 - val_loss: 0.2309 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1347 - acc: 0.8182 - val_loss: 0.2281 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1336 - acc: 0.8327 - val_loss: 0.2294 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1332 - acc: 0.8327 - val_loss: 0.2307 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1332 - acc: 0.8182 - val_loss: 0.2273 - val_acc: 0.7097\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1311 - acc: 0.8327 - val_loss: 0.2305 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1314 - acc: 0.8436 - val_loss: 0.2297 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1311 - acc: 0.8364 - val_loss: 0.2298 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 143us/step - loss: 0.1288 - acc: 0.8436 - val_loss: 0.2304 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.1281 - acc: 0.8364 - val_loss: 0.2265 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.1270 - acc: 0.8400 - val_loss: 0.2292 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1258 - acc: 0.8436 - val_loss: 0.2284 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1254 - acc: 0.8436 - val_loss: 0.2293 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1238 - acc: 0.8509 - val_loss: 0.2276 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1228 - acc: 0.8509 - val_loss: 0.2289 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.1215 - acc: 0.8509 - val_loss: 0.2286 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.1203 - acc: 0.8509 - val_loss: 0.2275 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.1201 - acc: 0.8509 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1185 - acc: 0.8473 - val_loss: 0.2281 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1170 - acc: 0.8545 - val_loss: 0.2310 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1158 - acc: 0.8545 - val_loss: 0.2293 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1146 - acc: 0.8618 - val_loss: 0.2311 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1132 - acc: 0.8727 - val_loss: 0.2314 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.1136 - acc: 0.8691 - val_loss: 0.2318 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1108 - acc: 0.8727 - val_loss: 0.2306 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1094 - acc: 0.8764 - val_loss: 0.2315 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1079 - acc: 0.8800 - val_loss: 0.2308 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1063 - acc: 0.8800 - val_loss: 0.2315 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1051 - acc: 0.8800 - val_loss: 0.2339 - val_acc: 0.6452\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 170us/step - loss: 0.1045 - acc: 0.8873 - val_loss: 0.2323 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1028 - acc: 0.8873 - val_loss: 0.2305 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.1020 - acc: 0.8982 - val_loss: 0.2281 - val_acc: 0.6452\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.0984 - acc: 0.9055 - val_loss: 0.2291 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 140us/step - loss: 0.0966 - acc: 0.9055 - val_loss: 0.2244 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0955 - acc: 0.9018 - val_loss: 0.2261 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0940 - acc: 0.9055 - val_loss: 0.2296 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0926 - acc: 0.9091 - val_loss: 0.2287 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 140us/step - loss: 0.0911 - acc: 0.9164 - val_loss: 0.2245 - val_acc: 0.6129\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 140us/step - loss: 0.0886 - acc: 0.9200 - val_loss: 0.2247 - val_acc: 0.6129\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.0871 - acc: 0.9164 - val_loss: 0.2278 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.0853 - acc: 0.9200 - val_loss: 0.2280 - val_acc: 0.6129\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 139us/step - loss: 0.0827 - acc: 0.9236 - val_loss: 0.2271 - val_acc: 0.6129\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 137us/step - loss: 0.0820 - acc: 0.9345 - val_loss: 0.2273 - val_acc: 0.6129\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 137us/step - loss: 0.0801 - acc: 0.9345 - val_loss: 0.2307 - val_acc: 0.5806\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.0789 - acc: 0.9273 - val_loss: 0.2315 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 19)                741       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 12)                240       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 994\n",
      "Trainable params: 994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 1ms/step - loss: 0.2499 - acc: 0.5491 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.2495 - acc: 0.5418 - val_loss: 0.2494 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.2482 - acc: 0.5418 - val_loss: 0.2473 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.2434 - acc: 0.5709 - val_loss: 0.2421 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.2344 - acc: 0.6545 - val_loss: 0.2329 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.2196 - acc: 0.6945 - val_loss: 0.2222 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.2045 - acc: 0.7418 - val_loss: 0.2126 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1912 - acc: 0.7455 - val_loss: 0.2057 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1809 - acc: 0.7382 - val_loss: 0.2020 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1730 - acc: 0.7564 - val_loss: 0.2054 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1680 - acc: 0.7673 - val_loss: 0.1994 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - ETA: 0s - loss: 0.1363 - acc: 0.800 - 0s 189us/step - loss: 0.1638 - acc: 0.7745 - val_loss: 0.2078 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1614 - acc: 0.7782 - val_loss: 0.2066 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1592 - acc: 0.7782 - val_loss: 0.2086 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1570 - acc: 0.7818 - val_loss: 0.2136 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1555 - acc: 0.7964 - val_loss: 0.2111 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.1541 - acc: 0.8036 - val_loss: 0.2138 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1527 - acc: 0.7964 - val_loss: 0.2115 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1516 - acc: 0.7964 - val_loss: 0.2137 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1495 - acc: 0.8145 - val_loss: 0.2138 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1500 - acc: 0.7964 - val_loss: 0.2160 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1468 - acc: 0.8291 - val_loss: 0.2134 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1453 - acc: 0.8255 - val_loss: 0.2140 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1438 - acc: 0.8291 - val_loss: 0.2126 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1431 - acc: 0.8109 - val_loss: 0.2101 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1411 - acc: 0.8364 - val_loss: 0.2103 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1398 - acc: 0.8400 - val_loss: 0.2093 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1389 - acc: 0.8327 - val_loss: 0.2098 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 215us/step - loss: 0.1372 - acc: 0.8364 - val_loss: 0.2074 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1345 - acc: 0.8473 - val_loss: 0.2090 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1342 - acc: 0.8364 - val_loss: 0.2094 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1326 - acc: 0.8436 - val_loss: 0.2079 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1306 - acc: 0.8364 - val_loss: 0.2074 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1303 - acc: 0.8436 - val_loss: 0.2094 - val_acc: 0.6452\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1275 - acc: 0.8400 - val_loss: 0.2087 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1272 - acc: 0.8436 - val_loss: 0.2041 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1251 - acc: 0.8509 - val_loss: 0.2022 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1228 - acc: 0.8545 - val_loss: 0.2053 - val_acc: 0.7097\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 145us/step - loss: 0.1214 - acc: 0.8509 - val_loss: 0.2031 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.1205 - acc: 0.8545 - val_loss: 0.2012 - val_acc: 0.7419\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.1187 - acc: 0.8582 - val_loss: 0.2006 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.1161 - acc: 0.8655 - val_loss: 0.2017 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1151 - acc: 0.8691 - val_loss: 0.1995 - val_acc: 0.7419\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1139 - acc: 0.8727 - val_loss: 0.1970 - val_acc: 0.7742\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1119 - acc: 0.8655 - val_loss: 0.1977 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1099 - acc: 0.8800 - val_loss: 0.1950 - val_acc: 0.7419\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1087 - acc: 0.8727 - val_loss: 0.1926 - val_acc: 0.7419\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1071 - acc: 0.8873 - val_loss: 0.1935 - val_acc: 0.7419\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.1042 - acc: 0.8873 - val_loss: 0.1921 - val_acc: 0.7419\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1028 - acc: 0.8873 - val_loss: 0.1893 - val_acc: 0.7419\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1000 - acc: 0.8945 - val_loss: 0.1897 - val_acc: 0.8065\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1002 - acc: 0.8909 - val_loss: 0.1915 - val_acc: 0.7419\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0978 - acc: 0.8909 - val_loss: 0.1900 - val_acc: 0.7742\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0954 - acc: 0.9055 - val_loss: 0.1877 - val_acc: 0.7742\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0942 - acc: 0.8945 - val_loss: 0.1877 - val_acc: 0.7419\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0918 - acc: 0.8982 - val_loss: 0.1874 - val_acc: 0.7742\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0908 - acc: 0.9091 - val_loss: 0.1856 - val_acc: 0.7742\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0869 - acc: 0.9164 - val_loss: 0.1874 - val_acc: 0.7419\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0856 - acc: 0.9164 - val_loss: 0.1895 - val_acc: 0.7742\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0818 - acc: 0.9236 - val_loss: 0.1877 - val_acc: 0.7742\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0802 - acc: 0.9236 - val_loss: 0.1869 - val_acc: 0.7419\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0781 - acc: 0.9164 - val_loss: 0.1895 - val_acc: 0.7742\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0771 - acc: 0.9273 - val_loss: 0.1913 - val_acc: 0.7419\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0739 - acc: 0.9309 - val_loss: 0.1909 - val_acc: 0.7742\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0702 - acc: 0.9382 - val_loss: 0.1904 - val_acc: 0.7742\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0678 - acc: 0.9418 - val_loss: 0.1883 - val_acc: 0.7742\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0646 - acc: 0.9491 - val_loss: 0.1866 - val_acc: 0.7742\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0627 - acc: 0.9491 - val_loss: 0.1862 - val_acc: 0.7742\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.0600 - acc: 0.9491 - val_loss: 0.1788 - val_acc: 0.7742\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 143us/step - loss: 0.0578 - acc: 0.9564 - val_loss: 0.1867 - val_acc: 0.7742\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.0549 - acc: 0.9564 - val_loss: 0.1886 - val_acc: 0.7742\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.0526 - acc: 0.9600 - val_loss: 0.1837 - val_acc: 0.7742\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.0512 - acc: 0.9600 - val_loss: 0.1898 - val_acc: 0.7419\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.0489 - acc: 0.9709 - val_loss: 0.1862 - val_acc: 0.7742\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0471 - acc: 0.9636 - val_loss: 0.1858 - val_acc: 0.7419\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0459 - acc: 0.9745 - val_loss: 0.1904 - val_acc: 0.7742\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0449 - acc: 0.9709 - val_loss: 0.1929 - val_acc: 0.7742\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0414 - acc: 0.9745 - val_loss: 0.1860 - val_acc: 0.7742\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0398 - acc: 0.9709 - val_loss: 0.1873 - val_acc: 0.7419\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0386 - acc: 0.9745 - val_loss: 0.1911 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0367 - acc: 0.9745 - val_loss: 0.1871 - val_acc: 0.7419\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0341 - acc: 0.9782 - val_loss: 0.1892 - val_acc: 0.7742\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0328 - acc: 0.9818 - val_loss: 0.1843 - val_acc: 0.7419\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0302 - acc: 0.9818 - val_loss: 0.1834 - val_acc: 0.7742\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0286 - acc: 0.9818 - val_loss: 0.1882 - val_acc: 0.7419\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0274 - acc: 0.9818 - val_loss: 0.1873 - val_acc: 0.7097\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0251 - acc: 0.9818 - val_loss: 0.1869 - val_acc: 0.7419\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0239 - acc: 0.9818 - val_loss: 0.1889 - val_acc: 0.7742\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0232 - acc: 0.9855 - val_loss: 0.1863 - val_acc: 0.7097\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0209 - acc: 0.9927 - val_loss: 0.1958 - val_acc: 0.7097\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0200 - acc: 0.9891 - val_loss: 0.1941 - val_acc: 0.7097\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0191 - acc: 0.9891 - val_loss: 0.1956 - val_acc: 0.7742\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0189 - acc: 0.9891 - val_loss: 0.1938 - val_acc: 0.7097\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.0173 - acc: 0.9927 - val_loss: 0.1996 - val_acc: 0.7097\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0171 - acc: 0.9927 - val_loss: 0.1982 - val_acc: 0.7097\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.0163 - acc: 0.9927 - val_loss: 0.1958 - val_acc: 0.7097\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0159 - acc: 0.9927 - val_loss: 0.2007 - val_acc: 0.7097\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0154 - acc: 0.9891 - val_loss: 0.2045 - val_acc: 0.7097\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 193us/step - loss: 0.0145 - acc: 0.9927 - val_loss: 0.2040 - val_acc: 0.7097\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0148 - acc: 0.9927 - val_loss: 0.2021 - val_acc: 0.7097\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 32)                1248      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 14)                462       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 1,725\n",
      "Trainable params: 1,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 1ms/step - loss: 0.2499 - acc: 0.5418 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.2493 - acc: 0.5418 - val_loss: 0.2490 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.2472 - acc: 0.5418 - val_loss: 0.2451 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.2401 - acc: 0.5418 - val_loss: 0.2375 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.2284 - acc: 0.5418 - val_loss: 0.2293 - val_acc: 0.5161\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.2165 - acc: 0.6145 - val_loss: 0.2251 - val_acc: 0.5806\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.2074 - acc: 0.7236 - val_loss: 0.2203 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1984 - acc: 0.7273 - val_loss: 0.2184 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1907 - acc: 0.7455 - val_loss: 0.2166 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1820 - acc: 0.7564 - val_loss: 0.2154 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1744 - acc: 0.7709 - val_loss: 0.2123 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1682 - acc: 0.7745 - val_loss: 0.2095 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1633 - acc: 0.7782 - val_loss: 0.2148 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1596 - acc: 0.7855 - val_loss: 0.2136 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1561 - acc: 0.7964 - val_loss: 0.2107 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1541 - acc: 0.7927 - val_loss: 0.2141 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1506 - acc: 0.8073 - val_loss: 0.2201 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1483 - acc: 0.8036 - val_loss: 0.2174 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1470 - acc: 0.8073 - val_loss: 0.2233 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1456 - acc: 0.8036 - val_loss: 0.2251 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1422 - acc: 0.8109 - val_loss: 0.2250 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1401 - acc: 0.8291 - val_loss: 0.2272 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1393 - acc: 0.8255 - val_loss: 0.2284 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1375 - acc: 0.8436 - val_loss: 0.2260 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1354 - acc: 0.8291 - val_loss: 0.2278 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1337 - acc: 0.8436 - val_loss: 0.2253 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1332 - acc: 0.8327 - val_loss: 0.2257 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1293 - acc: 0.8509 - val_loss: 0.2274 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1285 - acc: 0.8436 - val_loss: 0.2298 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1267 - acc: 0.8582 - val_loss: 0.2280 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1246 - acc: 0.8509 - val_loss: 0.2330 - val_acc: 0.6452\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1217 - acc: 0.8582 - val_loss: 0.2298 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1203 - acc: 0.8691 - val_loss: 0.2302 - val_acc: 0.6452\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1173 - acc: 0.8727 - val_loss: 0.2331 - val_acc: 0.6452\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1161 - acc: 0.8764 - val_loss: 0.2319 - val_acc: 0.6452\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1136 - acc: 0.8836 - val_loss: 0.2292 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1123 - acc: 0.8764 - val_loss: 0.2316 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1088 - acc: 0.8873 - val_loss: 0.2305 - val_acc: 0.6452\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1062 - acc: 0.8909 - val_loss: 0.2206 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1044 - acc: 0.8945 - val_loss: 0.2254 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1011 - acc: 0.8982 - val_loss: 0.2253 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0989 - acc: 0.8945 - val_loss: 0.2293 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0967 - acc: 0.9018 - val_loss: 0.2280 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0928 - acc: 0.9091 - val_loss: 0.2274 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0896 - acc: 0.9055 - val_loss: 0.2237 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0871 - acc: 0.9164 - val_loss: 0.2244 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0840 - acc: 0.9309 - val_loss: 0.2287 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0817 - acc: 0.9236 - val_loss: 0.2209 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0795 - acc: 0.9236 - val_loss: 0.2311 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0772 - acc: 0.9309 - val_loss: 0.2192 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.0752 - acc: 0.9309 - val_loss: 0.2200 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0711 - acc: 0.9382 - val_loss: 0.2162 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0722 - acc: 0.9309 - val_loss: 0.2113 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0672 - acc: 0.9382 - val_loss: 0.2117 - val_acc: 0.7097\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0641 - acc: 0.9382 - val_loss: 0.2122 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0625 - acc: 0.9345 - val_loss: 0.2121 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0622 - acc: 0.9382 - val_loss: 0.1990 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0585 - acc: 0.9527 - val_loss: 0.1962 - val_acc: 0.7097\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0570 - acc: 0.9491 - val_loss: 0.2129 - val_acc: 0.7419\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0562 - acc: 0.9491 - val_loss: 0.1938 - val_acc: 0.7419\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0521 - acc: 0.9564 - val_loss: 0.1829 - val_acc: 0.7742\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0499 - acc: 0.9564 - val_loss: 0.1927 - val_acc: 0.7419\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0475 - acc: 0.9564 - val_loss: 0.1857 - val_acc: 0.7742\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0452 - acc: 0.9673 - val_loss: 0.1874 - val_acc: 0.7742\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0420 - acc: 0.9673 - val_loss: 0.1807 - val_acc: 0.7742\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0426 - acc: 0.9636 - val_loss: 0.1851 - val_acc: 0.7419\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0391 - acc: 0.9745 - val_loss: 0.1825 - val_acc: 0.7419\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0378 - acc: 0.9745 - val_loss: 0.1842 - val_acc: 0.7419\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0355 - acc: 0.9745 - val_loss: 0.1834 - val_acc: 0.7742\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0346 - acc: 0.9709 - val_loss: 0.1770 - val_acc: 0.7419\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0335 - acc: 0.9745 - val_loss: 0.1802 - val_acc: 0.7742\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0323 - acc: 0.9745 - val_loss: 0.1801 - val_acc: 0.8065\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0308 - acc: 0.9745 - val_loss: 0.1865 - val_acc: 0.7742\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0308 - acc: 0.9745 - val_loss: 0.1770 - val_acc: 0.7742\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0292 - acc: 0.9745 - val_loss: 0.1745 - val_acc: 0.8065\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0281 - acc: 0.9745 - val_loss: 0.1795 - val_acc: 0.8065\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0276 - acc: 0.9745 - val_loss: 0.1768 - val_acc: 0.7419\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.0266 - acc: 0.9745 - val_loss: 0.1831 - val_acc: 0.8065\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.0260 - acc: 0.9782 - val_loss: 0.1814 - val_acc: 0.7742\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0237 - acc: 0.9782 - val_loss: 0.1893 - val_acc: 0.7742\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0232 - acc: 0.9782 - val_loss: 0.1896 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0225 - acc: 0.9782 - val_loss: 0.1928 - val_acc: 0.7742\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0219 - acc: 0.9782 - val_loss: 0.1903 - val_acc: 0.7742\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0214 - acc: 0.9782 - val_loss: 0.1865 - val_acc: 0.7742\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0210 - acc: 0.9782 - val_loss: 0.1894 - val_acc: 0.7742\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0203 - acc: 0.9782 - val_loss: 0.1928 - val_acc: 0.7742\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0188 - acc: 0.9818 - val_loss: 0.1914 - val_acc: 0.7419\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0173 - acc: 0.9855 - val_loss: 0.1870 - val_acc: 0.7742\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0172 - acc: 0.9855 - val_loss: 0.1850 - val_acc: 0.7742\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0157 - acc: 0.9855 - val_loss: 0.1867 - val_acc: 0.7742\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0142 - acc: 0.9855 - val_loss: 0.1855 - val_acc: 0.7742\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0132 - acc: 0.9891 - val_loss: 0.1852 - val_acc: 0.7419\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0117 - acc: 0.9964 - val_loss: 0.1918 - val_acc: 0.7742\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0105 - acc: 0.9927 - val_loss: 0.1898 - val_acc: 0.7742\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0094 - acc: 0.9964 - val_loss: 0.1902 - val_acc: 0.7742\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0091 - acc: 0.9964 - val_loss: 0.1925 - val_acc: 0.7742\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0086 - acc: 0.9964 - val_loss: 0.1911 - val_acc: 0.7742\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0082 - acc: 0.9964 - val_loss: 0.1939 - val_acc: 0.7742\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0083 - acc: 0.9964 - val_loss: 0.1970 - val_acc: 0.7742\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0076 - acc: 0.9964 - val_loss: 0.1964 - val_acc: 0.7742\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 20)                780       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 12)                252       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,045\n",
      "Trainable params: 1,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 1ms/step - loss: 0.2500 - acc: 0.4982 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.2491 - acc: 0.5418 - val_loss: 0.2490 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.2470 - acc: 0.5891 - val_loss: 0.2462 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.2417 - acc: 0.6982 - val_loss: 0.2393 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.2307 - acc: 0.7345 - val_loss: 0.2264 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.2145 - acc: 0.7455 - val_loss: 0.2124 - val_acc: 0.6774\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 148us/step - loss: 0.1967 - acc: 0.7527 - val_loss: 0.2044 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.1835 - acc: 0.7418 - val_loss: 0.2014 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1741 - acc: 0.7455 - val_loss: 0.1993 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1685 - acc: 0.7600 - val_loss: 0.2016 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.1643 - acc: 0.7636 - val_loss: 0.2038 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1620 - acc: 0.7636 - val_loss: 0.2044 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1603 - acc: 0.7709 - val_loss: 0.2038 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.1625 - acc: 0.7600 - val_loss: 0.2076 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.1572 - acc: 0.7818 - val_loss: 0.2082 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1551 - acc: 0.7745 - val_loss: 0.2117 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.1545 - acc: 0.7782 - val_loss: 0.2106 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1531 - acc: 0.7673 - val_loss: 0.2139 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 143us/step - loss: 0.1520 - acc: 0.7782 - val_loss: 0.2139 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1507 - acc: 0.7745 - val_loss: 0.2141 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.1500 - acc: 0.7818 - val_loss: 0.2161 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1498 - acc: 0.7782 - val_loss: 0.2179 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1489 - acc: 0.7927 - val_loss: 0.2177 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1472 - acc: 0.7927 - val_loss: 0.2202 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1467 - acc: 0.7927 - val_loss: 0.2206 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1456 - acc: 0.8036 - val_loss: 0.2202 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1448 - acc: 0.8000 - val_loss: 0.2223 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1430 - acc: 0.8073 - val_loss: 0.2203 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1421 - acc: 0.8073 - val_loss: 0.2219 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1413 - acc: 0.8036 - val_loss: 0.2231 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1399 - acc: 0.8218 - val_loss: 0.2205 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1389 - acc: 0.8255 - val_loss: 0.2224 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1388 - acc: 0.8073 - val_loss: 0.2226 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1368 - acc: 0.8109 - val_loss: 0.2234 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1365 - acc: 0.8145 - val_loss: 0.2221 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1369 - acc: 0.8145 - val_loss: 0.2236 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1345 - acc: 0.8145 - val_loss: 0.2234 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1340 - acc: 0.8364 - val_loss: 0.2242 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1308 - acc: 0.8327 - val_loss: 0.2259 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1297 - acc: 0.8255 - val_loss: 0.2256 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1284 - acc: 0.8473 - val_loss: 0.2267 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1282 - acc: 0.8364 - val_loss: 0.2249 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1258 - acc: 0.8400 - val_loss: 0.2283 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1237 - acc: 0.8545 - val_loss: 0.2273 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1222 - acc: 0.8436 - val_loss: 0.2292 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1216 - acc: 0.8545 - val_loss: 0.2294 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1198 - acc: 0.8655 - val_loss: 0.2310 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1182 - acc: 0.8618 - val_loss: 0.2311 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.1162 - acc: 0.8509 - val_loss: 0.2289 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.1151 - acc: 0.8655 - val_loss: 0.2292 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.1146 - acc: 0.8655 - val_loss: 0.2314 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1120 - acc: 0.8764 - val_loss: 0.2347 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1106 - acc: 0.8727 - val_loss: 0.2320 - val_acc: 0.7097\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1080 - acc: 0.8873 - val_loss: 0.2358 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1069 - acc: 0.8873 - val_loss: 0.2319 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1049 - acc: 0.8836 - val_loss: 0.2339 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1031 - acc: 0.9018 - val_loss: 0.2300 - val_acc: 0.7097\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1020 - acc: 0.8836 - val_loss: 0.2358 - val_acc: 0.7097\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0993 - acc: 0.8982 - val_loss: 0.2330 - val_acc: 0.7097\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1001 - acc: 0.8873 - val_loss: 0.2380 - val_acc: 0.7097\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0966 - acc: 0.9127 - val_loss: 0.2305 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.0939 - acc: 0.9018 - val_loss: 0.2433 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.0942 - acc: 0.8982 - val_loss: 0.2383 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.0902 - acc: 0.9055 - val_loss: 0.2337 - val_acc: 0.7097\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.0886 - acc: 0.9055 - val_loss: 0.2389 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0874 - acc: 0.9091 - val_loss: 0.2405 - val_acc: 0.6774\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 149us/step - loss: 0.0855 - acc: 0.9127 - val_loss: 0.2405 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0846 - acc: 0.9127 - val_loss: 0.2410 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.0823 - acc: 0.9236 - val_loss: 0.2418 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0821 - acc: 0.9127 - val_loss: 0.2305 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.0827 - acc: 0.9164 - val_loss: 0.2398 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0775 - acc: 0.9236 - val_loss: 0.2396 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0761 - acc: 0.9236 - val_loss: 0.2346 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.0739 - acc: 0.9382 - val_loss: 0.2357 - val_acc: 0.6452\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.0725 - acc: 0.9382 - val_loss: 0.2400 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.0708 - acc: 0.9345 - val_loss: 0.2316 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.0714 - acc: 0.9418 - val_loss: 0.2531 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0687 - acc: 0.9418 - val_loss: 0.2373 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0679 - acc: 0.9491 - val_loss: 0.2438 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0673 - acc: 0.9455 - val_loss: 0.2445 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0650 - acc: 0.9455 - val_loss: 0.2340 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0647 - acc: 0.9491 - val_loss: 0.2360 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0620 - acc: 0.9491 - val_loss: 0.2287 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0620 - acc: 0.9455 - val_loss: 0.2395 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0601 - acc: 0.9491 - val_loss: 0.2265 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0587 - acc: 0.9564 - val_loss: 0.2386 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0584 - acc: 0.9491 - val_loss: 0.2357 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0565 - acc: 0.9527 - val_loss: 0.2319 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0555 - acc: 0.9527 - val_loss: 0.2431 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0540 - acc: 0.9636 - val_loss: 0.2269 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0547 - acc: 0.9600 - val_loss: 0.2309 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0536 - acc: 0.9527 - val_loss: 0.2388 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0520 - acc: 0.9564 - val_loss: 0.2360 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0500 - acc: 0.9600 - val_loss: 0.2465 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0487 - acc: 0.9636 - val_loss: 0.2294 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0483 - acc: 0.9673 - val_loss: 0.2417 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.0476 - acc: 0.9636 - val_loss: 0.2345 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0466 - acc: 0.9600 - val_loss: 0.2370 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.0452 - acc: 0.9673 - val_loss: 0.2339 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 42)                1638      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 15)                645       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 2,299\n",
      "Trainable params: 2,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 1ms/step - loss: 0.2499 - acc: 0.5018 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.2492 - acc: 0.5418 - val_loss: 0.2490 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.2465 - acc: 0.5527 - val_loss: 0.2457 - val_acc: 0.5484\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.2375 - acc: 0.5855 - val_loss: 0.2354 - val_acc: 0.6129\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.2201 - acc: 0.6764 - val_loss: 0.2211 - val_acc: 0.6129\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.2018 - acc: 0.7309 - val_loss: 0.2127 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1862 - acc: 0.7455 - val_loss: 0.2039 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1754 - acc: 0.7564 - val_loss: 0.2099 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1694 - acc: 0.7527 - val_loss: 0.2051 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1651 - acc: 0.7636 - val_loss: 0.2131 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1596 - acc: 0.7855 - val_loss: 0.2128 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1576 - acc: 0.7891 - val_loss: 0.2179 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1561 - acc: 0.8036 - val_loss: 0.2157 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1533 - acc: 0.8036 - val_loss: 0.2219 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1515 - acc: 0.7964 - val_loss: 0.2282 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1501 - acc: 0.8000 - val_loss: 0.2287 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1466 - acc: 0.8109 - val_loss: 0.2301 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1460 - acc: 0.8145 - val_loss: 0.2276 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1437 - acc: 0.8182 - val_loss: 0.2291 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1418 - acc: 0.8182 - val_loss: 0.2296 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1399 - acc: 0.8327 - val_loss: 0.2305 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1372 - acc: 0.8364 - val_loss: 0.2324 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1359 - acc: 0.8327 - val_loss: 0.2330 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1337 - acc: 0.8400 - val_loss: 0.2324 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1311 - acc: 0.8436 - val_loss: 0.2332 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1295 - acc: 0.8473 - val_loss: 0.2349 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1292 - acc: 0.8473 - val_loss: 0.2351 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1254 - acc: 0.8436 - val_loss: 0.2332 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1221 - acc: 0.8545 - val_loss: 0.2318 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1203 - acc: 0.8655 - val_loss: 0.2307 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1162 - acc: 0.8618 - val_loss: 0.2326 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1133 - acc: 0.8545 - val_loss: 0.2283 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1099 - acc: 0.8655 - val_loss: 0.2318 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.1067 - acc: 0.8836 - val_loss: 0.2285 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1037 - acc: 0.8836 - val_loss: 0.2249 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0991 - acc: 0.9018 - val_loss: 0.2267 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0957 - acc: 0.8982 - val_loss: 0.2252 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0927 - acc: 0.9018 - val_loss: 0.2236 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0877 - acc: 0.9091 - val_loss: 0.2235 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0849 - acc: 0.9164 - val_loss: 0.2169 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0791 - acc: 0.9345 - val_loss: 0.2197 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0763 - acc: 0.9345 - val_loss: 0.2162 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0713 - acc: 0.9455 - val_loss: 0.2202 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0681 - acc: 0.9455 - val_loss: 0.2217 - val_acc: 0.7419\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0637 - acc: 0.9491 - val_loss: 0.2217 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0613 - acc: 0.9600 - val_loss: 0.2218 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0591 - acc: 0.9527 - val_loss: 0.2232 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0536 - acc: 0.9564 - val_loss: 0.2226 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.0506 - acc: 0.9600 - val_loss: 0.2233 - val_acc: 0.6452\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0464 - acc: 0.9636 - val_loss: 0.2285 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0425 - acc: 0.9673 - val_loss: 0.2314 - val_acc: 0.6452\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0394 - acc: 0.9709 - val_loss: 0.2281 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0373 - acc: 0.9745 - val_loss: 0.2282 - val_acc: 0.6452\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0334 - acc: 0.9782 - val_loss: 0.2282 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0302 - acc: 0.9891 - val_loss: 0.2357 - val_acc: 0.6452\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0284 - acc: 0.9891 - val_loss: 0.2409 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0258 - acc: 0.9927 - val_loss: 0.2366 - val_acc: 0.6452\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0245 - acc: 0.9927 - val_loss: 0.2435 - val_acc: 0.6452\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0228 - acc: 0.9927 - val_loss: 0.2428 - val_acc: 0.6452\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0207 - acc: 0.9964 - val_loss: 0.2428 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0185 - acc: 0.9964 - val_loss: 0.2427 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0181 - acc: 0.9964 - val_loss: 0.2452 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0167 - acc: 0.9964 - val_loss: 0.2437 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0151 - acc: 0.9964 - val_loss: 0.2380 - val_acc: 0.7097\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0146 - acc: 0.9964 - val_loss: 0.2455 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0136 - acc: 0.9964 - val_loss: 0.2455 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0128 - acc: 0.9964 - val_loss: 0.2427 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0121 - acc: 0.9964 - val_loss: 0.2442 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0114 - acc: 0.9964 - val_loss: 0.2417 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0112 - acc: 0.9964 - val_loss: 0.2420 - val_acc: 0.7097\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0107 - acc: 0.9964 - val_loss: 0.2469 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0098 - acc: 0.9964 - val_loss: 0.2449 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0097 - acc: 0.9964 - val_loss: 0.2427 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0092 - acc: 0.9964 - val_loss: 0.2479 - val_acc: 0.6452\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0089 - acc: 0.9964 - val_loss: 0.2434 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0084 - acc: 0.9964 - val_loss: 0.2463 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0080 - acc: 0.9964 - val_loss: 0.2467 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0079 - acc: 0.9964 - val_loss: 0.2448 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0076 - acc: 0.9964 - val_loss: 0.2471 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0073 - acc: 0.9964 - val_loss: 0.2485 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0071 - acc: 0.9964 - val_loss: 0.2487 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0070 - acc: 0.9964 - val_loss: 0.2491 - val_acc: 0.6452\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 159us/step - loss: 0.0068 - acc: 0.9964 - val_loss: 0.2503 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0067 - acc: 0.9964 - val_loss: 0.2468 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0065 - acc: 0.9964 - val_loss: 0.2508 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.0063 - acc: 0.9964 - val_loss: 0.2503 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.0062 - acc: 0.9964 - val_loss: 0.2514 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0060 - acc: 0.9964 - val_loss: 0.2515 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0059 - acc: 0.9964 - val_loss: 0.2484 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0058 - acc: 0.9964 - val_loss: 0.2508 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0057 - acc: 0.9964 - val_loss: 0.2515 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0056 - acc: 0.9964 - val_loss: 0.2528 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0056 - acc: 0.9964 - val_loss: 0.2516 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0054 - acc: 0.9964 - val_loss: 0.2518 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.2529 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.2541 - val_acc: 0.6452\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.2542 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2539 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2550 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.2548 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 32)                1248      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 11)                363       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 1,623\n",
      "Trainable params: 1,623\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 2ms/step - loss: 0.2499 - acc: 0.5345 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2496 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.2489 - acc: 0.5418 - val_loss: 0.2485 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.2459 - acc: 0.5418 - val_loss: 0.2439 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.2377 - acc: 0.5527 - val_loss: 0.2340 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.2241 - acc: 0.6436 - val_loss: 0.2243 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.2095 - acc: 0.7091 - val_loss: 0.2155 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1964 - acc: 0.7382 - val_loss: 0.2107 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1855 - acc: 0.7491 - val_loss: 0.2051 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1772 - acc: 0.7491 - val_loss: 0.2044 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1705 - acc: 0.7600 - val_loss: 0.2076 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1655 - acc: 0.7745 - val_loss: 0.2078 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1621 - acc: 0.7927 - val_loss: 0.2109 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1588 - acc: 0.7855 - val_loss: 0.2085 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1563 - acc: 0.7964 - val_loss: 0.2139 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1535 - acc: 0.7964 - val_loss: 0.2156 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1517 - acc: 0.8073 - val_loss: 0.2185 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1492 - acc: 0.8218 - val_loss: 0.2176 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1476 - acc: 0.8109 - val_loss: 0.2188 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1462 - acc: 0.8182 - val_loss: 0.2211 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1456 - acc: 0.8145 - val_loss: 0.2233 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1454 - acc: 0.8073 - val_loss: 0.2221 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1415 - acc: 0.8255 - val_loss: 0.2214 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1402 - acc: 0.8364 - val_loss: 0.2244 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1387 - acc: 0.8364 - val_loss: 0.2263 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1364 - acc: 0.8436 - val_loss: 0.2245 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1347 - acc: 0.8327 - val_loss: 0.2280 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1328 - acc: 0.8400 - val_loss: 0.2261 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1314 - acc: 0.8400 - val_loss: 0.2253 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1295 - acc: 0.8509 - val_loss: 0.2265 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1276 - acc: 0.8509 - val_loss: 0.2261 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1261 - acc: 0.8509 - val_loss: 0.2246 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1239 - acc: 0.8582 - val_loss: 0.2264 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1217 - acc: 0.8582 - val_loss: 0.2271 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1199 - acc: 0.8582 - val_loss: 0.2280 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1188 - acc: 0.8655 - val_loss: 0.2278 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1163 - acc: 0.8727 - val_loss: 0.2264 - val_acc: 0.7419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1136 - acc: 0.8727 - val_loss: 0.2273 - val_acc: 0.7419\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1117 - acc: 0.8764 - val_loss: 0.2273 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1100 - acc: 0.8800 - val_loss: 0.2263 - val_acc: 0.7419\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1075 - acc: 0.8873 - val_loss: 0.2277 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1058 - acc: 0.8873 - val_loss: 0.2296 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1028 - acc: 0.8909 - val_loss: 0.2284 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1016 - acc: 0.8945 - val_loss: 0.2282 - val_acc: 0.7419\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0999 - acc: 0.9018 - val_loss: 0.2297 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0971 - acc: 0.9018 - val_loss: 0.2308 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0947 - acc: 0.9018 - val_loss: 0.2303 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0925 - acc: 0.9055 - val_loss: 0.2330 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0903 - acc: 0.9091 - val_loss: 0.2300 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0901 - acc: 0.9091 - val_loss: 0.2306 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0856 - acc: 0.9055 - val_loss: 0.2278 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0848 - acc: 0.9127 - val_loss: 0.2282 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0812 - acc: 0.9127 - val_loss: 0.2284 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0789 - acc: 0.9127 - val_loss: 0.2264 - val_acc: 0.7097\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0772 - acc: 0.9127 - val_loss: 0.2238 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0758 - acc: 0.9200 - val_loss: 0.2303 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0733 - acc: 0.9236 - val_loss: 0.2283 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0704 - acc: 0.9236 - val_loss: 0.2328 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0671 - acc: 0.9309 - val_loss: 0.2341 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.0644 - acc: 0.9345 - val_loss: 0.2330 - val_acc: 0.7097\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0616 - acc: 0.9455 - val_loss: 0.2326 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0602 - acc: 0.9418 - val_loss: 0.2392 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0580 - acc: 0.9455 - val_loss: 0.2352 - val_acc: 0.7097\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0551 - acc: 0.9527 - val_loss: 0.2396 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0528 - acc: 0.9564 - val_loss: 0.2341 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0504 - acc: 0.9527 - val_loss: 0.2365 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0474 - acc: 0.9600 - val_loss: 0.2388 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0450 - acc: 0.9636 - val_loss: 0.2427 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0432 - acc: 0.9636 - val_loss: 0.2442 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0406 - acc: 0.9673 - val_loss: 0.2382 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0398 - acc: 0.9636 - val_loss: 0.2417 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0382 - acc: 0.9673 - val_loss: 0.2413 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0366 - acc: 0.9709 - val_loss: 0.2392 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0352 - acc: 0.9709 - val_loss: 0.2434 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0334 - acc: 0.9745 - val_loss: 0.2391 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0324 - acc: 0.9745 - val_loss: 0.2444 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0315 - acc: 0.9745 - val_loss: 0.2365 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0301 - acc: 0.9745 - val_loss: 0.2393 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0297 - acc: 0.9782 - val_loss: 0.2493 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0277 - acc: 0.9782 - val_loss: 0.2383 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0264 - acc: 0.9782 - val_loss: 0.2437 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0257 - acc: 0.9782 - val_loss: 0.2398 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0255 - acc: 0.9782 - val_loss: 0.2395 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0245 - acc: 0.9782 - val_loss: 0.2541 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0235 - acc: 0.9782 - val_loss: 0.2508 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0229 - acc: 0.9782 - val_loss: 0.2461 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0218 - acc: 0.9782 - val_loss: 0.2528 - val_acc: 0.6452\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0210 - acc: 0.9818 - val_loss: 0.2538 - val_acc: 0.6129\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0202 - acc: 0.9818 - val_loss: 0.2580 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0195 - acc: 0.9855 - val_loss: 0.2544 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0187 - acc: 0.9855 - val_loss: 0.2551 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0178 - acc: 0.9855 - val_loss: 0.2521 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.0171 - acc: 0.9855 - val_loss: 0.2573 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0168 - acc: 0.9855 - val_loss: 0.2597 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.0163 - acc: 0.9855 - val_loss: 0.2589 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0155 - acc: 0.9891 - val_loss: 0.2648 - val_acc: 0.6129\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0148 - acc: 0.9891 - val_loss: 0.2639 - val_acc: 0.6129\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 149us/step - loss: 0.0145 - acc: 0.9891 - val_loss: 0.2618 - val_acc: 0.5806\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0142 - acc: 0.9891 - val_loss: 0.2684 - val_acc: 0.6129\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0137 - acc: 0.9891 - val_loss: 0.2620 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 10)                390       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 13)                143       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 547\n",
      "Trainable params: 547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 2ms/step - loss: 0.2499 - acc: 0.5455 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.2494 - acc: 0.5418 - val_loss: 0.2496 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.2486 - acc: 0.5418 - val_loss: 0.2485 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.2463 - acc: 0.5418 - val_loss: 0.2459 - val_acc: 0.5161\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.2415 - acc: 0.5745 - val_loss: 0.2406 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.2336 - acc: 0.6618 - val_loss: 0.2331 - val_acc: 0.5806\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.2232 - acc: 0.7200 - val_loss: 0.2258 - val_acc: 0.6129\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.2108 - acc: 0.7382 - val_loss: 0.2174 - val_acc: 0.6452\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1989 - acc: 0.7418 - val_loss: 0.2092 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1885 - acc: 0.7564 - val_loss: 0.2050 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1795 - acc: 0.7527 - val_loss: 0.2040 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1745 - acc: 0.7418 - val_loss: 0.2026 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1702 - acc: 0.7564 - val_loss: 0.2043 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1661 - acc: 0.7564 - val_loss: 0.2056 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1634 - acc: 0.7673 - val_loss: 0.2072 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1627 - acc: 0.7782 - val_loss: 0.2102 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1607 - acc: 0.7782 - val_loss: 0.2101 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1594 - acc: 0.7818 - val_loss: 0.2136 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1584 - acc: 0.7709 - val_loss: 0.2140 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.1567 - acc: 0.7855 - val_loss: 0.2179 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1563 - acc: 0.7818 - val_loss: 0.2173 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1561 - acc: 0.7891 - val_loss: 0.2186 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1543 - acc: 0.7927 - val_loss: 0.2178 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1545 - acc: 0.7891 - val_loss: 0.2204 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1536 - acc: 0.8073 - val_loss: 0.2222 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1526 - acc: 0.7855 - val_loss: 0.2219 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1521 - acc: 0.7927 - val_loss: 0.2222 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1516 - acc: 0.7927 - val_loss: 0.2239 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1512 - acc: 0.7927 - val_loss: 0.2262 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1511 - acc: 0.8000 - val_loss: 0.2267 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1507 - acc: 0.8109 - val_loss: 0.2268 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1498 - acc: 0.8000 - val_loss: 0.2258 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1494 - acc: 0.8036 - val_loss: 0.2259 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1482 - acc: 0.8036 - val_loss: 0.2253 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1481 - acc: 0.8073 - val_loss: 0.2251 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1479 - acc: 0.8073 - val_loss: 0.2256 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1469 - acc: 0.8073 - val_loss: 0.2255 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1469 - acc: 0.8109 - val_loss: 0.2276 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1461 - acc: 0.8109 - val_loss: 0.2265 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1461 - acc: 0.8073 - val_loss: 0.2268 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1454 - acc: 0.8109 - val_loss: 0.2275 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1449 - acc: 0.8145 - val_loss: 0.2271 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1446 - acc: 0.8218 - val_loss: 0.2274 - val_acc: 0.7097\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1442 - acc: 0.8218 - val_loss: 0.2262 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1438 - acc: 0.8255 - val_loss: 0.2268 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1429 - acc: 0.8255 - val_loss: 0.2260 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1427 - acc: 0.8291 - val_loss: 0.2260 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1420 - acc: 0.8218 - val_loss: 0.2254 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1419 - acc: 0.8291 - val_loss: 0.2264 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1412 - acc: 0.8255 - val_loss: 0.2246 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1402 - acc: 0.8327 - val_loss: 0.2251 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1401 - acc: 0.8255 - val_loss: 0.2264 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1397 - acc: 0.8218 - val_loss: 0.2283 - val_acc: 0.7097\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1396 - acc: 0.8218 - val_loss: 0.2257 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1395 - acc: 0.8291 - val_loss: 0.2259 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1384 - acc: 0.8291 - val_loss: 0.2254 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1380 - acc: 0.8255 - val_loss: 0.2255 - val_acc: 0.7097\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1374 - acc: 0.8327 - val_loss: 0.2254 - val_acc: 0.7097\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1368 - acc: 0.8327 - val_loss: 0.2257 - val_acc: 0.7419\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1364 - acc: 0.8327 - val_loss: 0.2244 - val_acc: 0.7419\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1362 - acc: 0.8327 - val_loss: 0.2272 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1358 - acc: 0.8364 - val_loss: 0.2260 - val_acc: 0.7097\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1354 - acc: 0.8327 - val_loss: 0.2263 - val_acc: 0.7097\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1347 - acc: 0.8291 - val_loss: 0.2252 - val_acc: 0.7419\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1346 - acc: 0.8291 - val_loss: 0.2235 - val_acc: 0.7419\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1336 - acc: 0.8327 - val_loss: 0.2244 - val_acc: 0.7419\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1335 - acc: 0.8327 - val_loss: 0.2237 - val_acc: 0.7419\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1329 - acc: 0.8327 - val_loss: 0.2240 - val_acc: 0.7419\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1324 - acc: 0.8364 - val_loss: 0.2233 - val_acc: 0.7419\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1315 - acc: 0.8400 - val_loss: 0.2225 - val_acc: 0.7419\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1312 - acc: 0.8436 - val_loss: 0.2211 - val_acc: 0.7419\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1305 - acc: 0.8436 - val_loss: 0.2227 - val_acc: 0.7419\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1300 - acc: 0.8436 - val_loss: 0.2214 - val_acc: 0.7419\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1305 - acc: 0.8327 - val_loss: 0.2243 - val_acc: 0.7419\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1287 - acc: 0.8436 - val_loss: 0.2223 - val_acc: 0.7419\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1282 - acc: 0.8364 - val_loss: 0.2223 - val_acc: 0.7419\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1275 - acc: 0.8436 - val_loss: 0.2216 - val_acc: 0.7419\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1274 - acc: 0.8400 - val_loss: 0.2188 - val_acc: 0.7419\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1264 - acc: 0.8436 - val_loss: 0.2216 - val_acc: 0.7419\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1256 - acc: 0.8436 - val_loss: 0.2236 - val_acc: 0.7419\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1250 - acc: 0.8436 - val_loss: 0.2225 - val_acc: 0.7419\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1246 - acc: 0.8545 - val_loss: 0.2217 - val_acc: 0.7419\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1245 - acc: 0.8400 - val_loss: 0.2220 - val_acc: 0.7419\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1231 - acc: 0.8436 - val_loss: 0.2205 - val_acc: 0.7419\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1232 - acc: 0.8509 - val_loss: 0.2218 - val_acc: 0.7419\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1221 - acc: 0.8509 - val_loss: 0.2207 - val_acc: 0.7419\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1209 - acc: 0.8582 - val_loss: 0.2182 - val_acc: 0.7419\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1200 - acc: 0.8582 - val_loss: 0.2188 - val_acc: 0.7419\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1198 - acc: 0.8582 - val_loss: 0.2172 - val_acc: 0.7419\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1181 - acc: 0.8618 - val_loss: 0.2162 - val_acc: 0.7419\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1185 - acc: 0.8582 - val_loss: 0.2190 - val_acc: 0.7419\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1163 - acc: 0.8655 - val_loss: 0.2175 - val_acc: 0.7419\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1161 - acc: 0.8655 - val_loss: 0.2175 - val_acc: 0.7419\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1164 - acc: 0.8618 - val_loss: 0.2172 - val_acc: 0.7419\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.1145 - acc: 0.8691 - val_loss: 0.2188 - val_acc: 0.7419\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1136 - acc: 0.8655 - val_loss: 0.2159 - val_acc: 0.7419\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.1128 - acc: 0.8655 - val_loss: 0.2196 - val_acc: 0.7419\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.1119 - acc: 0.8691 - val_loss: 0.2147 - val_acc: 0.7419\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1105 - acc: 0.8691 - val_loss: 0.2166 - val_acc: 0.7419\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 41)                1599      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 13)                546       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 2,159\n",
      "Trainable params: 2,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 2ms/step - loss: 0.2501 - acc: 0.4582 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.2498 - acc: 0.5418 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.2492 - acc: 0.5418 - val_loss: 0.2489 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.2469 - acc: 0.5709 - val_loss: 0.2447 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.2384 - acc: 0.6945 - val_loss: 0.2337 - val_acc: 0.5806\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.2235 - acc: 0.7491 - val_loss: 0.2195 - val_acc: 0.6452\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 154us/step - loss: 0.1989 - acc: 0.7564 - val_loss: 0.2010 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1827 - acc: 0.7636 - val_loss: 0.2060 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1730 - acc: 0.7527 - val_loss: 0.2038 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1657 - acc: 0.7600 - val_loss: 0.2082 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1615 - acc: 0.7745 - val_loss: 0.2093 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1599 - acc: 0.7673 - val_loss: 0.2154 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1576 - acc: 0.7745 - val_loss: 0.2197 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1551 - acc: 0.7673 - val_loss: 0.2188 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1526 - acc: 0.8000 - val_loss: 0.2213 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1536 - acc: 0.7927 - val_loss: 0.2231 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1498 - acc: 0.7927 - val_loss: 0.2224 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1490 - acc: 0.7964 - val_loss: 0.2248 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1479 - acc: 0.8036 - val_loss: 0.2261 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1451 - acc: 0.8218 - val_loss: 0.2257 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1452 - acc: 0.8073 - val_loss: 0.2266 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1426 - acc: 0.8182 - val_loss: 0.2266 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1411 - acc: 0.8109 - val_loss: 0.2299 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1403 - acc: 0.8255 - val_loss: 0.2277 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1393 - acc: 0.8364 - val_loss: 0.2290 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1367 - acc: 0.8255 - val_loss: 0.2282 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1360 - acc: 0.8291 - val_loss: 0.2299 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1344 - acc: 0.8255 - val_loss: 0.2315 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1343 - acc: 0.8291 - val_loss: 0.2284 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1318 - acc: 0.8327 - val_loss: 0.2308 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1292 - acc: 0.8364 - val_loss: 0.2337 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1279 - acc: 0.8509 - val_loss: 0.2305 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1262 - acc: 0.8364 - val_loss: 0.2331 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1234 - acc: 0.8400 - val_loss: 0.2317 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1219 - acc: 0.8545 - val_loss: 0.2306 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1201 - acc: 0.8545 - val_loss: 0.2312 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1174 - acc: 0.8545 - val_loss: 0.2320 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1154 - acc: 0.8545 - val_loss: 0.2327 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1137 - acc: 0.8582 - val_loss: 0.2320 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1119 - acc: 0.8655 - val_loss: 0.2299 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1093 - acc: 0.8800 - val_loss: 0.2328 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1053 - acc: 0.8873 - val_loss: 0.2342 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1029 - acc: 0.8945 - val_loss: 0.2354 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1008 - acc: 0.8873 - val_loss: 0.2377 - val_acc: 0.7097\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0985 - acc: 0.8945 - val_loss: 0.2312 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0948 - acc: 0.8982 - val_loss: 0.2361 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0920 - acc: 0.9091 - val_loss: 0.2333 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0891 - acc: 0.9055 - val_loss: 0.2353 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0859 - acc: 0.9200 - val_loss: 0.2334 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0836 - acc: 0.9273 - val_loss: 0.2383 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0804 - acc: 0.9309 - val_loss: 0.2330 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0773 - acc: 0.9309 - val_loss: 0.2352 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0745 - acc: 0.9309 - val_loss: 0.2311 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0752 - acc: 0.9345 - val_loss: 0.2300 - val_acc: 0.7097\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0678 - acc: 0.9455 - val_loss: 0.2296 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0654 - acc: 0.9455 - val_loss: 0.2281 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0619 - acc: 0.9527 - val_loss: 0.2275 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0585 - acc: 0.9527 - val_loss: 0.2286 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0549 - acc: 0.9564 - val_loss: 0.2191 - val_acc: 0.6452\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0515 - acc: 0.9527 - val_loss: 0.2224 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0495 - acc: 0.9600 - val_loss: 0.2243 - val_acc: 0.7097\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0450 - acc: 0.9673 - val_loss: 0.2285 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0440 - acc: 0.9745 - val_loss: 0.2275 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0419 - acc: 0.9709 - val_loss: 0.2287 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0383 - acc: 0.9782 - val_loss: 0.2287 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0358 - acc: 0.9818 - val_loss: 0.2255 - val_acc: 0.6452\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 171us/step - loss: 0.0350 - acc: 0.9818 - val_loss: 0.2258 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0313 - acc: 0.9855 - val_loss: 0.2285 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0296 - acc: 0.9855 - val_loss: 0.2294 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0293 - acc: 0.9855 - val_loss: 0.2382 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0274 - acc: 0.9818 - val_loss: 0.2341 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0254 - acc: 0.9855 - val_loss: 0.2386 - val_acc: 0.6452\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0238 - acc: 0.9891 - val_loss: 0.2406 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0244 - acc: 0.9818 - val_loss: 0.2341 - val_acc: 0.6452\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0213 - acc: 0.9782 - val_loss: 0.2425 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0178 - acc: 0.9891 - val_loss: 0.2422 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0169 - acc: 0.9927 - val_loss: 0.2450 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0158 - acc: 0.9964 - val_loss: 0.2459 - val_acc: 0.6129\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0147 - acc: 0.9964 - val_loss: 0.2473 - val_acc: 0.6129\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0143 - acc: 0.9964 - val_loss: 0.2441 - val_acc: 0.6129\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0134 - acc: 0.9964 - val_loss: 0.2584 - val_acc: 0.6129\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0117 - acc: 0.9964 - val_loss: 0.2558 - val_acc: 0.6129\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0104 - acc: 0.9964 - val_loss: 0.2499 - val_acc: 0.6129\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0100 - acc: 0.9964 - val_loss: 0.2562 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.2547 - val_acc: 0.6129\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.2583 - val_acc: 0.6129\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.2578 - val_acc: 0.6452\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.2593 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.2609 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.2613 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.2557 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.2602 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.2641 - val_acc: 0.6129\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.2568 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.2654 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.2689 - val_acc: 0.6129\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.2640 - val_acc: 0.6129\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.2645 - val_acc: 0.6129\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.2686 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.2652 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 25)                975       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 14)                364       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 1,354\n",
      "Trainable params: 1,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 2ms/step - loss: 0.2500 - acc: 0.5164 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2494 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.2489 - acc: 0.5527 - val_loss: 0.2481 - val_acc: 0.6129\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.2459 - acc: 0.6473 - val_loss: 0.2432 - val_acc: 0.7097\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.2382 - acc: 0.7673 - val_loss: 0.2327 - val_acc: 0.6774\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.2230 - acc: 0.7418 - val_loss: 0.2180 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.2034 - acc: 0.7564 - val_loss: 0.2055 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1861 - acc: 0.7673 - val_loss: 0.1974 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1731 - acc: 0.7564 - val_loss: 0.1993 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1663 - acc: 0.7673 - val_loss: 0.1962 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1609 - acc: 0.7745 - val_loss: 0.2009 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1578 - acc: 0.7891 - val_loss: 0.2069 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1559 - acc: 0.7745 - val_loss: 0.2090 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1530 - acc: 0.7927 - val_loss: 0.2116 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1498 - acc: 0.8000 - val_loss: 0.2093 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1493 - acc: 0.8036 - val_loss: 0.2140 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1457 - acc: 0.8109 - val_loss: 0.2176 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1438 - acc: 0.8000 - val_loss: 0.2221 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1419 - acc: 0.8109 - val_loss: 0.2218 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1403 - acc: 0.8182 - val_loss: 0.2223 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1379 - acc: 0.8327 - val_loss: 0.2252 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1359 - acc: 0.8327 - val_loss: 0.2266 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1339 - acc: 0.8327 - val_loss: 0.2298 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1316 - acc: 0.8436 - val_loss: 0.2265 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1298 - acc: 0.8473 - val_loss: 0.2257 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1272 - acc: 0.8436 - val_loss: 0.2301 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1270 - acc: 0.8327 - val_loss: 0.2297 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1237 - acc: 0.8473 - val_loss: 0.2333 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1211 - acc: 0.8400 - val_loss: 0.2360 - val_acc: 0.6452\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1187 - acc: 0.8655 - val_loss: 0.2344 - val_acc: 0.6452\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1157 - acc: 0.8582 - val_loss: 0.2371 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1144 - acc: 0.8618 - val_loss: 0.2378 - val_acc: 0.6452\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1118 - acc: 0.8727 - val_loss: 0.2412 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1084 - acc: 0.8800 - val_loss: 0.2422 - val_acc: 0.6452\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1058 - acc: 0.8800 - val_loss: 0.2429 - val_acc: 0.6452\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1031 - acc: 0.8800 - val_loss: 0.2430 - val_acc: 0.6452\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1006 - acc: 0.8909 - val_loss: 0.2440 - val_acc: 0.6452\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0977 - acc: 0.8982 - val_loss: 0.2444 - val_acc: 0.6452\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0963 - acc: 0.9018 - val_loss: 0.2437 - val_acc: 0.6452\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0922 - acc: 0.9055 - val_loss: 0.2423 - val_acc: 0.6129\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0896 - acc: 0.9018 - val_loss: 0.2447 - val_acc: 0.6129\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0862 - acc: 0.9127 - val_loss: 0.2449 - val_acc: 0.5806\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0837 - acc: 0.9200 - val_loss: 0.2413 - val_acc: 0.6129\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0810 - acc: 0.9236 - val_loss: 0.2429 - val_acc: 0.6129\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0781 - acc: 0.9382 - val_loss: 0.2391 - val_acc: 0.5806\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0757 - acc: 0.9382 - val_loss: 0.2441 - val_acc: 0.6129\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0717 - acc: 0.9418 - val_loss: 0.2416 - val_acc: 0.5806\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0685 - acc: 0.9418 - val_loss: 0.2374 - val_acc: 0.6129\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0653 - acc: 0.9455 - val_loss: 0.2364 - val_acc: 0.6129\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0644 - acc: 0.9455 - val_loss: 0.2417 - val_acc: 0.5806\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0595 - acc: 0.9491 - val_loss: 0.2307 - val_acc: 0.6129\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0568 - acc: 0.9491 - val_loss: 0.2351 - val_acc: 0.6129\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0542 - acc: 0.9491 - val_loss: 0.2312 - val_acc: 0.6129\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0503 - acc: 0.9600 - val_loss: 0.2342 - val_acc: 0.6129\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0480 - acc: 0.9636 - val_loss: 0.2324 - val_acc: 0.6129\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0463 - acc: 0.9673 - val_loss: 0.2281 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0429 - acc: 0.9709 - val_loss: 0.2286 - val_acc: 0.5806\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0400 - acc: 0.9709 - val_loss: 0.2256 - val_acc: 0.6129\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0384 - acc: 0.9818 - val_loss: 0.2265 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0371 - acc: 0.9782 - val_loss: 0.2284 - val_acc: 0.6129\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0344 - acc: 0.9782 - val_loss: 0.2268 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0339 - acc: 0.9782 - val_loss: 0.2264 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0335 - acc: 0.9782 - val_loss: 0.2228 - val_acc: 0.7097\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0300 - acc: 0.9818 - val_loss: 0.2265 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0272 - acc: 0.9818 - val_loss: 0.2285 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0269 - acc: 0.9855 - val_loss: 0.2249 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0255 - acc: 0.9818 - val_loss: 0.2258 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0236 - acc: 0.9855 - val_loss: 0.2268 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0227 - acc: 0.9891 - val_loss: 0.2274 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0220 - acc: 0.9891 - val_loss: 0.2251 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0204 - acc: 0.9927 - val_loss: 0.2300 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0203 - acc: 0.9891 - val_loss: 0.2266 - val_acc: 0.6452\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0188 - acc: 0.9927 - val_loss: 0.2326 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0180 - acc: 0.9927 - val_loss: 0.2260 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0181 - acc: 0.9891 - val_loss: 0.2315 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0164 - acc: 0.9891 - val_loss: 0.2288 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0169 - acc: 0.9891 - val_loss: 0.2313 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0150 - acc: 0.9927 - val_loss: 0.2319 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0150 - acc: 0.9927 - val_loss: 0.2323 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0115 - acc: 0.9964 - val_loss: 0.2365 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0113 - acc: 0.9927 - val_loss: 0.2261 - val_acc: 0.7097\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 166us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.2357 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.2294 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0091 - acc: 0.9964 - val_loss: 0.2394 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.2304 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.2401 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.2295 - val_acc: 0.7097\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.2443 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.2323 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.2338 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.2385 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.2374 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.2320 - val_acc: 0.7097\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.2377 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.2363 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.2345 - val_acc: 0.7097\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.2330 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.2379 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.2357 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.2319 - val_acc: 0.7097\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 13)                507       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 11)                154       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 673\n",
      "Trainable params: 673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 2ms/step - loss: 0.2500 - acc: 0.5491 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.2492 - acc: 0.5418 - val_loss: 0.2491 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.2478 - acc: 0.5418 - val_loss: 0.2473 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.2446 - acc: 0.5418 - val_loss: 0.2442 - val_acc: 0.5161\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.2384 - acc: 0.5418 - val_loss: 0.2390 - val_acc: 0.5161\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.2302 - acc: 0.5418 - val_loss: 0.2345 - val_acc: 0.5161\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.2222 - acc: 0.5418 - val_loss: 0.2310 - val_acc: 0.5161\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.2160 - acc: 0.5418 - val_loss: 0.2294 - val_acc: 0.5161\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.2112 - acc: 0.5600 - val_loss: 0.2295 - val_acc: 0.5806\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.2069 - acc: 0.7418 - val_loss: 0.2270 - val_acc: 0.6452\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.2044 - acc: 0.7345 - val_loss: 0.2270 - val_acc: 0.6452\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.2005 - acc: 0.7455 - val_loss: 0.2266 - val_acc: 0.6452\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1965 - acc: 0.7527 - val_loss: 0.2246 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1910 - acc: 0.7600 - val_loss: 0.2223 - val_acc: 0.6452\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1862 - acc: 0.7673 - val_loss: 0.2193 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1799 - acc: 0.7745 - val_loss: 0.2145 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1735 - acc: 0.7782 - val_loss: 0.2132 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1665 - acc: 0.7782 - val_loss: 0.2126 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1611 - acc: 0.7855 - val_loss: 0.2091 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1569 - acc: 0.7891 - val_loss: 0.2108 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1534 - acc: 0.7855 - val_loss: 0.2128 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1494 - acc: 0.7855 - val_loss: 0.2116 - val_acc: 0.6452\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1474 - acc: 0.8000 - val_loss: 0.2120 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1452 - acc: 0.8036 - val_loss: 0.2140 - val_acc: 0.6452\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1430 - acc: 0.8000 - val_loss: 0.2143 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1411 - acc: 0.8073 - val_loss: 0.2141 - val_acc: 0.6452\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1395 - acc: 0.8073 - val_loss: 0.2145 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1376 - acc: 0.8145 - val_loss: 0.2164 - val_acc: 0.6452\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1357 - acc: 0.8218 - val_loss: 0.2179 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1341 - acc: 0.8364 - val_loss: 0.2184 - val_acc: 0.6452\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1322 - acc: 0.8255 - val_loss: 0.2204 - val_acc: 0.6452\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1306 - acc: 0.8218 - val_loss: 0.2212 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1298 - acc: 0.8364 - val_loss: 0.2220 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1288 - acc: 0.8436 - val_loss: 0.2217 - val_acc: 0.6452\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1267 - acc: 0.8400 - val_loss: 0.2226 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1248 - acc: 0.8473 - val_loss: 0.2265 - val_acc: 0.6452\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1243 - acc: 0.8436 - val_loss: 0.2230 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1219 - acc: 0.8509 - val_loss: 0.2239 - val_acc: 0.6452\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1206 - acc: 0.8618 - val_loss: 0.2257 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1177 - acc: 0.8655 - val_loss: 0.2254 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1172 - acc: 0.8618 - val_loss: 0.2257 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1150 - acc: 0.8691 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1131 - acc: 0.8764 - val_loss: 0.2284 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1112 - acc: 0.8764 - val_loss: 0.2285 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1091 - acc: 0.8800 - val_loss: 0.2303 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1070 - acc: 0.8764 - val_loss: 0.2335 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1051 - acc: 0.8800 - val_loss: 0.2316 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.1029 - acc: 0.8800 - val_loss: 0.2309 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1021 - acc: 0.8764 - val_loss: 0.2293 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0995 - acc: 0.8873 - val_loss: 0.2294 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0974 - acc: 0.8909 - val_loss: 0.2322 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0951 - acc: 0.8982 - val_loss: 0.2312 - val_acc: 0.6452\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0935 - acc: 0.8945 - val_loss: 0.2266 - val_acc: 0.6452\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0913 - acc: 0.9055 - val_loss: 0.2293 - val_acc: 0.6452\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0890 - acc: 0.9055 - val_loss: 0.2282 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0876 - acc: 0.9055 - val_loss: 0.2261 - val_acc: 0.6452\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0851 - acc: 0.9055 - val_loss: 0.2234 - val_acc: 0.6452\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0834 - acc: 0.9200 - val_loss: 0.2246 - val_acc: 0.6452\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0812 - acc: 0.9164 - val_loss: 0.2219 - val_acc: 0.6452\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0794 - acc: 0.9164 - val_loss: 0.2232 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0775 - acc: 0.9236 - val_loss: 0.2212 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0755 - acc: 0.9273 - val_loss: 0.2210 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0736 - acc: 0.9309 - val_loss: 0.2204 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0715 - acc: 0.9382 - val_loss: 0.2183 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0703 - acc: 0.9382 - val_loss: 0.2185 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0677 - acc: 0.9455 - val_loss: 0.2169 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0663 - acc: 0.9527 - val_loss: 0.2191 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0642 - acc: 0.9455 - val_loss: 0.2220 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0634 - acc: 0.9527 - val_loss: 0.2216 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0613 - acc: 0.9564 - val_loss: 0.2218 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0611 - acc: 0.9491 - val_loss: 0.2229 - val_acc: 0.6452\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0598 - acc: 0.9564 - val_loss: 0.2239 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0570 - acc: 0.9564 - val_loss: 0.2231 - val_acc: 0.6452\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0563 - acc: 0.9600 - val_loss: 0.2259 - val_acc: 0.6452\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0547 - acc: 0.9600 - val_loss: 0.2233 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0539 - acc: 0.9673 - val_loss: 0.2262 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0530 - acc: 0.9673 - val_loss: 0.2264 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0518 - acc: 0.9636 - val_loss: 0.2257 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0518 - acc: 0.9564 - val_loss: 0.2268 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0496 - acc: 0.9673 - val_loss: 0.2269 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0483 - acc: 0.9673 - val_loss: 0.2302 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0470 - acc: 0.9673 - val_loss: 0.2293 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0466 - acc: 0.9673 - val_loss: 0.2295 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0456 - acc: 0.9709 - val_loss: 0.2315 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0455 - acc: 0.9709 - val_loss: 0.2331 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0446 - acc: 0.9709 - val_loss: 0.2297 - val_acc: 0.6452\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0435 - acc: 0.9709 - val_loss: 0.2274 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0425 - acc: 0.9709 - val_loss: 0.2301 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0414 - acc: 0.9709 - val_loss: 0.2274 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0411 - acc: 0.9709 - val_loss: 0.2313 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.0401 - acc: 0.9709 - val_loss: 0.2318 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0392 - acc: 0.9709 - val_loss: 0.2322 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0391 - acc: 0.9709 - val_loss: 0.2318 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0380 - acc: 0.9709 - val_loss: 0.2327 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.0379 - acc: 0.9709 - val_loss: 0.2338 - val_acc: 0.6774\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 165us/step - loss: 0.0376 - acc: 0.9709 - val_loss: 0.2337 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0366 - acc: 0.9709 - val_loss: 0.2329 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0366 - acc: 0.9709 - val_loss: 0.2294 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0360 - acc: 0.9709 - val_loss: 0.2328 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 26)                1014      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 20)                540       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,575\n",
      "Trainable params: 1,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 2ms/step - loss: 0.2499 - acc: 0.5382 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.2495 - acc: 0.5418 - val_loss: 0.2494 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.2480 - acc: 0.5455 - val_loss: 0.2471 - val_acc: 0.5484\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.2425 - acc: 0.5964 - val_loss: 0.2397 - val_acc: 0.5806\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.2292 - acc: 0.7127 - val_loss: 0.2270 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.2096 - acc: 0.7273 - val_loss: 0.2140 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1904 - acc: 0.7382 - val_loss: 0.2094 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1773 - acc: 0.7455 - val_loss: 0.2083 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1690 - acc: 0.7636 - val_loss: 0.2104 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1627 - acc: 0.7745 - val_loss: 0.2109 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1590 - acc: 0.7745 - val_loss: 0.2165 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1576 - acc: 0.7782 - val_loss: 0.2194 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1545 - acc: 0.7818 - val_loss: 0.2195 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1519 - acc: 0.7855 - val_loss: 0.2233 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1516 - acc: 0.7927 - val_loss: 0.2249 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1483 - acc: 0.8036 - val_loss: 0.2259 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1480 - acc: 0.8000 - val_loss: 0.2276 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1449 - acc: 0.8109 - val_loss: 0.2286 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1425 - acc: 0.8327 - val_loss: 0.2284 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1419 - acc: 0.8218 - val_loss: 0.2303 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1390 - acc: 0.8291 - val_loss: 0.2310 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1362 - acc: 0.8436 - val_loss: 0.2299 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1360 - acc: 0.8436 - val_loss: 0.2289 - val_acc: 0.7419\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1330 - acc: 0.8400 - val_loss: 0.2315 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1299 - acc: 0.8436 - val_loss: 0.2329 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1286 - acc: 0.8436 - val_loss: 0.2355 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1263 - acc: 0.8582 - val_loss: 0.2362 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1239 - acc: 0.8545 - val_loss: 0.2360 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1217 - acc: 0.8727 - val_loss: 0.2367 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1181 - acc: 0.8800 - val_loss: 0.2368 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1157 - acc: 0.8691 - val_loss: 0.2406 - val_acc: 0.6452\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1123 - acc: 0.8800 - val_loss: 0.2400 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1103 - acc: 0.8764 - val_loss: 0.2370 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1071 - acc: 0.8945 - val_loss: 0.2385 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1038 - acc: 0.8945 - val_loss: 0.2450 - val_acc: 0.6452\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1008 - acc: 0.8982 - val_loss: 0.2440 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0973 - acc: 0.9091 - val_loss: 0.2490 - val_acc: 0.6452\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0946 - acc: 0.9055 - val_loss: 0.2436 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0911 - acc: 0.9164 - val_loss: 0.2470 - val_acc: 0.6452\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0871 - acc: 0.9164 - val_loss: 0.2471 - val_acc: 0.6129\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0851 - acc: 0.9127 - val_loss: 0.2506 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0821 - acc: 0.9200 - val_loss: 0.2516 - val_acc: 0.6129\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0773 - acc: 0.9345 - val_loss: 0.2500 - val_acc: 0.6129\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0740 - acc: 0.9345 - val_loss: 0.2495 - val_acc: 0.5806\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0722 - acc: 0.9418 - val_loss: 0.2505 - val_acc: 0.6129\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0665 - acc: 0.9382 - val_loss: 0.2553 - val_acc: 0.5484\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0627 - acc: 0.9491 - val_loss: 0.2588 - val_acc: 0.5806\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0596 - acc: 0.9527 - val_loss: 0.2558 - val_acc: 0.5484\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0566 - acc: 0.9455 - val_loss: 0.2567 - val_acc: 0.5806\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0556 - acc: 0.9564 - val_loss: 0.2576 - val_acc: 0.5806\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0510 - acc: 0.9564 - val_loss: 0.2648 - val_acc: 0.5806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0489 - acc: 0.9636 - val_loss: 0.2591 - val_acc: 0.6129\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0441 - acc: 0.9673 - val_loss: 0.2679 - val_acc: 0.6129\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0412 - acc: 0.9636 - val_loss: 0.2679 - val_acc: 0.5806\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0377 - acc: 0.9818 - val_loss: 0.2688 - val_acc: 0.5806\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0373 - acc: 0.9673 - val_loss: 0.2679 - val_acc: 0.6129\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0339 - acc: 0.9782 - val_loss: 0.2784 - val_acc: 0.6129\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0316 - acc: 0.9818 - val_loss: 0.2743 - val_acc: 0.6129\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0304 - acc: 0.9855 - val_loss: 0.2822 - val_acc: 0.6129\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0283 - acc: 0.9855 - val_loss: 0.2831 - val_acc: 0.6129\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0270 - acc: 0.9855 - val_loss: 0.2836 - val_acc: 0.6129\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0260 - acc: 0.9855 - val_loss: 0.2850 - val_acc: 0.6129\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0248 - acc: 0.9891 - val_loss: 0.2889 - val_acc: 0.6129\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0238 - acc: 0.9855 - val_loss: 0.2872 - val_acc: 0.6129\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0230 - acc: 0.9855 - val_loss: 0.2927 - val_acc: 0.6129\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0219 - acc: 0.9891 - val_loss: 0.2939 - val_acc: 0.6129\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0213 - acc: 0.9855 - val_loss: 0.2932 - val_acc: 0.6129\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0203 - acc: 0.9891 - val_loss: 0.2974 - val_acc: 0.6129\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0202 - acc: 0.9891 - val_loss: 0.2964 - val_acc: 0.6129\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0189 - acc: 0.9891 - val_loss: 0.3041 - val_acc: 0.6129\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0193 - acc: 0.9855 - val_loss: 0.2989 - val_acc: 0.6129\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0185 - acc: 0.9891 - val_loss: 0.3014 - val_acc: 0.6129\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0182 - acc: 0.9891 - val_loss: 0.3046 - val_acc: 0.6129\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0176 - acc: 0.9891 - val_loss: 0.3037 - val_acc: 0.6129\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0167 - acc: 0.9891 - val_loss: 0.3071 - val_acc: 0.6129\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0162 - acc: 0.9891 - val_loss: 0.3093 - val_acc: 0.6129\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0162 - acc: 0.9891 - val_loss: 0.3117 - val_acc: 0.6129\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0156 - acc: 0.9891 - val_loss: 0.3098 - val_acc: 0.6129\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0151 - acc: 0.9891 - val_loss: 0.3129 - val_acc: 0.6129\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0151 - acc: 0.9891 - val_loss: 0.3132 - val_acc: 0.6129\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0150 - acc: 0.9891 - val_loss: 0.3139 - val_acc: 0.6129\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0146 - acc: 0.9891 - val_loss: 0.3148 - val_acc: 0.6129\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0143 - acc: 0.9891 - val_loss: 0.3170 - val_acc: 0.6129\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0141 - acc: 0.9891 - val_loss: 0.3178 - val_acc: 0.6129\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0141 - acc: 0.9891 - val_loss: 0.3180 - val_acc: 0.6129\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0142 - acc: 0.9891 - val_loss: 0.3233 - val_acc: 0.6129\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0139 - acc: 0.9891 - val_loss: 0.3208 - val_acc: 0.6129\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0135 - acc: 0.9891 - val_loss: 0.3233 - val_acc: 0.6129\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0134 - acc: 0.9891 - val_loss: 0.3230 - val_acc: 0.6129\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0132 - acc: 0.9891 - val_loss: 0.3253 - val_acc: 0.6129\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0130 - acc: 0.9891 - val_loss: 0.3252 - val_acc: 0.6129\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0130 - acc: 0.9891 - val_loss: 0.3260 - val_acc: 0.6129\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0129 - acc: 0.9891 - val_loss: 0.3261 - val_acc: 0.6129\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0128 - acc: 0.9891 - val_loss: 0.3268 - val_acc: 0.6129\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0127 - acc: 0.9891 - val_loss: 0.3290 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0126 - acc: 0.9891 - val_loss: 0.3290 - val_acc: 0.6129\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0126 - acc: 0.9891 - val_loss: 0.3303 - val_acc: 0.6129\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0125 - acc: 0.9891 - val_loss: 0.3298 - val_acc: 0.6129\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0124 - acc: 0.9891 - val_loss: 0.3310 - val_acc: 0.6129\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0125 - acc: 0.9891 - val_loss: 0.3329 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 29)                1131      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 14)                420       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 1,566\n",
      "Trainable params: 1,566\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 2ms/step - loss: 0.2499 - acc: 0.5455 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.2493 - acc: 0.5418 - val_loss: 0.2491 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.2471 - acc: 0.5491 - val_loss: 0.2456 - val_acc: 0.5806\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.2403 - acc: 0.5964 - val_loss: 0.2384 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.2267 - acc: 0.6618 - val_loss: 0.2238 - val_acc: 0.6129\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 177us/step - loss: 0.2094 - acc: 0.7273 - val_loss: 0.2094 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1923 - acc: 0.7491 - val_loss: 0.2028 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1785 - acc: 0.7455 - val_loss: 0.1983 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1698 - acc: 0.7527 - val_loss: 0.2002 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1667 - acc: 0.7564 - val_loss: 0.2016 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1621 - acc: 0.7636 - val_loss: 0.2066 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1598 - acc: 0.7818 - val_loss: 0.2061 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1583 - acc: 0.7855 - val_loss: 0.2091 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1572 - acc: 0.7782 - val_loss: 0.2117 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1560 - acc: 0.8000 - val_loss: 0.2139 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1544 - acc: 0.8000 - val_loss: 0.2165 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1527 - acc: 0.8000 - val_loss: 0.2131 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1520 - acc: 0.8109 - val_loss: 0.2156 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1506 - acc: 0.8109 - val_loss: 0.2159 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1501 - acc: 0.8000 - val_loss: 0.2163 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1478 - acc: 0.8073 - val_loss: 0.2169 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1472 - acc: 0.8109 - val_loss: 0.2182 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1460 - acc: 0.8073 - val_loss: 0.2183 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1448 - acc: 0.8036 - val_loss: 0.2191 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1433 - acc: 0.8182 - val_loss: 0.2184 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1426 - acc: 0.8073 - val_loss: 0.2207 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1418 - acc: 0.8109 - val_loss: 0.2190 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1389 - acc: 0.8291 - val_loss: 0.2187 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1383 - acc: 0.8327 - val_loss: 0.2182 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1365 - acc: 0.8364 - val_loss: 0.2202 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1363 - acc: 0.8145 - val_loss: 0.2203 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1363 - acc: 0.8327 - val_loss: 0.2178 - val_acc: 0.7419\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1329 - acc: 0.8400 - val_loss: 0.2177 - val_acc: 0.7419\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1307 - acc: 0.8436 - val_loss: 0.2178 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1287 - acc: 0.8400 - val_loss: 0.2181 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1283 - acc: 0.8364 - val_loss: 0.2195 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1259 - acc: 0.8509 - val_loss: 0.2179 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1249 - acc: 0.8473 - val_loss: 0.2197 - val_acc: 0.7419\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1249 - acc: 0.8509 - val_loss: 0.2176 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1209 - acc: 0.8618 - val_loss: 0.2169 - val_acc: 0.7419\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1189 - acc: 0.8582 - val_loss: 0.2147 - val_acc: 0.7419\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1162 - acc: 0.8618 - val_loss: 0.2185 - val_acc: 0.7419\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1157 - acc: 0.8691 - val_loss: 0.2185 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1117 - acc: 0.8691 - val_loss: 0.2161 - val_acc: 0.7419\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1132 - acc: 0.8618 - val_loss: 0.2179 - val_acc: 0.7419\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1090 - acc: 0.8582 - val_loss: 0.2145 - val_acc: 0.7419\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1075 - acc: 0.8727 - val_loss: 0.2176 - val_acc: 0.7419\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1049 - acc: 0.8655 - val_loss: 0.2141 - val_acc: 0.7419\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1015 - acc: 0.8836 - val_loss: 0.2172 - val_acc: 0.7419\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0973 - acc: 0.8945 - val_loss: 0.2142 - val_acc: 0.7419\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0970 - acc: 0.8873 - val_loss: 0.2142 - val_acc: 0.7419\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0915 - acc: 0.8945 - val_loss: 0.2136 - val_acc: 0.7419\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0902 - acc: 0.9018 - val_loss: 0.2128 - val_acc: 0.7742\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0869 - acc: 0.9091 - val_loss: 0.2172 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0846 - acc: 0.9200 - val_loss: 0.2167 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0819 - acc: 0.9127 - val_loss: 0.2143 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0813 - acc: 0.9273 - val_loss: 0.2222 - val_acc: 0.6452\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0756 - acc: 0.9309 - val_loss: 0.2197 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0734 - acc: 0.9309 - val_loss: 0.2181 - val_acc: 0.7419\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0719 - acc: 0.9382 - val_loss: 0.2227 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0684 - acc: 0.9455 - val_loss: 0.2275 - val_acc: 0.6129\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0650 - acc: 0.9527 - val_loss: 0.2211 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0629 - acc: 0.9564 - val_loss: 0.2257 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0604 - acc: 0.9527 - val_loss: 0.2302 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0570 - acc: 0.9673 - val_loss: 0.2297 - val_acc: 0.6774\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 165us/step - loss: 0.0552 - acc: 0.9600 - val_loss: 0.2335 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0529 - acc: 0.9636 - val_loss: 0.2319 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0511 - acc: 0.9636 - val_loss: 0.2373 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0500 - acc: 0.9709 - val_loss: 0.2333 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0461 - acc: 0.9709 - val_loss: 0.2430 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0443 - acc: 0.9709 - val_loss: 0.2415 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0432 - acc: 0.9745 - val_loss: 0.2374 - val_acc: 0.6452\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0400 - acc: 0.9782 - val_loss: 0.2370 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0399 - acc: 0.9782 - val_loss: 0.2346 - val_acc: 0.6452\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0372 - acc: 0.9818 - val_loss: 0.2375 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0357 - acc: 0.9818 - val_loss: 0.2441 - val_acc: 0.6129\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0335 - acc: 0.9818 - val_loss: 0.2400 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0328 - acc: 0.9855 - val_loss: 0.2387 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0307 - acc: 0.9855 - val_loss: 0.2382 - val_acc: 0.7097\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0299 - acc: 0.9891 - val_loss: 0.2422 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0285 - acc: 0.9891 - val_loss: 0.2425 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0277 - acc: 0.9855 - val_loss: 0.2462 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0260 - acc: 0.9891 - val_loss: 0.2458 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0259 - acc: 0.9855 - val_loss: 0.2449 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0259 - acc: 0.9891 - val_loss: 0.2491 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0246 - acc: 0.9891 - val_loss: 0.2445 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0225 - acc: 0.9891 - val_loss: 0.2460 - val_acc: 0.6452\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0225 - acc: 0.9891 - val_loss: 0.2506 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0215 - acc: 0.9891 - val_loss: 0.2540 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0203 - acc: 0.9891 - val_loss: 0.2501 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0194 - acc: 0.9891 - val_loss: 0.2502 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0192 - acc: 0.9891 - val_loss: 0.2528 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0181 - acc: 0.9891 - val_loss: 0.2503 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0180 - acc: 0.9891 - val_loss: 0.2540 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0176 - acc: 0.9891 - val_loss: 0.2527 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0169 - acc: 0.9891 - val_loss: 0.2539 - val_acc: 0.6452\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0162 - acc: 0.9891 - val_loss: 0.2545 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0146 - acc: 0.9891 - val_loss: 0.2568 - val_acc: 0.5806\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0140 - acc: 0.9927 - val_loss: 0.2569 - val_acc: 0.6129\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0133 - acc: 0.9927 - val_loss: 0.2624 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 47)                1833      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 12)                576       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,422\n",
      "Trainable params: 2,422\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 2ms/step - loss: 0.2500 - acc: 0.4982 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.2494 - acc: 0.5418 - val_loss: 0.2488 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.2462 - acc: 0.5418 - val_loss: 0.2441 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.2376 - acc: 0.5418 - val_loss: 0.2342 - val_acc: 0.5806\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.2231 - acc: 0.6182 - val_loss: 0.2246 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.2090 - acc: 0.7091 - val_loss: 0.2192 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1969 - acc: 0.7236 - val_loss: 0.2120 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1870 - acc: 0.7455 - val_loss: 0.2125 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1773 - acc: 0.7564 - val_loss: 0.2060 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1707 - acc: 0.7636 - val_loss: 0.2091 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1642 - acc: 0.7745 - val_loss: 0.2092 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1624 - acc: 0.7782 - val_loss: 0.2133 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1579 - acc: 0.7782 - val_loss: 0.2135 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1571 - acc: 0.7673 - val_loss: 0.2154 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1546 - acc: 0.7855 - val_loss: 0.2194 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1520 - acc: 0.7927 - val_loss: 0.2204 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1498 - acc: 0.8000 - val_loss: 0.2209 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1505 - acc: 0.7891 - val_loss: 0.2196 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1475 - acc: 0.8109 - val_loss: 0.2263 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1450 - acc: 0.8109 - val_loss: 0.2245 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1438 - acc: 0.8182 - val_loss: 0.2281 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1426 - acc: 0.8145 - val_loss: 0.2261 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1418 - acc: 0.8073 - val_loss: 0.2309 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1396 - acc: 0.8145 - val_loss: 0.2292 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1370 - acc: 0.8255 - val_loss: 0.2271 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1360 - acc: 0.8255 - val_loss: 0.2258 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1337 - acc: 0.8218 - val_loss: 0.2281 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1311 - acc: 0.8291 - val_loss: 0.2317 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1311 - acc: 0.8327 - val_loss: 0.2323 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1285 - acc: 0.8400 - val_loss: 0.2303 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1275 - acc: 0.8436 - val_loss: 0.2322 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1260 - acc: 0.8509 - val_loss: 0.2280 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1242 - acc: 0.8400 - val_loss: 0.2308 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1205 - acc: 0.8473 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1174 - acc: 0.8618 - val_loss: 0.2284 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1150 - acc: 0.8655 - val_loss: 0.2242 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1128 - acc: 0.8727 - val_loss: 0.2260 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1117 - acc: 0.8727 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1136 - acc: 0.8655 - val_loss: 0.2321 - val_acc: 0.6452\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1059 - acc: 0.8909 - val_loss: 0.2237 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1028 - acc: 0.8873 - val_loss: 0.2213 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0998 - acc: 0.8909 - val_loss: 0.2236 - val_acc: 0.6452\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0961 - acc: 0.8982 - val_loss: 0.2268 - val_acc: 0.6452\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0934 - acc: 0.9018 - val_loss: 0.2286 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0910 - acc: 0.9200 - val_loss: 0.2269 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0863 - acc: 0.9164 - val_loss: 0.2208 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0836 - acc: 0.9236 - val_loss: 0.2246 - val_acc: 0.6452\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0827 - acc: 0.9200 - val_loss: 0.2239 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0808 - acc: 0.9273 - val_loss: 0.2179 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0746 - acc: 0.9382 - val_loss: 0.2215 - val_acc: 0.6452\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0702 - acc: 0.9527 - val_loss: 0.2234 - val_acc: 0.6452\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0667 - acc: 0.9564 - val_loss: 0.2196 - val_acc: 0.6452\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0636 - acc: 0.9527 - val_loss: 0.2233 - val_acc: 0.6129\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0611 - acc: 0.9564 - val_loss: 0.2269 - val_acc: 0.6129\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0579 - acc: 0.9636 - val_loss: 0.2246 - val_acc: 0.6129\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0554 - acc: 0.9600 - val_loss: 0.2278 - val_acc: 0.6129\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0534 - acc: 0.9636 - val_loss: 0.2235 - val_acc: 0.6452\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0502 - acc: 0.9673 - val_loss: 0.2217 - val_acc: 0.6452\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0474 - acc: 0.9673 - val_loss: 0.2315 - val_acc: 0.6452\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0448 - acc: 0.9673 - val_loss: 0.2312 - val_acc: 0.6452\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0428 - acc: 0.9673 - val_loss: 0.2324 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0407 - acc: 0.9673 - val_loss: 0.2321 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0388 - acc: 0.9709 - val_loss: 0.2327 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0359 - acc: 0.9709 - val_loss: 0.2357 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0344 - acc: 0.9709 - val_loss: 0.2342 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0316 - acc: 0.9745 - val_loss: 0.2421 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0291 - acc: 0.9782 - val_loss: 0.2389 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0277 - acc: 0.9818 - val_loss: 0.2422 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0256 - acc: 0.9855 - val_loss: 0.2448 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0247 - acc: 0.9855 - val_loss: 0.2406 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0241 - acc: 0.9855 - val_loss: 0.2478 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0228 - acc: 0.9855 - val_loss: 0.2448 - val_acc: 0.6452\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0215 - acc: 0.9855 - val_loss: 0.2491 - val_acc: 0.6129\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0203 - acc: 0.9855 - val_loss: 0.2500 - val_acc: 0.6129\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0199 - acc: 0.9855 - val_loss: 0.2509 - val_acc: 0.6452\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0182 - acc: 0.9855 - val_loss: 0.2450 - val_acc: 0.6129\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0174 - acc: 0.9855 - val_loss: 0.2449 - val_acc: 0.6129\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0170 - acc: 0.9855 - val_loss: 0.2590 - val_acc: 0.5806\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0159 - acc: 0.9891 - val_loss: 0.2551 - val_acc: 0.6129\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0137 - acc: 0.9891 - val_loss: 0.2537 - val_acc: 0.6129\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 160us/step - loss: 0.0129 - acc: 0.9891 - val_loss: 0.2549 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0118 - acc: 0.9927 - val_loss: 0.2575 - val_acc: 0.6129\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0109 - acc: 0.9964 - val_loss: 0.2603 - val_acc: 0.6129\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0103 - acc: 0.9964 - val_loss: 0.2574 - val_acc: 0.6129\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0097 - acc: 0.9964 - val_loss: 0.2602 - val_acc: 0.6129\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0092 - acc: 0.9964 - val_loss: 0.2615 - val_acc: 0.6129\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0088 - acc: 0.9964 - val_loss: 0.2616 - val_acc: 0.6129\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0084 - acc: 0.9964 - val_loss: 0.2659 - val_acc: 0.6129\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0084 - acc: 0.9964 - val_loss: 0.2619 - val_acc: 0.5806\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0079 - acc: 0.9964 - val_loss: 0.2690 - val_acc: 0.6129\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0075 - acc: 0.9964 - val_loss: 0.2684 - val_acc: 0.6129\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0073 - acc: 0.9964 - val_loss: 0.2684 - val_acc: 0.5806\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0071 - acc: 0.9964 - val_loss: 0.2687 - val_acc: 0.6129\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0068 - acc: 0.9964 - val_loss: 0.2686 - val_acc: 0.6129\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0066 - acc: 0.9964 - val_loss: 0.2707 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0064 - acc: 0.9964 - val_loss: 0.2720 - val_acc: 0.6129\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0063 - acc: 0.9964 - val_loss: 0.2714 - val_acc: 0.6129\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0062 - acc: 0.9964 - val_loss: 0.2725 - val_acc: 0.5806\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0061 - acc: 0.9964 - val_loss: 0.2744 - val_acc: 0.6129\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0059 - acc: 0.9964 - val_loss: 0.2756 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 43)                1677      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 20)                880       \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 2,578\n",
      "Trainable params: 2,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 2ms/step - loss: 0.2499 - acc: 0.5309 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.2491 - acc: 0.5418 - val_loss: 0.2487 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.2457 - acc: 0.5418 - val_loss: 0.2432 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.2354 - acc: 0.5709 - val_loss: 0.2328 - val_acc: 0.6129\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.2205 - acc: 0.6218 - val_loss: 0.2212 - val_acc: 0.6129\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.2041 - acc: 0.7200 - val_loss: 0.2169 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1904 - acc: 0.7309 - val_loss: 0.2067 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1785 - acc: 0.7527 - val_loss: 0.2051 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1707 - acc: 0.7600 - val_loss: 0.2057 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1654 - acc: 0.7855 - val_loss: 0.2049 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1603 - acc: 0.7818 - val_loss: 0.2084 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1575 - acc: 0.7818 - val_loss: 0.2114 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1550 - acc: 0.7927 - val_loss: 0.2147 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1510 - acc: 0.8000 - val_loss: 0.2155 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1492 - acc: 0.8036 - val_loss: 0.2156 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1462 - acc: 0.8145 - val_loss: 0.2171 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1442 - acc: 0.8073 - val_loss: 0.2186 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1417 - acc: 0.8073 - val_loss: 0.2178 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1395 - acc: 0.8255 - val_loss: 0.2186 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1377 - acc: 0.8182 - val_loss: 0.2182 - val_acc: 0.6452\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1351 - acc: 0.8327 - val_loss: 0.2221 - val_acc: 0.6452\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1317 - acc: 0.8327 - val_loss: 0.2157 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1303 - acc: 0.8291 - val_loss: 0.2142 - val_acc: 0.7419\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1260 - acc: 0.8400 - val_loss: 0.2154 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1235 - acc: 0.8436 - val_loss: 0.2188 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1205 - acc: 0.8509 - val_loss: 0.2185 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1177 - acc: 0.8545 - val_loss: 0.2170 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1154 - acc: 0.8727 - val_loss: 0.2118 - val_acc: 0.7419\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1123 - acc: 0.8764 - val_loss: 0.2140 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1080 - acc: 0.8836 - val_loss: 0.2177 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1054 - acc: 0.8836 - val_loss: 0.2127 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1004 - acc: 0.8945 - val_loss: 0.2185 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0970 - acc: 0.9055 - val_loss: 0.2135 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0930 - acc: 0.9018 - val_loss: 0.2128 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0889 - acc: 0.9164 - val_loss: 0.2119 - val_acc: 0.6452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0859 - acc: 0.9091 - val_loss: 0.2124 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0803 - acc: 0.9309 - val_loss: 0.2123 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0775 - acc: 0.9273 - val_loss: 0.2061 - val_acc: 0.6452\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0716 - acc: 0.9345 - val_loss: 0.2129 - val_acc: 0.6452\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0676 - acc: 0.9455 - val_loss: 0.2117 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0619 - acc: 0.9527 - val_loss: 0.2113 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0592 - acc: 0.9600 - val_loss: 0.2147 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0546 - acc: 0.9564 - val_loss: 0.2177 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0518 - acc: 0.9636 - val_loss: 0.2215 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0470 - acc: 0.9673 - val_loss: 0.2194 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0433 - acc: 0.9709 - val_loss: 0.2272 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0399 - acc: 0.9745 - val_loss: 0.2212 - val_acc: 0.6452\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0352 - acc: 0.9782 - val_loss: 0.2285 - val_acc: 0.6452\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0337 - acc: 0.9818 - val_loss: 0.2339 - val_acc: 0.6129\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0294 - acc: 0.9855 - val_loss: 0.2345 - val_acc: 0.6129\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0262 - acc: 0.9891 - val_loss: 0.2350 - val_acc: 0.6452\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0242 - acc: 0.9927 - val_loss: 0.2364 - val_acc: 0.6452\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0217 - acc: 0.9927 - val_loss: 0.2374 - val_acc: 0.6452\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0201 - acc: 0.9927 - val_loss: 0.2350 - val_acc: 0.6452\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0183 - acc: 0.9927 - val_loss: 0.2314 - val_acc: 0.6452\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0168 - acc: 0.9927 - val_loss: 0.2302 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0152 - acc: 0.9927 - val_loss: 0.2290 - val_acc: 0.6452\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0137 - acc: 0.9964 - val_loss: 0.2303 - val_acc: 0.6452\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0131 - acc: 0.9927 - val_loss: 0.2304 - val_acc: 0.6452\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0121 - acc: 0.9964 - val_loss: 0.2303 - val_acc: 0.6452\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0110 - acc: 0.9964 - val_loss: 0.2349 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0102 - acc: 0.9964 - val_loss: 0.2321 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0097 - acc: 0.9964 - val_loss: 0.2328 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0091 - acc: 0.9964 - val_loss: 0.2358 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0082 - acc: 0.9964 - val_loss: 0.2340 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0074 - acc: 0.9964 - val_loss: 0.2355 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0059 - acc: 0.9964 - val_loss: 0.2356 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.2362 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.2377 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.2383 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.2396 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.2400 - val_acc: 0.6452\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.2400 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.2406 - val_acc: 0.6452\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.2423 - val_acc: 0.6452\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.2418 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.2431 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2432 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.2440 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2461 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.2442 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2446 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2466 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2473 - val_acc: 0.6129\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2477 - val_acc: 0.6129\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2465 - val_acc: 0.6129\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2486 - val_acc: 0.6129\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2492 - val_acc: 0.6129\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2496 - val_acc: 0.6129\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.2489 - val_acc: 0.6129\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 9.8639e-04 - acc: 1.0000 - val_loss: 0.2493 - val_acc: 0.6129\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 9.4397e-04 - acc: 1.0000 - val_loss: 0.2504 - val_acc: 0.6129\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 9.1049e-04 - acc: 1.0000 - val_loss: 0.2498 - val_acc: 0.6129\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 8.7625e-04 - acc: 1.0000 - val_loss: 0.2505 - val_acc: 0.6129\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 8.2923e-04 - acc: 1.0000 - val_loss: 0.2515 - val_acc: 0.6129\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 163us/step - loss: 8.0049e-04 - acc: 1.0000 - val_loss: 0.2525 - val_acc: 0.6129\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 7.7272e-04 - acc: 1.0000 - val_loss: 0.2534 - val_acc: 0.6129\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 7.3336e-04 - acc: 1.0000 - val_loss: 0.2534 - val_acc: 0.6129\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 7.0234e-04 - acc: 1.0000 - val_loss: 0.2540 - val_acc: 0.6129\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 6.7462e-04 - acc: 1.0000 - val_loss: 0.2539 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 11)                429       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 11)                132       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 573\n",
      "Trainable params: 573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 2ms/step - loss: 0.2499 - acc: 0.5345 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.2492 - acc: 0.5418 - val_loss: 0.2492 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.2478 - acc: 0.5418 - val_loss: 0.2473 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.2438 - acc: 0.5564 - val_loss: 0.2424 - val_acc: 0.5806\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.2356 - acc: 0.6109 - val_loss: 0.2355 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.2252 - acc: 0.6800 - val_loss: 0.2277 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.2137 - acc: 0.7055 - val_loss: 0.2219 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.2031 - acc: 0.7382 - val_loss: 0.2170 - val_acc: 0.6452\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1935 - acc: 0.7345 - val_loss: 0.2136 - val_acc: 0.6452\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1854 - acc: 0.7455 - val_loss: 0.2080 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1792 - acc: 0.7418 - val_loss: 0.2063 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1738 - acc: 0.7527 - val_loss: 0.2052 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1700 - acc: 0.7636 - val_loss: 0.2074 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1663 - acc: 0.7600 - val_loss: 0.2085 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1640 - acc: 0.7636 - val_loss: 0.2083 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1622 - acc: 0.7709 - val_loss: 0.2113 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1607 - acc: 0.7818 - val_loss: 0.2124 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1584 - acc: 0.7673 - val_loss: 0.2177 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1572 - acc: 0.7818 - val_loss: 0.2162 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1553 - acc: 0.7891 - val_loss: 0.2170 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1540 - acc: 0.7891 - val_loss: 0.2182 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1533 - acc: 0.7818 - val_loss: 0.2213 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1529 - acc: 0.7964 - val_loss: 0.2249 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1522 - acc: 0.7964 - val_loss: 0.2213 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1512 - acc: 0.7927 - val_loss: 0.2235 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1514 - acc: 0.7891 - val_loss: 0.2238 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1488 - acc: 0.8182 - val_loss: 0.2261 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1484 - acc: 0.8182 - val_loss: 0.2241 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1471 - acc: 0.8218 - val_loss: 0.2266 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1472 - acc: 0.8182 - val_loss: 0.2251 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1467 - acc: 0.8182 - val_loss: 0.2264 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1461 - acc: 0.8109 - val_loss: 0.2307 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1456 - acc: 0.8182 - val_loss: 0.2279 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1437 - acc: 0.8255 - val_loss: 0.2286 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1429 - acc: 0.8400 - val_loss: 0.2278 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1422 - acc: 0.8327 - val_loss: 0.2291 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1410 - acc: 0.8255 - val_loss: 0.2293 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1402 - acc: 0.8255 - val_loss: 0.2297 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1400 - acc: 0.8327 - val_loss: 0.2298 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1396 - acc: 0.8145 - val_loss: 0.2282 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1406 - acc: 0.8327 - val_loss: 0.2303 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1389 - acc: 0.8327 - val_loss: 0.2284 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1368 - acc: 0.8473 - val_loss: 0.2289 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1362 - acc: 0.8473 - val_loss: 0.2275 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1368 - acc: 0.8218 - val_loss: 0.2276 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1359 - acc: 0.8400 - val_loss: 0.2283 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1337 - acc: 0.8509 - val_loss: 0.2265 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1339 - acc: 0.8364 - val_loss: 0.2251 - val_acc: 0.6774\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 153us/step - loss: 0.1316 - acc: 0.8509 - val_loss: 0.2265 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1311 - acc: 0.8473 - val_loss: 0.2242 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1303 - acc: 0.8509 - val_loss: 0.2252 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1315 - acc: 0.8436 - val_loss: 0.2254 - val_acc: 0.6452\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1279 - acc: 0.8545 - val_loss: 0.2237 - val_acc: 0.6452\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1269 - acc: 0.8582 - val_loss: 0.2244 - val_acc: 0.6452\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1262 - acc: 0.8582 - val_loss: 0.2241 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1259 - acc: 0.8509 - val_loss: 0.2235 - val_acc: 0.6452\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1237 - acc: 0.8582 - val_loss: 0.2201 - val_acc: 0.6452\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1227 - acc: 0.8582 - val_loss: 0.2198 - val_acc: 0.6452\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1218 - acc: 0.8655 - val_loss: 0.2216 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1222 - acc: 0.8582 - val_loss: 0.2205 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1209 - acc: 0.8582 - val_loss: 0.2185 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1188 - acc: 0.8691 - val_loss: 0.2185 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1173 - acc: 0.8691 - val_loss: 0.2184 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.1162 - acc: 0.8800 - val_loss: 0.2178 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1151 - acc: 0.8764 - val_loss: 0.2127 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1140 - acc: 0.8800 - val_loss: 0.2132 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1135 - acc: 0.8836 - val_loss: 0.2139 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1117 - acc: 0.8873 - val_loss: 0.2126 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1106 - acc: 0.8800 - val_loss: 0.2126 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1086 - acc: 0.8836 - val_loss: 0.2108 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1075 - acc: 0.8909 - val_loss: 0.2077 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1064 - acc: 0.8945 - val_loss: 0.2071 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1049 - acc: 0.8945 - val_loss: 0.2065 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1041 - acc: 0.8945 - val_loss: 0.2100 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1020 - acc: 0.9055 - val_loss: 0.2044 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1016 - acc: 0.9127 - val_loss: 0.2052 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0992 - acc: 0.9164 - val_loss: 0.1999 - val_acc: 0.7097\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0981 - acc: 0.9164 - val_loss: 0.2035 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0977 - acc: 0.9091 - val_loss: 0.1950 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0973 - acc: 0.9127 - val_loss: 0.2003 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0941 - acc: 0.9127 - val_loss: 0.1977 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0926 - acc: 0.9091 - val_loss: 0.1992 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0916 - acc: 0.9164 - val_loss: 0.1966 - val_acc: 0.7097\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0905 - acc: 0.9200 - val_loss: 0.1951 - val_acc: 0.7097\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0890 - acc: 0.9200 - val_loss: 0.2019 - val_acc: 0.7097\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0884 - acc: 0.9236 - val_loss: 0.1927 - val_acc: 0.7097\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0869 - acc: 0.9273 - val_loss: 0.1971 - val_acc: 0.7742\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0858 - acc: 0.9200 - val_loss: 0.1955 - val_acc: 0.7097\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0837 - acc: 0.9309 - val_loss: 0.1966 - val_acc: 0.7742\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0837 - acc: 0.9200 - val_loss: 0.1916 - val_acc: 0.7742\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0828 - acc: 0.9236 - val_loss: 0.1963 - val_acc: 0.7742\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0809 - acc: 0.9273 - val_loss: 0.1957 - val_acc: 0.7742\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0801 - acc: 0.9236 - val_loss: 0.1926 - val_acc: 0.7742\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0784 - acc: 0.9345 - val_loss: 0.1968 - val_acc: 0.7742\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0762 - acc: 0.9345 - val_loss: 0.1962 - val_acc: 0.7742\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0756 - acc: 0.9345 - val_loss: 0.1942 - val_acc: 0.8065\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0737 - acc: 0.9418 - val_loss: 0.1984 - val_acc: 0.7742\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0726 - acc: 0.9382 - val_loss: 0.2009 - val_acc: 0.7742\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0729 - acc: 0.9345 - val_loss: 0.1957 - val_acc: 0.7419\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 21)                819       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 13)                286       \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 1,119\n",
      "Trainable params: 1,119\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 2ms/step - loss: 0.2499 - acc: 0.5345 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.2495 - acc: 0.5418 - val_loss: 0.2494 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.2481 - acc: 0.5418 - val_loss: 0.2476 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.2441 - acc: 0.5418 - val_loss: 0.2431 - val_acc: 0.5161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.2357 - acc: 0.5418 - val_loss: 0.2362 - val_acc: 0.5161\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.2246 - acc: 0.5418 - val_loss: 0.2305 - val_acc: 0.5161\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.2159 - acc: 0.5418 - val_loss: 0.2269 - val_acc: 0.5161\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.2105 - acc: 0.6509 - val_loss: 0.2265 - val_acc: 0.5806\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.2048 - acc: 0.7055 - val_loss: 0.2302 - val_acc: 0.6452\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.2014 - acc: 0.7309 - val_loss: 0.2311 - val_acc: 0.6452\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1982 - acc: 0.7418 - val_loss: 0.2299 - val_acc: 0.6452\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1949 - acc: 0.7527 - val_loss: 0.2303 - val_acc: 0.6452\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1920 - acc: 0.7636 - val_loss: 0.2286 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1900 - acc: 0.7709 - val_loss: 0.2333 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1876 - acc: 0.7964 - val_loss: 0.2284 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1851 - acc: 0.7855 - val_loss: 0.2306 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1842 - acc: 0.7927 - val_loss: 0.2312 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1821 - acc: 0.7891 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1790 - acc: 0.7964 - val_loss: 0.2301 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1772 - acc: 0.8145 - val_loss: 0.2309 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1748 - acc: 0.8109 - val_loss: 0.2319 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1728 - acc: 0.8109 - val_loss: 0.2301 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1711 - acc: 0.8182 - val_loss: 0.2302 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1692 - acc: 0.8182 - val_loss: 0.2292 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1672 - acc: 0.8218 - val_loss: 0.2298 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1660 - acc: 0.8255 - val_loss: 0.2275 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1653 - acc: 0.8182 - val_loss: 0.2299 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1627 - acc: 0.8327 - val_loss: 0.2295 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1612 - acc: 0.8327 - val_loss: 0.2276 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1608 - acc: 0.8291 - val_loss: 0.2243 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1583 - acc: 0.8291 - val_loss: 0.2280 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1562 - acc: 0.8400 - val_loss: 0.2264 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1551 - acc: 0.8364 - val_loss: 0.2250 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1533 - acc: 0.8364 - val_loss: 0.2272 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1513 - acc: 0.8400 - val_loss: 0.2261 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1497 - acc: 0.8400 - val_loss: 0.2265 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1483 - acc: 0.8473 - val_loss: 0.2263 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1474 - acc: 0.8436 - val_loss: 0.2278 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1454 - acc: 0.8545 - val_loss: 0.2310 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1433 - acc: 0.8509 - val_loss: 0.2254 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1424 - acc: 0.8618 - val_loss: 0.2263 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1404 - acc: 0.8655 - val_loss: 0.2244 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1388 - acc: 0.8582 - val_loss: 0.2266 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1373 - acc: 0.8727 - val_loss: 0.2290 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1367 - acc: 0.8618 - val_loss: 0.2244 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1350 - acc: 0.8691 - val_loss: 0.2311 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1339 - acc: 0.8691 - val_loss: 0.2295 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1310 - acc: 0.8727 - val_loss: 0.2310 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1299 - acc: 0.8727 - val_loss: 0.2329 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1292 - acc: 0.8691 - val_loss: 0.2249 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1274 - acc: 0.8727 - val_loss: 0.2303 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1250 - acc: 0.8800 - val_loss: 0.2282 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1239 - acc: 0.8800 - val_loss: 0.2319 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1224 - acc: 0.8800 - val_loss: 0.2326 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1211 - acc: 0.8800 - val_loss: 0.2353 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1203 - acc: 0.8800 - val_loss: 0.2277 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1191 - acc: 0.8873 - val_loss: 0.2347 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1174 - acc: 0.8836 - val_loss: 0.2214 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1140 - acc: 0.8873 - val_loss: 0.2348 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1115 - acc: 0.8836 - val_loss: 0.2279 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1071 - acc: 0.8873 - val_loss: 0.2332 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1032 - acc: 0.8873 - val_loss: 0.2383 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1012 - acc: 0.8945 - val_loss: 0.2361 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0987 - acc: 0.8982 - val_loss: 0.2375 - val_acc: 0.6774\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 170us/step - loss: 0.0957 - acc: 0.8982 - val_loss: 0.2380 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0932 - acc: 0.9055 - val_loss: 0.2423 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0908 - acc: 0.9091 - val_loss: 0.2401 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0884 - acc: 0.9091 - val_loss: 0.2430 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0863 - acc: 0.9164 - val_loss: 0.2411 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0850 - acc: 0.9091 - val_loss: 0.2391 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0823 - acc: 0.9164 - val_loss: 0.2431 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0803 - acc: 0.9200 - val_loss: 0.2412 - val_acc: 0.7097\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0782 - acc: 0.9236 - val_loss: 0.2396 - val_acc: 0.7097\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0772 - acc: 0.9236 - val_loss: 0.2413 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0757 - acc: 0.9236 - val_loss: 0.2441 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0740 - acc: 0.9236 - val_loss: 0.2430 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0726 - acc: 0.9236 - val_loss: 0.2409 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0717 - acc: 0.9273 - val_loss: 0.2467 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0704 - acc: 0.9236 - val_loss: 0.2441 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0692 - acc: 0.9236 - val_loss: 0.2343 - val_acc: 0.7742\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0682 - acc: 0.9273 - val_loss: 0.2361 - val_acc: 0.7742\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0668 - acc: 0.9273 - val_loss: 0.2422 - val_acc: 0.7419\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0662 - acc: 0.9273 - val_loss: 0.2437 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0651 - acc: 0.9273 - val_loss: 0.2403 - val_acc: 0.7419\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0644 - acc: 0.9273 - val_loss: 0.2451 - val_acc: 0.7097\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0638 - acc: 0.9273 - val_loss: 0.2441 - val_acc: 0.7419\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0631 - acc: 0.9273 - val_loss: 0.2500 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0625 - acc: 0.9273 - val_loss: 0.2486 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0618 - acc: 0.9273 - val_loss: 0.2511 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - ETA: 0s - loss: 0.0115 - acc: 1.000 - 0s 205us/step - loss: 0.0612 - acc: 0.9273 - val_loss: 0.2515 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0607 - acc: 0.9273 - val_loss: 0.2495 - val_acc: 0.7097\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0598 - acc: 0.9273 - val_loss: 0.2573 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0591 - acc: 0.9273 - val_loss: 0.2552 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0582 - acc: 0.9273 - val_loss: 0.2584 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0576 - acc: 0.9273 - val_loss: 0.2551 - val_acc: 0.7097\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0566 - acc: 0.9273 - val_loss: 0.2637 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0553 - acc: 0.9273 - val_loss: 0.2640 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0541 - acc: 0.9309 - val_loss: 0.2668 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0532 - acc: 0.9309 - val_loss: 0.2643 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0524 - acc: 0.9382 - val_loss: 0.2715 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 41)                1599      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 18)                756       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 2,374\n",
      "Trainable params: 2,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 3ms/step - loss: 0.2499 - acc: 0.5418 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.2492 - acc: 0.5418 - val_loss: 0.2486 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.2462 - acc: 0.5418 - val_loss: 0.2441 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.2366 - acc: 0.5636 - val_loss: 0.2331 - val_acc: 0.6129\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.2217 - acc: 0.6473 - val_loss: 0.2223 - val_acc: 0.6129\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.2092 - acc: 0.7200 - val_loss: 0.2188 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1976 - acc: 0.7273 - val_loss: 0.2124 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1874 - acc: 0.7455 - val_loss: 0.2070 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1778 - acc: 0.7709 - val_loss: 0.2099 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1701 - acc: 0.7636 - val_loss: 0.2027 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1638 - acc: 0.8000 - val_loss: 0.2026 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1576 - acc: 0.8036 - val_loss: 0.2083 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1537 - acc: 0.8073 - val_loss: 0.2062 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1496 - acc: 0.8036 - val_loss: 0.2130 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1470 - acc: 0.8109 - val_loss: 0.2060 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1447 - acc: 0.8182 - val_loss: 0.2159 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1416 - acc: 0.8255 - val_loss: 0.2142 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1393 - acc: 0.8255 - val_loss: 0.2133 - val_acc: 0.7097\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 178us/step - loss: 0.1378 - acc: 0.8255 - val_loss: 0.2133 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1346 - acc: 0.8473 - val_loss: 0.2164 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1321 - acc: 0.8473 - val_loss: 0.2164 - val_acc: 0.7419\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1317 - acc: 0.8400 - val_loss: 0.2192 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1291 - acc: 0.8582 - val_loss: 0.2170 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1262 - acc: 0.8655 - val_loss: 0.2212 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1252 - acc: 0.8545 - val_loss: 0.2234 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1222 - acc: 0.8691 - val_loss: 0.2229 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1205 - acc: 0.8655 - val_loss: 0.2227 - val_acc: 0.7419\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1168 - acc: 0.8691 - val_loss: 0.2211 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1138 - acc: 0.8764 - val_loss: 0.2240 - val_acc: 0.7419\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1121 - acc: 0.8727 - val_loss: 0.2243 - val_acc: 0.7419\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1107 - acc: 0.8800 - val_loss: 0.2250 - val_acc: 0.7419\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1066 - acc: 0.8836 - val_loss: 0.2234 - val_acc: 0.7419\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1049 - acc: 0.8909 - val_loss: 0.2233 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1020 - acc: 0.8836 - val_loss: 0.2286 - val_acc: 0.7419\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0973 - acc: 0.8982 - val_loss: 0.2232 - val_acc: 0.7419\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0946 - acc: 0.8945 - val_loss: 0.2278 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0919 - acc: 0.9018 - val_loss: 0.2204 - val_acc: 0.7419\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0895 - acc: 0.9091 - val_loss: 0.2260 - val_acc: 0.7419\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0853 - acc: 0.9055 - val_loss: 0.2262 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0811 - acc: 0.9164 - val_loss: 0.2227 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0768 - acc: 0.9200 - val_loss: 0.2186 - val_acc: 0.7419\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0754 - acc: 0.9200 - val_loss: 0.2237 - val_acc: 0.6452\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0688 - acc: 0.9345 - val_loss: 0.2173 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0644 - acc: 0.9382 - val_loss: 0.2181 - val_acc: 0.7419\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0593 - acc: 0.9491 - val_loss: 0.2097 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0584 - acc: 0.9418 - val_loss: 0.2132 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0535 - acc: 0.9564 - val_loss: 0.1984 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0498 - acc: 0.9673 - val_loss: 0.1978 - val_acc: 0.7742\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0465 - acc: 0.9600 - val_loss: 0.2027 - val_acc: 0.7419\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0434 - acc: 0.9673 - val_loss: 0.2008 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0420 - acc: 0.9709 - val_loss: 0.2068 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0373 - acc: 0.9745 - val_loss: 0.2004 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0347 - acc: 0.9745 - val_loss: 0.2015 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0334 - acc: 0.9782 - val_loss: 0.2046 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0313 - acc: 0.9782 - val_loss: 0.2130 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0300 - acc: 0.9782 - val_loss: 0.1999 - val_acc: 0.7419\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0278 - acc: 0.9782 - val_loss: 0.2019 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0258 - acc: 0.9818 - val_loss: 0.1987 - val_acc: 0.7419\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0232 - acc: 0.9818 - val_loss: 0.1964 - val_acc: 0.7419\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0202 - acc: 0.9891 - val_loss: 0.2010 - val_acc: 0.7419\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0191 - acc: 0.9891 - val_loss: 0.2034 - val_acc: 0.7097\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0165 - acc: 0.9891 - val_loss: 0.2071 - val_acc: 0.7419\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0148 - acc: 0.9927 - val_loss: 0.2047 - val_acc: 0.7419\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0136 - acc: 0.9927 - val_loss: 0.2130 - val_acc: 0.7419\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0130 - acc: 0.9927 - val_loss: 0.2044 - val_acc: 0.7097\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0121 - acc: 0.9927 - val_loss: 0.2108 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0117 - acc: 0.9927 - val_loss: 0.2081 - val_acc: 0.7419\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0112 - acc: 0.9927 - val_loss: 0.2088 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0108 - acc: 0.9927 - val_loss: 0.2113 - val_acc: 0.7097\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0104 - acc: 0.9927 - val_loss: 0.2118 - val_acc: 0.7097\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0100 - acc: 0.9927 - val_loss: 0.2132 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0098 - acc: 0.9927 - val_loss: 0.2156 - val_acc: 0.7097\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0094 - acc: 0.9927 - val_loss: 0.2124 - val_acc: 0.7097\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0092 - acc: 0.9927 - val_loss: 0.2160 - val_acc: 0.7097\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0088 - acc: 0.9927 - val_loss: 0.2152 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0086 - acc: 0.9927 - val_loss: 0.2203 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0076 - acc: 0.9964 - val_loss: 0.2281 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0069 - acc: 0.9964 - val_loss: 0.2257 - val_acc: 0.6774\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 192us/step - loss: 0.0066 - acc: 0.9964 - val_loss: 0.2255 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0063 - acc: 0.9964 - val_loss: 0.2225 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0061 - acc: 0.9964 - val_loss: 0.2257 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0059 - acc: 0.9964 - val_loss: 0.2222 - val_acc: 0.7097\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0058 - acc: 0.9964 - val_loss: 0.2239 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 0.9964 - val_loss: 0.2237 - val_acc: 0.7097\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.2255 - val_acc: 0.7097\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0054 - acc: 0.9964 - val_loss: 0.2231 - val_acc: 0.7097\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.2250 - val_acc: 0.7097\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.2236 - val_acc: 0.7097\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2237 - val_acc: 0.7097\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.2237 - val_acc: 0.7097\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.2248 - val_acc: 0.7097\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.2237 - val_acc: 0.7097\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.2248 - val_acc: 0.7097\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0048 - acc: 0.9964 - val_loss: 0.2238 - val_acc: 0.7097\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0048 - acc: 0.9964 - val_loss: 0.2251 - val_acc: 0.7097\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0047 - acc: 0.9964 - val_loss: 0.2249 - val_acc: 0.7097\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0047 - acc: 0.9964 - val_loss: 0.2250 - val_acc: 0.7097\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0046 - acc: 0.9964 - val_loss: 0.2249 - val_acc: 0.7097\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 0.9964 - val_loss: 0.2262 - val_acc: 0.7097\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0045 - acc: 0.9964 - val_loss: 0.2259 - val_acc: 0.7097\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 29)                1131      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 14)                420       \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 1,566\n",
      "Trainable params: 1,566\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 3ms/step - loss: 0.2500 - acc: 0.5200 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.2494 - acc: 0.5418 - val_loss: 0.2492 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.2478 - acc: 0.5418 - val_loss: 0.2468 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.2427 - acc: 0.5418 - val_loss: 0.2406 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.2325 - acc: 0.5782 - val_loss: 0.2291 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.2178 - acc: 0.7164 - val_loss: 0.2208 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.2053 - acc: 0.7273 - val_loss: 0.2155 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1953 - acc: 0.7309 - val_loss: 0.2124 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1850 - acc: 0.7455 - val_loss: 0.2049 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1774 - acc: 0.7782 - val_loss: 0.2061 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1716 - acc: 0.7709 - val_loss: 0.2079 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1657 - acc: 0.7782 - val_loss: 0.2083 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1624 - acc: 0.7818 - val_loss: 0.2116 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1603 - acc: 0.7855 - val_loss: 0.2113 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1563 - acc: 0.7891 - val_loss: 0.2154 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1546 - acc: 0.7927 - val_loss: 0.2152 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1528 - acc: 0.7927 - val_loss: 0.2194 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1514 - acc: 0.8036 - val_loss: 0.2160 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1494 - acc: 0.8000 - val_loss: 0.2184 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1485 - acc: 0.8109 - val_loss: 0.2172 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1463 - acc: 0.8109 - val_loss: 0.2201 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1454 - acc: 0.8073 - val_loss: 0.2193 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1437 - acc: 0.8145 - val_loss: 0.2200 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1418 - acc: 0.8218 - val_loss: 0.2198 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1414 - acc: 0.8291 - val_loss: 0.2214 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1400 - acc: 0.8291 - val_loss: 0.2184 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1381 - acc: 0.8218 - val_loss: 0.2198 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1360 - acc: 0.8327 - val_loss: 0.2224 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1348 - acc: 0.8364 - val_loss: 0.2239 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1333 - acc: 0.8436 - val_loss: 0.2185 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1310 - acc: 0.8473 - val_loss: 0.2208 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1293 - acc: 0.8436 - val_loss: 0.2204 - val_acc: 0.7419\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1284 - acc: 0.8473 - val_loss: 0.2207 - val_acc: 0.7419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1270 - acc: 0.8509 - val_loss: 0.2213 - val_acc: 0.7419\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1245 - acc: 0.8509 - val_loss: 0.2133 - val_acc: 0.7742\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1232 - acc: 0.8545 - val_loss: 0.2176 - val_acc: 0.7419\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1213 - acc: 0.8618 - val_loss: 0.2199 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1196 - acc: 0.8691 - val_loss: 0.2182 - val_acc: 0.7419\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1177 - acc: 0.8691 - val_loss: 0.2137 - val_acc: 0.7419\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1155 - acc: 0.8727 - val_loss: 0.2139 - val_acc: 0.7419\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1145 - acc: 0.8727 - val_loss: 0.2121 - val_acc: 0.7419\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1133 - acc: 0.8727 - val_loss: 0.2127 - val_acc: 0.7419\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1103 - acc: 0.8764 - val_loss: 0.2115 - val_acc: 0.7419\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1096 - acc: 0.8764 - val_loss: 0.2082 - val_acc: 0.7419\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1079 - acc: 0.8836 - val_loss: 0.2127 - val_acc: 0.7419\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1047 - acc: 0.8909 - val_loss: 0.2106 - val_acc: 0.7419\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1037 - acc: 0.8836 - val_loss: 0.2053 - val_acc: 0.7742\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1035 - acc: 0.8873 - val_loss: 0.2013 - val_acc: 0.7742\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0996 - acc: 0.8982 - val_loss: 0.2065 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0975 - acc: 0.9091 - val_loss: 0.2053 - val_acc: 0.7742\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0949 - acc: 0.9091 - val_loss: 0.2060 - val_acc: 0.7419\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0933 - acc: 0.9055 - val_loss: 0.2035 - val_acc: 0.7419\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0917 - acc: 0.9091 - val_loss: 0.2037 - val_acc: 0.7419\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0898 - acc: 0.9127 - val_loss: 0.2024 - val_acc: 0.7419\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0878 - acc: 0.9164 - val_loss: 0.1959 - val_acc: 0.7742\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0853 - acc: 0.9273 - val_loss: 0.1956 - val_acc: 0.7742\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0835 - acc: 0.9236 - val_loss: 0.1854 - val_acc: 0.7742\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0817 - acc: 0.9273 - val_loss: 0.1899 - val_acc: 0.7742\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0796 - acc: 0.9273 - val_loss: 0.1867 - val_acc: 0.7742\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0779 - acc: 0.9273 - val_loss: 0.1887 - val_acc: 0.7742\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.0760 - acc: 0.9273 - val_loss: 0.1861 - val_acc: 0.8065\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0745 - acc: 0.9345 - val_loss: 0.1800 - val_acc: 0.8065\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0720 - acc: 0.9345 - val_loss: 0.1832 - val_acc: 0.7742\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0702 - acc: 0.9345 - val_loss: 0.1783 - val_acc: 0.8387\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0692 - acc: 0.9345 - val_loss: 0.1791 - val_acc: 0.8065\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0676 - acc: 0.9382 - val_loss: 0.1811 - val_acc: 0.8065\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0652 - acc: 0.9382 - val_loss: 0.1883 - val_acc: 0.7419\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0633 - acc: 0.9491 - val_loss: 0.1779 - val_acc: 0.8065\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0615 - acc: 0.9491 - val_loss: 0.1759 - val_acc: 0.8065\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0582 - acc: 0.9527 - val_loss: 0.1812 - val_acc: 0.8065\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0560 - acc: 0.9564 - val_loss: 0.1817 - val_acc: 0.8065\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0530 - acc: 0.9564 - val_loss: 0.1812 - val_acc: 0.8065\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0517 - acc: 0.9564 - val_loss: 0.1809 - val_acc: 0.8065\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0497 - acc: 0.9564 - val_loss: 0.1828 - val_acc: 0.8065\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0475 - acc: 0.9600 - val_loss: 0.1879 - val_acc: 0.8065\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0467 - acc: 0.9600 - val_loss: 0.1853 - val_acc: 0.8065\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0446 - acc: 0.9636 - val_loss: 0.1901 - val_acc: 0.8065\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0418 - acc: 0.9636 - val_loss: 0.1895 - val_acc: 0.8065\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0405 - acc: 0.9673 - val_loss: 0.1892 - val_acc: 0.7742\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0402 - acc: 0.9709 - val_loss: 0.1928 - val_acc: 0.7742\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0388 - acc: 0.9636 - val_loss: 0.1975 - val_acc: 0.7419\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0370 - acc: 0.9709 - val_loss: 0.1988 - val_acc: 0.7419\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0351 - acc: 0.9709 - val_loss: 0.1980 - val_acc: 0.7419\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0347 - acc: 0.9709 - val_loss: 0.1983 - val_acc: 0.7419\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0342 - acc: 0.9673 - val_loss: 0.2005 - val_acc: 0.7419\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0322 - acc: 0.9782 - val_loss: 0.2025 - val_acc: 0.7419\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0296 - acc: 0.9782 - val_loss: 0.2047 - val_acc: 0.7419\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0292 - acc: 0.9782 - val_loss: 0.2052 - val_acc: 0.7419\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0276 - acc: 0.9782 - val_loss: 0.2069 - val_acc: 0.7097\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0258 - acc: 0.9782 - val_loss: 0.2043 - val_acc: 0.7419\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0255 - acc: 0.9782 - val_loss: 0.2081 - val_acc: 0.7419\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0244 - acc: 0.9782 - val_loss: 0.2104 - val_acc: 0.7097\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0235 - acc: 0.9818 - val_loss: 0.2094 - val_acc: 0.7419\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 171us/step - loss: 0.0218 - acc: 0.9855 - val_loss: 0.2112 - val_acc: 0.7419\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0213 - acc: 0.9818 - val_loss: 0.2091 - val_acc: 0.7419\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0206 - acc: 0.9855 - val_loss: 0.2111 - val_acc: 0.7419\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0196 - acc: 0.9855 - val_loss: 0.2114 - val_acc: 0.7097\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0192 - acc: 0.9855 - val_loss: 0.2116 - val_acc: 0.7419\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0189 - acc: 0.9855 - val_loss: 0.2140 - val_acc: 0.7419\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0182 - acc: 0.9855 - val_loss: 0.2119 - val_acc: 0.7097\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 13)                507       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 14)                196       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 718\n",
      "Trainable params: 718\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 3ms/step - loss: 0.2500 - acc: 0.5018 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.2500 - acc: 0.5418 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2496 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.2490 - acc: 0.5418 - val_loss: 0.2486 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.2471 - acc: 0.5418 - val_loss: 0.2461 - val_acc: 0.5161\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.2427 - acc: 0.5418 - val_loss: 0.2413 - val_acc: 0.5161\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.2353 - acc: 0.5527 - val_loss: 0.2341 - val_acc: 0.5806\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.2260 - acc: 0.6364 - val_loss: 0.2278 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.2172 - acc: 0.6727 - val_loss: 0.2217 - val_acc: 0.6452\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.2082 - acc: 0.7127 - val_loss: 0.2164 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.2003 - acc: 0.7309 - val_loss: 0.2112 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1930 - acc: 0.7345 - val_loss: 0.2108 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1858 - acc: 0.7491 - val_loss: 0.2071 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1795 - acc: 0.7527 - val_loss: 0.2047 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1744 - acc: 0.7491 - val_loss: 0.2013 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1698 - acc: 0.7564 - val_loss: 0.2081 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1666 - acc: 0.7527 - val_loss: 0.2078 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1640 - acc: 0.7818 - val_loss: 0.2080 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1621 - acc: 0.7745 - val_loss: 0.2103 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1596 - acc: 0.7745 - val_loss: 0.2100 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1591 - acc: 0.7818 - val_loss: 0.2131 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1566 - acc: 0.7891 - val_loss: 0.2116 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1553 - acc: 0.8000 - val_loss: 0.2132 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1541 - acc: 0.7964 - val_loss: 0.2145 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1530 - acc: 0.8073 - val_loss: 0.2147 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1520 - acc: 0.8073 - val_loss: 0.2151 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1504 - acc: 0.8036 - val_loss: 0.2172 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1496 - acc: 0.8073 - val_loss: 0.2176 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1487 - acc: 0.8073 - val_loss: 0.2193 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1473 - acc: 0.8109 - val_loss: 0.2181 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1459 - acc: 0.8182 - val_loss: 0.2185 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1454 - acc: 0.8109 - val_loss: 0.2164 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1445 - acc: 0.8109 - val_loss: 0.2158 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1436 - acc: 0.8145 - val_loss: 0.2174 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1420 - acc: 0.8109 - val_loss: 0.2167 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1414 - acc: 0.8182 - val_loss: 0.2157 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1403 - acc: 0.8182 - val_loss: 0.2139 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1397 - acc: 0.8255 - val_loss: 0.2173 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1382 - acc: 0.8255 - val_loss: 0.2144 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1381 - acc: 0.8145 - val_loss: 0.2161 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1366 - acc: 0.8182 - val_loss: 0.2131 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1358 - acc: 0.8327 - val_loss: 0.2120 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1345 - acc: 0.8218 - val_loss: 0.2139 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1333 - acc: 0.8327 - val_loss: 0.2104 - val_acc: 0.7419\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1327 - acc: 0.8327 - val_loss: 0.2100 - val_acc: 0.7419\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1319 - acc: 0.8364 - val_loss: 0.2108 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1304 - acc: 0.8473 - val_loss: 0.2092 - val_acc: 0.7419\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1293 - acc: 0.8400 - val_loss: 0.2094 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1283 - acc: 0.8436 - val_loss: 0.2080 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1274 - acc: 0.8509 - val_loss: 0.2076 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1265 - acc: 0.8545 - val_loss: 0.2075 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1256 - acc: 0.8582 - val_loss: 0.2050 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1246 - acc: 0.8509 - val_loss: 0.2080 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1236 - acc: 0.8655 - val_loss: 0.2066 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1227 - acc: 0.8691 - val_loss: 0.2060 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1215 - acc: 0.8727 - val_loss: 0.2030 - val_acc: 0.7419\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1206 - acc: 0.8764 - val_loss: 0.2041 - val_acc: 0.7419\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1192 - acc: 0.8764 - val_loss: 0.2039 - val_acc: 0.7419\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1186 - acc: 0.8691 - val_loss: 0.2033 - val_acc: 0.7419\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1172 - acc: 0.8727 - val_loss: 0.2016 - val_acc: 0.7419\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1161 - acc: 0.8655 - val_loss: 0.2056 - val_acc: 0.7419\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1157 - acc: 0.8727 - val_loss: 0.2023 - val_acc: 0.7419\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1135 - acc: 0.8800 - val_loss: 0.2036 - val_acc: 0.7419\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1129 - acc: 0.8727 - val_loss: 0.2019 - val_acc: 0.7419\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1123 - acc: 0.8764 - val_loss: 0.2018 - val_acc: 0.7419\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1107 - acc: 0.8800 - val_loss: 0.2020 - val_acc: 0.7419\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1098 - acc: 0.8800 - val_loss: 0.2006 - val_acc: 0.7419\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1087 - acc: 0.8836 - val_loss: 0.2024 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1075 - acc: 0.8800 - val_loss: 0.2033 - val_acc: 0.7097\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1060 - acc: 0.8873 - val_loss: 0.2040 - val_acc: 0.7097\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1048 - acc: 0.8836 - val_loss: 0.2033 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1046 - acc: 0.8836 - val_loss: 0.2061 - val_acc: 0.7097\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1031 - acc: 0.8873 - val_loss: 0.2057 - val_acc: 0.7097\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1018 - acc: 0.8909 - val_loss: 0.2053 - val_acc: 0.7097\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1008 - acc: 0.8945 - val_loss: 0.2032 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0997 - acc: 0.8945 - val_loss: 0.2049 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0985 - acc: 0.8982 - val_loss: 0.2024 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0978 - acc: 0.8873 - val_loss: 0.2044 - val_acc: 0.7097\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0977 - acc: 0.8909 - val_loss: 0.2046 - val_acc: 0.7097\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0959 - acc: 0.8945 - val_loss: 0.2033 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0938 - acc: 0.8945 - val_loss: 0.2064 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0926 - acc: 0.8945 - val_loss: 0.2054 - val_acc: 0.7097\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0917 - acc: 0.9091 - val_loss: 0.2057 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0905 - acc: 0.8982 - val_loss: 0.2075 - val_acc: 0.7097\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0901 - acc: 0.8982 - val_loss: 0.2055 - val_acc: 0.7097\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0880 - acc: 0.9055 - val_loss: 0.2074 - val_acc: 0.7097\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0873 - acc: 0.9091 - val_loss: 0.2050 - val_acc: 0.7097\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0860 - acc: 0.9164 - val_loss: 0.2104 - val_acc: 0.7097\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0849 - acc: 0.9091 - val_loss: 0.2041 - val_acc: 0.7097\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0841 - acc: 0.9164 - val_loss: 0.2063 - val_acc: 0.7097\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0838 - acc: 0.9164 - val_loss: 0.2092 - val_acc: 0.7097\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0832 - acc: 0.9164 - val_loss: 0.2065 - val_acc: 0.7097\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0807 - acc: 0.9164 - val_loss: 0.2056 - val_acc: 0.7097\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0802 - acc: 0.9200 - val_loss: 0.2088 - val_acc: 0.7097\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0791 - acc: 0.9236 - val_loss: 0.2088 - val_acc: 0.7097\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0777 - acc: 0.9236 - val_loss: 0.2075 - val_acc: 0.7097\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0766 - acc: 0.9200 - val_loss: 0.2092 - val_acc: 0.7097\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0763 - acc: 0.9200 - val_loss: 0.2120 - val_acc: 0.7419\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0752 - acc: 0.9273 - val_loss: 0.2072 - val_acc: 0.7419\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0738 - acc: 0.9236 - val_loss: 0.2090 - val_acc: 0.7097\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 11)                429       \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 20)                240       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 690\n",
      "Trainable params: 690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 3ms/step - loss: 0.2500 - acc: 0.5091 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.2494 - acc: 0.5418 - val_loss: 0.2495 - val_acc: 0.5161\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 196us/step - loss: 0.2481 - acc: 0.5418 - val_loss: 0.2476 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.2435 - acc: 0.5418 - val_loss: 0.2439 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.2371 - acc: 0.5418 - val_loss: 0.2399 - val_acc: 0.5161\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.2278 - acc: 0.5418 - val_loss: 0.2341 - val_acc: 0.5161\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.2194 - acc: 0.5782 - val_loss: 0.2307 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.2125 - acc: 0.6509 - val_loss: 0.2285 - val_acc: 0.5806\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.2067 - acc: 0.7127 - val_loss: 0.2284 - val_acc: 0.6129\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.2024 - acc: 0.7236 - val_loss: 0.2263 - val_acc: 0.6452\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1982 - acc: 0.7236 - val_loss: 0.2282 - val_acc: 0.6452\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1947 - acc: 0.7455 - val_loss: 0.2262 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1919 - acc: 0.7455 - val_loss: 0.2285 - val_acc: 0.6452\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1890 - acc: 0.7491 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1863 - acc: 0.7418 - val_loss: 0.2305 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1830 - acc: 0.7709 - val_loss: 0.2274 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1809 - acc: 0.7673 - val_loss: 0.2290 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1789 - acc: 0.7709 - val_loss: 0.2312 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1769 - acc: 0.7709 - val_loss: 0.2287 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1745 - acc: 0.7891 - val_loss: 0.2289 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1722 - acc: 0.8000 - val_loss: 0.2292 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1704 - acc: 0.7964 - val_loss: 0.2309 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1687 - acc: 0.8000 - val_loss: 0.2308 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1668 - acc: 0.8000 - val_loss: 0.2311 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1651 - acc: 0.8036 - val_loss: 0.2327 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1637 - acc: 0.8036 - val_loss: 0.2316 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1621 - acc: 0.8000 - val_loss: 0.2336 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1604 - acc: 0.8036 - val_loss: 0.2347 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1586 - acc: 0.8145 - val_loss: 0.2333 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1572 - acc: 0.8255 - val_loss: 0.2338 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1557 - acc: 0.8109 - val_loss: 0.2352 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1545 - acc: 0.8182 - val_loss: 0.2355 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1529 - acc: 0.8255 - val_loss: 0.2357 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1516 - acc: 0.8218 - val_loss: 0.2391 - val_acc: 0.6452\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1499 - acc: 0.8255 - val_loss: 0.2395 - val_acc: 0.6452\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1485 - acc: 0.8364 - val_loss: 0.2381 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1466 - acc: 0.8364 - val_loss: 0.2402 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1457 - acc: 0.8327 - val_loss: 0.2425 - val_acc: 0.6452\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1433 - acc: 0.8436 - val_loss: 0.2389 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1420 - acc: 0.8400 - val_loss: 0.2397 - val_acc: 0.6452\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1411 - acc: 0.8364 - val_loss: 0.2404 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1392 - acc: 0.8436 - val_loss: 0.2405 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1375 - acc: 0.8473 - val_loss: 0.2421 - val_acc: 0.6452\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1355 - acc: 0.8436 - val_loss: 0.2402 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1334 - acc: 0.8545 - val_loss: 0.2411 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1323 - acc: 0.8509 - val_loss: 0.2416 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1304 - acc: 0.8545 - val_loss: 0.2422 - val_acc: 0.6452\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1292 - acc: 0.8582 - val_loss: 0.2420 - val_acc: 0.6452\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1276 - acc: 0.8582 - val_loss: 0.2425 - val_acc: 0.6129\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1262 - acc: 0.8582 - val_loss: 0.2431 - val_acc: 0.6129\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1252 - acc: 0.8509 - val_loss: 0.2430 - val_acc: 0.6129\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1234 - acc: 0.8582 - val_loss: 0.2425 - val_acc: 0.6452\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1217 - acc: 0.8582 - val_loss: 0.2445 - val_acc: 0.6129\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1203 - acc: 0.8618 - val_loss: 0.2417 - val_acc: 0.6452\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1187 - acc: 0.8618 - val_loss: 0.2434 - val_acc: 0.6452\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1175 - acc: 0.8618 - val_loss: 0.2416 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1160 - acc: 0.8655 - val_loss: 0.2415 - val_acc: 0.6452\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1148 - acc: 0.8618 - val_loss: 0.2425 - val_acc: 0.6452\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1141 - acc: 0.8655 - val_loss: 0.2409 - val_acc: 0.6452\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1119 - acc: 0.8836 - val_loss: 0.2398 - val_acc: 0.6452\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1113 - acc: 0.8800 - val_loss: 0.2376 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1076 - acc: 0.8800 - val_loss: 0.2405 - val_acc: 0.6452\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 189us/step - loss: 0.1073 - acc: 0.8909 - val_loss: 0.2393 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1052 - acc: 0.8836 - val_loss: 0.2412 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1036 - acc: 0.8982 - val_loss: 0.2402 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1024 - acc: 0.9018 - val_loss: 0.2374 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1007 - acc: 0.9018 - val_loss: 0.2413 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0993 - acc: 0.9091 - val_loss: 0.2361 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0980 - acc: 0.9127 - val_loss: 0.2367 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0969 - acc: 0.9127 - val_loss: 0.2419 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0958 - acc: 0.9164 - val_loss: 0.2403 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0946 - acc: 0.9127 - val_loss: 0.2378 - val_acc: 0.6452\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0932 - acc: 0.9127 - val_loss: 0.2414 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0920 - acc: 0.9127 - val_loss: 0.2398 - val_acc: 0.6452\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0905 - acc: 0.9164 - val_loss: 0.2404 - val_acc: 0.6452\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0896 - acc: 0.9127 - val_loss: 0.2406 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0884 - acc: 0.9200 - val_loss: 0.2408 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0873 - acc: 0.9164 - val_loss: 0.2418 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0862 - acc: 0.9236 - val_loss: 0.2412 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0848 - acc: 0.9236 - val_loss: 0.2422 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0843 - acc: 0.9200 - val_loss: 0.2411 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0832 - acc: 0.9273 - val_loss: 0.2436 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0821 - acc: 0.9200 - val_loss: 0.2456 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0814 - acc: 0.9236 - val_loss: 0.2450 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0802 - acc: 0.9273 - val_loss: 0.2481 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0790 - acc: 0.9309 - val_loss: 0.2467 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0783 - acc: 0.9309 - val_loss: 0.2467 - val_acc: 0.6452\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0774 - acc: 0.9273 - val_loss: 0.2508 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0762 - acc: 0.9382 - val_loss: 0.2492 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0755 - acc: 0.9382 - val_loss: 0.2490 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0745 - acc: 0.9345 - val_loss: 0.2482 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0737 - acc: 0.9273 - val_loss: 0.2524 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0727 - acc: 0.9382 - val_loss: 0.2539 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0715 - acc: 0.9382 - val_loss: 0.2526 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0708 - acc: 0.9345 - val_loss: 0.2527 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0694 - acc: 0.9382 - val_loss: 0.2547 - val_acc: 0.6452\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0682 - acc: 0.9382 - val_loss: 0.2563 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0667 - acc: 0.9382 - val_loss: 0.2564 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0648 - acc: 0.9418 - val_loss: 0.2606 - val_acc: 0.6129\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0636 - acc: 0.9418 - val_loss: 0.2614 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 29)                1131      \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 14)                420       \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 1,566\n",
      "Trainable params: 1,566\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 3ms/step - loss: 0.2500 - acc: 0.4873 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2496 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.2488 - acc: 0.5564 - val_loss: 0.2477 - val_acc: 0.6452\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.2454 - acc: 0.6909 - val_loss: 0.2429 - val_acc: 0.6129\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.2370 - acc: 0.7491 - val_loss: 0.2315 - val_acc: 0.7097\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.2202 - acc: 0.7600 - val_loss: 0.2150 - val_acc: 0.7097\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.2004 - acc: 0.7455 - val_loss: 0.2011 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1851 - acc: 0.7418 - val_loss: 0.1955 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1754 - acc: 0.7491 - val_loss: 0.1962 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1685 - acc: 0.7673 - val_loss: 0.1993 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1659 - acc: 0.7527 - val_loss: 0.2018 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1631 - acc: 0.7600 - val_loss: 0.2043 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1607 - acc: 0.7636 - val_loss: 0.2080 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1592 - acc: 0.7709 - val_loss: 0.2108 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1577 - acc: 0.7745 - val_loss: 0.2123 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1563 - acc: 0.7782 - val_loss: 0.2137 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1560 - acc: 0.7891 - val_loss: 0.2151 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1535 - acc: 0.7891 - val_loss: 0.2181 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1530 - acc: 0.7964 - val_loss: 0.2175 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1523 - acc: 0.8036 - val_loss: 0.2166 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1505 - acc: 0.7964 - val_loss: 0.2191 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1492 - acc: 0.8036 - val_loss: 0.2194 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1484 - acc: 0.8145 - val_loss: 0.2203 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1475 - acc: 0.8182 - val_loss: 0.2208 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1462 - acc: 0.8145 - val_loss: 0.2201 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1466 - acc: 0.8109 - val_loss: 0.2229 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1452 - acc: 0.8145 - val_loss: 0.2195 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1443 - acc: 0.8182 - val_loss: 0.2184 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1427 - acc: 0.8218 - val_loss: 0.2210 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1421 - acc: 0.8218 - val_loss: 0.2209 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1413 - acc: 0.8255 - val_loss: 0.2222 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1390 - acc: 0.8364 - val_loss: 0.2216 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1383 - acc: 0.8327 - val_loss: 0.2218 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1367 - acc: 0.8364 - val_loss: 0.2199 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1357 - acc: 0.8473 - val_loss: 0.2226 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1340 - acc: 0.8473 - val_loss: 0.2218 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1332 - acc: 0.8509 - val_loss: 0.2223 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1312 - acc: 0.8545 - val_loss: 0.2215 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1306 - acc: 0.8436 - val_loss: 0.2238 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1303 - acc: 0.8509 - val_loss: 0.2255 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1274 - acc: 0.8582 - val_loss: 0.2247 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.1267 - acc: 0.8618 - val_loss: 0.2266 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1251 - acc: 0.8691 - val_loss: 0.2256 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1236 - acc: 0.8655 - val_loss: 0.2260 - val_acc: 0.7097\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1210 - acc: 0.8655 - val_loss: 0.2252 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1199 - acc: 0.8582 - val_loss: 0.2260 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1195 - acc: 0.8764 - val_loss: 0.2265 - val_acc: 0.7419\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1168 - acc: 0.8727 - val_loss: 0.2249 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1145 - acc: 0.8727 - val_loss: 0.2279 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1120 - acc: 0.8909 - val_loss: 0.2272 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1125 - acc: 0.8873 - val_loss: 0.2246 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1084 - acc: 0.8873 - val_loss: 0.2268 - val_acc: 0.7419\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1057 - acc: 0.8909 - val_loss: 0.2258 - val_acc: 0.7419\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1040 - acc: 0.8945 - val_loss: 0.2245 - val_acc: 0.7419\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1012 - acc: 0.8945 - val_loss: 0.2236 - val_acc: 0.7419\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0978 - acc: 0.9018 - val_loss: 0.2259 - val_acc: 0.7419\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0968 - acc: 0.8909 - val_loss: 0.2316 - val_acc: 0.7419\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0931 - acc: 0.9127 - val_loss: 0.2251 - val_acc: 0.7097\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0916 - acc: 0.9091 - val_loss: 0.2253 - val_acc: 0.7742\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0877 - acc: 0.9236 - val_loss: 0.2278 - val_acc: 0.7419\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0851 - acc: 0.9309 - val_loss: 0.2241 - val_acc: 0.7419\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0825 - acc: 0.9236 - val_loss: 0.2272 - val_acc: 0.7419\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0805 - acc: 0.9345 - val_loss: 0.2252 - val_acc: 0.7419\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0781 - acc: 0.9345 - val_loss: 0.2273 - val_acc: 0.7097\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0772 - acc: 0.9345 - val_loss: 0.2356 - val_acc: 0.7097\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0732 - acc: 0.9382 - val_loss: 0.2255 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0712 - acc: 0.9455 - val_loss: 0.2286 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0706 - acc: 0.9382 - val_loss: 0.2298 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0654 - acc: 0.9491 - val_loss: 0.2311 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0631 - acc: 0.9527 - val_loss: 0.2292 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0615 - acc: 0.9527 - val_loss: 0.2226 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0582 - acc: 0.9527 - val_loss: 0.2290 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0562 - acc: 0.9636 - val_loss: 0.2338 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0541 - acc: 0.9636 - val_loss: 0.2247 - val_acc: 0.6452\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0513 - acc: 0.9600 - val_loss: 0.2291 - val_acc: 0.6452\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0484 - acc: 0.9636 - val_loss: 0.2342 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0469 - acc: 0.9709 - val_loss: 0.2351 - val_acc: 0.6452\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 189us/step - loss: 0.0453 - acc: 0.9673 - val_loss: 0.2251 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0427 - acc: 0.9709 - val_loss: 0.2307 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0408 - acc: 0.9745 - val_loss: 0.2355 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0384 - acc: 0.9745 - val_loss: 0.2310 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0375 - acc: 0.9745 - val_loss: 0.2301 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0357 - acc: 0.9745 - val_loss: 0.2372 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0334 - acc: 0.9818 - val_loss: 0.2287 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0325 - acc: 0.9782 - val_loss: 0.2317 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0307 - acc: 0.9818 - val_loss: 0.2311 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0290 - acc: 0.9818 - val_loss: 0.2329 - val_acc: 0.6452\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0277 - acc: 0.9818 - val_loss: 0.2324 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0267 - acc: 0.9855 - val_loss: 0.2320 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0257 - acc: 0.9855 - val_loss: 0.2373 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0246 - acc: 0.9855 - val_loss: 0.2374 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0236 - acc: 0.9855 - val_loss: 0.2392 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0232 - acc: 0.9855 - val_loss: 0.2384 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0222 - acc: 0.9855 - val_loss: 0.2376 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0218 - acc: 0.9855 - val_loss: 0.2384 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0211 - acc: 0.9855 - val_loss: 0.2416 - val_acc: 0.6452\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0204 - acc: 0.9855 - val_loss: 0.2343 - val_acc: 0.6129\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0197 - acc: 0.9855 - val_loss: 0.2321 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0190 - acc: 0.9891 - val_loss: 0.2343 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0183 - acc: 0.9855 - val_loss: 0.2452 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 14)                546       \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 20)                300       \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 867\n",
      "Trainable params: 867\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 3ms/step - loss: 0.2500 - acc: 0.5309 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.2495 - acc: 0.5418 - val_loss: 0.2495 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.2480 - acc: 0.5418 - val_loss: 0.2479 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.2443 - acc: 0.5418 - val_loss: 0.2436 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.2356 - acc: 0.5491 - val_loss: 0.2374 - val_acc: 0.5484\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.2265 - acc: 0.5782 - val_loss: 0.2311 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.2152 - acc: 0.6945 - val_loss: 0.2249 - val_acc: 0.5806\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.2061 - acc: 0.7236 - val_loss: 0.2234 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1981 - acc: 0.7236 - val_loss: 0.2174 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1911 - acc: 0.7418 - val_loss: 0.2171 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1842 - acc: 0.7600 - val_loss: 0.2149 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1798 - acc: 0.7564 - val_loss: 0.2155 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1743 - acc: 0.7673 - val_loss: 0.2166 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1728 - acc: 0.7600 - val_loss: 0.2157 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1677 - acc: 0.7636 - val_loss: 0.2231 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1644 - acc: 0.7709 - val_loss: 0.2191 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1627 - acc: 0.7636 - val_loss: 0.2209 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1608 - acc: 0.7745 - val_loss: 0.2249 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1590 - acc: 0.7745 - val_loss: 0.2279 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1579 - acc: 0.7782 - val_loss: 0.2272 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1573 - acc: 0.7745 - val_loss: 0.2297 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1561 - acc: 0.7709 - val_loss: 0.2292 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1544 - acc: 0.7745 - val_loss: 0.2315 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1535 - acc: 0.7818 - val_loss: 0.2347 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1528 - acc: 0.7818 - val_loss: 0.2337 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1513 - acc: 0.7927 - val_loss: 0.2343 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1506 - acc: 0.7855 - val_loss: 0.2357 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1497 - acc: 0.7964 - val_loss: 0.2373 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1491 - acc: 0.8000 - val_loss: 0.2347 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1477 - acc: 0.8036 - val_loss: 0.2365 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1468 - acc: 0.8073 - val_loss: 0.2380 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1466 - acc: 0.8145 - val_loss: 0.2341 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1445 - acc: 0.8145 - val_loss: 0.2369 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1437 - acc: 0.8145 - val_loss: 0.2375 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1425 - acc: 0.8145 - val_loss: 0.2356 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1417 - acc: 0.8255 - val_loss: 0.2371 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1409 - acc: 0.8145 - val_loss: 0.2376 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1401 - acc: 0.8182 - val_loss: 0.2361 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1388 - acc: 0.8327 - val_loss: 0.2364 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1399 - acc: 0.8145 - val_loss: 0.2371 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1364 - acc: 0.8255 - val_loss: 0.2345 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1369 - acc: 0.8218 - val_loss: 0.2334 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1356 - acc: 0.8255 - val_loss: 0.2363 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1340 - acc: 0.8364 - val_loss: 0.2341 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1325 - acc: 0.8364 - val_loss: 0.2359 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1320 - acc: 0.8509 - val_loss: 0.2361 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1306 - acc: 0.8364 - val_loss: 0.2332 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1302 - acc: 0.8400 - val_loss: 0.2308 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1293 - acc: 0.8436 - val_loss: 0.2331 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1269 - acc: 0.8473 - val_loss: 0.2322 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1252 - acc: 0.8582 - val_loss: 0.2297 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1256 - acc: 0.8509 - val_loss: 0.2326 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1228 - acc: 0.8582 - val_loss: 0.2284 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1210 - acc: 0.8727 - val_loss: 0.2274 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1191 - acc: 0.8764 - val_loss: 0.2269 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1176 - acc: 0.8836 - val_loss: 0.2265 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1157 - acc: 0.8873 - val_loss: 0.2260 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1149 - acc: 0.8836 - val_loss: 0.2240 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1141 - acc: 0.8764 - val_loss: 0.2248 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1108 - acc: 0.8836 - val_loss: 0.2245 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1091 - acc: 0.8873 - val_loss: 0.2227 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1074 - acc: 0.8982 - val_loss: 0.2223 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1060 - acc: 0.8873 - val_loss: 0.2202 - val_acc: 0.7097\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1047 - acc: 0.8909 - val_loss: 0.2242 - val_acc: 0.7097\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1024 - acc: 0.8945 - val_loss: 0.2202 - val_acc: 0.7097\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1008 - acc: 0.9055 - val_loss: 0.2212 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0995 - acc: 0.9018 - val_loss: 0.2225 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0972 - acc: 0.9018 - val_loss: 0.2187 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0956 - acc: 0.9127 - val_loss: 0.2200 - val_acc: 0.7097\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0948 - acc: 0.9091 - val_loss: 0.2187 - val_acc: 0.7097\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0918 - acc: 0.9127 - val_loss: 0.2182 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0910 - acc: 0.9164 - val_loss: 0.2166 - val_acc: 0.7419\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0887 - acc: 0.9236 - val_loss: 0.2176 - val_acc: 0.7419\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0880 - acc: 0.9236 - val_loss: 0.2188 - val_acc: 0.7097\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0856 - acc: 0.9273 - val_loss: 0.2211 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0840 - acc: 0.9309 - val_loss: 0.2215 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0821 - acc: 0.9382 - val_loss: 0.2222 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0811 - acc: 0.9345 - val_loss: 0.2209 - val_acc: 0.7097\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0799 - acc: 0.9382 - val_loss: 0.2218 - val_acc: 0.7097\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0773 - acc: 0.9418 - val_loss: 0.2201 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0758 - acc: 0.9382 - val_loss: 0.2191 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0737 - acc: 0.9382 - val_loss: 0.2139 - val_acc: 0.7097\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0722 - acc: 0.9382 - val_loss: 0.2199 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0698 - acc: 0.9455 - val_loss: 0.2135 - val_acc: 0.7097\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0680 - acc: 0.9455 - val_loss: 0.2167 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0665 - acc: 0.9455 - val_loss: 0.2202 - val_acc: 0.7097\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0654 - acc: 0.9455 - val_loss: 0.2196 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0635 - acc: 0.9527 - val_loss: 0.2137 - val_acc: 0.7419\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0619 - acc: 0.9527 - val_loss: 0.2201 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0604 - acc: 0.9527 - val_loss: 0.2178 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0588 - acc: 0.9527 - val_loss: 0.2179 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0579 - acc: 0.9564 - val_loss: 0.2212 - val_acc: 0.7097\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 166us/step - loss: 0.0565 - acc: 0.9564 - val_loss: 0.2216 - val_acc: 0.7097\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0551 - acc: 0.9564 - val_loss: 0.2193 - val_acc: 0.7097\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0540 - acc: 0.9564 - val_loss: 0.2191 - val_acc: 0.7097\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0531 - acc: 0.9564 - val_loss: 0.2264 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0524 - acc: 0.9564 - val_loss: 0.2256 - val_acc: 0.7097\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0515 - acc: 0.9564 - val_loss: 0.2249 - val_acc: 0.7097\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0508 - acc: 0.9564 - val_loss: 0.2246 - val_acc: 0.7097\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0498 - acc: 0.9564 - val_loss: 0.2281 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_73 (Dense)             (None, 39)                1521      \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 14)                560       \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 2,096\n",
      "Trainable params: 2,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 3ms/step - loss: 0.2499 - acc: 0.5164 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.2489 - acc: 0.5418 - val_loss: 0.2484 - val_acc: 0.5484\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.2458 - acc: 0.5855 - val_loss: 0.2433 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.2370 - acc: 0.7236 - val_loss: 0.2332 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.2192 - acc: 0.7345 - val_loss: 0.2163 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1991 - acc: 0.7491 - val_loss: 0.2067 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1820 - acc: 0.7455 - val_loss: 0.2006 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1703 - acc: 0.7527 - val_loss: 0.2060 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1650 - acc: 0.7636 - val_loss: 0.2083 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1628 - acc: 0.7564 - val_loss: 0.2073 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1583 - acc: 0.7818 - val_loss: 0.2106 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1571 - acc: 0.7745 - val_loss: 0.2139 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1545 - acc: 0.7891 - val_loss: 0.2171 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1531 - acc: 0.7818 - val_loss: 0.2168 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1513 - acc: 0.7964 - val_loss: 0.2163 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1492 - acc: 0.7964 - val_loss: 0.2157 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1482 - acc: 0.8036 - val_loss: 0.2196 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1465 - acc: 0.8000 - val_loss: 0.2191 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1451 - acc: 0.8145 - val_loss: 0.2224 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1429 - acc: 0.8145 - val_loss: 0.2197 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1423 - acc: 0.8000 - val_loss: 0.2216 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1396 - acc: 0.8182 - val_loss: 0.2205 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1380 - acc: 0.8145 - val_loss: 0.2217 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1356 - acc: 0.8218 - val_loss: 0.2230 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.1350 - acc: 0.8145 - val_loss: 0.2247 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1347 - acc: 0.8218 - val_loss: 0.2229 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1305 - acc: 0.8436 - val_loss: 0.2231 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1279 - acc: 0.8400 - val_loss: 0.2227 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1264 - acc: 0.8509 - val_loss: 0.2249 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1243 - acc: 0.8509 - val_loss: 0.2232 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 214us/step - loss: 0.1213 - acc: 0.8582 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1209 - acc: 0.8618 - val_loss: 0.2256 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1177 - acc: 0.8691 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1147 - acc: 0.8764 - val_loss: 0.2298 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1117 - acc: 0.8873 - val_loss: 0.2293 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1092 - acc: 0.8873 - val_loss: 0.2283 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1065 - acc: 0.8909 - val_loss: 0.2305 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1042 - acc: 0.8945 - val_loss: 0.2281 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1025 - acc: 0.9018 - val_loss: 0.2369 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1002 - acc: 0.8909 - val_loss: 0.2354 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0978 - acc: 0.9055 - val_loss: 0.2300 - val_acc: 0.6452\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0935 - acc: 0.9055 - val_loss: 0.2346 - val_acc: 0.6452\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0905 - acc: 0.9091 - val_loss: 0.2325 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0890 - acc: 0.9018 - val_loss: 0.2371 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0861 - acc: 0.9164 - val_loss: 0.2303 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0842 - acc: 0.9091 - val_loss: 0.2341 - val_acc: 0.6452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0798 - acc: 0.9236 - val_loss: 0.2301 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0796 - acc: 0.9127 - val_loss: 0.2303 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0747 - acc: 0.9309 - val_loss: 0.2259 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0723 - acc: 0.9236 - val_loss: 0.2309 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0695 - acc: 0.9455 - val_loss: 0.2296 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0674 - acc: 0.9382 - val_loss: 0.2282 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0654 - acc: 0.9455 - val_loss: 0.2279 - val_acc: 0.6129\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0622 - acc: 0.9491 - val_loss: 0.2296 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0602 - acc: 0.9491 - val_loss: 0.2338 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0572 - acc: 0.9527 - val_loss: 0.2307 - val_acc: 0.6452\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0547 - acc: 0.9600 - val_loss: 0.2350 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0537 - acc: 0.9636 - val_loss: 0.2250 - val_acc: 0.6452\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0514 - acc: 0.9673 - val_loss: 0.2310 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0481 - acc: 0.9636 - val_loss: 0.2290 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0463 - acc: 0.9636 - val_loss: 0.2381 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0441 - acc: 0.9673 - val_loss: 0.2323 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0415 - acc: 0.9636 - val_loss: 0.2386 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0398 - acc: 0.9673 - val_loss: 0.2386 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0364 - acc: 0.9709 - val_loss: 0.2325 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0356 - acc: 0.9745 - val_loss: 0.2443 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.0321 - acc: 0.9745 - val_loss: 0.2441 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0294 - acc: 0.9782 - val_loss: 0.2469 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0298 - acc: 0.9818 - val_loss: 0.2572 - val_acc: 0.6129\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0283 - acc: 0.9855 - val_loss: 0.2541 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0249 - acc: 0.9891 - val_loss: 0.2517 - val_acc: 0.6129\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0251 - acc: 0.9891 - val_loss: 0.2589 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0227 - acc: 0.9927 - val_loss: 0.2624 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0215 - acc: 0.9891 - val_loss: 0.2593 - val_acc: 0.6129\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0211 - acc: 0.9891 - val_loss: 0.2619 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0201 - acc: 0.9927 - val_loss: 0.2565 - val_acc: 0.6129\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0203 - acc: 0.9927 - val_loss: 0.2607 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0185 - acc: 0.9927 - val_loss: 0.2700 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0175 - acc: 0.9927 - val_loss: 0.2634 - val_acc: 0.6129\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0170 - acc: 0.9927 - val_loss: 0.2622 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0162 - acc: 0.9927 - val_loss: 0.2660 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0152 - acc: 0.9927 - val_loss: 0.2629 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0150 - acc: 0.9927 - val_loss: 0.2686 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0146 - acc: 0.9927 - val_loss: 0.2715 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0144 - acc: 0.9927 - val_loss: 0.2675 - val_acc: 0.6129\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0137 - acc: 0.9927 - val_loss: 0.2687 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0134 - acc: 0.9927 - val_loss: 0.2736 - val_acc: 0.6129\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0127 - acc: 0.9927 - val_loss: 0.2664 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0124 - acc: 0.9927 - val_loss: 0.2731 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.0122 - acc: 0.9927 - val_loss: 0.2769 - val_acc: 0.6129\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0120 - acc: 0.9927 - val_loss: 0.2701 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0118 - acc: 0.9927 - val_loss: 0.2859 - val_acc: 0.6129\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0116 - acc: 0.9927 - val_loss: 0.2802 - val_acc: 0.6129\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0112 - acc: 0.9927 - val_loss: 0.2775 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0110 - acc: 0.9927 - val_loss: 0.2826 - val_acc: 0.6452\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0107 - acc: 0.9927 - val_loss: 0.2762 - val_acc: 0.6129\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0111 - acc: 0.9927 - val_loss: 0.2866 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0106 - acc: 0.9927 - val_loss: 0.2784 - val_acc: 0.6129\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0103 - acc: 0.9927 - val_loss: 0.2822 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_76 (Dense)             (None, 15)                585       \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 13)                208       \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 807\n",
      "Trainable params: 807\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 3ms/step - loss: 0.2499 - acc: 0.5382 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 178us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.2490 - acc: 0.5418 - val_loss: 0.2490 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.2474 - acc: 0.5418 - val_loss: 0.2467 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.2428 - acc: 0.5491 - val_loss: 0.2417 - val_acc: 0.5484\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.2352 - acc: 0.6073 - val_loss: 0.2333 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.2243 - acc: 0.6364 - val_loss: 0.2272 - val_acc: 0.5806\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.2127 - acc: 0.6982 - val_loss: 0.2183 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.2018 - acc: 0.7273 - val_loss: 0.2126 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1913 - acc: 0.7345 - val_loss: 0.2070 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1827 - acc: 0.7491 - val_loss: 0.2059 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1753 - acc: 0.7600 - val_loss: 0.2054 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1701 - acc: 0.7709 - val_loss: 0.2042 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1652 - acc: 0.7745 - val_loss: 0.2071 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1621 - acc: 0.7818 - val_loss: 0.2074 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1589 - acc: 0.7927 - val_loss: 0.2096 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1564 - acc: 0.7709 - val_loss: 0.2115 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1552 - acc: 0.7745 - val_loss: 0.2144 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1521 - acc: 0.8000 - val_loss: 0.2141 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1505 - acc: 0.7927 - val_loss: 0.2138 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1492 - acc: 0.7964 - val_loss: 0.2153 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1475 - acc: 0.8073 - val_loss: 0.2195 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.1473 - acc: 0.7964 - val_loss: 0.2183 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1449 - acc: 0.8036 - val_loss: 0.2187 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1431 - acc: 0.8109 - val_loss: 0.2199 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1419 - acc: 0.8036 - val_loss: 0.2204 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1401 - acc: 0.8145 - val_loss: 0.2196 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1394 - acc: 0.8182 - val_loss: 0.2212 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1375 - acc: 0.8145 - val_loss: 0.2203 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1363 - acc: 0.8291 - val_loss: 0.2207 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1351 - acc: 0.8255 - val_loss: 0.2231 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1336 - acc: 0.8436 - val_loss: 0.2222 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1333 - acc: 0.8291 - val_loss: 0.2219 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1306 - acc: 0.8400 - val_loss: 0.2214 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1292 - acc: 0.8509 - val_loss: 0.2239 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1278 - acc: 0.8509 - val_loss: 0.2200 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1263 - acc: 0.8473 - val_loss: 0.2219 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1248 - acc: 0.8545 - val_loss: 0.2222 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1239 - acc: 0.8582 - val_loss: 0.2216 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1223 - acc: 0.8618 - val_loss: 0.2207 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1210 - acc: 0.8545 - val_loss: 0.2210 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1210 - acc: 0.8436 - val_loss: 0.2194 - val_acc: 0.7419\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1196 - acc: 0.8545 - val_loss: 0.2214 - val_acc: 0.7419\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1162 - acc: 0.8545 - val_loss: 0.2222 - val_acc: 0.7419\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1165 - acc: 0.8582 - val_loss: 0.2196 - val_acc: 0.7419\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1141 - acc: 0.8618 - val_loss: 0.2204 - val_acc: 0.7419\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1137 - acc: 0.8618 - val_loss: 0.2216 - val_acc: 0.7419\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1123 - acc: 0.8545 - val_loss: 0.2225 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1100 - acc: 0.8727 - val_loss: 0.2219 - val_acc: 0.7419\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1081 - acc: 0.8655 - val_loss: 0.2242 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1078 - acc: 0.8655 - val_loss: 0.2220 - val_acc: 0.7419\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1064 - acc: 0.8764 - val_loss: 0.2223 - val_acc: 0.7419\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.1057 - acc: 0.8691 - val_loss: 0.2206 - val_acc: 0.7742\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1053 - acc: 0.8618 - val_loss: 0.2222 - val_acc: 0.7419\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1029 - acc: 0.8800 - val_loss: 0.2206 - val_acc: 0.7419\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1010 - acc: 0.8836 - val_loss: 0.2220 - val_acc: 0.7742\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0994 - acc: 0.8873 - val_loss: 0.2223 - val_acc: 0.7742\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0977 - acc: 0.8945 - val_loss: 0.2200 - val_acc: 0.7742\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0963 - acc: 0.8982 - val_loss: 0.2205 - val_acc: 0.7419\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0971 - acc: 0.8836 - val_loss: 0.2214 - val_acc: 0.7419\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0959 - acc: 0.9055 - val_loss: 0.2204 - val_acc: 0.7419\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 168us/step - loss: 0.0938 - acc: 0.8800 - val_loss: 0.2224 - val_acc: 0.7742\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0924 - acc: 0.8945 - val_loss: 0.2232 - val_acc: 0.7742\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0915 - acc: 0.9018 - val_loss: 0.2248 - val_acc: 0.7419\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0895 - acc: 0.9127 - val_loss: 0.2223 - val_acc: 0.7742\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0887 - acc: 0.9091 - val_loss: 0.2225 - val_acc: 0.7742\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0877 - acc: 0.9091 - val_loss: 0.2246 - val_acc: 0.7742\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0860 - acc: 0.9091 - val_loss: 0.2215 - val_acc: 0.7742\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0856 - acc: 0.9055 - val_loss: 0.2216 - val_acc: 0.7742\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0840 - acc: 0.9200 - val_loss: 0.2223 - val_acc: 0.7742\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0825 - acc: 0.9127 - val_loss: 0.2251 - val_acc: 0.7742\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0818 - acc: 0.9236 - val_loss: 0.2219 - val_acc: 0.7419\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0802 - acc: 0.9236 - val_loss: 0.2245 - val_acc: 0.7742\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0800 - acc: 0.9236 - val_loss: 0.2256 - val_acc: 0.7097\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0781 - acc: 0.9236 - val_loss: 0.2256 - val_acc: 0.7419\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0771 - acc: 0.9236 - val_loss: 0.2232 - val_acc: 0.7742\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0754 - acc: 0.9200 - val_loss: 0.2245 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0741 - acc: 0.9273 - val_loss: 0.2249 - val_acc: 0.7742\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0732 - acc: 0.9309 - val_loss: 0.2233 - val_acc: 0.7097\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0728 - acc: 0.9273 - val_loss: 0.2244 - val_acc: 0.7742\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0709 - acc: 0.9345 - val_loss: 0.2261 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0710 - acc: 0.9273 - val_loss: 0.2259 - val_acc: 0.7419\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0691 - acc: 0.9382 - val_loss: 0.2244 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0675 - acc: 0.9309 - val_loss: 0.2253 - val_acc: 0.7097\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0656 - acc: 0.9345 - val_loss: 0.2261 - val_acc: 0.7097\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0647 - acc: 0.9418 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0629 - acc: 0.9455 - val_loss: 0.2284 - val_acc: 0.7419\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0628 - acc: 0.9418 - val_loss: 0.2274 - val_acc: 0.7097\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0605 - acc: 0.9455 - val_loss: 0.2242 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0595 - acc: 0.9491 - val_loss: 0.2256 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0579 - acc: 0.9491 - val_loss: 0.2261 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0564 - acc: 0.9527 - val_loss: 0.2239 - val_acc: 0.7097\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0559 - acc: 0.9455 - val_loss: 0.2226 - val_acc: 0.7097\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0558 - acc: 0.9636 - val_loss: 0.2236 - val_acc: 0.7419\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0545 - acc: 0.9600 - val_loss: 0.2260 - val_acc: 0.7097\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0536 - acc: 0.9527 - val_loss: 0.2183 - val_acc: 0.7097\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0521 - acc: 0.9564 - val_loss: 0.2214 - val_acc: 0.7097\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0505 - acc: 0.9564 - val_loss: 0.2218 - val_acc: 0.7097\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0499 - acc: 0.9564 - val_loss: 0.2145 - val_acc: 0.7419\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0487 - acc: 0.9564 - val_loss: 0.2167 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_79 (Dense)             (None, 43)                1677      \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 17)                748       \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 1)                 18        \n",
      "=================================================================\n",
      "Total params: 2,443\n",
      "Trainable params: 2,443\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 3ms/step - loss: 0.2499 - acc: 0.5309 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.2492 - acc: 0.5418 - val_loss: 0.2488 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.2465 - acc: 0.5418 - val_loss: 0.2442 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.2373 - acc: 0.5964 - val_loss: 0.2343 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.2209 - acc: 0.6764 - val_loss: 0.2237 - val_acc: 0.6129\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.2042 - acc: 0.7127 - val_loss: 0.2110 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1889 - acc: 0.7273 - val_loss: 0.2101 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1777 - acc: 0.7564 - val_loss: 0.2079 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1688 - acc: 0.7636 - val_loss: 0.2102 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.1633 - acc: 0.7818 - val_loss: 0.2082 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1587 - acc: 0.7818 - val_loss: 0.2097 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1545 - acc: 0.7927 - val_loss: 0.2154 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1519 - acc: 0.8073 - val_loss: 0.2150 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1503 - acc: 0.8036 - val_loss: 0.2176 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1474 - acc: 0.8145 - val_loss: 0.2190 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1459 - acc: 0.8182 - val_loss: 0.2160 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1418 - acc: 0.8218 - val_loss: 0.2157 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1406 - acc: 0.8218 - val_loss: 0.2176 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1384 - acc: 0.8364 - val_loss: 0.2159 - val_acc: 0.7419\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1363 - acc: 0.8255 - val_loss: 0.2172 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1330 - acc: 0.8436 - val_loss: 0.2165 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1316 - acc: 0.8473 - val_loss: 0.2136 - val_acc: 0.7419\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1293 - acc: 0.8436 - val_loss: 0.2194 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1264 - acc: 0.8509 - val_loss: 0.2136 - val_acc: 0.7419\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1238 - acc: 0.8509 - val_loss: 0.2168 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1224 - acc: 0.8509 - val_loss: 0.2129 - val_acc: 0.7419\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1214 - acc: 0.8582 - val_loss: 0.2101 - val_acc: 0.7419\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1176 - acc: 0.8545 - val_loss: 0.2114 - val_acc: 0.7419\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1146 - acc: 0.8691 - val_loss: 0.2130 - val_acc: 0.7419\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1113 - acc: 0.8727 - val_loss: 0.2139 - val_acc: 0.7419\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1079 - acc: 0.8836 - val_loss: 0.2113 - val_acc: 0.7742\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1059 - acc: 0.8764 - val_loss: 0.2055 - val_acc: 0.7742\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1031 - acc: 0.8982 - val_loss: 0.2069 - val_acc: 0.7742\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0993 - acc: 0.9018 - val_loss: 0.2041 - val_acc: 0.7742\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0983 - acc: 0.8836 - val_loss: 0.2112 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0933 - acc: 0.9055 - val_loss: 0.2070 - val_acc: 0.7419\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0903 - acc: 0.9018 - val_loss: 0.2035 - val_acc: 0.7419\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0870 - acc: 0.9127 - val_loss: 0.2006 - val_acc: 0.7419\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0836 - acc: 0.9127 - val_loss: 0.1977 - val_acc: 0.7742\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0801 - acc: 0.9236 - val_loss: 0.2013 - val_acc: 0.7419\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0770 - acc: 0.9127 - val_loss: 0.2045 - val_acc: 0.7419\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0717 - acc: 0.9382 - val_loss: 0.2037 - val_acc: 0.7742\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0689 - acc: 0.9345 - val_loss: 0.2034 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0632 - acc: 0.9491 - val_loss: 0.2002 - val_acc: 0.7742\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0655 - acc: 0.9382 - val_loss: 0.2039 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0580 - acc: 0.9527 - val_loss: 0.1960 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0527 - acc: 0.9636 - val_loss: 0.1989 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0493 - acc: 0.9673 - val_loss: 0.1946 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0468 - acc: 0.9745 - val_loss: 0.2016 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0443 - acc: 0.9782 - val_loss: 0.2001 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0408 - acc: 0.9745 - val_loss: 0.1966 - val_acc: 0.7419\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0360 - acc: 0.9818 - val_loss: 0.1982 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0344 - acc: 0.9818 - val_loss: 0.2008 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0316 - acc: 0.9818 - val_loss: 0.2038 - val_acc: 0.6452\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0290 - acc: 0.9855 - val_loss: 0.1972 - val_acc: 0.6452\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0281 - acc: 0.9891 - val_loss: 0.1977 - val_acc: 0.7419\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0258 - acc: 0.9891 - val_loss: 0.2028 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0242 - acc: 0.9891 - val_loss: 0.2021 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0226 - acc: 0.9891 - val_loss: 0.2040 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0216 - acc: 0.9891 - val_loss: 0.1993 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0209 - acc: 0.9891 - val_loss: 0.2015 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0198 - acc: 0.9891 - val_loss: 0.2064 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0190 - acc: 0.9891 - val_loss: 0.2070 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0181 - acc: 0.9891 - val_loss: 0.2073 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0174 - acc: 0.9891 - val_loss: 0.2075 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0167 - acc: 0.9891 - val_loss: 0.2081 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0162 - acc: 0.9891 - val_loss: 0.2095 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0158 - acc: 0.9891 - val_loss: 0.2104 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0154 - acc: 0.9891 - val_loss: 0.2111 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0150 - acc: 0.9891 - val_loss: 0.2083 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0145 - acc: 0.9891 - val_loss: 0.2157 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0141 - acc: 0.9891 - val_loss: 0.2190 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0129 - acc: 0.9891 - val_loss: 0.2210 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0123 - acc: 0.9927 - val_loss: 0.2204 - val_acc: 0.7097\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0117 - acc: 0.9927 - val_loss: 0.2244 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0111 - acc: 0.9927 - val_loss: 0.2207 - val_acc: 0.6774\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 192us/step - loss: 0.0109 - acc: 0.9927 - val_loss: 0.2203 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0108 - acc: 0.9927 - val_loss: 0.2270 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0103 - acc: 0.9927 - val_loss: 0.2225 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0101 - acc: 0.9927 - val_loss: 0.2251 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0099 - acc: 0.9927 - val_loss: 0.2245 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0097 - acc: 0.9927 - val_loss: 0.2250 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0096 - acc: 0.9927 - val_loss: 0.2239 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0094 - acc: 0.9927 - val_loss: 0.2268 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0093 - acc: 0.9927 - val_loss: 0.2221 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0092 - acc: 0.9927 - val_loss: 0.2260 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0091 - acc: 0.9927 - val_loss: 0.2263 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0089 - acc: 0.9927 - val_loss: 0.2269 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0089 - acc: 0.9927 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0088 - acc: 0.9927 - val_loss: 0.2277 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0088 - acc: 0.9927 - val_loss: 0.2290 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0087 - acc: 0.9927 - val_loss: 0.2293 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0086 - acc: 0.9927 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0085 - acc: 0.9927 - val_loss: 0.2284 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0084 - acc: 0.9927 - val_loss: 0.2308 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0084 - acc: 0.9927 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0083 - acc: 0.9927 - val_loss: 0.2318 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0082 - acc: 0.9927 - val_loss: 0.2309 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0082 - acc: 0.9927 - val_loss: 0.2295 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0081 - acc: 0.9927 - val_loss: 0.2314 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_82 (Dense)             (None, 27)                1053      \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 12)                336       \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,402\n",
      "Trainable params: 1,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 3ms/step - loss: 0.2499 - acc: 0.5236 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.2495 - acc: 0.5418 - val_loss: 0.2494 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.2482 - acc: 0.5418 - val_loss: 0.2476 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.2443 - acc: 0.5455 - val_loss: 0.2430 - val_acc: 0.5806\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.2364 - acc: 0.6145 - val_loss: 0.2358 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.2242 - acc: 0.6836 - val_loss: 0.2274 - val_acc: 0.5806\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.2102 - acc: 0.7164 - val_loss: 0.2143 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1951 - acc: 0.7345 - val_loss: 0.2049 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1820 - acc: 0.7418 - val_loss: 0.2059 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1735 - acc: 0.7455 - val_loss: 0.2005 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1687 - acc: 0.7636 - val_loss: 0.2075 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1651 - acc: 0.7527 - val_loss: 0.2098 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1611 - acc: 0.7709 - val_loss: 0.2099 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1603 - acc: 0.7600 - val_loss: 0.2129 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1600 - acc: 0.7636 - val_loss: 0.2147 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1592 - acc: 0.7782 - val_loss: 0.2137 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1558 - acc: 0.7818 - val_loss: 0.2205 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1555 - acc: 0.7818 - val_loss: 0.2195 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1535 - acc: 0.7855 - val_loss: 0.2203 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1529 - acc: 0.7818 - val_loss: 0.2207 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1512 - acc: 0.7891 - val_loss: 0.2211 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1500 - acc: 0.7891 - val_loss: 0.2216 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1493 - acc: 0.8073 - val_loss: 0.2218 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1484 - acc: 0.8036 - val_loss: 0.2225 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1483 - acc: 0.7964 - val_loss: 0.2230 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1481 - acc: 0.8036 - val_loss: 0.2237 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1478 - acc: 0.8073 - val_loss: 0.2252 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1456 - acc: 0.8327 - val_loss: 0.2244 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1439 - acc: 0.8218 - val_loss: 0.2240 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1431 - acc: 0.8218 - val_loss: 0.2258 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1424 - acc: 0.8145 - val_loss: 0.2240 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1408 - acc: 0.8327 - val_loss: 0.2275 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1390 - acc: 0.8182 - val_loss: 0.2273 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1390 - acc: 0.8255 - val_loss: 0.2265 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 215us/step - loss: 0.1377 - acc: 0.8364 - val_loss: 0.2285 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1367 - acc: 0.8255 - val_loss: 0.2298 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1359 - acc: 0.8327 - val_loss: 0.2272 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1348 - acc: 0.8327 - val_loss: 0.2290 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1344 - acc: 0.8327 - val_loss: 0.2283 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1326 - acc: 0.8364 - val_loss: 0.2289 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1306 - acc: 0.8436 - val_loss: 0.2275 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1301 - acc: 0.8509 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1286 - acc: 0.8509 - val_loss: 0.2277 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1270 - acc: 0.8509 - val_loss: 0.2305 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1261 - acc: 0.8545 - val_loss: 0.2314 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1248 - acc: 0.8509 - val_loss: 0.2306 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1230 - acc: 0.8618 - val_loss: 0.2324 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1220 - acc: 0.8545 - val_loss: 0.2332 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1201 - acc: 0.8655 - val_loss: 0.2347 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1190 - acc: 0.8618 - val_loss: 0.2338 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1174 - acc: 0.8582 - val_loss: 0.2314 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1162 - acc: 0.8582 - val_loss: 0.2334 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1143 - acc: 0.8764 - val_loss: 0.2338 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1131 - acc: 0.8764 - val_loss: 0.2316 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1107 - acc: 0.8800 - val_loss: 0.2347 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1101 - acc: 0.8800 - val_loss: 0.2355 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1079 - acc: 0.8873 - val_loss: 0.2372 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1061 - acc: 0.8909 - val_loss: 0.2367 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1053 - acc: 0.8909 - val_loss: 0.2352 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1029 - acc: 0.8909 - val_loss: 0.2337 - val_acc: 0.7097\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1015 - acc: 0.8945 - val_loss: 0.2364 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0995 - acc: 0.9055 - val_loss: 0.2355 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0971 - acc: 0.9055 - val_loss: 0.2359 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0958 - acc: 0.9055 - val_loss: 0.2344 - val_acc: 0.7097\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0934 - acc: 0.8982 - val_loss: 0.2359 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0924 - acc: 0.9164 - val_loss: 0.2380 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0905 - acc: 0.9018 - val_loss: 0.2402 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0899 - acc: 0.9091 - val_loss: 0.2393 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0855 - acc: 0.9200 - val_loss: 0.2428 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0833 - acc: 0.9273 - val_loss: 0.2431 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0811 - acc: 0.9273 - val_loss: 0.2413 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0808 - acc: 0.9236 - val_loss: 0.2431 - val_acc: 0.7097\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0772 - acc: 0.9309 - val_loss: 0.2410 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0762 - acc: 0.9345 - val_loss: 0.2482 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0741 - acc: 0.9273 - val_loss: 0.2426 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0713 - acc: 0.9382 - val_loss: 0.2426 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0699 - acc: 0.9418 - val_loss: 0.2493 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0669 - acc: 0.9418 - val_loss: 0.2509 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0663 - acc: 0.9455 - val_loss: 0.2545 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0638 - acc: 0.9491 - val_loss: 0.2468 - val_acc: 0.6129\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0617 - acc: 0.9491 - val_loss: 0.2516 - val_acc: 0.5806\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0602 - acc: 0.9564 - val_loss: 0.2555 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0583 - acc: 0.9527 - val_loss: 0.2540 - val_acc: 0.6129\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0566 - acc: 0.9564 - val_loss: 0.2561 - val_acc: 0.6129\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0555 - acc: 0.9564 - val_loss: 0.2515 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0536 - acc: 0.9564 - val_loss: 0.2546 - val_acc: 0.6129\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0513 - acc: 0.9600 - val_loss: 0.2488 - val_acc: 0.6129\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0510 - acc: 0.9564 - val_loss: 0.2588 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0497 - acc: 0.9673 - val_loss: 0.2538 - val_acc: 0.5806\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0483 - acc: 0.9636 - val_loss: 0.2562 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0465 - acc: 0.9709 - val_loss: 0.2603 - val_acc: 0.5806\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 172us/step - loss: 0.0456 - acc: 0.9709 - val_loss: 0.2576 - val_acc: 0.5806\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0442 - acc: 0.9673 - val_loss: 0.2550 - val_acc: 0.6129\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0424 - acc: 0.9709 - val_loss: 0.2636 - val_acc: 0.5806\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0419 - acc: 0.9745 - val_loss: 0.2603 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0407 - acc: 0.9745 - val_loss: 0.2531 - val_acc: 0.5806\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0400 - acc: 0.9745 - val_loss: 0.2590 - val_acc: 0.5806\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0386 - acc: 0.9745 - val_loss: 0.2583 - val_acc: 0.6129\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0376 - acc: 0.9709 - val_loss: 0.2623 - val_acc: 0.5806\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0372 - acc: 0.9782 - val_loss: 0.2627 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_85 (Dense)             (None, 39)                1521      \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 16)                640       \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,178\n",
      "Trainable params: 2,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 4ms/step - loss: 0.2498 - acc: 0.5418 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 215us/step - loss: 0.2489 - acc: 0.5418 - val_loss: 0.2488 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.2462 - acc: 0.5418 - val_loss: 0.2451 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.2381 - acc: 0.5418 - val_loss: 0.2389 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.2264 - acc: 0.5855 - val_loss: 0.2310 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.2130 - acc: 0.6836 - val_loss: 0.2240 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.2027 - acc: 0.7236 - val_loss: 0.2228 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1923 - acc: 0.7418 - val_loss: 0.2139 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1844 - acc: 0.7455 - val_loss: 0.2130 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1761 - acc: 0.7636 - val_loss: 0.2112 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1689 - acc: 0.7600 - val_loss: 0.2130 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1621 - acc: 0.7782 - val_loss: 0.2126 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1581 - acc: 0.7818 - val_loss: 0.2117 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1560 - acc: 0.7927 - val_loss: 0.2119 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1534 - acc: 0.7927 - val_loss: 0.2151 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1501 - acc: 0.8109 - val_loss: 0.2191 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1470 - acc: 0.8182 - val_loss: 0.2198 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1440 - acc: 0.8145 - val_loss: 0.2208 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1428 - acc: 0.8182 - val_loss: 0.2230 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1424 - acc: 0.8182 - val_loss: 0.2293 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1384 - acc: 0.8364 - val_loss: 0.2230 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1361 - acc: 0.8400 - val_loss: 0.2226 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1347 - acc: 0.8473 - val_loss: 0.2254 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1322 - acc: 0.8473 - val_loss: 0.2272 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1308 - acc: 0.8473 - val_loss: 0.2195 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1282 - acc: 0.8545 - val_loss: 0.2208 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1260 - acc: 0.8545 - val_loss: 0.2191 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1240 - acc: 0.8582 - val_loss: 0.2184 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1207 - acc: 0.8691 - val_loss: 0.2159 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1198 - acc: 0.8618 - val_loss: 0.2187 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1202 - acc: 0.8655 - val_loss: 0.2071 - val_acc: 0.7419\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1165 - acc: 0.8655 - val_loss: 0.2180 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1126 - acc: 0.8800 - val_loss: 0.2083 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1099 - acc: 0.8873 - val_loss: 0.2091 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1070 - acc: 0.8873 - val_loss: 0.2104 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1056 - acc: 0.8873 - val_loss: 0.2019 - val_acc: 0.7419\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1028 - acc: 0.8909 - val_loss: 0.2066 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0990 - acc: 0.9018 - val_loss: 0.1981 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0960 - acc: 0.9018 - val_loss: 0.2057 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0935 - acc: 0.9018 - val_loss: 0.1932 - val_acc: 0.7419\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0892 - acc: 0.9127 - val_loss: 0.1921 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 215us/step - loss: 0.0855 - acc: 0.9164 - val_loss: 0.1936 - val_acc: 0.7419\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0841 - acc: 0.9018 - val_loss: 0.1969 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0785 - acc: 0.9273 - val_loss: 0.1927 - val_acc: 0.7742\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0756 - acc: 0.9309 - val_loss: 0.1914 - val_acc: 0.7742\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0724 - acc: 0.9236 - val_loss: 0.1871 - val_acc: 0.8065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0671 - acc: 0.9273 - val_loss: 0.1881 - val_acc: 0.7742\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0624 - acc: 0.9418 - val_loss: 0.1883 - val_acc: 0.7742\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0578 - acc: 0.9455 - val_loss: 0.1841 - val_acc: 0.8065\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0528 - acc: 0.9636 - val_loss: 0.1842 - val_acc: 0.8387\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0483 - acc: 0.9636 - val_loss: 0.1852 - val_acc: 0.8065\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0438 - acc: 0.9709 - val_loss: 0.1861 - val_acc: 0.8065\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0416 - acc: 0.9745 - val_loss: 0.1882 - val_acc: 0.8065\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0379 - acc: 0.9818 - val_loss: 0.1852 - val_acc: 0.8065\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0343 - acc: 0.9855 - val_loss: 0.1926 - val_acc: 0.8065\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0321 - acc: 0.9891 - val_loss: 0.1951 - val_acc: 0.7419\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0293 - acc: 0.9891 - val_loss: 0.1881 - val_acc: 0.7419\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0271 - acc: 0.9891 - val_loss: 0.1964 - val_acc: 0.7742\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0243 - acc: 0.9927 - val_loss: 0.1967 - val_acc: 0.7742\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0222 - acc: 0.9927 - val_loss: 0.1964 - val_acc: 0.7419\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0212 - acc: 0.9927 - val_loss: 0.1932 - val_acc: 0.8065\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0187 - acc: 0.9927 - val_loss: 0.1932 - val_acc: 0.7419\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0168 - acc: 0.9927 - val_loss: 0.1963 - val_acc: 0.7419\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0153 - acc: 0.9964 - val_loss: 0.1939 - val_acc: 0.8065\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0140 - acc: 0.9964 - val_loss: 0.1965 - val_acc: 0.7419\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0128 - acc: 0.9964 - val_loss: 0.1946 - val_acc: 0.8065\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0125 - acc: 0.9964 - val_loss: 0.1921 - val_acc: 0.7742\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0113 - acc: 0.9964 - val_loss: 0.1928 - val_acc: 0.7742\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0104 - acc: 0.9964 - val_loss: 0.1955 - val_acc: 0.7742\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0098 - acc: 0.9964 - val_loss: 0.1949 - val_acc: 0.8065\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0095 - acc: 0.9964 - val_loss: 0.1967 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0089 - acc: 0.9964 - val_loss: 0.1947 - val_acc: 0.7419\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0085 - acc: 0.9964 - val_loss: 0.1962 - val_acc: 0.7742\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0081 - acc: 0.9964 - val_loss: 0.1939 - val_acc: 0.7742\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0077 - acc: 0.9964 - val_loss: 0.1953 - val_acc: 0.7742\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0075 - acc: 0.9964 - val_loss: 0.1949 - val_acc: 0.7742\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0073 - acc: 0.9964 - val_loss: 0.1945 - val_acc: 0.7742\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0070 - acc: 0.9964 - val_loss: 0.1938 - val_acc: 0.7742\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0068 - acc: 0.9964 - val_loss: 0.1937 - val_acc: 0.7742\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0066 - acc: 0.9964 - val_loss: 0.1952 - val_acc: 0.7742\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0063 - acc: 0.9964 - val_loss: 0.1947 - val_acc: 0.7742\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0062 - acc: 0.9964 - val_loss: 0.1948 - val_acc: 0.7742\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0061 - acc: 0.9964 - val_loss: 0.1925 - val_acc: 0.7742\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0059 - acc: 0.9964 - val_loss: 0.1943 - val_acc: 0.7742\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0059 - acc: 0.9964 - val_loss: 0.1938 - val_acc: 0.7742\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0057 - acc: 0.9964 - val_loss: 0.1961 - val_acc: 0.7742\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0056 - acc: 0.9964 - val_loss: 0.1963 - val_acc: 0.7742\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.1958 - val_acc: 0.7742\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0054 - acc: 0.9964 - val_loss: 0.1949 - val_acc: 0.7742\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.1973 - val_acc: 0.7742\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.1965 - val_acc: 0.7742\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.1963 - val_acc: 0.7742\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.1979 - val_acc: 0.7742\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.1967 - val_acc: 0.7742\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.1982 - val_acc: 0.7742\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.1961 - val_acc: 0.7742\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0048 - acc: 0.9964 - val_loss: 0.1967 - val_acc: 0.7742\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0048 - acc: 0.9964 - val_loss: 0.1984 - val_acc: 0.7742\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0047 - acc: 0.9964 - val_loss: 0.1973 - val_acc: 0.7742\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0047 - acc: 0.9964 - val_loss: 0.1964 - val_acc: 0.7742\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_88 (Dense)             (None, 22)                858       \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 15)                345       \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 1,219\n",
      "Trainable params: 1,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 1s 4ms/step - loss: 0.2499 - acc: 0.5309 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2496 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.2490 - acc: 0.5418 - val_loss: 0.2486 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.2469 - acc: 0.5600 - val_loss: 0.2448 - val_acc: 0.6129\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.2409 - acc: 0.6545 - val_loss: 0.2365 - val_acc: 0.6774\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 214us/step - loss: 0.2301 - acc: 0.7236 - val_loss: 0.2245 - val_acc: 0.7097\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.2130 - acc: 0.7309 - val_loss: 0.2125 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1953 - acc: 0.7527 - val_loss: 0.2008 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1802 - acc: 0.7564 - val_loss: 0.2011 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1720 - acc: 0.7455 - val_loss: 0.2033 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1689 - acc: 0.7455 - val_loss: 0.2040 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1661 - acc: 0.7673 - val_loss: 0.2077 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1612 - acc: 0.7745 - val_loss: 0.2112 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1587 - acc: 0.7745 - val_loss: 0.2134 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1582 - acc: 0.7782 - val_loss: 0.2145 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1553 - acc: 0.7745 - val_loss: 0.2168 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1563 - acc: 0.7782 - val_loss: 0.2177 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1529 - acc: 0.7891 - val_loss: 0.2188 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 215us/step - loss: 0.1515 - acc: 0.7855 - val_loss: 0.2205 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1504 - acc: 0.7964 - val_loss: 0.2237 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1504 - acc: 0.7964 - val_loss: 0.2237 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1491 - acc: 0.8036 - val_loss: 0.2238 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1485 - acc: 0.8036 - val_loss: 0.2268 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1459 - acc: 0.8000 - val_loss: 0.2279 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1451 - acc: 0.8000 - val_loss: 0.2276 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1443 - acc: 0.8145 - val_loss: 0.2270 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1431 - acc: 0.8073 - val_loss: 0.2281 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1428 - acc: 0.8109 - val_loss: 0.2281 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1408 - acc: 0.8182 - val_loss: 0.2289 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1396 - acc: 0.8364 - val_loss: 0.2290 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1384 - acc: 0.8364 - val_loss: 0.2289 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1380 - acc: 0.8291 - val_loss: 0.2305 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1366 - acc: 0.8291 - val_loss: 0.2303 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1358 - acc: 0.8327 - val_loss: 0.2334 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1339 - acc: 0.8364 - val_loss: 0.2328 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1338 - acc: 0.8400 - val_loss: 0.2322 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1326 - acc: 0.8400 - val_loss: 0.2333 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1304 - acc: 0.8509 - val_loss: 0.2345 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1300 - acc: 0.8436 - val_loss: 0.2360 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1281 - acc: 0.8473 - val_loss: 0.2349 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1269 - acc: 0.8582 - val_loss: 0.2347 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1262 - acc: 0.8582 - val_loss: 0.2332 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1254 - acc: 0.8545 - val_loss: 0.2349 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1232 - acc: 0.8545 - val_loss: 0.2358 - val_acc: 0.7097\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1221 - acc: 0.8618 - val_loss: 0.2354 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1208 - acc: 0.8655 - val_loss: 0.2358 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1205 - acc: 0.8691 - val_loss: 0.2358 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1185 - acc: 0.8691 - val_loss: 0.2364 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1171 - acc: 0.8691 - val_loss: 0.2333 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1153 - acc: 0.8727 - val_loss: 0.2356 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 213us/step - loss: 0.1141 - acc: 0.8764 - val_loss: 0.2365 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1128 - acc: 0.8764 - val_loss: 0.2366 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1113 - acc: 0.8764 - val_loss: 0.2310 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1103 - acc: 0.8727 - val_loss: 0.2351 - val_acc: 0.7097\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1094 - acc: 0.8800 - val_loss: 0.2375 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1079 - acc: 0.8800 - val_loss: 0.2330 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1059 - acc: 0.8873 - val_loss: 0.2357 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1045 - acc: 0.8836 - val_loss: 0.2348 - val_acc: 0.7097\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1031 - acc: 0.8836 - val_loss: 0.2370 - val_acc: 0.7097\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1025 - acc: 0.8873 - val_loss: 0.2375 - val_acc: 0.7097\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 173us/step - loss: 0.1016 - acc: 0.8945 - val_loss: 0.2360 - val_acc: 0.7097\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1015 - acc: 0.8945 - val_loss: 0.2371 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0973 - acc: 0.9018 - val_loss: 0.2383 - val_acc: 0.7097\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0966 - acc: 0.8945 - val_loss: 0.2355 - val_acc: 0.7097\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0942 - acc: 0.9018 - val_loss: 0.2333 - val_acc: 0.7097\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0933 - acc: 0.8982 - val_loss: 0.2385 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0924 - acc: 0.9018 - val_loss: 0.2366 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0906 - acc: 0.9091 - val_loss: 0.2327 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0882 - acc: 0.9127 - val_loss: 0.2333 - val_acc: 0.7097\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0865 - acc: 0.9091 - val_loss: 0.2348 - val_acc: 0.7097\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0849 - acc: 0.9200 - val_loss: 0.2363 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0833 - acc: 0.9164 - val_loss: 0.2353 - val_acc: 0.7097\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0815 - acc: 0.9164 - val_loss: 0.2364 - val_acc: 0.7097\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0803 - acc: 0.9236 - val_loss: 0.2339 - val_acc: 0.7097\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0783 - acc: 0.9273 - val_loss: 0.2349 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0759 - acc: 0.9273 - val_loss: 0.2349 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0740 - acc: 0.9236 - val_loss: 0.2328 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0722 - acc: 0.9345 - val_loss: 0.2364 - val_acc: 0.7097\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0708 - acc: 0.9309 - val_loss: 0.2356 - val_acc: 0.7097\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0693 - acc: 0.9309 - val_loss: 0.2371 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0674 - acc: 0.9382 - val_loss: 0.2363 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0660 - acc: 0.9309 - val_loss: 0.2384 - val_acc: 0.7097\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0641 - acc: 0.9418 - val_loss: 0.2386 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0635 - acc: 0.9382 - val_loss: 0.2399 - val_acc: 0.7097\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0609 - acc: 0.9418 - val_loss: 0.2363 - val_acc: 0.7097\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0594 - acc: 0.9455 - val_loss: 0.2402 - val_acc: 0.7097\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0571 - acc: 0.9491 - val_loss: 0.2382 - val_acc: 0.7097\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0545 - acc: 0.9527 - val_loss: 0.2369 - val_acc: 0.7097\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0557 - acc: 0.9491 - val_loss: 0.2360 - val_acc: 0.7097\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0505 - acc: 0.9600 - val_loss: 0.2413 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0502 - acc: 0.9564 - val_loss: 0.2381 - val_acc: 0.7097\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0492 - acc: 0.9600 - val_loss: 0.2371 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0477 - acc: 0.9600 - val_loss: 0.2361 - val_acc: 0.7097\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0463 - acc: 0.9600 - val_loss: 0.2389 - val_acc: 0.7097\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0447 - acc: 0.9600 - val_loss: 0.2385 - val_acc: 0.7097\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0433 - acc: 0.9600 - val_loss: 0.2438 - val_acc: 0.6452\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0426 - acc: 0.9636 - val_loss: 0.2415 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0400 - acc: 0.9600 - val_loss: 0.2424 - val_acc: 0.7097\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0397 - acc: 0.9636 - val_loss: 0.2403 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0378 - acc: 0.9673 - val_loss: 0.2388 - val_acc: 0.7097\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_91 (Dense)             (None, 13)                507       \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 12)                168       \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 688\n",
      "Trainable params: 688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 4ms/step - loss: 0.2498 - acc: 0.5455 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2496 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.2490 - acc: 0.5418 - val_loss: 0.2489 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.2478 - acc: 0.5418 - val_loss: 0.2466 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.2439 - acc: 0.5418 - val_loss: 0.2423 - val_acc: 0.5161\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.2365 - acc: 0.5418 - val_loss: 0.2348 - val_acc: 0.5484\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.2268 - acc: 0.5891 - val_loss: 0.2284 - val_acc: 0.6129\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.2163 - acc: 0.6800 - val_loss: 0.2226 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.2065 - acc: 0.7164 - val_loss: 0.2168 - val_acc: 0.6452\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1979 - acc: 0.7273 - val_loss: 0.2142 - val_acc: 0.6452\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1897 - acc: 0.7418 - val_loss: 0.2096 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1831 - acc: 0.7564 - val_loss: 0.2112 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1771 - acc: 0.7527 - val_loss: 0.2072 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1731 - acc: 0.7636 - val_loss: 0.2078 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1687 - acc: 0.7564 - val_loss: 0.2082 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1658 - acc: 0.7564 - val_loss: 0.2136 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1629 - acc: 0.7745 - val_loss: 0.2089 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1605 - acc: 0.7745 - val_loss: 0.2137 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1590 - acc: 0.7818 - val_loss: 0.2173 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1577 - acc: 0.7745 - val_loss: 0.2160 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1565 - acc: 0.7855 - val_loss: 0.2176 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1552 - acc: 0.7782 - val_loss: 0.2173 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1546 - acc: 0.7818 - val_loss: 0.2169 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1524 - acc: 0.7891 - val_loss: 0.2183 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1508 - acc: 0.7927 - val_loss: 0.2206 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1500 - acc: 0.7927 - val_loss: 0.2180 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1488 - acc: 0.7927 - val_loss: 0.2206 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1478 - acc: 0.8000 - val_loss: 0.2210 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1462 - acc: 0.7964 - val_loss: 0.2204 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1453 - acc: 0.8109 - val_loss: 0.2216 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1446 - acc: 0.8073 - val_loss: 0.2210 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1430 - acc: 0.8218 - val_loss: 0.2220 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1424 - acc: 0.8145 - val_loss: 0.2226 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1411 - acc: 0.8145 - val_loss: 0.2231 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1403 - acc: 0.8109 - val_loss: 0.2222 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1390 - acc: 0.8291 - val_loss: 0.2219 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1384 - acc: 0.8145 - val_loss: 0.2234 - val_acc: 0.6452\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1376 - acc: 0.8218 - val_loss: 0.2206 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.1362 - acc: 0.8327 - val_loss: 0.2232 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1352 - acc: 0.8327 - val_loss: 0.2220 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1346 - acc: 0.8255 - val_loss: 0.2226 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1333 - acc: 0.8327 - val_loss: 0.2215 - val_acc: 0.6452\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1334 - acc: 0.8364 - val_loss: 0.2190 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1317 - acc: 0.8364 - val_loss: 0.2210 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1298 - acc: 0.8436 - val_loss: 0.2197 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1289 - acc: 0.8473 - val_loss: 0.2200 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1282 - acc: 0.8473 - val_loss: 0.2201 - val_acc: 0.6452\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1268 - acc: 0.8473 - val_loss: 0.2197 - val_acc: 0.6452\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.1255 - acc: 0.8545 - val_loss: 0.2187 - val_acc: 0.6452\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1248 - acc: 0.8509 - val_loss: 0.2202 - val_acc: 0.6452\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1230 - acc: 0.8473 - val_loss: 0.2219 - val_acc: 0.6452\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1231 - acc: 0.8509 - val_loss: 0.2210 - val_acc: 0.6452\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1215 - acc: 0.8618 - val_loss: 0.2234 - val_acc: 0.6452\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1199 - acc: 0.8618 - val_loss: 0.2207 - val_acc: 0.6452\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1190 - acc: 0.8582 - val_loss: 0.2197 - val_acc: 0.6452\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1177 - acc: 0.8545 - val_loss: 0.2183 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1166 - acc: 0.8618 - val_loss: 0.2205 - val_acc: 0.6452\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1161 - acc: 0.8764 - val_loss: 0.2190 - val_acc: 0.6452\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1144 - acc: 0.8655 - val_loss: 0.2182 - val_acc: 0.6452\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1123 - acc: 0.8691 - val_loss: 0.2204 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1105 - acc: 0.8800 - val_loss: 0.2213 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1095 - acc: 0.8691 - val_loss: 0.2220 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1084 - acc: 0.8764 - val_loss: 0.2232 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1061 - acc: 0.8836 - val_loss: 0.2222 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1046 - acc: 0.8909 - val_loss: 0.2198 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1026 - acc: 0.8873 - val_loss: 0.2230 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1003 - acc: 0.8909 - val_loss: 0.2239 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0990 - acc: 0.8873 - val_loss: 0.2259 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0979 - acc: 0.8873 - val_loss: 0.2316 - val_acc: 0.6129\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0955 - acc: 0.8945 - val_loss: 0.2320 - val_acc: 0.6129\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0943 - acc: 0.9018 - val_loss: 0.2297 - val_acc: 0.5806\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0924 - acc: 0.9127 - val_loss: 0.2323 - val_acc: 0.5806\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0903 - acc: 0.9055 - val_loss: 0.2365 - val_acc: 0.5806\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0885 - acc: 0.9055 - val_loss: 0.2345 - val_acc: 0.5806\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0866 - acc: 0.9236 - val_loss: 0.2378 - val_acc: 0.5806\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 171us/step - loss: 0.0858 - acc: 0.9055 - val_loss: 0.2447 - val_acc: 0.5806\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0840 - acc: 0.9236 - val_loss: 0.2432 - val_acc: 0.5806\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0820 - acc: 0.9236 - val_loss: 0.2402 - val_acc: 0.5806\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0806 - acc: 0.9200 - val_loss: 0.2446 - val_acc: 0.5806\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0781 - acc: 0.9273 - val_loss: 0.2507 - val_acc: 0.5806\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0766 - acc: 0.9309 - val_loss: 0.2473 - val_acc: 0.5806\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0753 - acc: 0.9273 - val_loss: 0.2473 - val_acc: 0.5484\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0733 - acc: 0.9382 - val_loss: 0.2513 - val_acc: 0.5806\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0719 - acc: 0.9418 - val_loss: 0.2509 - val_acc: 0.5806\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0711 - acc: 0.9382 - val_loss: 0.2528 - val_acc: 0.5484\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0690 - acc: 0.9418 - val_loss: 0.2549 - val_acc: 0.5484\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0675 - acc: 0.9382 - val_loss: 0.2557 - val_acc: 0.5484\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0670 - acc: 0.9455 - val_loss: 0.2583 - val_acc: 0.5484\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0645 - acc: 0.9418 - val_loss: 0.2600 - val_acc: 0.5484\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0639 - acc: 0.9455 - val_loss: 0.2642 - val_acc: 0.5484\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0628 - acc: 0.9418 - val_loss: 0.2655 - val_acc: 0.5484\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0607 - acc: 0.9491 - val_loss: 0.2681 - val_acc: 0.5484\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0593 - acc: 0.9491 - val_loss: 0.2692 - val_acc: 0.5484\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0580 - acc: 0.9527 - val_loss: 0.2707 - val_acc: 0.5484\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0580 - acc: 0.9491 - val_loss: 0.2734 - val_acc: 0.5806\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0567 - acc: 0.9564 - val_loss: 0.2757 - val_acc: 0.5484\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0549 - acc: 0.9564 - val_loss: 0.2742 - val_acc: 0.5806\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0531 - acc: 0.9564 - val_loss: 0.2775 - val_acc: 0.5484\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0530 - acc: 0.9564 - val_loss: 0.2742 - val_acc: 0.5806\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0502 - acc: 0.9600 - val_loss: 0.2789 - val_acc: 0.5806\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_94 (Dense)             (None, 46)                1794      \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 15)                705       \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 2,515\n",
      "Trainable params: 2,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 4ms/step - loss: 0.2498 - acc: 0.5382 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.2490 - acc: 0.5418 - val_loss: 0.2487 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.2461 - acc: 0.5418 - val_loss: 0.2442 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.2385 - acc: 0.5527 - val_loss: 0.2366 - val_acc: 0.6129\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.2252 - acc: 0.6364 - val_loss: 0.2283 - val_acc: 0.6129\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.2103 - acc: 0.7018 - val_loss: 0.2165 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1962 - acc: 0.7418 - val_loss: 0.2166 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1829 - acc: 0.7527 - val_loss: 0.2095 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1744 - acc: 0.7600 - val_loss: 0.2092 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1670 - acc: 0.7600 - val_loss: 0.2126 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1637 - acc: 0.7527 - val_loss: 0.2165 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1597 - acc: 0.7745 - val_loss: 0.2164 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.1563 - acc: 0.7855 - val_loss: 0.2181 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.1559 - acc: 0.7855 - val_loss: 0.2196 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1520 - acc: 0.7964 - val_loss: 0.2228 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1510 - acc: 0.8000 - val_loss: 0.2199 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1492 - acc: 0.8036 - val_loss: 0.2222 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1468 - acc: 0.8109 - val_loss: 0.2245 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1459 - acc: 0.8109 - val_loss: 0.2281 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1434 - acc: 0.8182 - val_loss: 0.2241 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1413 - acc: 0.8145 - val_loss: 0.2280 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1395 - acc: 0.8291 - val_loss: 0.2249 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1375 - acc: 0.8291 - val_loss: 0.2256 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1361 - acc: 0.8291 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1325 - acc: 0.8327 - val_loss: 0.2246 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1313 - acc: 0.8436 - val_loss: 0.2254 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1306 - acc: 0.8327 - val_loss: 0.2238 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1268 - acc: 0.8473 - val_loss: 0.2236 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1245 - acc: 0.8545 - val_loss: 0.2270 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1214 - acc: 0.8545 - val_loss: 0.2252 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1196 - acc: 0.8582 - val_loss: 0.2223 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1174 - acc: 0.8655 - val_loss: 0.2209 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1133 - acc: 0.8727 - val_loss: 0.2194 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1118 - acc: 0.8873 - val_loss: 0.2179 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1090 - acc: 0.8836 - val_loss: 0.2192 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1100 - acc: 0.8764 - val_loss: 0.2175 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1055 - acc: 0.8691 - val_loss: 0.2188 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0995 - acc: 0.8945 - val_loss: 0.2110 - val_acc: 0.7419\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.0958 - acc: 0.9055 - val_loss: 0.2116 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0924 - acc: 0.9091 - val_loss: 0.2109 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0905 - acc: 0.8909 - val_loss: 0.2142 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0874 - acc: 0.9091 - val_loss: 0.2112 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0818 - acc: 0.9200 - val_loss: 0.2093 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0789 - acc: 0.9273 - val_loss: 0.2058 - val_acc: 0.7419\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0774 - acc: 0.9273 - val_loss: 0.2126 - val_acc: 0.7419\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0726 - acc: 0.9382 - val_loss: 0.2090 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0698 - acc: 0.9491 - val_loss: 0.2084 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0664 - acc: 0.9455 - val_loss: 0.2049 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0638 - acc: 0.9455 - val_loss: 0.1991 - val_acc: 0.7419\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0615 - acc: 0.9564 - val_loss: 0.1988 - val_acc: 0.7742\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0581 - acc: 0.9527 - val_loss: 0.2000 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0544 - acc: 0.9527 - val_loss: 0.2067 - val_acc: 0.6452\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0530 - acc: 0.9564 - val_loss: 0.2051 - val_acc: 0.6452\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0490 - acc: 0.9600 - val_loss: 0.2027 - val_acc: 0.6452\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0469 - acc: 0.9636 - val_loss: 0.2031 - val_acc: 0.6452\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0435 - acc: 0.9709 - val_loss: 0.2036 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0404 - acc: 0.9709 - val_loss: 0.2037 - val_acc: 0.6129\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0382 - acc: 0.9745 - val_loss: 0.2051 - val_acc: 0.6129\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0376 - acc: 0.9745 - val_loss: 0.2016 - val_acc: 0.7097\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0339 - acc: 0.9745 - val_loss: 0.2082 - val_acc: 0.6129\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0329 - acc: 0.9818 - val_loss: 0.2126 - val_acc: 0.5806\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0309 - acc: 0.9818 - val_loss: 0.2094 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0283 - acc: 0.9818 - val_loss: 0.2116 - val_acc: 0.6129\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0268 - acc: 0.9818 - val_loss: 0.2090 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0252 - acc: 0.9818 - val_loss: 0.2010 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0245 - acc: 0.9855 - val_loss: 0.2100 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0230 - acc: 0.9855 - val_loss: 0.2146 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0218 - acc: 0.9855 - val_loss: 0.2206 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0210 - acc: 0.9891 - val_loss: 0.2125 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0187 - acc: 0.9891 - val_loss: 0.2174 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0181 - acc: 0.9891 - val_loss: 0.2196 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.0164 - acc: 0.9891 - val_loss: 0.2236 - val_acc: 0.6452\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0153 - acc: 0.9891 - val_loss: 0.2202 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0137 - acc: 0.9927 - val_loss: 0.2270 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0130 - acc: 0.9927 - val_loss: 0.2246 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0122 - acc: 0.9927 - val_loss: 0.2264 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0122 - acc: 0.9927 - val_loss: 0.2265 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0113 - acc: 0.9927 - val_loss: 0.2265 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0108 - acc: 0.9927 - val_loss: 0.2276 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0104 - acc: 0.9927 - val_loss: 0.2270 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0100 - acc: 0.9927 - val_loss: 0.2266 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0095 - acc: 0.9927 - val_loss: 0.2327 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0091 - acc: 0.9927 - val_loss: 0.2281 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0089 - acc: 0.9927 - val_loss: 0.2298 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.0086 - acc: 0.9927 - val_loss: 0.2307 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.0083 - acc: 0.9927 - val_loss: 0.2302 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0081 - acc: 0.9927 - val_loss: 0.2295 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0079 - acc: 0.9927 - val_loss: 0.2320 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0078 - acc: 0.9927 - val_loss: 0.2314 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0077 - acc: 0.9927 - val_loss: 0.2345 - val_acc: 0.6452\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 196us/step - loss: 0.0075 - acc: 0.9927 - val_loss: 0.2323 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0074 - acc: 0.9927 - val_loss: 0.2328 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0072 - acc: 0.9927 - val_loss: 0.2331 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0071 - acc: 0.9927 - val_loss: 0.2349 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 214us/step - loss: 0.0069 - acc: 0.9927 - val_loss: 0.2335 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0068 - acc: 0.9927 - val_loss: 0.2353 - val_acc: 0.6452\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0067 - acc: 0.9927 - val_loss: 0.2359 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0066 - acc: 0.9927 - val_loss: 0.2358 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0065 - acc: 0.9927 - val_loss: 0.2350 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0064 - acc: 0.9927 - val_loss: 0.2348 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_97 (Dense)             (None, 28)                1092      \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 13)                377       \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 1,483\n",
      "Trainable params: 1,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 4ms/step - loss: 0.2500 - acc: 0.5018 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2493 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.2485 - acc: 0.5418 - val_loss: 0.2476 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.2447 - acc: 0.5418 - val_loss: 0.2418 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.2362 - acc: 0.5564 - val_loss: 0.2322 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.2235 - acc: 0.6945 - val_loss: 0.2238 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.2087 - acc: 0.7055 - val_loss: 0.2169 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1969 - acc: 0.7273 - val_loss: 0.2116 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.1861 - acc: 0.7491 - val_loss: 0.2083 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1774 - acc: 0.7600 - val_loss: 0.2034 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1709 - acc: 0.7636 - val_loss: 0.2052 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1663 - acc: 0.7709 - val_loss: 0.2029 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1619 - acc: 0.7891 - val_loss: 0.2165 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1590 - acc: 0.7855 - val_loss: 0.2093 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1562 - acc: 0.7855 - val_loss: 0.2126 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1550 - acc: 0.8036 - val_loss: 0.2155 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.1530 - acc: 0.7964 - val_loss: 0.2138 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1509 - acc: 0.7964 - val_loss: 0.2200 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1505 - acc: 0.8073 - val_loss: 0.2162 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1486 - acc: 0.8109 - val_loss: 0.2193 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1462 - acc: 0.8036 - val_loss: 0.2183 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 261us/step - loss: 0.1459 - acc: 0.8145 - val_loss: 0.2191 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1443 - acc: 0.8073 - val_loss: 0.2213 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.1437 - acc: 0.8182 - val_loss: 0.2212 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1420 - acc: 0.8255 - val_loss: 0.2213 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1399 - acc: 0.8291 - val_loss: 0.2236 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1394 - acc: 0.8291 - val_loss: 0.2240 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.1387 - acc: 0.8291 - val_loss: 0.2250 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.1400 - acc: 0.8145 - val_loss: 0.2257 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1384 - acc: 0.8218 - val_loss: 0.2232 - val_acc: 0.7419\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1347 - acc: 0.8364 - val_loss: 0.2225 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1339 - acc: 0.8400 - val_loss: 0.2262 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1336 - acc: 0.8255 - val_loss: 0.2253 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1308 - acc: 0.8400 - val_loss: 0.2254 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1298 - acc: 0.8364 - val_loss: 0.2253 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1280 - acc: 0.8364 - val_loss: 0.2284 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.1271 - acc: 0.8327 - val_loss: 0.2272 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1251 - acc: 0.8436 - val_loss: 0.2274 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1231 - acc: 0.8509 - val_loss: 0.2269 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1215 - acc: 0.8582 - val_loss: 0.2286 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1204 - acc: 0.8545 - val_loss: 0.2287 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1185 - acc: 0.8618 - val_loss: 0.2269 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1159 - acc: 0.8582 - val_loss: 0.2264 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1146 - acc: 0.8691 - val_loss: 0.2274 - val_acc: 0.7097\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1119 - acc: 0.8727 - val_loss: 0.2284 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.1124 - acc: 0.8727 - val_loss: 0.2278 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1075 - acc: 0.8945 - val_loss: 0.2238 - val_acc: 0.7419\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1066 - acc: 0.8909 - val_loss: 0.2234 - val_acc: 0.7419\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.1038 - acc: 0.9091 - val_loss: 0.2243 - val_acc: 0.7419\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1018 - acc: 0.9091 - val_loss: 0.2238 - val_acc: 0.7419\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1004 - acc: 0.9091 - val_loss: 0.2235 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0979 - acc: 0.9055 - val_loss: 0.2230 - val_acc: 0.7419\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0961 - acc: 0.9127 - val_loss: 0.2217 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0945 - acc: 0.9055 - val_loss: 0.2218 - val_acc: 0.7097\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0918 - acc: 0.9164 - val_loss: 0.2216 - val_acc: 0.7419\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.0904 - acc: 0.9164 - val_loss: 0.2254 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0877 - acc: 0.9236 - val_loss: 0.2212 - val_acc: 0.7419\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0844 - acc: 0.9236 - val_loss: 0.2168 - val_acc: 0.7097\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 316us/step - loss: 0.0828 - acc: 0.9236 - val_loss: 0.2183 - val_acc: 0.7419\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.0800 - acc: 0.9309 - val_loss: 0.2164 - val_acc: 0.7419\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 261us/step - loss: 0.0789 - acc: 0.9236 - val_loss: 0.2171 - val_acc: 0.7419\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0769 - acc: 0.9236 - val_loss: 0.2185 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0743 - acc: 0.9309 - val_loss: 0.2099 - val_acc: 0.7742\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.0733 - acc: 0.9309 - val_loss: 0.2091 - val_acc: 0.7097\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0728 - acc: 0.9345 - val_loss: 0.2070 - val_acc: 0.7742\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0688 - acc: 0.9345 - val_loss: 0.2118 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0652 - acc: 0.9418 - val_loss: 0.2123 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0630 - acc: 0.9418 - val_loss: 0.2138 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0630 - acc: 0.9418 - val_loss: 0.2155 - val_acc: 0.7419\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0585 - acc: 0.9418 - val_loss: 0.2131 - val_acc: 0.7419\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0558 - acc: 0.9455 - val_loss: 0.2120 - val_acc: 0.7742\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0542 - acc: 0.9527 - val_loss: 0.2154 - val_acc: 0.7097\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0522 - acc: 0.9600 - val_loss: 0.2163 - val_acc: 0.7742\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0500 - acc: 0.9527 - val_loss: 0.2160 - val_acc: 0.7742\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0464 - acc: 0.9636 - val_loss: 0.2158 - val_acc: 0.7419\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 215us/step - loss: 0.0454 - acc: 0.9673 - val_loss: 0.2178 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.0426 - acc: 0.9600 - val_loss: 0.2247 - val_acc: 0.7419\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0439 - acc: 0.9564 - val_loss: 0.2240 - val_acc: 0.7097\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0389 - acc: 0.9745 - val_loss: 0.2192 - val_acc: 0.7419\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0372 - acc: 0.9782 - val_loss: 0.2210 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0368 - acc: 0.9709 - val_loss: 0.2275 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0362 - acc: 0.9818 - val_loss: 0.2229 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0316 - acc: 0.9818 - val_loss: 0.2287 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0301 - acc: 0.9855 - val_loss: 0.2314 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0272 - acc: 0.9891 - val_loss: 0.2385 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0267 - acc: 0.9891 - val_loss: 0.2364 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0246 - acc: 0.9891 - val_loss: 0.2373 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0248 - acc: 0.9855 - val_loss: 0.2331 - val_acc: 0.7097\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0225 - acc: 0.9891 - val_loss: 0.2367 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.0214 - acc: 0.9891 - val_loss: 0.2415 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0213 - acc: 0.9891 - val_loss: 0.2402 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0210 - acc: 0.9855 - val_loss: 0.2460 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0208 - acc: 0.9855 - val_loss: 0.2447 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0201 - acc: 0.9891 - val_loss: 0.2386 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0180 - acc: 0.9891 - val_loss: 0.2379 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0165 - acc: 0.9891 - val_loss: 0.2465 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0166 - acc: 0.9891 - val_loss: 0.2434 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0159 - acc: 0.9855 - val_loss: 0.2423 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0160 - acc: 0.9855 - val_loss: 0.2413 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0146 - acc: 0.9855 - val_loss: 0.2459 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_100 (Dense)            (None, 48)                1872      \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 14)                686       \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 2,573\n",
      "Trainable params: 2,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 4ms/step - loss: 0.2500 - acc: 0.4945 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2495 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.2489 - acc: 0.5891 - val_loss: 0.2479 - val_acc: 0.6129\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.2451 - acc: 0.6873 - val_loss: 0.2417 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.2343 - acc: 0.7527 - val_loss: 0.2295 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.2157 - acc: 0.7455 - val_loss: 0.2110 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1931 - acc: 0.7382 - val_loss: 0.1960 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1781 - acc: 0.7345 - val_loss: 0.1981 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1697 - acc: 0.7527 - val_loss: 0.2007 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1646 - acc: 0.7527 - val_loss: 0.2041 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1618 - acc: 0.7527 - val_loss: 0.2071 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1586 - acc: 0.7745 - val_loss: 0.2105 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.1569 - acc: 0.7673 - val_loss: 0.2151 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1547 - acc: 0.7636 - val_loss: 0.2124 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1526 - acc: 0.7709 - val_loss: 0.2138 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1528 - acc: 0.7745 - val_loss: 0.2145 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1504 - acc: 0.7891 - val_loss: 0.2167 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1489 - acc: 0.7891 - val_loss: 0.2170 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1478 - acc: 0.7964 - val_loss: 0.2156 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1462 - acc: 0.7891 - val_loss: 0.2178 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.1446 - acc: 0.8000 - val_loss: 0.2184 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.1425 - acc: 0.8109 - val_loss: 0.2163 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1433 - acc: 0.8000 - val_loss: 0.2159 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1400 - acc: 0.8145 - val_loss: 0.2177 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1380 - acc: 0.8109 - val_loss: 0.2149 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1364 - acc: 0.8327 - val_loss: 0.2169 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1353 - acc: 0.8255 - val_loss: 0.2162 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1329 - acc: 0.8291 - val_loss: 0.2178 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1317 - acc: 0.8255 - val_loss: 0.2173 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1303 - acc: 0.8400 - val_loss: 0.2150 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1281 - acc: 0.8291 - val_loss: 0.2188 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1266 - acc: 0.8327 - val_loss: 0.2168 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1235 - acc: 0.8473 - val_loss: 0.2158 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1238 - acc: 0.8364 - val_loss: 0.2182 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1194 - acc: 0.8364 - val_loss: 0.2174 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1165 - acc: 0.8582 - val_loss: 0.2157 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1155 - acc: 0.8764 - val_loss: 0.2130 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1125 - acc: 0.8655 - val_loss: 0.2147 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1120 - acc: 0.8691 - val_loss: 0.2174 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1092 - acc: 0.8582 - val_loss: 0.2151 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1051 - acc: 0.8618 - val_loss: 0.2121 - val_acc: 0.7419\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1026 - acc: 0.8727 - val_loss: 0.2146 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0997 - acc: 0.8873 - val_loss: 0.2112 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0960 - acc: 0.8945 - val_loss: 0.2114 - val_acc: 0.7097\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.0941 - acc: 0.8982 - val_loss: 0.2126 - val_acc: 0.7419\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.0904 - acc: 0.9055 - val_loss: 0.2113 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0902 - acc: 0.9018 - val_loss: 0.2083 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0877 - acc: 0.9127 - val_loss: 0.2112 - val_acc: 0.7419\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0823 - acc: 0.9127 - val_loss: 0.2126 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0802 - acc: 0.9127 - val_loss: 0.2088 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0781 - acc: 0.9200 - val_loss: 0.2104 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0739 - acc: 0.9382 - val_loss: 0.2080 - val_acc: 0.6452\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.0712 - acc: 0.9345 - val_loss: 0.2071 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0687 - acc: 0.9382 - val_loss: 0.2084 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0677 - acc: 0.9345 - val_loss: 0.2011 - val_acc: 0.7419\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0627 - acc: 0.9491 - val_loss: 0.2049 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0606 - acc: 0.9564 - val_loss: 0.2013 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0577 - acc: 0.9600 - val_loss: 0.1999 - val_acc: 0.7419\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0558 - acc: 0.9600 - val_loss: 0.2084 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.0528 - acc: 0.9673 - val_loss: 0.1993 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0513 - acc: 0.9636 - val_loss: 0.2115 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0468 - acc: 0.9673 - val_loss: 0.2060 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0446 - acc: 0.9745 - val_loss: 0.2044 - val_acc: 0.7419\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.0419 - acc: 0.9745 - val_loss: 0.2030 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0397 - acc: 0.9818 - val_loss: 0.2092 - val_acc: 0.7419\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0367 - acc: 0.9818 - val_loss: 0.2033 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.0340 - acc: 0.9818 - val_loss: 0.2093 - val_acc: 0.7419\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0328 - acc: 0.9818 - val_loss: 0.2130 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.0300 - acc: 0.9855 - val_loss: 0.2125 - val_acc: 0.7097\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0292 - acc: 0.9891 - val_loss: 0.2155 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0267 - acc: 0.9855 - val_loss: 0.2171 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.0261 - acc: 0.9891 - val_loss: 0.2138 - val_acc: 0.7097\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0239 - acc: 0.9855 - val_loss: 0.2155 - val_acc: 0.7419\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0224 - acc: 0.9891 - val_loss: 0.2151 - val_acc: 0.7419\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0211 - acc: 0.9891 - val_loss: 0.2158 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0201 - acc: 0.9927 - val_loss: 0.2166 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0182 - acc: 0.9927 - val_loss: 0.2150 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.0177 - acc: 0.9927 - val_loss: 0.2204 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0165 - acc: 0.9927 - val_loss: 0.2203 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0159 - acc: 0.9927 - val_loss: 0.2184 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0152 - acc: 0.9927 - val_loss: 0.2222 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0148 - acc: 0.9927 - val_loss: 0.2266 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0141 - acc: 0.9927 - val_loss: 0.2207 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0139 - acc: 0.9927 - val_loss: 0.2227 - val_acc: 0.7097\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0133 - acc: 0.9927 - val_loss: 0.2266 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0128 - acc: 0.9927 - val_loss: 0.2228 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0126 - acc: 0.9927 - val_loss: 0.2249 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0121 - acc: 0.9927 - val_loss: 0.2292 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0120 - acc: 0.9927 - val_loss: 0.2276 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0116 - acc: 0.9927 - val_loss: 0.2248 - val_acc: 0.7097\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0114 - acc: 0.9927 - val_loss: 0.2285 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.0111 - acc: 0.9927 - val_loss: 0.2302 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.0109 - acc: 0.9927 - val_loss: 0.2301 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.0107 - acc: 0.9927 - val_loss: 0.2294 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.0105 - acc: 0.9927 - val_loss: 0.2293 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.0104 - acc: 0.9927 - val_loss: 0.2297 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.0102 - acc: 0.9927 - val_loss: 0.2310 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0100 - acc: 0.9927 - val_loss: 0.2292 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 215us/step - loss: 0.0099 - acc: 0.9927 - val_loss: 0.2298 - val_acc: 0.7097\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0098 - acc: 0.9927 - val_loss: 0.2332 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_103 (Dense)            (None, 42)                1638      \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 18)                774       \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 2,431\n",
      "Trainable params: 2,431\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 5ms/step - loss: 0.2500 - acc: 0.5491 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.2494 - acc: 0.5418 - val_loss: 0.2490 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.2473 - acc: 0.6073 - val_loss: 0.2455 - val_acc: 0.6129\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.2388 - acc: 0.7127 - val_loss: 0.2337 - val_acc: 0.6129\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.2191 - acc: 0.7309 - val_loss: 0.2166 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1940 - acc: 0.7527 - val_loss: 0.2039 - val_acc: 0.7097\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1759 - acc: 0.7564 - val_loss: 0.2007 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1663 - acc: 0.7564 - val_loss: 0.2040 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1624 - acc: 0.7709 - val_loss: 0.2118 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1569 - acc: 0.7855 - val_loss: 0.2088 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1529 - acc: 0.7891 - val_loss: 0.2148 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1511 - acc: 0.7891 - val_loss: 0.2188 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1486 - acc: 0.7964 - val_loss: 0.2177 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1458 - acc: 0.8145 - val_loss: 0.2192 - val_acc: 0.7097\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 260us/step - loss: 0.1429 - acc: 0.8145 - val_loss: 0.2237 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1402 - acc: 0.8255 - val_loss: 0.2160 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1380 - acc: 0.8182 - val_loss: 0.2160 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1351 - acc: 0.8327 - val_loss: 0.2205 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1334 - acc: 0.8291 - val_loss: 0.2211 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1309 - acc: 0.8364 - val_loss: 0.2217 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.1289 - acc: 0.8364 - val_loss: 0.2246 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.1264 - acc: 0.8436 - val_loss: 0.2248 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.1214 - acc: 0.8545 - val_loss: 0.2240 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.1189 - acc: 0.8545 - val_loss: 0.2246 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1171 - acc: 0.8582 - val_loss: 0.2272 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1142 - acc: 0.8545 - val_loss: 0.2223 - val_acc: 0.7419\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1095 - acc: 0.8691 - val_loss: 0.2237 - val_acc: 0.7419\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1049 - acc: 0.8873 - val_loss: 0.2221 - val_acc: 0.7419\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1013 - acc: 0.8945 - val_loss: 0.2243 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0971 - acc: 0.8982 - val_loss: 0.2282 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0943 - acc: 0.9091 - val_loss: 0.2276 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0879 - acc: 0.9236 - val_loss: 0.2284 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0859 - acc: 0.9164 - val_loss: 0.2287 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0804 - acc: 0.9164 - val_loss: 0.2265 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0762 - acc: 0.9345 - val_loss: 0.2280 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0713 - acc: 0.9382 - val_loss: 0.2296 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0662 - acc: 0.9491 - val_loss: 0.2215 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0643 - acc: 0.9491 - val_loss: 0.2180 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0561 - acc: 0.9600 - val_loss: 0.2186 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0531 - acc: 0.9600 - val_loss: 0.2157 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0483 - acc: 0.9673 - val_loss: 0.2231 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0446 - acc: 0.9782 - val_loss: 0.2244 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0418 - acc: 0.9818 - val_loss: 0.2283 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0371 - acc: 0.9855 - val_loss: 0.2256 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0359 - acc: 0.9855 - val_loss: 0.2260 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.0322 - acc: 0.9855 - val_loss: 0.2268 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.0320 - acc: 0.9818 - val_loss: 0.2289 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0310 - acc: 0.9891 - val_loss: 0.2391 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0261 - acc: 0.9891 - val_loss: 0.2352 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0242 - acc: 0.9891 - val_loss: 0.2409 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0231 - acc: 0.9891 - val_loss: 0.2389 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.0220 - acc: 0.9891 - val_loss: 0.2425 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0209 - acc: 0.9891 - val_loss: 0.2378 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0202 - acc: 0.9891 - val_loss: 0.2425 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0190 - acc: 0.9891 - val_loss: 0.2404 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0175 - acc: 0.9891 - val_loss: 0.2426 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0167 - acc: 0.9891 - val_loss: 0.2482 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0156 - acc: 0.9927 - val_loss: 0.2376 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0141 - acc: 0.9927 - val_loss: 0.2455 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0131 - acc: 0.9927 - val_loss: 0.2501 - val_acc: 0.6452\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.0117 - acc: 0.9964 - val_loss: 0.2514 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.0106 - acc: 0.9964 - val_loss: 0.2540 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0098 - acc: 0.9964 - val_loss: 0.2584 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0100 - acc: 0.9964 - val_loss: 0.2518 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0089 - acc: 0.9964 - val_loss: 0.2580 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0083 - acc: 0.9964 - val_loss: 0.2547 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0079 - acc: 0.9964 - val_loss: 0.2591 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0077 - acc: 0.9964 - val_loss: 0.2554 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0074 - acc: 0.9964 - val_loss: 0.2614 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0069 - acc: 0.9964 - val_loss: 0.2620 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.0067 - acc: 0.9964 - val_loss: 0.2620 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 214us/step - loss: 0.0063 - acc: 0.9964 - val_loss: 0.2613 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0059 - acc: 0.9964 - val_loss: 0.2569 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0044 - acc: 0.9964 - val_loss: 0.2589 - val_acc: 0.6774\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 214us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.2574 - val_acc: 0.6452\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.2597 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.2611 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.2591 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.2618 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2628 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.2655 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2675 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.2682 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2677 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2680 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2700 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2703 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2710 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2727 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.2708 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 9.9849e-04 - acc: 1.0000 - val_loss: 0.2741 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 9.4323e-04 - acc: 1.0000 - val_loss: 0.2754 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 8.7832e-04 - acc: 1.0000 - val_loss: 0.2750 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 8.4576e-04 - acc: 1.0000 - val_loss: 0.2760 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 7.9047e-04 - acc: 1.0000 - val_loss: 0.2761 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 7.5489e-04 - acc: 1.0000 - val_loss: 0.2771 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 7.2042e-04 - acc: 1.0000 - val_loss: 0.2769 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 6.8074e-04 - acc: 1.0000 - val_loss: 0.2776 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 6.4569e-04 - acc: 1.0000 - val_loss: 0.2781 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 6.1924e-04 - acc: 1.0000 - val_loss: 0.2784 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_106 (Dense)            (None, 28)                1092      \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 20)                580       \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,693\n",
      "Trainable params: 1,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 4ms/step - loss: 0.2499 - acc: 0.5345 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.2493 - acc: 0.5418 - val_loss: 0.2488 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.2466 - acc: 0.5418 - val_loss: 0.2455 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.2404 - acc: 0.5418 - val_loss: 0.2380 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.2285 - acc: 0.6000 - val_loss: 0.2293 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.2159 - acc: 0.6836 - val_loss: 0.2209 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.2034 - acc: 0.7418 - val_loss: 0.2214 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1938 - acc: 0.7309 - val_loss: 0.2159 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1855 - acc: 0.7455 - val_loss: 0.2102 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1768 - acc: 0.7564 - val_loss: 0.2114 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1715 - acc: 0.7709 - val_loss: 0.2087 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1665 - acc: 0.7818 - val_loss: 0.2096 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1618 - acc: 0.7709 - val_loss: 0.2157 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1589 - acc: 0.7891 - val_loss: 0.2139 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1555 - acc: 0.7891 - val_loss: 0.2165 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1534 - acc: 0.7927 - val_loss: 0.2175 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1508 - acc: 0.8145 - val_loss: 0.2225 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1493 - acc: 0.8109 - val_loss: 0.2246 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1467 - acc: 0.8145 - val_loss: 0.2252 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1466 - acc: 0.8145 - val_loss: 0.2283 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1446 - acc: 0.8145 - val_loss: 0.2285 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1435 - acc: 0.8218 - val_loss: 0.2266 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1402 - acc: 0.8255 - val_loss: 0.2291 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1389 - acc: 0.8218 - val_loss: 0.2277 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1383 - acc: 0.8218 - val_loss: 0.2264 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1375 - acc: 0.8145 - val_loss: 0.2291 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1341 - acc: 0.8255 - val_loss: 0.2291 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1321 - acc: 0.8327 - val_loss: 0.2297 - val_acc: 0.6774\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 182us/step - loss: 0.1307 - acc: 0.8364 - val_loss: 0.2286 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1284 - acc: 0.8400 - val_loss: 0.2312 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1270 - acc: 0.8473 - val_loss: 0.2322 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1250 - acc: 0.8509 - val_loss: 0.2321 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1233 - acc: 0.8509 - val_loss: 0.2336 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1204 - acc: 0.8582 - val_loss: 0.2306 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1181 - acc: 0.8545 - val_loss: 0.2319 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1157 - acc: 0.8691 - val_loss: 0.2296 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1136 - acc: 0.8764 - val_loss: 0.2291 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1110 - acc: 0.8836 - val_loss: 0.2287 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.1083 - acc: 0.8836 - val_loss: 0.2263 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1062 - acc: 0.8982 - val_loss: 0.2261 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.1032 - acc: 0.8945 - val_loss: 0.2240 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1010 - acc: 0.8945 - val_loss: 0.2223 - val_acc: 0.6452\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0991 - acc: 0.9091 - val_loss: 0.2240 - val_acc: 0.6452\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0954 - acc: 0.9055 - val_loss: 0.2183 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0927 - acc: 0.9127 - val_loss: 0.2179 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.0899 - acc: 0.9164 - val_loss: 0.2130 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.0866 - acc: 0.9236 - val_loss: 0.2141 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0849 - acc: 0.9309 - val_loss: 0.2132 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0813 - acc: 0.9309 - val_loss: 0.2104 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0778 - acc: 0.9382 - val_loss: 0.2101 - val_acc: 0.7419\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0762 - acc: 0.9382 - val_loss: 0.2090 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0725 - acc: 0.9418 - val_loss: 0.2097 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0699 - acc: 0.9418 - val_loss: 0.2029 - val_acc: 0.7419\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.0673 - acc: 0.9418 - val_loss: 0.2007 - val_acc: 0.7419\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0632 - acc: 0.9418 - val_loss: 0.1976 - val_acc: 0.7742\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 213us/step - loss: 0.0638 - acc: 0.9418 - val_loss: 0.2031 - val_acc: 0.7419\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0575 - acc: 0.9564 - val_loss: 0.1976 - val_acc: 0.7742\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 280us/step - loss: 0.0555 - acc: 0.9600 - val_loss: 0.1929 - val_acc: 0.7742\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.0501 - acc: 0.9636 - val_loss: 0.1977 - val_acc: 0.7742\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0471 - acc: 0.9673 - val_loss: 0.1950 - val_acc: 0.7742\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0438 - acc: 0.9709 - val_loss: 0.1937 - val_acc: 0.7419\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0408 - acc: 0.9709 - val_loss: 0.2035 - val_acc: 0.7419\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0397 - acc: 0.9745 - val_loss: 0.2059 - val_acc: 0.7742\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0376 - acc: 0.9782 - val_loss: 0.2027 - val_acc: 0.7742\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.0339 - acc: 0.9818 - val_loss: 0.1990 - val_acc: 0.7742\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.0321 - acc: 0.9818 - val_loss: 0.1992 - val_acc: 0.7742\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 306us/step - loss: 0.0300 - acc: 0.9818 - val_loss: 0.1965 - val_acc: 0.7742\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 277us/step - loss: 0.0286 - acc: 0.9818 - val_loss: 0.1950 - val_acc: 0.7742\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 303us/step - loss: 0.0274 - acc: 0.9818 - val_loss: 0.1999 - val_acc: 0.7742\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0265 - acc: 0.9818 - val_loss: 0.2012 - val_acc: 0.7742\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0252 - acc: 0.9818 - val_loss: 0.1976 - val_acc: 0.7419\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0253 - acc: 0.9818 - val_loss: 0.1981 - val_acc: 0.7742\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0230 - acc: 0.9855 - val_loss: 0.1981 - val_acc: 0.7742\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0225 - acc: 0.9855 - val_loss: 0.1965 - val_acc: 0.7742\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0212 - acc: 0.9855 - val_loss: 0.1918 - val_acc: 0.7742\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0207 - acc: 0.9855 - val_loss: 0.1967 - val_acc: 0.7742\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0198 - acc: 0.9855 - val_loss: 0.1946 - val_acc: 0.7742\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0188 - acc: 0.9855 - val_loss: 0.1963 - val_acc: 0.7742\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0186 - acc: 0.9855 - val_loss: 0.1882 - val_acc: 0.7742\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0178 - acc: 0.9891 - val_loss: 0.1921 - val_acc: 0.7742\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0171 - acc: 0.9891 - val_loss: 0.1868 - val_acc: 0.8065\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0170 - acc: 0.9818 - val_loss: 0.1922 - val_acc: 0.7742\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0163 - acc: 0.9891 - val_loss: 0.1900 - val_acc: 0.8065\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.0145 - acc: 0.9927 - val_loss: 0.1869 - val_acc: 0.8065\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.0144 - acc: 0.9927 - val_loss: 0.1881 - val_acc: 0.8065\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0144 - acc: 0.9891 - val_loss: 0.1928 - val_acc: 0.7742\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0135 - acc: 0.9927 - val_loss: 0.1853 - val_acc: 0.8065\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0125 - acc: 0.9927 - val_loss: 0.1882 - val_acc: 0.8065\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 190us/step - loss: 0.0111 - acc: 0.9927 - val_loss: 0.1867 - val_acc: 0.8065\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0104 - acc: 0.9964 - val_loss: 0.1891 - val_acc: 0.8065\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0097 - acc: 0.9964 - val_loss: 0.1870 - val_acc: 0.8065\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0097 - acc: 0.9964 - val_loss: 0.1901 - val_acc: 0.8065\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0096 - acc: 0.9964 - val_loss: 0.1859 - val_acc: 0.8065\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0100 - acc: 0.9964 - val_loss: 0.1881 - val_acc: 0.8065\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0083 - acc: 0.9964 - val_loss: 0.1848 - val_acc: 0.8065\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0082 - acc: 0.9964 - val_loss: 0.1875 - val_acc: 0.8065\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0077 - acc: 0.9964 - val_loss: 0.1891 - val_acc: 0.8065\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0074 - acc: 0.9964 - val_loss: 0.1877 - val_acc: 0.8065\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0072 - acc: 0.9964 - val_loss: 0.1902 - val_acc: 0.8065\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0069 - acc: 0.9964 - val_loss: 0.1877 - val_acc: 0.8065\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_109 (Dense)            (None, 48)                1872      \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 15)                735       \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 2,623\n",
      "Trainable params: 2,623\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 5ms/step - loss: 0.2500 - acc: 0.5382 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.2494 - acc: 0.5418 - val_loss: 0.2492 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.2475 - acc: 0.5418 - val_loss: 0.2457 - val_acc: 0.5484\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.2400 - acc: 0.6036 - val_loss: 0.2363 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.2236 - acc: 0.6982 - val_loss: 0.2222 - val_acc: 0.6774\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 281us/step - loss: 0.2033 - acc: 0.7309 - val_loss: 0.2067 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 283us/step - loss: 0.1833 - acc: 0.7527 - val_loss: 0.2058 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.1729 - acc: 0.7564 - val_loss: 0.2027 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.1656 - acc: 0.7673 - val_loss: 0.2069 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1623 - acc: 0.7709 - val_loss: 0.2054 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1580 - acc: 0.7891 - val_loss: 0.2117 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1551 - acc: 0.7855 - val_loss: 0.2165 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1535 - acc: 0.7782 - val_loss: 0.2179 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1515 - acc: 0.7927 - val_loss: 0.2178 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1487 - acc: 0.8109 - val_loss: 0.2210 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1473 - acc: 0.7964 - val_loss: 0.2239 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1455 - acc: 0.8036 - val_loss: 0.2214 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1434 - acc: 0.8109 - val_loss: 0.2236 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.1415 - acc: 0.8291 - val_loss: 0.2216 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1383 - acc: 0.8218 - val_loss: 0.2234 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.1367 - acc: 0.8327 - val_loss: 0.2219 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1350 - acc: 0.8255 - val_loss: 0.2230 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.1320 - acc: 0.8364 - val_loss: 0.2251 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 268us/step - loss: 0.1296 - acc: 0.8400 - val_loss: 0.2249 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.1263 - acc: 0.8436 - val_loss: 0.2208 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1247 - acc: 0.8327 - val_loss: 0.2233 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1217 - acc: 0.8473 - val_loss: 0.2212 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1190 - acc: 0.8509 - val_loss: 0.2255 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1175 - acc: 0.8691 - val_loss: 0.2253 - val_acc: 0.6452\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1141 - acc: 0.8618 - val_loss: 0.2238 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1102 - acc: 0.8655 - val_loss: 0.2254 - val_acc: 0.6452\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.1061 - acc: 0.8800 - val_loss: 0.2247 - val_acc: 0.6452\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.1030 - acc: 0.8909 - val_loss: 0.2274 - val_acc: 0.6452\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1006 - acc: 0.8909 - val_loss: 0.2323 - val_acc: 0.6452\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0976 - acc: 0.9055 - val_loss: 0.2245 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0931 - acc: 0.9127 - val_loss: 0.2310 - val_acc: 0.6129\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.0901 - acc: 0.9200 - val_loss: 0.2305 - val_acc: 0.6129\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.0860 - acc: 0.9273 - val_loss: 0.2270 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 300us/step - loss: 0.0844 - acc: 0.9273 - val_loss: 0.2261 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 308us/step - loss: 0.0795 - acc: 0.9345 - val_loss: 0.2294 - val_acc: 0.6129\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.0763 - acc: 0.9345 - val_loss: 0.2320 - val_acc: 0.6129\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.0735 - acc: 0.9345 - val_loss: 0.2342 - val_acc: 0.6452\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0693 - acc: 0.9382 - val_loss: 0.2342 - val_acc: 0.6129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0667 - acc: 0.9382 - val_loss: 0.2347 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0631 - acc: 0.9345 - val_loss: 0.2365 - val_acc: 0.6129\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0577 - acc: 0.9527 - val_loss: 0.2350 - val_acc: 0.6129\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0554 - acc: 0.9600 - val_loss: 0.2333 - val_acc: 0.6129\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0502 - acc: 0.9600 - val_loss: 0.2265 - val_acc: 0.6129\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0477 - acc: 0.9709 - val_loss: 0.2330 - val_acc: 0.6129\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0455 - acc: 0.9745 - val_loss: 0.2422 - val_acc: 0.6129\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0422 - acc: 0.9745 - val_loss: 0.2354 - val_acc: 0.6129\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0404 - acc: 0.9782 - val_loss: 0.2347 - val_acc: 0.6129\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0370 - acc: 0.9782 - val_loss: 0.2414 - val_acc: 0.6129\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0345 - acc: 0.9782 - val_loss: 0.2325 - val_acc: 0.6129\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0323 - acc: 0.9782 - val_loss: 0.2313 - val_acc: 0.6129\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0308 - acc: 0.9818 - val_loss: 0.2334 - val_acc: 0.6129\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0279 - acc: 0.9855 - val_loss: 0.2313 - val_acc: 0.6129\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0265 - acc: 0.9855 - val_loss: 0.2320 - val_acc: 0.6129\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0249 - acc: 0.9891 - val_loss: 0.2313 - val_acc: 0.6129\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0230 - acc: 0.9891 - val_loss: 0.2370 - val_acc: 0.6129\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0220 - acc: 0.9855 - val_loss: 0.2271 - val_acc: 0.6129\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0204 - acc: 0.9891 - val_loss: 0.2290 - val_acc: 0.6129\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0188 - acc: 0.9927 - val_loss: 0.2311 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0182 - acc: 0.9927 - val_loss: 0.2304 - val_acc: 0.6129\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0168 - acc: 0.9927 - val_loss: 0.2304 - val_acc: 0.6129\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0162 - acc: 0.9927 - val_loss: 0.2280 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0156 - acc: 0.9927 - val_loss: 0.2335 - val_acc: 0.6129\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0149 - acc: 0.9927 - val_loss: 0.2368 - val_acc: 0.6129\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0143 - acc: 0.9927 - val_loss: 0.2331 - val_acc: 0.5806\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0135 - acc: 0.9927 - val_loss: 0.2346 - val_acc: 0.6129\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0132 - acc: 0.9927 - val_loss: 0.2371 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0126 - acc: 0.9927 - val_loss: 0.2319 - val_acc: 0.6129\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0124 - acc: 0.9927 - val_loss: 0.2401 - val_acc: 0.6129\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0115 - acc: 0.9927 - val_loss: 0.2377 - val_acc: 0.6129\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0117 - acc: 0.9927 - val_loss: 0.2397 - val_acc: 0.6129\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0110 - acc: 0.9927 - val_loss: 0.2409 - val_acc: 0.6129\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0111 - acc: 0.9927 - val_loss: 0.2427 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0102 - acc: 0.9927 - val_loss: 0.2455 - val_acc: 0.5806\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0094 - acc: 0.9927 - val_loss: 0.2528 - val_acc: 0.5806\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0090 - acc: 0.9927 - val_loss: 0.2529 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0078 - acc: 0.9964 - val_loss: 0.2542 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.0074 - acc: 0.9964 - val_loss: 0.2519 - val_acc: 0.5806\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 315us/step - loss: 0.0068 - acc: 0.9964 - val_loss: 0.2523 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 289us/step - loss: 0.0065 - acc: 0.9964 - val_loss: 0.2553 - val_acc: 0.5806\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 285us/step - loss: 0.0063 - acc: 0.9964 - val_loss: 0.2543 - val_acc: 0.6129\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 277us/step - loss: 0.0061 - acc: 0.9964 - val_loss: 0.2553 - val_acc: 0.6129\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.0060 - acc: 0.9964 - val_loss: 0.2543 - val_acc: 0.5806\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.0060 - acc: 0.9964 - val_loss: 0.2544 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0057 - acc: 0.9964 - val_loss: 0.2539 - val_acc: 0.6129\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0056 - acc: 0.9964 - val_loss: 0.2548 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.2565 - val_acc: 0.6129\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0054 - acc: 0.9964 - val_loss: 0.2558 - val_acc: 0.6129\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.2554 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.2565 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.2560 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2560 - val_acc: 0.6452\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.2572 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.2566 - val_acc: 0.6129\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.2558 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.2579 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_112 (Dense)            (None, 36)                1404      \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 16)                592       \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,013\n",
      "Trainable params: 2,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 5ms/step - loss: 0.2498 - acc: 0.5455 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.2492 - acc: 0.5418 - val_loss: 0.2488 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.2465 - acc: 0.5418 - val_loss: 0.2444 - val_acc: 0.5484\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.2383 - acc: 0.5818 - val_loss: 0.2350 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.2249 - acc: 0.6145 - val_loss: 0.2241 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.2087 - acc: 0.7200 - val_loss: 0.2194 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1950 - acc: 0.7418 - val_loss: 0.2092 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.1830 - acc: 0.7418 - val_loss: 0.2097 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1737 - acc: 0.7455 - val_loss: 0.2096 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.1669 - acc: 0.7564 - val_loss: 0.2124 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1619 - acc: 0.7745 - val_loss: 0.2189 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1586 - acc: 0.7745 - val_loss: 0.2207 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1554 - acc: 0.7891 - val_loss: 0.2236 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1534 - acc: 0.8000 - val_loss: 0.2256 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1505 - acc: 0.7964 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1486 - acc: 0.8000 - val_loss: 0.2310 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1474 - acc: 0.8073 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.1444 - acc: 0.8145 - val_loss: 0.2320 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1413 - acc: 0.8182 - val_loss: 0.2323 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1394 - acc: 0.8255 - val_loss: 0.2333 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1372 - acc: 0.8327 - val_loss: 0.2340 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1343 - acc: 0.8327 - val_loss: 0.2346 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 295us/step - loss: 0.1320 - acc: 0.8291 - val_loss: 0.2376 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 320us/step - loss: 0.1300 - acc: 0.8364 - val_loss: 0.2376 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 311us/step - loss: 0.1267 - acc: 0.8400 - val_loss: 0.2373 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.1234 - acc: 0.8582 - val_loss: 0.2389 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.1206 - acc: 0.8618 - val_loss: 0.2381 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.1181 - acc: 0.8618 - val_loss: 0.2350 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1141 - acc: 0.8764 - val_loss: 0.2348 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1107 - acc: 0.8764 - val_loss: 0.2444 - val_acc: 0.6452\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1086 - acc: 0.8873 - val_loss: 0.2377 - val_acc: 0.6129\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1039 - acc: 0.8909 - val_loss: 0.2427 - val_acc: 0.6452\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1037 - acc: 0.8836 - val_loss: 0.2455 - val_acc: 0.6452\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0991 - acc: 0.8982 - val_loss: 0.2396 - val_acc: 0.6129\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0960 - acc: 0.9164 - val_loss: 0.2420 - val_acc: 0.6452\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0930 - acc: 0.9127 - val_loss: 0.2441 - val_acc: 0.6452\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0870 - acc: 0.9236 - val_loss: 0.2431 - val_acc: 0.6452\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0844 - acc: 0.9200 - val_loss: 0.2402 - val_acc: 0.6452\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0802 - acc: 0.9382 - val_loss: 0.2390 - val_acc: 0.6452\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0773 - acc: 0.9345 - val_loss: 0.2406 - val_acc: 0.6452\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 283us/step - loss: 0.0738 - acc: 0.9382 - val_loss: 0.2402 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 277us/step - loss: 0.0715 - acc: 0.9455 - val_loss: 0.2421 - val_acc: 0.6129\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.0677 - acc: 0.9455 - val_loss: 0.2424 - val_acc: 0.6452\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0644 - acc: 0.9491 - val_loss: 0.2392 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.0613 - acc: 0.9527 - val_loss: 0.2422 - val_acc: 0.6129\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0587 - acc: 0.9564 - val_loss: 0.2390 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0551 - acc: 0.9600 - val_loss: 0.2458 - val_acc: 0.6129\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.0528 - acc: 0.9564 - val_loss: 0.2431 - val_acc: 0.6452\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.0532 - acc: 0.9564 - val_loss: 0.2412 - val_acc: 0.6452\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0471 - acc: 0.9600 - val_loss: 0.2423 - val_acc: 0.6452\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0459 - acc: 0.9673 - val_loss: 0.2477 - val_acc: 0.6452\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0436 - acc: 0.9673 - val_loss: 0.2451 - val_acc: 0.6129\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0410 - acc: 0.9745 - val_loss: 0.2418 - val_acc: 0.6129\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0381 - acc: 0.9745 - val_loss: 0.2506 - val_acc: 0.6452\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0370 - acc: 0.9745 - val_loss: 0.2471 - val_acc: 0.6129\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0349 - acc: 0.9782 - val_loss: 0.2511 - val_acc: 0.6129\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0333 - acc: 0.9782 - val_loss: 0.2535 - val_acc: 0.6129\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0315 - acc: 0.9782 - val_loss: 0.2484 - val_acc: 0.6129\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0303 - acc: 0.9782 - val_loss: 0.2540 - val_acc: 0.6452\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0284 - acc: 0.9782 - val_loss: 0.2588 - val_acc: 0.6129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0269 - acc: 0.9782 - val_loss: 0.2522 - val_acc: 0.6129\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0238 - acc: 0.9818 - val_loss: 0.2545 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.0219 - acc: 0.9818 - val_loss: 0.2581 - val_acc: 0.6129\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0189 - acc: 0.9891 - val_loss: 0.2570 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.0174 - acc: 0.9964 - val_loss: 0.2573 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0153 - acc: 0.9964 - val_loss: 0.2627 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0141 - acc: 0.9964 - val_loss: 0.2597 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0133 - acc: 0.9964 - val_loss: 0.2651 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0121 - acc: 0.9964 - val_loss: 0.2638 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0114 - acc: 0.9964 - val_loss: 0.2705 - val_acc: 0.6129\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0108 - acc: 0.9964 - val_loss: 0.2698 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0100 - acc: 0.9964 - val_loss: 0.2699 - val_acc: 0.6129\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0096 - acc: 0.9964 - val_loss: 0.2693 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0091 - acc: 0.9964 - val_loss: 0.2743 - val_acc: 0.6129\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0087 - acc: 0.9964 - val_loss: 0.2731 - val_acc: 0.6452\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 213us/step - loss: 0.0083 - acc: 0.9964 - val_loss: 0.2745 - val_acc: 0.6129\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0079 - acc: 0.9964 - val_loss: 0.2745 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0076 - acc: 0.9964 - val_loss: 0.2751 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0074 - acc: 0.9964 - val_loss: 0.2766 - val_acc: 0.6129\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0072 - acc: 0.9964 - val_loss: 0.2754 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0070 - acc: 0.9964 - val_loss: 0.2796 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.0068 - acc: 0.9964 - val_loss: 0.2768 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0066 - acc: 0.9964 - val_loss: 0.2793 - val_acc: 0.6129\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0063 - acc: 0.9964 - val_loss: 0.2785 - val_acc: 0.6129\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0062 - acc: 0.9964 - val_loss: 0.2819 - val_acc: 0.6129\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0061 - acc: 0.9964 - val_loss: 0.2794 - val_acc: 0.6129\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0059 - acc: 0.9964 - val_loss: 0.2805 - val_acc: 0.6129\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.0058 - acc: 0.9964 - val_loss: 0.2800 - val_acc: 0.6129\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0057 - acc: 0.9964 - val_loss: 0.2802 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0056 - acc: 0.9964 - val_loss: 0.2828 - val_acc: 0.6129\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.2824 - val_acc: 0.6129\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0054 - acc: 0.9964 - val_loss: 0.2820 - val_acc: 0.6129\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.2814 - val_acc: 0.6129\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.2834 - val_acc: 0.6129\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.2827 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2835 - val_acc: 0.6129\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.2836 - val_acc: 0.6129\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.2852 - val_acc: 0.6129\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.2848 - val_acc: 0.6129\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.2860 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_115 (Dense)            (None, 33)                1287      \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 17)                578       \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 1)                 18        \n",
      "=================================================================\n",
      "Total params: 1,883\n",
      "Trainable params: 1,883\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 5ms/step - loss: 0.2499 - acc: 0.5382 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.2493 - acc: 0.5418 - val_loss: 0.2492 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.2471 - acc: 0.5418 - val_loss: 0.2457 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.2398 - acc: 0.5818 - val_loss: 0.2374 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.2255 - acc: 0.6364 - val_loss: 0.2234 - val_acc: 0.6129\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.2064 - acc: 0.7164 - val_loss: 0.2098 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1881 - acc: 0.7418 - val_loss: 0.2043 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1774 - acc: 0.7527 - val_loss: 0.2038 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 314us/step - loss: 0.1703 - acc: 0.7600 - val_loss: 0.2050 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.1662 - acc: 0.7636 - val_loss: 0.2068 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.1642 - acc: 0.7564 - val_loss: 0.2088 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1621 - acc: 0.7600 - val_loss: 0.2146 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1605 - acc: 0.7636 - val_loss: 0.2141 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1592 - acc: 0.7709 - val_loss: 0.2183 - val_acc: 0.6774\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 189us/step - loss: 0.1574 - acc: 0.7709 - val_loss: 0.2186 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1561 - acc: 0.7745 - val_loss: 0.2198 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1552 - acc: 0.7891 - val_loss: 0.2197 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1551 - acc: 0.7673 - val_loss: 0.2204 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.1536 - acc: 0.7927 - val_loss: 0.2213 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1518 - acc: 0.7927 - val_loss: 0.2214 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1502 - acc: 0.7927 - val_loss: 0.2230 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1499 - acc: 0.8036 - val_loss: 0.2280 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1481 - acc: 0.8000 - val_loss: 0.2225 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1467 - acc: 0.7927 - val_loss: 0.2222 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1461 - acc: 0.7964 - val_loss: 0.2228 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1456 - acc: 0.8109 - val_loss: 0.2237 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1454 - acc: 0.8000 - val_loss: 0.2198 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1424 - acc: 0.8145 - val_loss: 0.2247 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1419 - acc: 0.8109 - val_loss: 0.2234 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1400 - acc: 0.8109 - val_loss: 0.2243 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1387 - acc: 0.8218 - val_loss: 0.2264 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1380 - acc: 0.8291 - val_loss: 0.2264 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1380 - acc: 0.8109 - val_loss: 0.2248 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1356 - acc: 0.8291 - val_loss: 0.2248 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1351 - acc: 0.8327 - val_loss: 0.2285 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1325 - acc: 0.8364 - val_loss: 0.2253 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1306 - acc: 0.8255 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1286 - acc: 0.8436 - val_loss: 0.2306 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1299 - acc: 0.8400 - val_loss: 0.2301 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1259 - acc: 0.8400 - val_loss: 0.2305 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1228 - acc: 0.8473 - val_loss: 0.2292 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1214 - acc: 0.8509 - val_loss: 0.2288 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1193 - acc: 0.8509 - val_loss: 0.2240 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.1192 - acc: 0.8655 - val_loss: 0.2291 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.1154 - acc: 0.8582 - val_loss: 0.2240 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.1134 - acc: 0.8655 - val_loss: 0.2208 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1097 - acc: 0.8764 - val_loss: 0.2262 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1101 - acc: 0.8800 - val_loss: 0.2223 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 331us/step - loss: 0.1057 - acc: 0.8909 - val_loss: 0.2244 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.1035 - acc: 0.8836 - val_loss: 0.2232 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1012 - acc: 0.9055 - val_loss: 0.2286 - val_acc: 0.6452\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0978 - acc: 0.9018 - val_loss: 0.2241 - val_acc: 0.6452\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0942 - acc: 0.9018 - val_loss: 0.2246 - val_acc: 0.6129\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0912 - acc: 0.9055 - val_loss: 0.2203 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 213us/step - loss: 0.0877 - acc: 0.9018 - val_loss: 0.2234 - val_acc: 0.6452\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.0852 - acc: 0.9055 - val_loss: 0.2200 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 279us/step - loss: 0.0812 - acc: 0.9236 - val_loss: 0.2296 - val_acc: 0.6129\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0793 - acc: 0.9345 - val_loss: 0.2236 - val_acc: 0.6452\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.0745 - acc: 0.9309 - val_loss: 0.2311 - val_acc: 0.6129\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0747 - acc: 0.9382 - val_loss: 0.2253 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0697 - acc: 0.9418 - val_loss: 0.2305 - val_acc: 0.6129\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0643 - acc: 0.9491 - val_loss: 0.2271 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.0626 - acc: 0.9491 - val_loss: 0.2264 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.0581 - acc: 0.9564 - val_loss: 0.2370 - val_acc: 0.6129\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.0572 - acc: 0.9636 - val_loss: 0.2339 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.0528 - acc: 0.9709 - val_loss: 0.2390 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.0501 - acc: 0.9636 - val_loss: 0.2406 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.0471 - acc: 0.9673 - val_loss: 0.2472 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.0432 - acc: 0.9709 - val_loss: 0.2573 - val_acc: 0.6129\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0431 - acc: 0.9709 - val_loss: 0.2528 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0388 - acc: 0.9782 - val_loss: 0.2567 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0370 - acc: 0.9782 - val_loss: 0.2637 - val_acc: 0.6129\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0345 - acc: 0.9818 - val_loss: 0.2593 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0314 - acc: 0.9818 - val_loss: 0.2582 - val_acc: 0.6452\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 218us/step - loss: 0.0298 - acc: 0.9891 - val_loss: 0.2604 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0290 - acc: 0.9855 - val_loss: 0.2698 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0264 - acc: 0.9891 - val_loss: 0.2700 - val_acc: 0.6129\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0255 - acc: 0.9891 - val_loss: 0.2650 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.0248 - acc: 0.9927 - val_loss: 0.2772 - val_acc: 0.5806\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.0218 - acc: 0.9927 - val_loss: 0.2692 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.0202 - acc: 0.9927 - val_loss: 0.2756 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.0190 - acc: 0.9927 - val_loss: 0.2750 - val_acc: 0.6129\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0188 - acc: 0.9927 - val_loss: 0.2842 - val_acc: 0.5806\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0174 - acc: 0.9927 - val_loss: 0.2778 - val_acc: 0.6129\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0170 - acc: 0.9927 - val_loss: 0.2807 - val_acc: 0.6129\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0167 - acc: 0.9927 - val_loss: 0.2830 - val_acc: 0.6129\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0156 - acc: 0.9927 - val_loss: 0.2883 - val_acc: 0.6129\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 262us/step - loss: 0.0148 - acc: 0.9927 - val_loss: 0.2832 - val_acc: 0.5806\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.0142 - acc: 0.9927 - val_loss: 0.2863 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.0142 - acc: 0.9927 - val_loss: 0.2896 - val_acc: 0.5806\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0131 - acc: 0.9927 - val_loss: 0.2896 - val_acc: 0.5806\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0127 - acc: 0.9927 - val_loss: 0.2878 - val_acc: 0.5806\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0127 - acc: 0.9927 - val_loss: 0.2871 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0120 - acc: 0.9927 - val_loss: 0.2923 - val_acc: 0.6129\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0120 - acc: 0.9927 - val_loss: 0.2894 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.0114 - acc: 0.9927 - val_loss: 0.2924 - val_acc: 0.6129\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.0112 - acc: 0.9927 - val_loss: 0.2907 - val_acc: 0.6129\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0110 - acc: 0.9927 - val_loss: 0.2827 - val_acc: 0.6129\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0101 - acc: 0.9927 - val_loss: 0.2811 - val_acc: 0.5806\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0101 - acc: 0.9927 - val_loss: 0.2721 - val_acc: 0.5806\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_118 (Dense)            (None, 11)                429       \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 18)                216       \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 664\n",
      "Trainable params: 664\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 5ms/step - loss: 0.2500 - acc: 0.4873 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.2498 - acc: 0.5418 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.2493 - acc: 0.5418 - val_loss: 0.2494 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.2479 - acc: 0.5418 - val_loss: 0.2471 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.2435 - acc: 0.5818 - val_loss: 0.2414 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.2346 - acc: 0.6727 - val_loss: 0.2323 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.2211 - acc: 0.7309 - val_loss: 0.2210 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.2039 - acc: 0.7382 - val_loss: 0.2112 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.1903 - acc: 0.7491 - val_loss: 0.2046 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 286us/step - loss: 0.1788 - acc: 0.7491 - val_loss: 0.2041 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1720 - acc: 0.7564 - val_loss: 0.2056 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1676 - acc: 0.7564 - val_loss: 0.2100 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1650 - acc: 0.7527 - val_loss: 0.2107 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.1616 - acc: 0.7673 - val_loss: 0.2102 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1600 - acc: 0.7636 - val_loss: 0.2125 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1597 - acc: 0.7673 - val_loss: 0.2134 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1582 - acc: 0.7709 - val_loss: 0.2159 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.1566 - acc: 0.7745 - val_loss: 0.2193 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.1553 - acc: 0.7818 - val_loss: 0.2192 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1550 - acc: 0.7782 - val_loss: 0.2173 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.1543 - acc: 0.7855 - val_loss: 0.2200 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.1528 - acc: 0.7891 - val_loss: 0.2182 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.1538 - acc: 0.7855 - val_loss: 0.2197 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1512 - acc: 0.7927 - val_loss: 0.2210 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1511 - acc: 0.7891 - val_loss: 0.2203 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1504 - acc: 0.7964 - val_loss: 0.2207 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1516 - acc: 0.7855 - val_loss: 0.2216 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1486 - acc: 0.8109 - val_loss: 0.2210 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1485 - acc: 0.8073 - val_loss: 0.2246 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1464 - acc: 0.8218 - val_loss: 0.2227 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.1463 - acc: 0.8109 - val_loss: 0.2227 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1456 - acc: 0.8145 - val_loss: 0.2239 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1440 - acc: 0.8255 - val_loss: 0.2240 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1433 - acc: 0.8255 - val_loss: 0.2230 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1422 - acc: 0.8291 - val_loss: 0.2245 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1418 - acc: 0.8255 - val_loss: 0.2240 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1410 - acc: 0.8327 - val_loss: 0.2263 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1402 - acc: 0.8255 - val_loss: 0.2254 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.1388 - acc: 0.8255 - val_loss: 0.2246 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1376 - acc: 0.8327 - val_loss: 0.2253 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.1367 - acc: 0.8291 - val_loss: 0.2247 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.1357 - acc: 0.8364 - val_loss: 0.2274 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1345 - acc: 0.8291 - val_loss: 0.2230 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.1341 - acc: 0.8291 - val_loss: 0.2260 - val_acc: 0.7097\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 214us/step - loss: 0.1319 - acc: 0.8255 - val_loss: 0.2273 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1316 - acc: 0.8400 - val_loss: 0.2272 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1309 - acc: 0.8218 - val_loss: 0.2241 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.1295 - acc: 0.8400 - val_loss: 0.2232 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.1278 - acc: 0.8436 - val_loss: 0.2261 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1269 - acc: 0.8327 - val_loss: 0.2275 - val_acc: 0.7419\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.1267 - acc: 0.8400 - val_loss: 0.2255 - val_acc: 0.7419\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1246 - acc: 0.8364 - val_loss: 0.2255 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1238 - acc: 0.8436 - val_loss: 0.2257 - val_acc: 0.7419\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1221 - acc: 0.8436 - val_loss: 0.2289 - val_acc: 0.7097\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1212 - acc: 0.8473 - val_loss: 0.2280 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1199 - acc: 0.8473 - val_loss: 0.2273 - val_acc: 0.7419\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1189 - acc: 0.8545 - val_loss: 0.2259 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1171 - acc: 0.8618 - val_loss: 0.2308 - val_acc: 0.7097\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1157 - acc: 0.8582 - val_loss: 0.2295 - val_acc: 0.7419\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1147 - acc: 0.8618 - val_loss: 0.2295 - val_acc: 0.7097\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1134 - acc: 0.8582 - val_loss: 0.2288 - val_acc: 0.7419\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1129 - acc: 0.8618 - val_loss: 0.2279 - val_acc: 0.7419\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1109 - acc: 0.8691 - val_loss: 0.2283 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1096 - acc: 0.8618 - val_loss: 0.2296 - val_acc: 0.7097\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1079 - acc: 0.8727 - val_loss: 0.2307 - val_acc: 0.7097\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1067 - acc: 0.8764 - val_loss: 0.2300 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.1065 - acc: 0.8800 - val_loss: 0.2340 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.1045 - acc: 0.8800 - val_loss: 0.2274 - val_acc: 0.7419\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.1029 - acc: 0.8836 - val_loss: 0.2350 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1017 - acc: 0.8873 - val_loss: 0.2311 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1003 - acc: 0.8982 - val_loss: 0.2296 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.1003 - acc: 0.8982 - val_loss: 0.2310 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0984 - acc: 0.8909 - val_loss: 0.2295 - val_acc: 0.7097\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0964 - acc: 0.9055 - val_loss: 0.2287 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.0951 - acc: 0.9018 - val_loss: 0.2318 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0948 - acc: 0.9055 - val_loss: 0.2277 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0920 - acc: 0.9164 - val_loss: 0.2306 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0908 - acc: 0.9200 - val_loss: 0.2311 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0896 - acc: 0.9164 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0877 - acc: 0.9236 - val_loss: 0.2268 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0862 - acc: 0.9236 - val_loss: 0.2274 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0849 - acc: 0.9273 - val_loss: 0.2232 - val_acc: 0.7097\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 262us/step - loss: 0.0839 - acc: 0.9273 - val_loss: 0.2276 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0813 - acc: 0.9273 - val_loss: 0.2279 - val_acc: 0.7097\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0799 - acc: 0.9273 - val_loss: 0.2238 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0785 - acc: 0.9345 - val_loss: 0.2224 - val_acc: 0.7097\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0783 - acc: 0.9273 - val_loss: 0.2176 - val_acc: 0.7097\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0745 - acc: 0.9309 - val_loss: 0.2132 - val_acc: 0.7419\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0732 - acc: 0.9345 - val_loss: 0.2184 - val_acc: 0.6774\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 181us/step - loss: 0.0719 - acc: 0.9345 - val_loss: 0.2225 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0693 - acc: 0.9418 - val_loss: 0.2147 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0684 - acc: 0.9418 - val_loss: 0.2134 - val_acc: 0.7419\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0672 - acc: 0.9491 - val_loss: 0.2146 - val_acc: 0.7419\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0649 - acc: 0.9455 - val_loss: 0.2192 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0639 - acc: 0.9418 - val_loss: 0.2147 - val_acc: 0.7097\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0614 - acc: 0.9491 - val_loss: 0.2191 - val_acc: 0.6452\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0605 - acc: 0.9418 - val_loss: 0.2175 - val_acc: 0.7097\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0585 - acc: 0.9455 - val_loss: 0.2135 - val_acc: 0.7419\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0577 - acc: 0.9527 - val_loss: 0.2150 - val_acc: 0.7097\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0551 - acc: 0.9491 - val_loss: 0.2180 - val_acc: 0.7097\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_121 (Dense)            (None, 48)                1872      \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 13)                637       \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 2,523\n",
      "Trainable params: 2,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 5ms/step - loss: 0.2499 - acc: 0.5309 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.2494 - acc: 0.5418 - val_loss: 0.2493 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.2474 - acc: 0.5418 - val_loss: 0.2464 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.2395 - acc: 0.5491 - val_loss: 0.2386 - val_acc: 0.5484\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.2256 - acc: 0.6036 - val_loss: 0.2309 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.2117 - acc: 0.6945 - val_loss: 0.2205 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1998 - acc: 0.7382 - val_loss: 0.2143 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1892 - acc: 0.7491 - val_loss: 0.2135 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1793 - acc: 0.7527 - val_loss: 0.2124 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1730 - acc: 0.7673 - val_loss: 0.2139 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1656 - acc: 0.7673 - val_loss: 0.2105 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1614 - acc: 0.7745 - val_loss: 0.2103 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1587 - acc: 0.7673 - val_loss: 0.2144 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1555 - acc: 0.7818 - val_loss: 0.2141 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1541 - acc: 0.7818 - val_loss: 0.2164 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1514 - acc: 0.7891 - val_loss: 0.2165 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1490 - acc: 0.8036 - val_loss: 0.2196 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1473 - acc: 0.8073 - val_loss: 0.2199 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 380us/step - loss: 0.1456 - acc: 0.8145 - val_loss: 0.2203 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1433 - acc: 0.8036 - val_loss: 0.2224 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 214us/step - loss: 0.1421 - acc: 0.8218 - val_loss: 0.2265 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.1400 - acc: 0.8182 - val_loss: 0.2278 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1389 - acc: 0.8218 - val_loss: 0.2240 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1367 - acc: 0.8291 - val_loss: 0.2259 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.1348 - acc: 0.8364 - val_loss: 0.2216 - val_acc: 0.6452\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1327 - acc: 0.8400 - val_loss: 0.2207 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1307 - acc: 0.8473 - val_loss: 0.2236 - val_acc: 0.6452\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.1285 - acc: 0.8545 - val_loss: 0.2237 - val_acc: 0.6452\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1269 - acc: 0.8473 - val_loss: 0.2258 - val_acc: 0.6452\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1246 - acc: 0.8582 - val_loss: 0.2259 - val_acc: 0.6452\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 213us/step - loss: 0.1223 - acc: 0.8582 - val_loss: 0.2298 - val_acc: 0.6452\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.1206 - acc: 0.8655 - val_loss: 0.2281 - val_acc: 0.6452\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1172 - acc: 0.8764 - val_loss: 0.2228 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1156 - acc: 0.8727 - val_loss: 0.2270 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.1126 - acc: 0.8727 - val_loss: 0.2236 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1099 - acc: 0.8800 - val_loss: 0.2202 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1056 - acc: 0.8873 - val_loss: 0.2191 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1037 - acc: 0.8909 - val_loss: 0.2202 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1025 - acc: 0.8873 - val_loss: 0.2223 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0968 - acc: 0.8945 - val_loss: 0.2158 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0949 - acc: 0.8982 - val_loss: 0.2153 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.0902 - acc: 0.9200 - val_loss: 0.2100 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.0868 - acc: 0.9164 - val_loss: 0.2128 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.0847 - acc: 0.9127 - val_loss: 0.2039 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.0802 - acc: 0.9345 - val_loss: 0.2090 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.0758 - acc: 0.9345 - val_loss: 0.2072 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.0716 - acc: 0.9382 - val_loss: 0.2053 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.0689 - acc: 0.9418 - val_loss: 0.2140 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0639 - acc: 0.9491 - val_loss: 0.2076 - val_acc: 0.7419\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0618 - acc: 0.9491 - val_loss: 0.2073 - val_acc: 0.7419\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0605 - acc: 0.9527 - val_loss: 0.2126 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0546 - acc: 0.9600 - val_loss: 0.2056 - val_acc: 0.7419\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0526 - acc: 0.9636 - val_loss: 0.2158 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0509 - acc: 0.9709 - val_loss: 0.2162 - val_acc: 0.7097\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0484 - acc: 0.9673 - val_loss: 0.2086 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.0456 - acc: 0.9709 - val_loss: 0.2130 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0444 - acc: 0.9709 - val_loss: 0.2018 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.0430 - acc: 0.9709 - val_loss: 0.2010 - val_acc: 0.7097\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.0387 - acc: 0.9709 - val_loss: 0.2040 - val_acc: 0.7097\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0364 - acc: 0.9745 - val_loss: 0.1990 - val_acc: 0.7419\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0343 - acc: 0.9745 - val_loss: 0.2048 - val_acc: 0.7097\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0333 - acc: 0.9745 - val_loss: 0.2098 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0330 - acc: 0.9745 - val_loss: 0.1964 - val_acc: 0.7097\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0305 - acc: 0.9745 - val_loss: 0.2046 - val_acc: 0.7097\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.0283 - acc: 0.9782 - val_loss: 0.2110 - val_acc: 0.7097\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.0270 - acc: 0.9782 - val_loss: 0.2071 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.0254 - acc: 0.9818 - val_loss: 0.2135 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0240 - acc: 0.9782 - val_loss: 0.2120 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0222 - acc: 0.9855 - val_loss: 0.2068 - val_acc: 0.7097\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.0196 - acc: 0.9891 - val_loss: 0.2086 - val_acc: 0.7097\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.0176 - acc: 0.9927 - val_loss: 0.2093 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.0159 - acc: 0.9927 - val_loss: 0.2175 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.0147 - acc: 0.9927 - val_loss: 0.2154 - val_acc: 0.7097\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0139 - acc: 0.9927 - val_loss: 0.2160 - val_acc: 0.7097\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0131 - acc: 0.9927 - val_loss: 0.2137 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.0123 - acc: 0.9927 - val_loss: 0.2188 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.0118 - acc: 0.9927 - val_loss: 0.2297 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0104 - acc: 0.9927 - val_loss: 0.2277 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.0094 - acc: 0.9964 - val_loss: 0.2240 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 279us/step - loss: 0.0088 - acc: 0.9964 - val_loss: 0.2228 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.0082 - acc: 0.9964 - val_loss: 0.2273 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0078 - acc: 0.9964 - val_loss: 0.2337 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0075 - acc: 0.9964 - val_loss: 0.2253 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0072 - acc: 0.9964 - val_loss: 0.2275 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0068 - acc: 0.9964 - val_loss: 0.2292 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0067 - acc: 0.9964 - val_loss: 0.2276 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0064 - acc: 0.9964 - val_loss: 0.2294 - val_acc: 0.6452\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.0062 - acc: 0.9964 - val_loss: 0.2306 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.0061 - acc: 0.9964 - val_loss: 0.2303 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 298us/step - loss: 0.0059 - acc: 0.9964 - val_loss: 0.2267 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 268us/step - loss: 0.0058 - acc: 0.9964 - val_loss: 0.2285 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 289us/step - loss: 0.0056 - acc: 0.9964 - val_loss: 0.2310 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.2306 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.0054 - acc: 0.9964 - val_loss: 0.2302 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.2326 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2289 - val_acc: 0.7097\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2308 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.2310 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.2323 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_124 (Dense)            (None, 46)                1794      \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 15)                705       \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 2,515\n",
      "Trainable params: 2,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 5ms/step - loss: 0.2499 - acc: 0.5345 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.2493 - acc: 0.5418 - val_loss: 0.2491 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.2469 - acc: 0.5564 - val_loss: 0.2460 - val_acc: 0.5806\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.2398 - acc: 0.6036 - val_loss: 0.2363 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.2243 - acc: 0.6473 - val_loss: 0.2226 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.2049 - acc: 0.7200 - val_loss: 0.2105 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1876 - acc: 0.7309 - val_loss: 0.2023 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1743 - acc: 0.7600 - val_loss: 0.2041 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1671 - acc: 0.7673 - val_loss: 0.2008 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1643 - acc: 0.7745 - val_loss: 0.2136 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1609 - acc: 0.7673 - val_loss: 0.2145 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1575 - acc: 0.7636 - val_loss: 0.2189 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1560 - acc: 0.7855 - val_loss: 0.2203 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1536 - acc: 0.7891 - val_loss: 0.2211 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.1515 - acc: 0.8000 - val_loss: 0.2222 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1499 - acc: 0.7964 - val_loss: 0.2256 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1481 - acc: 0.8145 - val_loss: 0.2254 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1462 - acc: 0.8218 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.1457 - acc: 0.8182 - val_loss: 0.2295 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1432 - acc: 0.8218 - val_loss: 0.2318 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1418 - acc: 0.8145 - val_loss: 0.2302 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1414 - acc: 0.8109 - val_loss: 0.2295 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1386 - acc: 0.8182 - val_loss: 0.2305 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1359 - acc: 0.8218 - val_loss: 0.2302 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1348 - acc: 0.8291 - val_loss: 0.2329 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1331 - acc: 0.8291 - val_loss: 0.2333 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1299 - acc: 0.8255 - val_loss: 0.2341 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1276 - acc: 0.8400 - val_loss: 0.2360 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1261 - acc: 0.8327 - val_loss: 0.2376 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1243 - acc: 0.8400 - val_loss: 0.2381 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1203 - acc: 0.8545 - val_loss: 0.2381 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1172 - acc: 0.8582 - val_loss: 0.2390 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1148 - acc: 0.8655 - val_loss: 0.2389 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1136 - acc: 0.8800 - val_loss: 0.2394 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1108 - acc: 0.8800 - val_loss: 0.2420 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1065 - acc: 0.8909 - val_loss: 0.2417 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.1049 - acc: 0.8982 - val_loss: 0.2424 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1019 - acc: 0.8836 - val_loss: 0.2425 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0998 - acc: 0.8909 - val_loss: 0.2450 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0963 - acc: 0.9018 - val_loss: 0.2471 - val_acc: 0.6452\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0929 - acc: 0.9018 - val_loss: 0.2470 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0891 - acc: 0.9018 - val_loss: 0.2518 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0876 - acc: 0.9164 - val_loss: 0.2556 - val_acc: 0.6452\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 215us/step - loss: 0.0827 - acc: 0.9127 - val_loss: 0.2592 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0813 - acc: 0.9273 - val_loss: 0.2500 - val_acc: 0.6129\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0758 - acc: 0.9309 - val_loss: 0.2594 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0731 - acc: 0.9236 - val_loss: 0.2624 - val_acc: 0.6452\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0702 - acc: 0.9418 - val_loss: 0.2598 - val_acc: 0.6129\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0667 - acc: 0.9455 - val_loss: 0.2620 - val_acc: 0.6129\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0647 - acc: 0.9418 - val_loss: 0.2594 - val_acc: 0.6129\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0621 - acc: 0.9455 - val_loss: 0.2696 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0611 - acc: 0.9345 - val_loss: 0.2690 - val_acc: 0.6129\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0568 - acc: 0.9491 - val_loss: 0.2641 - val_acc: 0.6129\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.0556 - acc: 0.9455 - val_loss: 0.2642 - val_acc: 0.6129\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0513 - acc: 0.9564 - val_loss: 0.2664 - val_acc: 0.6129\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0491 - acc: 0.9564 - val_loss: 0.2631 - val_acc: 0.6129\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0471 - acc: 0.9527 - val_loss: 0.2633 - val_acc: 0.6129\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0421 - acc: 0.9636 - val_loss: 0.2612 - val_acc: 0.6129\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0391 - acc: 0.9709 - val_loss: 0.2699 - val_acc: 0.6129\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0364 - acc: 0.9782 - val_loss: 0.2731 - val_acc: 0.6129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.0326 - acc: 0.9818 - val_loss: 0.2734 - val_acc: 0.5161\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.0299 - acc: 0.9818 - val_loss: 0.2953 - val_acc: 0.5806\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0319 - acc: 0.9782 - val_loss: 0.2824 - val_acc: 0.5484\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0262 - acc: 0.9927 - val_loss: 0.2929 - val_acc: 0.5161\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.0253 - acc: 0.9927 - val_loss: 0.2903 - val_acc: 0.5161\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0222 - acc: 0.9927 - val_loss: 0.2982 - val_acc: 0.4839\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0210 - acc: 0.9927 - val_loss: 0.2961 - val_acc: 0.4839\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0193 - acc: 0.9927 - val_loss: 0.2955 - val_acc: 0.5161\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0181 - acc: 0.9927 - val_loss: 0.3019 - val_acc: 0.5484\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0173 - acc: 0.9927 - val_loss: 0.3047 - val_acc: 0.4839\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0162 - acc: 0.9927 - val_loss: 0.3033 - val_acc: 0.5484\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0158 - acc: 0.9927 - val_loss: 0.3051 - val_acc: 0.5161\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0150 - acc: 0.9927 - val_loss: 0.3067 - val_acc: 0.5161\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0142 - acc: 0.9927 - val_loss: 0.3096 - val_acc: 0.5161\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0137 - acc: 0.9927 - val_loss: 0.3112 - val_acc: 0.5161\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0133 - acc: 0.9927 - val_loss: 0.3078 - val_acc: 0.5161\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0128 - acc: 0.9927 - val_loss: 0.3088 - val_acc: 0.5161\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0125 - acc: 0.9927 - val_loss: 0.3118 - val_acc: 0.5161\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0121 - acc: 0.9927 - val_loss: 0.3119 - val_acc: 0.5161\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0117 - acc: 0.9927 - val_loss: 0.3128 - val_acc: 0.4839\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0115 - acc: 0.9927 - val_loss: 0.3126 - val_acc: 0.5161\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0112 - acc: 0.9927 - val_loss: 0.3128 - val_acc: 0.5484\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0109 - acc: 0.9927 - val_loss: 0.3141 - val_acc: 0.5484\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0107 - acc: 0.9927 - val_loss: 0.3143 - val_acc: 0.5161\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0104 - acc: 0.9927 - val_loss: 0.3130 - val_acc: 0.5484\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.0102 - acc: 0.9927 - val_loss: 0.3107 - val_acc: 0.5484\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.0099 - acc: 0.9927 - val_loss: 0.3066 - val_acc: 0.5484\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.0098 - acc: 0.9927 - val_loss: 0.2959 - val_acc: 0.5484\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0092 - acc: 0.9927 - val_loss: 0.2948 - val_acc: 0.5484\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0083 - acc: 0.9964 - val_loss: 0.2878 - val_acc: 0.4839\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0070 - acc: 0.9964 - val_loss: 0.2926 - val_acc: 0.5161\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0065 - acc: 0.9964 - val_loss: 0.2903 - val_acc: 0.5484\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.0062 - acc: 0.9964 - val_loss: 0.2950 - val_acc: 0.5806\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.0061 - acc: 0.9964 - val_loss: 0.2976 - val_acc: 0.4839\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.0059 - acc: 0.9964 - val_loss: 0.2929 - val_acc: 0.5806\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0057 - acc: 0.9964 - val_loss: 0.2982 - val_acc: 0.5806\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0056 - acc: 0.9964 - val_loss: 0.2971 - val_acc: 0.5806\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.2972 - val_acc: 0.5806\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.0054 - acc: 0.9964 - val_loss: 0.2990 - val_acc: 0.5806\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.2980 - val_acc: 0.5806\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_127 (Dense)            (None, 27)                1053      \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 13)                364       \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 1,431\n",
      "Trainable params: 1,431\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 5ms/step - loss: 0.2499 - acc: 0.5418 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.2498 - acc: 0.5418 - val_loss: 0.2496 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.2489 - acc: 0.5418 - val_loss: 0.2485 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.2464 - acc: 0.5527 - val_loss: 0.2442 - val_acc: 0.5806\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.2389 - acc: 0.6291 - val_loss: 0.2353 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.2247 - acc: 0.6909 - val_loss: 0.2227 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.2071 - acc: 0.7127 - val_loss: 0.2114 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.1911 - acc: 0.7418 - val_loss: 0.2071 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1800 - acc: 0.7309 - val_loss: 0.2064 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1709 - acc: 0.7527 - val_loss: 0.2037 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1651 - acc: 0.7564 - val_loss: 0.2117 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1632 - acc: 0.7600 - val_loss: 0.2117 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1594 - acc: 0.7818 - val_loss: 0.2149 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1574 - acc: 0.7782 - val_loss: 0.2139 - val_acc: 0.6774\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 228us/step - loss: 0.1550 - acc: 0.7818 - val_loss: 0.2179 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1541 - acc: 0.7927 - val_loss: 0.2176 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.1541 - acc: 0.7782 - val_loss: 0.2186 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1511 - acc: 0.7964 - val_loss: 0.2214 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1493 - acc: 0.8036 - val_loss: 0.2203 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.1480 - acc: 0.8109 - val_loss: 0.2223 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1467 - acc: 0.8073 - val_loss: 0.2248 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1461 - acc: 0.8145 - val_loss: 0.2229 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.1440 - acc: 0.8218 - val_loss: 0.2252 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1427 - acc: 0.8109 - val_loss: 0.2256 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 281us/step - loss: 0.1419 - acc: 0.8182 - val_loss: 0.2262 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.1404 - acc: 0.8073 - val_loss: 0.2287 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1394 - acc: 0.8255 - val_loss: 0.2269 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1380 - acc: 0.8255 - val_loss: 0.2257 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1376 - acc: 0.8182 - val_loss: 0.2261 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1351 - acc: 0.8255 - val_loss: 0.2249 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.1332 - acc: 0.8255 - val_loss: 0.2243 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1320 - acc: 0.8218 - val_loss: 0.2285 - val_acc: 0.6452\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1312 - acc: 0.8327 - val_loss: 0.2249 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1291 - acc: 0.8255 - val_loss: 0.2253 - val_acc: 0.6452\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1267 - acc: 0.8436 - val_loss: 0.2253 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1260 - acc: 0.8436 - val_loss: 0.2212 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1237 - acc: 0.8618 - val_loss: 0.2246 - val_acc: 0.6452\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1220 - acc: 0.8473 - val_loss: 0.2230 - val_acc: 0.6452\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1193 - acc: 0.8655 - val_loss: 0.2235 - val_acc: 0.6452\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1186 - acc: 0.8800 - val_loss: 0.2226 - val_acc: 0.6452\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1167 - acc: 0.8655 - val_loss: 0.2180 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1153 - acc: 0.8800 - val_loss: 0.2189 - val_acc: 0.6452\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1122 - acc: 0.8909 - val_loss: 0.2175 - val_acc: 0.6452\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1096 - acc: 0.8800 - val_loss: 0.2195 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1070 - acc: 0.8909 - val_loss: 0.2188 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1064 - acc: 0.8836 - val_loss: 0.2170 - val_acc: 0.6129\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1027 - acc: 0.8982 - val_loss: 0.2146 - val_acc: 0.6452\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1009 - acc: 0.9055 - val_loss: 0.2143 - val_acc: 0.6452\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0981 - acc: 0.9018 - val_loss: 0.2166 - val_acc: 0.6129\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.0952 - acc: 0.9055 - val_loss: 0.2129 - val_acc: 0.6452\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0930 - acc: 0.9127 - val_loss: 0.2161 - val_acc: 0.6452\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0914 - acc: 0.9055 - val_loss: 0.2136 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0885 - acc: 0.9091 - val_loss: 0.2128 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0858 - acc: 0.9018 - val_loss: 0.2119 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0823 - acc: 0.9236 - val_loss: 0.2129 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.0800 - acc: 0.9236 - val_loss: 0.2073 - val_acc: 0.7419\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0771 - acc: 0.9200 - val_loss: 0.2099 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0740 - acc: 0.9345 - val_loss: 0.2137 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0716 - acc: 0.9309 - val_loss: 0.2165 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0681 - acc: 0.9345 - val_loss: 0.2109 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0670 - acc: 0.9345 - val_loss: 0.2228 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0630 - acc: 0.9418 - val_loss: 0.2151 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0621 - acc: 0.9418 - val_loss: 0.2190 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0575 - acc: 0.9455 - val_loss: 0.2157 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0542 - acc: 0.9491 - val_loss: 0.2146 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0565 - acc: 0.9491 - val_loss: 0.2227 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0499 - acc: 0.9600 - val_loss: 0.2293 - val_acc: 0.6129\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0476 - acc: 0.9564 - val_loss: 0.2219 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0440 - acc: 0.9673 - val_loss: 0.2224 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0420 - acc: 0.9709 - val_loss: 0.2296 - val_acc: 0.5806\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0391 - acc: 0.9709 - val_loss: 0.2309 - val_acc: 0.5806\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0381 - acc: 0.9709 - val_loss: 0.2265 - val_acc: 0.6129\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0366 - acc: 0.9782 - val_loss: 0.2331 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0332 - acc: 0.9818 - val_loss: 0.2326 - val_acc: 0.6452\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 198us/step - loss: 0.0326 - acc: 0.9782 - val_loss: 0.2424 - val_acc: 0.5161\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0303 - acc: 0.9855 - val_loss: 0.2345 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0282 - acc: 0.9891 - val_loss: 0.2294 - val_acc: 0.6129\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0260 - acc: 0.9927 - val_loss: 0.2340 - val_acc: 0.5484\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0250 - acc: 0.9927 - val_loss: 0.2333 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0239 - acc: 0.9927 - val_loss: 0.2366 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0221 - acc: 0.9927 - val_loss: 0.2328 - val_acc: 0.6129\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0219 - acc: 0.9927 - val_loss: 0.2390 - val_acc: 0.6129\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0204 - acc: 0.9927 - val_loss: 0.2337 - val_acc: 0.5806\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0195 - acc: 0.9891 - val_loss: 0.2361 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0177 - acc: 0.9927 - val_loss: 0.2338 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0181 - acc: 0.9964 - val_loss: 0.2383 - val_acc: 0.6129\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0173 - acc: 0.9927 - val_loss: 0.2372 - val_acc: 0.6129\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0163 - acc: 0.9964 - val_loss: 0.2333 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0140 - acc: 0.9964 - val_loss: 0.2408 - val_acc: 0.5484\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0135 - acc: 0.9964 - val_loss: 0.2377 - val_acc: 0.6129\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0126 - acc: 0.9964 - val_loss: 0.2390 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0119 - acc: 0.9964 - val_loss: 0.2399 - val_acc: 0.6129\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0128 - acc: 0.9964 - val_loss: 0.2418 - val_acc: 0.6129\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0112 - acc: 0.9964 - val_loss: 0.2424 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0104 - acc: 0.9964 - val_loss: 0.2424 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0099 - acc: 0.9964 - val_loss: 0.2425 - val_acc: 0.6452\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0098 - acc: 0.9964 - val_loss: 0.2421 - val_acc: 0.7097\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0094 - acc: 0.9964 - val_loss: 0.2413 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0091 - acc: 0.9964 - val_loss: 0.2388 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0087 - acc: 0.9964 - val_loss: 0.2418 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_130 (Dense)            (None, 46)                1794      \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 15)                705       \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 2,515\n",
      "Trainable params: 2,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 5ms/step - loss: 0.2499 - acc: 0.5273 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.2493 - acc: 0.5418 - val_loss: 0.2490 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.2472 - acc: 0.5418 - val_loss: 0.2451 - val_acc: 0.5484\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.2405 - acc: 0.6255 - val_loss: 0.2351 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.2254 - acc: 0.6982 - val_loss: 0.2187 - val_acc: 0.6774\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.2029 - acc: 0.7345 - val_loss: 0.2065 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1840 - acc: 0.7491 - val_loss: 0.1975 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1717 - acc: 0.7527 - val_loss: 0.1962 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1643 - acc: 0.7600 - val_loss: 0.2024 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1594 - acc: 0.7709 - val_loss: 0.2049 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1561 - acc: 0.7891 - val_loss: 0.2139 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1542 - acc: 0.7818 - val_loss: 0.2160 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1500 - acc: 0.7964 - val_loss: 0.2126 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1485 - acc: 0.8109 - val_loss: 0.2180 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1466 - acc: 0.8036 - val_loss: 0.2168 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1433 - acc: 0.8109 - val_loss: 0.2220 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1405 - acc: 0.8182 - val_loss: 0.2235 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 301us/step - loss: 0.1391 - acc: 0.8291 - val_loss: 0.2242 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.1356 - acc: 0.8182 - val_loss: 0.2266 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1326 - acc: 0.8327 - val_loss: 0.2261 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1300 - acc: 0.8436 - val_loss: 0.2286 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 281us/step - loss: 0.1283 - acc: 0.8473 - val_loss: 0.2249 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1238 - acc: 0.8400 - val_loss: 0.2251 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1217 - acc: 0.8582 - val_loss: 0.2279 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.1186 - acc: 0.8655 - val_loss: 0.2287 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1154 - acc: 0.8655 - val_loss: 0.2304 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1129 - acc: 0.8655 - val_loss: 0.2303 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1084 - acc: 0.8764 - val_loss: 0.2304 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1041 - acc: 0.8873 - val_loss: 0.2281 - val_acc: 0.7419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1006 - acc: 0.8909 - val_loss: 0.2316 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.0956 - acc: 0.9018 - val_loss: 0.2276 - val_acc: 0.7419\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.0925 - acc: 0.9055 - val_loss: 0.2323 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0885 - acc: 0.9164 - val_loss: 0.2334 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.0850 - acc: 0.9164 - val_loss: 0.2339 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.0820 - acc: 0.9236 - val_loss: 0.2310 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.0774 - acc: 0.9236 - val_loss: 0.2333 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 302us/step - loss: 0.0737 - acc: 0.9273 - val_loss: 0.2326 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 305us/step - loss: 0.0689 - acc: 0.9345 - val_loss: 0.2357 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0652 - acc: 0.9455 - val_loss: 0.2293 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0611 - acc: 0.9455 - val_loss: 0.2371 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0560 - acc: 0.9636 - val_loss: 0.2310 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.0523 - acc: 0.9709 - val_loss: 0.2343 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.0501 - acc: 0.9709 - val_loss: 0.2364 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.0457 - acc: 0.9709 - val_loss: 0.2305 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.0422 - acc: 0.9745 - val_loss: 0.2379 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0387 - acc: 0.9782 - val_loss: 0.2385 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0381 - acc: 0.9745 - val_loss: 0.2463 - val_acc: 0.6452\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.0352 - acc: 0.9818 - val_loss: 0.2460 - val_acc: 0.6452\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0318 - acc: 0.9818 - val_loss: 0.2447 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.0299 - acc: 0.9891 - val_loss: 0.2454 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0279 - acc: 0.9891 - val_loss: 0.2451 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 213us/step - loss: 0.0261 - acc: 0.9891 - val_loss: 0.2430 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0246 - acc: 0.9891 - val_loss: 0.2486 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.0234 - acc: 0.9891 - val_loss: 0.2478 - val_acc: 0.6452\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 278us/step - loss: 0.0225 - acc: 0.9855 - val_loss: 0.2436 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0227 - acc: 0.9855 - val_loss: 0.2402 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0211 - acc: 0.9891 - val_loss: 0.2543 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.0197 - acc: 0.9891 - val_loss: 0.2429 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0190 - acc: 0.9891 - val_loss: 0.2437 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0188 - acc: 0.9891 - val_loss: 0.2473 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0177 - acc: 0.9891 - val_loss: 0.2418 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0171 - acc: 0.9891 - val_loss: 0.2484 - val_acc: 0.6129\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0165 - acc: 0.9891 - val_loss: 0.2380 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0152 - acc: 0.9891 - val_loss: 0.2434 - val_acc: 0.5806\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0155 - acc: 0.9891 - val_loss: 0.2416 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0134 - acc: 0.9927 - val_loss: 0.2330 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0121 - acc: 0.9927 - val_loss: 0.2301 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0109 - acc: 0.9927 - val_loss: 0.2308 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0101 - acc: 0.9964 - val_loss: 0.2357 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0096 - acc: 0.9964 - val_loss: 0.2363 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.0086 - acc: 0.9964 - val_loss: 0.2387 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0082 - acc: 0.9964 - val_loss: 0.2332 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.0080 - acc: 0.9964 - val_loss: 0.2431 - val_acc: 0.6129\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.0073 - acc: 0.9964 - val_loss: 0.2437 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.0071 - acc: 0.9964 - val_loss: 0.2443 - val_acc: 0.6129\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0068 - acc: 0.9964 - val_loss: 0.2486 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.0066 - acc: 0.9964 - val_loss: 0.2464 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.0064 - acc: 0.9964 - val_loss: 0.2494 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.0062 - acc: 0.9964 - val_loss: 0.2474 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0061 - acc: 0.9964 - val_loss: 0.2493 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.0060 - acc: 0.9964 - val_loss: 0.2514 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.0058 - acc: 0.9964 - val_loss: 0.2521 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.0057 - acc: 0.9964 - val_loss: 0.2528 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.0056 - acc: 0.9964 - val_loss: 0.2529 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.2530 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0054 - acc: 0.9964 - val_loss: 0.2524 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.2566 - val_acc: 0.6452\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.2557 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2565 - val_acc: 0.6452\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 251us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2567 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.2571 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.2587 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.2579 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0048 - acc: 0.9964 - val_loss: 0.2613 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0048 - acc: 0.9964 - val_loss: 0.2587 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0047 - acc: 0.9964 - val_loss: 0.2594 - val_acc: 0.6452\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0047 - acc: 0.9964 - val_loss: 0.2592 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0047 - acc: 0.9964 - val_loss: 0.2621 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0046 - acc: 0.9964 - val_loss: 0.2621 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0045 - acc: 0.9964 - val_loss: 0.2616 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_133 (Dense)            (None, 18)                702       \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 1,063\n",
      "Trainable params: 1,063\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 5ms/step - loss: 0.2499 - acc: 0.5382 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2495 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.2484 - acc: 0.5418 - val_loss: 0.2477 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.2450 - acc: 0.5418 - val_loss: 0.2421 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.2356 - acc: 0.5964 - val_loss: 0.2332 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.2228 - acc: 0.6655 - val_loss: 0.2243 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.2086 - acc: 0.7236 - val_loss: 0.2178 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.1956 - acc: 0.7273 - val_loss: 0.2121 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1849 - acc: 0.7418 - val_loss: 0.2102 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1780 - acc: 0.7709 - val_loss: 0.2053 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.1739 - acc: 0.7455 - val_loss: 0.2060 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1675 - acc: 0.7636 - val_loss: 0.2110 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 287us/step - loss: 0.1659 - acc: 0.7673 - val_loss: 0.2133 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.1644 - acc: 0.7745 - val_loss: 0.2163 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.1638 - acc: 0.7636 - val_loss: 0.2251 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1588 - acc: 0.7782 - val_loss: 0.2197 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.1582 - acc: 0.7855 - val_loss: 0.2253 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.1565 - acc: 0.7855 - val_loss: 0.2287 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1555 - acc: 0.7855 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1550 - acc: 0.7818 - val_loss: 0.2304 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.1548 - acc: 0.7818 - val_loss: 0.2278 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1543 - acc: 0.7891 - val_loss: 0.2307 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.1513 - acc: 0.7964 - val_loss: 0.2281 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.1502 - acc: 0.7891 - val_loss: 0.2334 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.1490 - acc: 0.8000 - val_loss: 0.2341 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1479 - acc: 0.8073 - val_loss: 0.2315 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 289us/step - loss: 0.1474 - acc: 0.8109 - val_loss: 0.2316 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.1459 - acc: 0.8109 - val_loss: 0.2338 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.1460 - acc: 0.8145 - val_loss: 0.2338 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.1443 - acc: 0.8109 - val_loss: 0.2351 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 262us/step - loss: 0.1435 - acc: 0.8145 - val_loss: 0.2365 - val_acc: 0.6452\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1422 - acc: 0.8182 - val_loss: 0.2332 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.1410 - acc: 0.8182 - val_loss: 0.2341 - val_acc: 0.6452\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1407 - acc: 0.8218 - val_loss: 0.2359 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1388 - acc: 0.8291 - val_loss: 0.2330 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1376 - acc: 0.8255 - val_loss: 0.2365 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 296us/step - loss: 0.1368 - acc: 0.8291 - val_loss: 0.2322 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.1352 - acc: 0.8327 - val_loss: 0.2340 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.1338 - acc: 0.8327 - val_loss: 0.2331 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1324 - acc: 0.8400 - val_loss: 0.2333 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1327 - acc: 0.8436 - val_loss: 0.2320 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1306 - acc: 0.8400 - val_loss: 0.2332 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 301us/step - loss: 0.1303 - acc: 0.8364 - val_loss: 0.2331 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1286 - acc: 0.8400 - val_loss: 0.2331 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.1260 - acc: 0.8545 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1249 - acc: 0.8509 - val_loss: 0.2334 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1243 - acc: 0.8545 - val_loss: 0.2282 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.1228 - acc: 0.8582 - val_loss: 0.2269 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.1208 - acc: 0.8582 - val_loss: 0.2259 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 261us/step - loss: 0.1197 - acc: 0.8582 - val_loss: 0.2267 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1176 - acc: 0.8691 - val_loss: 0.2245 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1166 - acc: 0.8582 - val_loss: 0.2256 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1150 - acc: 0.8618 - val_loss: 0.2247 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.1151 - acc: 0.8691 - val_loss: 0.2268 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1124 - acc: 0.8655 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1101 - acc: 0.8655 - val_loss: 0.2257 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1094 - acc: 0.8764 - val_loss: 0.2232 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1076 - acc: 0.8691 - val_loss: 0.2263 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1046 - acc: 0.8836 - val_loss: 0.2235 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.1031 - acc: 0.8800 - val_loss: 0.2263 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1017 - acc: 0.8945 - val_loss: 0.2217 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.1004 - acc: 0.9018 - val_loss: 0.2199 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0998 - acc: 0.8836 - val_loss: 0.2187 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0977 - acc: 0.8873 - val_loss: 0.2221 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0955 - acc: 0.9018 - val_loss: 0.2198 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0917 - acc: 0.9127 - val_loss: 0.2169 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.0903 - acc: 0.9055 - val_loss: 0.2157 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0879 - acc: 0.9018 - val_loss: 0.2137 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0883 - acc: 0.9091 - val_loss: 0.2159 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0847 - acc: 0.9236 - val_loss: 0.2155 - val_acc: 0.7097\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0826 - acc: 0.9164 - val_loss: 0.2140 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0802 - acc: 0.9273 - val_loss: 0.2123 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0785 - acc: 0.9273 - val_loss: 0.2102 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0762 - acc: 0.9273 - val_loss: 0.2122 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.0744 - acc: 0.9273 - val_loss: 0.2140 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 268us/step - loss: 0.0728 - acc: 0.9273 - val_loss: 0.2054 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0712 - acc: 0.9345 - val_loss: 0.2091 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0698 - acc: 0.9345 - val_loss: 0.2070 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0668 - acc: 0.9309 - val_loss: 0.2085 - val_acc: 0.7097\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0663 - acc: 0.9345 - val_loss: 0.2103 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0623 - acc: 0.9345 - val_loss: 0.2097 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0604 - acc: 0.9418 - val_loss: 0.2115 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0602 - acc: 0.9418 - val_loss: 0.2068 - val_acc: 0.7419\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0570 - acc: 0.9527 - val_loss: 0.2108 - val_acc: 0.7419\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0547 - acc: 0.9455 - val_loss: 0.2143 - val_acc: 0.7097\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0540 - acc: 0.9418 - val_loss: 0.2134 - val_acc: 0.7419\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0509 - acc: 0.9527 - val_loss: 0.2177 - val_acc: 0.7419\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.0482 - acc: 0.9564 - val_loss: 0.2207 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0458 - acc: 0.9600 - val_loss: 0.2213 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.0439 - acc: 0.9564 - val_loss: 0.2294 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0433 - acc: 0.9600 - val_loss: 0.2188 - val_acc: 0.7097\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 213us/step - loss: 0.0409 - acc: 0.9636 - val_loss: 0.2146 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0389 - acc: 0.9709 - val_loss: 0.2266 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0371 - acc: 0.9782 - val_loss: 0.2255 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0356 - acc: 0.9782 - val_loss: 0.2348 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.0340 - acc: 0.9818 - val_loss: 0.2342 - val_acc: 0.6129\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.0322 - acc: 0.9818 - val_loss: 0.2428 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.0299 - acc: 0.9818 - val_loss: 0.2450 - val_acc: 0.6129\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0280 - acc: 0.9855 - val_loss: 0.2429 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 304us/step - loss: 0.0273 - acc: 0.9818 - val_loss: 0.2466 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_136 (Dense)            (None, 13)                507       \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 658\n",
      "Trainable params: 658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 2s 5ms/step - loss: 0.2499 - acc: 0.5418 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2495 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.2487 - acc: 0.5418 - val_loss: 0.2487 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.2464 - acc: 0.5418 - val_loss: 0.2460 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.2416 - acc: 0.5418 - val_loss: 0.2412 - val_acc: 0.5161\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.2345 - acc: 0.5418 - val_loss: 0.2343 - val_acc: 0.5161\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.2251 - acc: 0.5782 - val_loss: 0.2295 - val_acc: 0.6129\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.2163 - acc: 0.6727 - val_loss: 0.2266 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.2087 - acc: 0.7091 - val_loss: 0.2209 - val_acc: 0.6129\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.2022 - acc: 0.7236 - val_loss: 0.2210 - val_acc: 0.6452\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.1964 - acc: 0.7345 - val_loss: 0.2174 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1917 - acc: 0.7418 - val_loss: 0.2153 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.1864 - acc: 0.7636 - val_loss: 0.2160 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1815 - acc: 0.7527 - val_loss: 0.2139 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1775 - acc: 0.7600 - val_loss: 0.2123 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.1736 - acc: 0.7745 - val_loss: 0.2140 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1701 - acc: 0.7709 - val_loss: 0.2117 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1676 - acc: 0.7818 - val_loss: 0.2105 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1648 - acc: 0.7818 - val_loss: 0.2118 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1626 - acc: 0.7891 - val_loss: 0.2125 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.1616 - acc: 0.7782 - val_loss: 0.2124 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1600 - acc: 0.7709 - val_loss: 0.2205 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1584 - acc: 0.7855 - val_loss: 0.2149 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1573 - acc: 0.7927 - val_loss: 0.2169 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1560 - acc: 0.7927 - val_loss: 0.2179 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1548 - acc: 0.8036 - val_loss: 0.2190 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1551 - acc: 0.8036 - val_loss: 0.2214 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1532 - acc: 0.7927 - val_loss: 0.2213 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1525 - acc: 0.8073 - val_loss: 0.2220 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1518 - acc: 0.8000 - val_loss: 0.2240 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1512 - acc: 0.8000 - val_loss: 0.2243 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1506 - acc: 0.7964 - val_loss: 0.2239 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.1500 - acc: 0.8036 - val_loss: 0.2259 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.1494 - acc: 0.8145 - val_loss: 0.2250 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1484 - acc: 0.8109 - val_loss: 0.2256 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1479 - acc: 0.8109 - val_loss: 0.2277 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1474 - acc: 0.8218 - val_loss: 0.2279 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1468 - acc: 0.8182 - val_loss: 0.2285 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1459 - acc: 0.8036 - val_loss: 0.2303 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1455 - acc: 0.8073 - val_loss: 0.2290 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.1449 - acc: 0.8145 - val_loss: 0.2299 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1449 - acc: 0.8073 - val_loss: 0.2340 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 277us/step - loss: 0.1437 - acc: 0.8182 - val_loss: 0.2301 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1427 - acc: 0.8218 - val_loss: 0.2336 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1423 - acc: 0.8218 - val_loss: 0.2347 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1414 - acc: 0.8255 - val_loss: 0.2334 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1416 - acc: 0.8255 - val_loss: 0.2305 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1410 - acc: 0.8182 - val_loss: 0.2351 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.1396 - acc: 0.8291 - val_loss: 0.2348 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.1395 - acc: 0.8327 - val_loss: 0.2330 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1388 - acc: 0.8255 - val_loss: 0.2364 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1387 - acc: 0.8327 - val_loss: 0.2369 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1371 - acc: 0.8291 - val_loss: 0.2372 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1365 - acc: 0.8327 - val_loss: 0.2392 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1360 - acc: 0.8364 - val_loss: 0.2363 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.1348 - acc: 0.8436 - val_loss: 0.2375 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1343 - acc: 0.8364 - val_loss: 0.2391 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.1337 - acc: 0.8400 - val_loss: 0.2393 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.1324 - acc: 0.8436 - val_loss: 0.2377 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1321 - acc: 0.8364 - val_loss: 0.2399 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1313 - acc: 0.8436 - val_loss: 0.2373 - val_acc: 0.7097\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.1308 - acc: 0.8545 - val_loss: 0.2387 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.1313 - acc: 0.8509 - val_loss: 0.2380 - val_acc: 0.7097\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.1300 - acc: 0.8545 - val_loss: 0.2411 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.1281 - acc: 0.8545 - val_loss: 0.2398 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.1273 - acc: 0.8545 - val_loss: 0.2417 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1260 - acc: 0.8509 - val_loss: 0.2436 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1255 - acc: 0.8618 - val_loss: 0.2423 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1253 - acc: 0.8655 - val_loss: 0.2440 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1243 - acc: 0.8582 - val_loss: 0.2463 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1237 - acc: 0.8582 - val_loss: 0.2420 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1223 - acc: 0.8618 - val_loss: 0.2451 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1225 - acc: 0.8618 - val_loss: 0.2434 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1210 - acc: 0.8691 - val_loss: 0.2450 - val_acc: 0.7097\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1196 - acc: 0.8691 - val_loss: 0.2466 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1187 - acc: 0.8691 - val_loss: 0.2468 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1181 - acc: 0.8691 - val_loss: 0.2483 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.1172 - acc: 0.8691 - val_loss: 0.2486 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1161 - acc: 0.8691 - val_loss: 0.2483 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1153 - acc: 0.8727 - val_loss: 0.2494 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1143 - acc: 0.8764 - val_loss: 0.2471 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1133 - acc: 0.8764 - val_loss: 0.2491 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.1128 - acc: 0.8727 - val_loss: 0.2484 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1112 - acc: 0.8836 - val_loss: 0.2515 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1099 - acc: 0.8764 - val_loss: 0.2501 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1091 - acc: 0.8873 - val_loss: 0.2524 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1079 - acc: 0.8873 - val_loss: 0.2523 - val_acc: 0.6452\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1069 - acc: 0.8873 - val_loss: 0.2531 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1070 - acc: 0.8873 - val_loss: 0.2534 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1046 - acc: 0.8945 - val_loss: 0.2539 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1038 - acc: 0.8909 - val_loss: 0.2554 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1031 - acc: 0.8945 - val_loss: 0.2538 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1015 - acc: 0.8945 - val_loss: 0.2558 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1007 - acc: 0.8945 - val_loss: 0.2534 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1001 - acc: 0.8945 - val_loss: 0.2581 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0990 - acc: 0.8945 - val_loss: 0.2571 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0980 - acc: 0.9055 - val_loss: 0.2583 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0973 - acc: 0.8982 - val_loss: 0.2585 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0962 - acc: 0.9018 - val_loss: 0.2601 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0953 - acc: 0.9018 - val_loss: 0.2611 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_139 (Dense)            (None, 35)                1365      \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 13)                468       \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 1,847\n",
      "Trainable params: 1,847\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 5ms/step - loss: 0.2501 - acc: 0.4582 - val_loss: 0.2499 - val_acc: 0.6452\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.2498 - acc: 0.5564 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 215us/step - loss: 0.2492 - acc: 0.5418 - val_loss: 0.2486 - val_acc: 0.5484\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.2469 - acc: 0.6436 - val_loss: 0.2448 - val_acc: 0.6129\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.2401 - acc: 0.7091 - val_loss: 0.2338 - val_acc: 0.7097\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.2243 - acc: 0.7455 - val_loss: 0.2199 - val_acc: 0.7097\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.2037 - acc: 0.7527 - val_loss: 0.2062 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.1872 - acc: 0.7418 - val_loss: 0.1970 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1745 - acc: 0.7564 - val_loss: 0.1970 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1673 - acc: 0.7600 - val_loss: 0.2039 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1640 - acc: 0.7673 - val_loss: 0.2102 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 262us/step - loss: 0.1601 - acc: 0.7745 - val_loss: 0.2132 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 317us/step - loss: 0.1570 - acc: 0.7855 - val_loss: 0.2150 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 288us/step - loss: 0.1546 - acc: 0.7855 - val_loss: 0.2188 - val_acc: 0.7097\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 267us/step - loss: 0.1549 - acc: 0.7891 - val_loss: 0.2190 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 281us/step - loss: 0.1519 - acc: 0.7964 - val_loss: 0.2206 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 280us/step - loss: 0.1485 - acc: 0.8036 - val_loss: 0.2210 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.1477 - acc: 0.7964 - val_loss: 0.2227 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1452 - acc: 0.8182 - val_loss: 0.2217 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1432 - acc: 0.8109 - val_loss: 0.2251 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1408 - acc: 0.8182 - val_loss: 0.2230 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1391 - acc: 0.8218 - val_loss: 0.2238 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1370 - acc: 0.8218 - val_loss: 0.2262 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.1347 - acc: 0.8218 - val_loss: 0.2253 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.1329 - acc: 0.8218 - val_loss: 0.2242 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.1310 - acc: 0.8291 - val_loss: 0.2250 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1284 - acc: 0.8327 - val_loss: 0.2235 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1270 - acc: 0.8364 - val_loss: 0.2251 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1240 - acc: 0.8436 - val_loss: 0.2238 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1215 - acc: 0.8509 - val_loss: 0.2243 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1191 - acc: 0.8582 - val_loss: 0.2237 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1167 - acc: 0.8655 - val_loss: 0.2248 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1143 - acc: 0.8618 - val_loss: 0.2244 - val_acc: 0.6452\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1121 - acc: 0.8655 - val_loss: 0.2259 - val_acc: 0.6452\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1087 - acc: 0.8727 - val_loss: 0.2233 - val_acc: 0.6452\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.1065 - acc: 0.8800 - val_loss: 0.2240 - val_acc: 0.6452\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1035 - acc: 0.8836 - val_loss: 0.2227 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1010 - acc: 0.8800 - val_loss: 0.2248 - val_acc: 0.6452\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.0978 - acc: 0.8836 - val_loss: 0.2262 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.0940 - acc: 0.8945 - val_loss: 0.2229 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0902 - acc: 0.9091 - val_loss: 0.2246 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0863 - acc: 0.9127 - val_loss: 0.2236 - val_acc: 0.6452\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0841 - acc: 0.9164 - val_loss: 0.2259 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0790 - acc: 0.9200 - val_loss: 0.2226 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.0756 - acc: 0.9200 - val_loss: 0.2265 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0728 - acc: 0.9236 - val_loss: 0.2262 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0679 - acc: 0.9273 - val_loss: 0.2224 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0647 - acc: 0.9418 - val_loss: 0.2257 - val_acc: 0.7419\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.0609 - acc: 0.9418 - val_loss: 0.2261 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0574 - acc: 0.9564 - val_loss: 0.2294 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0544 - acc: 0.9600 - val_loss: 0.2255 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0507 - acc: 0.9782 - val_loss: 0.2262 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0502 - acc: 0.9709 - val_loss: 0.2281 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0462 - acc: 0.9782 - val_loss: 0.2300 - val_acc: 0.7419\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0424 - acc: 0.9818 - val_loss: 0.2291 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0400 - acc: 0.9818 - val_loss: 0.2320 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0381 - acc: 0.9818 - val_loss: 0.2308 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0358 - acc: 0.9855 - val_loss: 0.2292 - val_acc: 0.7097\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0332 - acc: 0.9855 - val_loss: 0.2332 - val_acc: 0.7097\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0314 - acc: 0.9855 - val_loss: 0.2362 - val_acc: 0.7419\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.0302 - acc: 0.9891 - val_loss: 0.2271 - val_acc: 0.7097\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0296 - acc: 0.9855 - val_loss: 0.2322 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0269 - acc: 0.9855 - val_loss: 0.2300 - val_acc: 0.7419\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0257 - acc: 0.9855 - val_loss: 0.2362 - val_acc: 0.7419\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0250 - acc: 0.9855 - val_loss: 0.2365 - val_acc: 0.7097\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0233 - acc: 0.9891 - val_loss: 0.2336 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0228 - acc: 0.9855 - val_loss: 0.2359 - val_acc: 0.7419\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.0215 - acc: 0.9891 - val_loss: 0.2338 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0213 - acc: 0.9891 - val_loss: 0.2355 - val_acc: 0.7097\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0200 - acc: 0.9891 - val_loss: 0.2346 - val_acc: 0.7097\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0195 - acc: 0.9891 - val_loss: 0.2343 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0187 - acc: 0.9891 - val_loss: 0.2371 - val_acc: 0.7097\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0181 - acc: 0.9891 - val_loss: 0.2360 - val_acc: 0.7097\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.0176 - acc: 0.9891 - val_loss: 0.2354 - val_acc: 0.7097\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 240us/step - loss: 0.0173 - acc: 0.9891 - val_loss: 0.2362 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0166 - acc: 0.9891 - val_loss: 0.2373 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0163 - acc: 0.9891 - val_loss: 0.2369 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0160 - acc: 0.9891 - val_loss: 0.2377 - val_acc: 0.7097\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0156 - acc: 0.9891 - val_loss: 0.2370 - val_acc: 0.7097\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0155 - acc: 0.9891 - val_loss: 0.2404 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0149 - acc: 0.9891 - val_loss: 0.2367 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0147 - acc: 0.9891 - val_loss: 0.2378 - val_acc: 0.7097\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0144 - acc: 0.9891 - val_loss: 0.2364 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0141 - acc: 0.9891 - val_loss: 0.2374 - val_acc: 0.7097\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0138 - acc: 0.9891 - val_loss: 0.2373 - val_acc: 0.7097\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0136 - acc: 0.9891 - val_loss: 0.2379 - val_acc: 0.7097\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0134 - acc: 0.9891 - val_loss: 0.2388 - val_acc: 0.7097\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0131 - acc: 0.9891 - val_loss: 0.2385 - val_acc: 0.7097\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0130 - acc: 0.9891 - val_loss: 0.2413 - val_acc: 0.7097\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0130 - acc: 0.9891 - val_loss: 0.2361 - val_acc: 0.7097\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0125 - acc: 0.9891 - val_loss: 0.2384 - val_acc: 0.7097\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0122 - acc: 0.9891 - val_loss: 0.2360 - val_acc: 0.7097\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0119 - acc: 0.9891 - val_loss: 0.2342 - val_acc: 0.7097\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0116 - acc: 0.9891 - val_loss: 0.2300 - val_acc: 0.7097\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0100 - acc: 0.9927 - val_loss: 0.2254 - val_acc: 0.7097\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0086 - acc: 0.9964 - val_loss: 0.2233 - val_acc: 0.7097\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0084 - acc: 0.9927 - val_loss: 0.2296 - val_acc: 0.7097\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0090 - acc: 0.9927 - val_loss: 0.2232 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0069 - acc: 0.9964 - val_loss: 0.2328 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0063 - acc: 0.9964 - val_loss: 0.2297 - val_acc: 0.7097\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_142 (Dense)            (None, 32)                1248      \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,589\n",
      "Trainable params: 1,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 2s 6ms/step - loss: 0.2500 - acc: 0.5345 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.2491 - acc: 0.5418 - val_loss: 0.2489 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 262us/step - loss: 0.2473 - acc: 0.5418 - val_loss: 0.2463 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.2421 - acc: 0.5855 - val_loss: 0.2408 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.2316 - acc: 0.6582 - val_loss: 0.2307 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.2157 - acc: 0.7345 - val_loss: 0.2180 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 293us/step - loss: 0.1983 - acc: 0.7418 - val_loss: 0.2100 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 276us/step - loss: 0.1843 - acc: 0.7491 - val_loss: 0.2052 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.1737 - acc: 0.7564 - val_loss: 0.2044 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1671 - acc: 0.7564 - val_loss: 0.2052 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1640 - acc: 0.7636 - val_loss: 0.2097 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.1617 - acc: 0.7636 - val_loss: 0.2091 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 311us/step - loss: 0.1600 - acc: 0.7745 - val_loss: 0.2119 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 289us/step - loss: 0.1571 - acc: 0.7600 - val_loss: 0.2151 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 279us/step - loss: 0.1548 - acc: 0.7855 - val_loss: 0.2168 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 293us/step - loss: 0.1540 - acc: 0.7782 - val_loss: 0.2186 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.1529 - acc: 0.7891 - val_loss: 0.2203 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 279us/step - loss: 0.1504 - acc: 0.7927 - val_loss: 0.2194 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.1493 - acc: 0.7855 - val_loss: 0.2234 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.1480 - acc: 0.7964 - val_loss: 0.2242 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.1471 - acc: 0.8036 - val_loss: 0.2262 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1456 - acc: 0.8145 - val_loss: 0.2230 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.1446 - acc: 0.8145 - val_loss: 0.2279 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1430 - acc: 0.8036 - val_loss: 0.2256 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1430 - acc: 0.8145 - val_loss: 0.2253 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.1404 - acc: 0.8182 - val_loss: 0.2265 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1394 - acc: 0.8218 - val_loss: 0.2304 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 213us/step - loss: 0.1371 - acc: 0.8327 - val_loss: 0.2255 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1367 - acc: 0.8255 - val_loss: 0.2236 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.1361 - acc: 0.8218 - val_loss: 0.2266 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 301us/step - loss: 0.1345 - acc: 0.8255 - val_loss: 0.2274 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 303us/step - loss: 0.1322 - acc: 0.8327 - val_loss: 0.2247 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 316us/step - loss: 0.1299 - acc: 0.8291 - val_loss: 0.2294 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 279us/step - loss: 0.1287 - acc: 0.8291 - val_loss: 0.2288 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 281us/step - loss: 0.1278 - acc: 0.8291 - val_loss: 0.2305 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.1253 - acc: 0.8327 - val_loss: 0.2314 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 261us/step - loss: 0.1239 - acc: 0.8473 - val_loss: 0.2282 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1216 - acc: 0.8509 - val_loss: 0.2268 - val_acc: 0.7419\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.1200 - acc: 0.8545 - val_loss: 0.2298 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.1182 - acc: 0.8655 - val_loss: 0.2272 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1174 - acc: 0.8618 - val_loss: 0.2307 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1146 - acc: 0.8691 - val_loss: 0.2300 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1131 - acc: 0.8691 - val_loss: 0.2314 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.1113 - acc: 0.8655 - val_loss: 0.2291 - val_acc: 0.7419\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1086 - acc: 0.8691 - val_loss: 0.2306 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.1061 - acc: 0.8836 - val_loss: 0.2294 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.1047 - acc: 0.8836 - val_loss: 0.2304 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 268us/step - loss: 0.1031 - acc: 0.8873 - val_loss: 0.2317 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0999 - acc: 0.9018 - val_loss: 0.2305 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0984 - acc: 0.9091 - val_loss: 0.2312 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.0957 - acc: 0.9164 - val_loss: 0.2304 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 280us/step - loss: 0.0939 - acc: 0.9200 - val_loss: 0.2314 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.0919 - acc: 0.9236 - val_loss: 0.2324 - val_acc: 0.7097\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.0901 - acc: 0.9273 - val_loss: 0.2295 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0875 - acc: 0.9200 - val_loss: 0.2320 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0839 - acc: 0.9236 - val_loss: 0.2330 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0830 - acc: 0.9345 - val_loss: 0.2320 - val_acc: 0.7097\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0808 - acc: 0.9309 - val_loss: 0.2272 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0773 - acc: 0.9309 - val_loss: 0.2274 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.0750 - acc: 0.9455 - val_loss: 0.2246 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0722 - acc: 0.9455 - val_loss: 0.2226 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0697 - acc: 0.9418 - val_loss: 0.2226 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0670 - acc: 0.9564 - val_loss: 0.2201 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 262us/step - loss: 0.0652 - acc: 0.9600 - val_loss: 0.2210 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0622 - acc: 0.9600 - val_loss: 0.2224 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0599 - acc: 0.9564 - val_loss: 0.2237 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0577 - acc: 0.9636 - val_loss: 0.2228 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0559 - acc: 0.9600 - val_loss: 0.2177 - val_acc: 0.7097\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0533 - acc: 0.9673 - val_loss: 0.2239 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0515 - acc: 0.9709 - val_loss: 0.2243 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0487 - acc: 0.9745 - val_loss: 0.2333 - val_acc: 0.6452\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0465 - acc: 0.9782 - val_loss: 0.2247 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0440 - acc: 0.9782 - val_loss: 0.2284 - val_acc: 0.7097\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.0413 - acc: 0.9745 - val_loss: 0.2340 - val_acc: 0.6452\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0397 - acc: 0.9745 - val_loss: 0.2276 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0384 - acc: 0.9818 - val_loss: 0.2339 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0369 - acc: 0.9782 - val_loss: 0.2380 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0342 - acc: 0.9818 - val_loss: 0.2388 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0334 - acc: 0.9745 - val_loss: 0.2340 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0310 - acc: 0.9818 - val_loss: 0.2399 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0300 - acc: 0.9818 - val_loss: 0.2412 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0283 - acc: 0.9855 - val_loss: 0.2346 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0271 - acc: 0.9927 - val_loss: 0.2365 - val_acc: 0.7097\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0257 - acc: 0.9818 - val_loss: 0.2414 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0246 - acc: 0.9891 - val_loss: 0.2469 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0233 - acc: 0.9891 - val_loss: 0.2423 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0224 - acc: 0.9927 - val_loss: 0.2490 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0212 - acc: 0.9927 - val_loss: 0.2509 - val_acc: 0.6774\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 204us/step - loss: 0.0207 - acc: 0.9891 - val_loss: 0.2537 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0194 - acc: 0.9927 - val_loss: 0.2518 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0190 - acc: 0.9927 - val_loss: 0.2546 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0187 - acc: 0.9891 - val_loss: 0.2492 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0177 - acc: 0.9927 - val_loss: 0.2612 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0174 - acc: 0.9927 - val_loss: 0.2575 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0162 - acc: 0.9927 - val_loss: 0.2593 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0157 - acc: 0.9927 - val_loss: 0.2662 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0170 - acc: 0.9927 - val_loss: 0.2640 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0145 - acc: 0.9927 - val_loss: 0.2629 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0141 - acc: 0.9927 - val_loss: 0.2656 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_145 (Dense)            (None, 23)                897       \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 19)                456       \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 1)                 20        \n",
      "=================================================================\n",
      "Total params: 1,373\n",
      "Trainable params: 1,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 2s 6ms/step - loss: 0.2500 - acc: 0.5382 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.2494 - acc: 0.5418 - val_loss: 0.2493 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.2479 - acc: 0.5418 - val_loss: 0.2468 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.2426 - acc: 0.5418 - val_loss: 0.2396 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.2314 - acc: 0.5673 - val_loss: 0.2307 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.2191 - acc: 0.6764 - val_loss: 0.2225 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.2082 - acc: 0.7127 - val_loss: 0.2207 - val_acc: 0.5806\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1987 - acc: 0.7382 - val_loss: 0.2114 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1913 - acc: 0.7418 - val_loss: 0.2071 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 288us/step - loss: 0.1842 - acc: 0.7273 - val_loss: 0.2117 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1757 - acc: 0.7455 - val_loss: 0.2073 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.1734 - acc: 0.7418 - val_loss: 0.2091 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1676 - acc: 0.7636 - val_loss: 0.2121 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.1640 - acc: 0.7709 - val_loss: 0.2157 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1618 - acc: 0.7709 - val_loss: 0.2187 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1603 - acc: 0.7745 - val_loss: 0.2207 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1592 - acc: 0.7709 - val_loss: 0.2205 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1576 - acc: 0.7782 - val_loss: 0.2278 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1560 - acc: 0.7891 - val_loss: 0.2249 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1545 - acc: 0.7855 - val_loss: 0.2289 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1540 - acc: 0.7855 - val_loss: 0.2283 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.1538 - acc: 0.7891 - val_loss: 0.2341 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1518 - acc: 0.7927 - val_loss: 0.2327 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1510 - acc: 0.7964 - val_loss: 0.2371 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 276us/step - loss: 0.1496 - acc: 0.8036 - val_loss: 0.2343 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.1489 - acc: 0.8036 - val_loss: 0.2348 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 277us/step - loss: 0.1474 - acc: 0.8109 - val_loss: 0.2367 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 288us/step - loss: 0.1459 - acc: 0.8073 - val_loss: 0.2385 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1455 - acc: 0.8109 - val_loss: 0.2395 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.1444 - acc: 0.8218 - val_loss: 0.2396 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.1439 - acc: 0.8109 - val_loss: 0.2418 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.1424 - acc: 0.8218 - val_loss: 0.2427 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 261us/step - loss: 0.1418 - acc: 0.8291 - val_loss: 0.2444 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 279us/step - loss: 0.1399 - acc: 0.8218 - val_loss: 0.2444 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 295us/step - loss: 0.1403 - acc: 0.8145 - val_loss: 0.2452 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1382 - acc: 0.8218 - val_loss: 0.2476 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.1364 - acc: 0.8109 - val_loss: 0.2479 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.1348 - acc: 0.8255 - val_loss: 0.2495 - val_acc: 0.6452\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.1339 - acc: 0.8182 - val_loss: 0.2523 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.1317 - acc: 0.8291 - val_loss: 0.2512 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 288us/step - loss: 0.1309 - acc: 0.8218 - val_loss: 0.2517 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 278us/step - loss: 0.1303 - acc: 0.8473 - val_loss: 0.2511 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 278us/step - loss: 0.1279 - acc: 0.8364 - val_loss: 0.2529 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.1261 - acc: 0.8364 - val_loss: 0.2538 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.1262 - acc: 0.8582 - val_loss: 0.2570 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.1235 - acc: 0.8327 - val_loss: 0.2561 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1225 - acc: 0.8509 - val_loss: 0.2561 - val_acc: 0.6452\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.1214 - acc: 0.8545 - val_loss: 0.2556 - val_acc: 0.6129\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 276us/step - loss: 0.1194 - acc: 0.8473 - val_loss: 0.2573 - val_acc: 0.6452\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 268us/step - loss: 0.1189 - acc: 0.8509 - val_loss: 0.2601 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 276us/step - loss: 0.1170 - acc: 0.8655 - val_loss: 0.2621 - val_acc: 0.6129\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1146 - acc: 0.8618 - val_loss: 0.2598 - val_acc: 0.6452\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1129 - acc: 0.8764 - val_loss: 0.2625 - val_acc: 0.6129\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.1119 - acc: 0.8655 - val_loss: 0.2626 - val_acc: 0.6129\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1106 - acc: 0.8618 - val_loss: 0.2662 - val_acc: 0.6129\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1086 - acc: 0.8764 - val_loss: 0.2659 - val_acc: 0.6129\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1064 - acc: 0.8691 - val_loss: 0.2664 - val_acc: 0.6452\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.1048 - acc: 0.8873 - val_loss: 0.2682 - val_acc: 0.6129\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1032 - acc: 0.8800 - val_loss: 0.2683 - val_acc: 0.6452\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.1007 - acc: 0.9018 - val_loss: 0.2679 - val_acc: 0.6452\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 261us/step - loss: 0.1010 - acc: 0.8909 - val_loss: 0.2680 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.0968 - acc: 0.8982 - val_loss: 0.2696 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0953 - acc: 0.8982 - val_loss: 0.2687 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0930 - acc: 0.9018 - val_loss: 0.2705 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0928 - acc: 0.9018 - val_loss: 0.2688 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.0893 - acc: 0.9164 - val_loss: 0.2667 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0874 - acc: 0.9091 - val_loss: 0.2645 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0853 - acc: 0.9164 - val_loss: 0.2671 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0841 - acc: 0.9164 - val_loss: 0.2665 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0819 - acc: 0.9236 - val_loss: 0.2638 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0798 - acc: 0.9236 - val_loss: 0.2617 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 278us/step - loss: 0.0774 - acc: 0.9200 - val_loss: 0.2623 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0748 - acc: 0.9345 - val_loss: 0.2613 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.0723 - acc: 0.9345 - val_loss: 0.2578 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0705 - acc: 0.9345 - val_loss: 0.2576 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 277us/step - loss: 0.0687 - acc: 0.9382 - val_loss: 0.2545 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0662 - acc: 0.9382 - val_loss: 0.2564 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0653 - acc: 0.9418 - val_loss: 0.2515 - val_acc: 0.7097\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0632 - acc: 0.9455 - val_loss: 0.2536 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.0636 - acc: 0.9382 - val_loss: 0.2527 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.0596 - acc: 0.9491 - val_loss: 0.2532 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0577 - acc: 0.9564 - val_loss: 0.2524 - val_acc: 0.7097\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0563 - acc: 0.9600 - val_loss: 0.2520 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0550 - acc: 0.9564 - val_loss: 0.2490 - val_acc: 0.7097\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0536 - acc: 0.9527 - val_loss: 0.2494 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0535 - acc: 0.9600 - val_loss: 0.2455 - val_acc: 0.7097\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 261us/step - loss: 0.0511 - acc: 0.9600 - val_loss: 0.2441 - val_acc: 0.7097\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.0498 - acc: 0.9564 - val_loss: 0.2454 - val_acc: 0.7097\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0506 - acc: 0.9564 - val_loss: 0.2455 - val_acc: 0.7097\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.0499 - acc: 0.9527 - val_loss: 0.2490 - val_acc: 0.7097\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0484 - acc: 0.9600 - val_loss: 0.2440 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.0462 - acc: 0.9600 - val_loss: 0.2422 - val_acc: 0.7097\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.0454 - acc: 0.9600 - val_loss: 0.2462 - val_acc: 0.7097\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.0445 - acc: 0.9564 - val_loss: 0.2412 - val_acc: 0.7097\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0435 - acc: 0.9636 - val_loss: 0.2418 - val_acc: 0.7097\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0430 - acc: 0.9600 - val_loss: 0.2422 - val_acc: 0.7097\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0423 - acc: 0.9636 - val_loss: 0.2449 - val_acc: 0.7097\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0425 - acc: 0.9636 - val_loss: 0.2448 - val_acc: 0.7097\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.0408 - acc: 0.9600 - val_loss: 0.2461 - val_acc: 0.7097\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.0403 - acc: 0.9600 - val_loss: 0.2440 - val_acc: 0.7097\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_148 (Dense)            (None, 10)                390       \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 511\n",
      "Trainable params: 511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 2s 6ms/step - loss: 0.2500 - acc: 0.4945 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.2498 - acc: 0.5418 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.2494 - acc: 0.5418 - val_loss: 0.2493 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.2483 - acc: 0.5418 - val_loss: 0.2480 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.2460 - acc: 0.5527 - val_loss: 0.2448 - val_acc: 0.5484\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.2409 - acc: 0.6036 - val_loss: 0.2395 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.2331 - acc: 0.6509 - val_loss: 0.2321 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.2228 - acc: 0.6982 - val_loss: 0.2239 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.2112 - acc: 0.7382 - val_loss: 0.2178 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.2004 - acc: 0.7382 - val_loss: 0.2109 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 314us/step - loss: 0.1907 - acc: 0.7455 - val_loss: 0.2048 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 284us/step - loss: 0.1833 - acc: 0.7382 - val_loss: 0.2051 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1770 - acc: 0.7491 - val_loss: 0.2050 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1724 - acc: 0.7527 - val_loss: 0.2038 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1702 - acc: 0.7600 - val_loss: 0.2057 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.1670 - acc: 0.7527 - val_loss: 0.2095 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 289us/step - loss: 0.1656 - acc: 0.7527 - val_loss: 0.2088 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1635 - acc: 0.7636 - val_loss: 0.2106 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.1628 - acc: 0.7709 - val_loss: 0.2121 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1619 - acc: 0.7745 - val_loss: 0.2122 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1603 - acc: 0.7745 - val_loss: 0.2145 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 286us/step - loss: 0.1600 - acc: 0.7855 - val_loss: 0.2141 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 261us/step - loss: 0.1599 - acc: 0.7673 - val_loss: 0.2152 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.1601 - acc: 0.7600 - val_loss: 0.2173 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 323us/step - loss: 0.1586 - acc: 0.7745 - val_loss: 0.2170 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.1582 - acc: 0.7782 - val_loss: 0.2200 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 304us/step - loss: 0.1576 - acc: 0.7927 - val_loss: 0.2212 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 278us/step - loss: 0.1567 - acc: 0.7855 - val_loss: 0.2201 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.1564 - acc: 0.7818 - val_loss: 0.2206 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 326us/step - loss: 0.1558 - acc: 0.7927 - val_loss: 0.2219 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 319us/step - loss: 0.1563 - acc: 0.7855 - val_loss: 0.2227 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 341us/step - loss: 0.1552 - acc: 0.7818 - val_loss: 0.2227 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 299us/step - loss: 0.1550 - acc: 0.7891 - val_loss: 0.2232 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1547 - acc: 0.7818 - val_loss: 0.2242 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1541 - acc: 0.7855 - val_loss: 0.2238 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1542 - acc: 0.7891 - val_loss: 0.2243 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1534 - acc: 0.7964 - val_loss: 0.2251 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 302us/step - loss: 0.1533 - acc: 0.7891 - val_loss: 0.2246 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.1526 - acc: 0.7964 - val_loss: 0.2263 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 284us/step - loss: 0.1520 - acc: 0.7964 - val_loss: 0.2263 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 307us/step - loss: 0.1516 - acc: 0.8073 - val_loss: 0.2260 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.1516 - acc: 0.8000 - val_loss: 0.2274 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.1509 - acc: 0.8000 - val_loss: 0.2261 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.1503 - acc: 0.8073 - val_loss: 0.2267 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1504 - acc: 0.8109 - val_loss: 0.2264 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.1497 - acc: 0.8109 - val_loss: 0.2264 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1492 - acc: 0.8109 - val_loss: 0.2268 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1486 - acc: 0.8109 - val_loss: 0.2268 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.1485 - acc: 0.8218 - val_loss: 0.2272 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1480 - acc: 0.8109 - val_loss: 0.2265 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1475 - acc: 0.8145 - val_loss: 0.2257 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.1472 - acc: 0.8182 - val_loss: 0.2255 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1468 - acc: 0.8109 - val_loss: 0.2259 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1460 - acc: 0.8218 - val_loss: 0.2267 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1457 - acc: 0.8218 - val_loss: 0.2269 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1459 - acc: 0.8218 - val_loss: 0.2296 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1451 - acc: 0.8145 - val_loss: 0.2283 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1448 - acc: 0.8218 - val_loss: 0.2275 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1441 - acc: 0.8255 - val_loss: 0.2275 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1440 - acc: 0.8145 - val_loss: 0.2281 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1434 - acc: 0.8218 - val_loss: 0.2259 - val_acc: 0.7097\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 215us/step - loss: 0.1426 - acc: 0.8291 - val_loss: 0.2262 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.1427 - acc: 0.8109 - val_loss: 0.2266 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.1418 - acc: 0.8255 - val_loss: 0.2269 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 213us/step - loss: 0.1416 - acc: 0.8218 - val_loss: 0.2283 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 214us/step - loss: 0.1410 - acc: 0.8182 - val_loss: 0.2269 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1406 - acc: 0.8291 - val_loss: 0.2265 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.1403 - acc: 0.8255 - val_loss: 0.2277 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1409 - acc: 0.8145 - val_loss: 0.2275 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.1391 - acc: 0.8291 - val_loss: 0.2266 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1384 - acc: 0.8291 - val_loss: 0.2270 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1375 - acc: 0.8364 - val_loss: 0.2288 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1371 - acc: 0.8327 - val_loss: 0.2291 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.1367 - acc: 0.8436 - val_loss: 0.2280 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.1369 - acc: 0.8327 - val_loss: 0.2290 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.1366 - acc: 0.8218 - val_loss: 0.2294 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1354 - acc: 0.8364 - val_loss: 0.2297 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1354 - acc: 0.8400 - val_loss: 0.2283 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1337 - acc: 0.8400 - val_loss: 0.2288 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1339 - acc: 0.8255 - val_loss: 0.2277 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1332 - acc: 0.8545 - val_loss: 0.2279 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1334 - acc: 0.8436 - val_loss: 0.2280 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1326 - acc: 0.8291 - val_loss: 0.2281 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1316 - acc: 0.8400 - val_loss: 0.2294 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1313 - acc: 0.8473 - val_loss: 0.2272 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1306 - acc: 0.8436 - val_loss: 0.2264 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1305 - acc: 0.8473 - val_loss: 0.2262 - val_acc: 0.7097\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1295 - acc: 0.8473 - val_loss: 0.2264 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1294 - acc: 0.8473 - val_loss: 0.2274 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1289 - acc: 0.8473 - val_loss: 0.2270 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1283 - acc: 0.8545 - val_loss: 0.2265 - val_acc: 0.7097\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1278 - acc: 0.8473 - val_loss: 0.2279 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.1269 - acc: 0.8509 - val_loss: 0.2276 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1265 - acc: 0.8473 - val_loss: 0.2276 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 215us/step - loss: 0.1262 - acc: 0.8582 - val_loss: 0.2257 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1260 - acc: 0.8618 - val_loss: 0.2264 - val_acc: 0.7097\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1253 - acc: 0.8618 - val_loss: 0.2268 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1253 - acc: 0.8655 - val_loss: 0.2290 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1235 - acc: 0.8655 - val_loss: 0.2269 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1233 - acc: 0.8655 - val_loss: 0.2286 - val_acc: 0.6774\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time as tm\n",
    "import datetime\n",
    "import pickle\n",
    "from keras.optimizers import Adam\n",
    "      \n",
    "        \n",
    "def create_file_name():\n",
    "    ts = tm.time()\n",
    "    name = datetime.datetime.fromtimestamp(ts).strftime('%Y%m%d%H%M%S') + '_ann'\n",
    "    return name\n",
    "\n",
    "path='./Netze/'\n",
    "\n",
    "\n",
    "for i in range(0,50):\n",
    "    \n",
    "    units1 = random.randrange(10,51,1) #\n",
    "    units2 = random.randrange(10,21,1) \n",
    "    name_file=create_file_name()\n",
    "    \n",
    "    #opt=Adam(lr=learning_rate))\n",
    "    \n",
    "    # Initialising the ANN\n",
    "    regressor = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    regressor.add(Dense(units = units1, kernel_initializer = 'uniform', activation = 'relu', input_shape = (38,)))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    regressor.add(Dense(units = units2, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # Adding the output layer\n",
    "    regressor.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    #Summary anzeigen\n",
    "    regressor.summary()\n",
    "\n",
    "    # Compiling the ANN - wie soll es lernen\n",
    "    regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "\n",
    "    # Fitting the ANN to the Training set \n",
    "    #input = data[:,0:4] output= (data[:,4]\n",
    "    history = regressor.fit(data[:,0:38], data[:,38], batch_size = 10, epochs = 100, validation_split = 0.1)\n",
    "    \n",
    "    \n",
    "    with open(path + name_file + '.pkl', 'wb') as output:\n",
    "        ann_net = {'history_val_loss':history.history['val_loss'],'history_loss':history.history['loss'],'units1':units1,'units2':units2}\n",
    "        pickle.dump(ann_net, output)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if os.path.exists(path):\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename[(len(filename)-3):len(filename)] == 'pkl':\n",
    "                #print(\"file: \", filename)\n",
    "                with open(path + filename, 'rb') as input:\n",
    "                    ann_net = pickle.load(input)\n",
    "\n",
    "                    plt.plot(ann_net['history_loss'])\n",
    "else:\n",
    "    print('FAIL')\n",
    "\n",
    "plt.title('Verlauf der Kostenfunktion - ANN')\n",
    "plt.ylabel('Kostenfunktion C')\n",
    "plt.xlabel('Epochen')\n",
    "figure = plt.gcf() # get current figure\n",
    "figure.set_size_inches(8, 6)\n",
    "\n",
    "pic_name=create_file_name()+'_bild'\n",
    "plt.savefig(path + pic_name + '.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if os.path.exists(path):\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename[(len(filename)-3):len(filename)] == 'pkl':\n",
    "                #print(\"file: \", filename)\n",
    "                with open(path + filename, 'rb') as input:\n",
    "                    ann_net = pickle.load(input)\n",
    "\n",
    "                    plt.plot(ann_net['history_val_loss'])\n",
    "else:\n",
    "    print('FAIL')\n",
    "\n",
    "plt.title('Verlauf der Kostenfunktion - ANN - Val_loss')\n",
    "plt.ylabel('Kostenfunktion C')\n",
    "plt.xlabel('Epochen')\n",
    "figure = plt.gcf() # get current figure\n",
    "figure.set_size_inches(8, 6)\n",
    "\n",
    "pic_name=create_file_name()+'_bild_val_loss'\n",
    "plt.savefig(path + pic_name + '.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean(arr, start, stop):\n",
    "    if start > stop:\n",
    "        tmp = start\n",
    "        start = stop\n",
    "        stop = tmp\n",
    "    sum = 0\n",
    "    #print('laenge:', len(arr))\n",
    "    j = 0\n",
    "    for i in range(start, stop):\n",
    "        sum = sum + arr[i]\n",
    "        j = j + 1\n",
    "    return (sum / j)\n",
    "\n",
    "\n",
    "def calc_min(arr, start, stop):\n",
    "    if start > stop:\n",
    "        tmp = start\n",
    "        start = stop\n",
    "        stop = tmp\n",
    "    min = 100.0\n",
    "    j = 0\n",
    "    for i in range(start, stop):\n",
    "        if arr[i] < min:\n",
    "            min = arr[i]\n",
    "    return min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b600279186a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mann_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                     \u001b[0mtemp_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalc_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_net\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'history_val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                     \u001b[0mtemp_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalc_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_net\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'history_val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtemp_min\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3f8dab4eedb9>\u001b[0m in \u001b[0;36mcalc_mean\u001b[0;34m(arr, start, stop)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "points=[]\n",
    "min=100\n",
    "units1_min=0\n",
    "units2_min=2\n",
    "if os.path.exists(path):\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename[(len(filename)-3):len(filename)] == 'pkl':\n",
    "                #print(\"file: \", filename)\n",
    "                with open(path + filename, 'rb') as input:\n",
    "                    ann_net = pickle.load(input)\n",
    "                    temp_mean=calc_mean(ann_net['history_val_loss'],15,100)\n",
    "                    temp_min=calc_min(ann_net['history_val_loss'],15,100)\n",
    "                    if temp_min<min:\n",
    "                        min=temp_min\n",
    "                        units1_min= ann_net['units1']\n",
    "                        units2_min= ann_net['units2']\n",
    "                    if temp_mean<0.24: #ausschneiden\n",
    "                        pointx=ann_net['units1']\n",
    "                        pointy=ann_net['units2']\n",
    "                        pointz=temp_mean\n",
    "                        pointsrow=[]\n",
    "                        pointsrow.append(pointx)\n",
    "                        pointsrow.append(pointy)\n",
    "                        pointsrow.append(pointz)\n",
    "                        points.append(pointsrow)\n",
    "else:\n",
    "    print('FAIL')\n",
    "\n",
    "   \n",
    "print('minimales Netz')\n",
    "print(min)\n",
    "print(units1_min)\n",
    "print(units2_min)\n",
    "print('--------------------')\n",
    "    \n",
    "points = np.array(points)\n",
    "plt.scatter(points[:, 0], points[:, 1], c=points[:, 2]) #scatter = punktdiagramme\n",
    "plt.title(\"Kostvergleich ab Epoche 15-100 abh√§ngig der Neuronen der Layer\")\n",
    "plt.xlabel(\"Neuronen erster Layer\")\n",
    "plt.ylabel(\"Neuronen zweiter Layer\")\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(\"Kosten\", labelpad=+2)\n",
    "figure = plt.gcf()  # get current figure\n",
    "figure.set_size_inches(8, 6) \n",
    "pic_name=create_file_name()+'_bild_Neuronenvergleich'\n",
    "plt.savefig(path + pic_name + '.png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
