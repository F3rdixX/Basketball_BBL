{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import urllib.request, json \n",
    "with urllib.request.urlopen(\"http://statistik.easycredit-bbl.de/XML/exchange/540/Schedule.php?type=json&saison=2017&fixedGamesOnly=0\") as url:\n",
    "    games = json.loads(url.read().decode())\n",
    "\n",
    "    \n",
    "    \n",
    "arenakap = {486:6594,413:14500,433:4200,420:6150,415:6000,425:3300,430:6000,426:5002,540:3140,418:6200,421:4003,422:3603,483:3076,477:3447,428:3000,439:4200,517:3533,432:3132}\n",
    "\n",
    "dataset=[]\n",
    "\n",
    "for i in range(0,len(games['competition'][0]['spiel'])):\n",
    "    datasetrow=[]     \n",
    "    datasetrow.append(games['competition'][0]['spiel'][i]['home_id'])\n",
    "    datasetrow.append(games['competition'][0]['spiel'][i]['gast_id'])\n",
    "    datasetrow.append(int(games['competition'][0]['spiel'][i]['home_result']>games['competition'][0]['spiel'][i]['gast_result']))\n",
    "    datasetrow.append(int(games['competition'][0]['spiel'][i]['zuschauer']))\n",
    "    datasetrow.append(arenakap[int(games['competition'][0]['spiel'][i]['home_id'])])\n",
    "    \n",
    "    dataset.append(datasetrow)\n",
    "\n",
    "\n",
    "# Umwandlung des Datasets in ein Numpy Array \n",
    "import numpy as np\n",
    "# : bedeutet in diesem Fall auslesen aller zeilen\n",
    "dataset=np.asarray(dataset)\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "transformed_home_ids = encoder.fit_transform(dataset[:,0])\n",
    "\n",
    "\n",
    "#ohne fit, damit die Teams eindeutig bleiben, nur transformation notwendig\n",
    "transformed_gast_ids = encoder.transform(dataset[:,1])\n",
    "\n",
    "# Umformung der Zuschauer in eine Spalte (vorher war es nur eine Zeile)\n",
    "#print(np.reshape(dataset[:,3],(306,1)))\n",
    "\n",
    "# Featurescaling der Zuschaueranzahl & Hallenkapazit√§ten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "arenaKap_scaler=MinMaxScaler()\n",
    "arenaKap_scaler.fit([[0],[14500]]) #Maximum Berlin und 0 Minimum\n",
    "#reshaping\n",
    "transformed_zuschauer=arenaKap_scaler.transform(np.reshape(dataset[:,3],(306,1)))\n",
    "transformed_kap=arenaKap_scaler.transform(np.reshape(dataset[:,4],(306,1)))\n",
    "\n",
    "\n",
    "data=np.c_[transformed_home_ids,transformed_gast_ids,transformed_zuschauer,transformed_kap,dataset[:,2]]\n",
    "\n",
    "# Importing the Keras libraries and packages \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                468       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                195       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 679\n",
      "Trainable params: 679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 897us/step - loss: 0.2499 - acc: 0.5273 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.2492 - acc: 0.5418 - val_loss: 0.2492 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.2479 - acc: 0.5418 - val_loss: 0.2475 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.2445 - acc: 0.5564 - val_loss: 0.2434 - val_acc: 0.6129\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.2374 - acc: 0.6545 - val_loss: 0.2344 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.2243 - acc: 0.7127 - val_loss: 0.2227 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.2091 - acc: 0.7309 - val_loss: 0.2131 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.1950 - acc: 0.7309 - val_loss: 0.2054 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1843 - acc: 0.7527 - val_loss: 0.2008 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1751 - acc: 0.7418 - val_loss: 0.2027 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1696 - acc: 0.7527 - val_loss: 0.2002 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1676 - acc: 0.7673 - val_loss: 0.2002 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1645 - acc: 0.7564 - val_loss: 0.2059 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1622 - acc: 0.7673 - val_loss: 0.2052 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1606 - acc: 0.7600 - val_loss: 0.2104 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1583 - acc: 0.7709 - val_loss: 0.2110 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1576 - acc: 0.7745 - val_loss: 0.2101 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1563 - acc: 0.7745 - val_loss: 0.2125 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1551 - acc: 0.8000 - val_loss: 0.2144 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1542 - acc: 0.7891 - val_loss: 0.2160 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1536 - acc: 0.7855 - val_loss: 0.2128 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1527 - acc: 0.8000 - val_loss: 0.2169 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1512 - acc: 0.7891 - val_loss: 0.2169 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1499 - acc: 0.7964 - val_loss: 0.2167 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1496 - acc: 0.8036 - val_loss: 0.2154 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1490 - acc: 0.8073 - val_loss: 0.2181 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1475 - acc: 0.8145 - val_loss: 0.2196 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1474 - acc: 0.8000 - val_loss: 0.2187 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1474 - acc: 0.8073 - val_loss: 0.2180 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1458 - acc: 0.8109 - val_loss: 0.2201 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1458 - acc: 0.8036 - val_loss: 0.2224 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1444 - acc: 0.8036 - val_loss: 0.2204 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1430 - acc: 0.8073 - val_loss: 0.2206 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.1425 - acc: 0.8109 - val_loss: 0.2215 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 140us/step - loss: 0.1424 - acc: 0.8218 - val_loss: 0.2245 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.1433 - acc: 0.8218 - val_loss: 0.2220 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 143us/step - loss: 0.1409 - acc: 0.8182 - val_loss: 0.2216 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.1397 - acc: 0.8291 - val_loss: 0.2210 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1390 - acc: 0.8291 - val_loss: 0.2226 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.1390 - acc: 0.8218 - val_loss: 0.2231 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1379 - acc: 0.8182 - val_loss: 0.2228 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.1366 - acc: 0.8327 - val_loss: 0.2222 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.1360 - acc: 0.8255 - val_loss: 0.2232 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1347 - acc: 0.8182 - val_loss: 0.2224 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 143us/step - loss: 0.1339 - acc: 0.8255 - val_loss: 0.2219 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.1333 - acc: 0.8255 - val_loss: 0.2195 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.1325 - acc: 0.8255 - val_loss: 0.2255 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1312 - acc: 0.8364 - val_loss: 0.2230 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 143us/step - loss: 0.1313 - acc: 0.8291 - val_loss: 0.2204 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.1301 - acc: 0.8218 - val_loss: 0.2224 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1298 - acc: 0.8364 - val_loss: 0.2216 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.1278 - acc: 0.8327 - val_loss: 0.2243 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.1272 - acc: 0.8364 - val_loss: 0.2234 - val_acc: 0.6774\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 152us/step - loss: 0.1258 - acc: 0.8291 - val_loss: 0.2267 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.1252 - acc: 0.8436 - val_loss: 0.2247 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 139us/step - loss: 0.1237 - acc: 0.8364 - val_loss: 0.2264 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.1230 - acc: 0.8436 - val_loss: 0.2259 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1216 - acc: 0.8509 - val_loss: 0.2258 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1231 - acc: 0.8436 - val_loss: 0.2279 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1195 - acc: 0.8509 - val_loss: 0.2289 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.1182 - acc: 0.8618 - val_loss: 0.2281 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1175 - acc: 0.8691 - val_loss: 0.2278 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.1164 - acc: 0.8582 - val_loss: 0.2311 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1154 - acc: 0.8582 - val_loss: 0.2299 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.1131 - acc: 0.8727 - val_loss: 0.2330 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1120 - acc: 0.8655 - val_loss: 0.2307 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.1109 - acc: 0.8655 - val_loss: 0.2309 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.1105 - acc: 0.8655 - val_loss: 0.2325 - val_acc: 0.7097\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 143us/step - loss: 0.1076 - acc: 0.8800 - val_loss: 0.2341 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 138us/step - loss: 0.1054 - acc: 0.8764 - val_loss: 0.2275 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 138us/step - loss: 0.1040 - acc: 0.8873 - val_loss: 0.2302 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.1029 - acc: 0.8764 - val_loss: 0.2283 - val_acc: 0.7097\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 139us/step - loss: 0.1000 - acc: 0.8945 - val_loss: 0.2295 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 139us/step - loss: 0.0985 - acc: 0.8873 - val_loss: 0.2323 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.0966 - acc: 0.9018 - val_loss: 0.2264 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 140us/step - loss: 0.0949 - acc: 0.9055 - val_loss: 0.2275 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 137us/step - loss: 0.0919 - acc: 0.9091 - val_loss: 0.2267 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.0914 - acc: 0.9018 - val_loss: 0.2248 - val_acc: 0.7097\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0887 - acc: 0.9091 - val_loss: 0.2293 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0869 - acc: 0.9091 - val_loss: 0.2287 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0848 - acc: 0.9127 - val_loss: 0.2327 - val_acc: 0.6129\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0832 - acc: 0.9164 - val_loss: 0.2306 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0808 - acc: 0.9164 - val_loss: 0.2308 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.0792 - acc: 0.9200 - val_loss: 0.2312 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.0770 - acc: 0.9345 - val_loss: 0.2284 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 140us/step - loss: 0.0763 - acc: 0.9236 - val_loss: 0.2346 - val_acc: 0.6452\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 143us/step - loss: 0.0746 - acc: 0.9273 - val_loss: 0.2325 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.0729 - acc: 0.9309 - val_loss: 0.2320 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.0733 - acc: 0.9273 - val_loss: 0.2421 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 137us/step - loss: 0.0720 - acc: 0.9273 - val_loss: 0.2308 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.0689 - acc: 0.9491 - val_loss: 0.2413 - val_acc: 0.5806\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.0672 - acc: 0.9273 - val_loss: 0.2436 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 138us/step - loss: 0.0654 - acc: 0.9345 - val_loss: 0.2418 - val_acc: 0.6129\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 138us/step - loss: 0.0640 - acc: 0.9382 - val_loss: 0.2477 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.0623 - acc: 0.9491 - val_loss: 0.2426 - val_acc: 0.6129\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.0611 - acc: 0.9491 - val_loss: 0.2440 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.0591 - acc: 0.9491 - val_loss: 0.2472 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.0577 - acc: 0.9527 - val_loss: 0.2544 - val_acc: 0.6129\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0568 - acc: 0.9527 - val_loss: 0.2532 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 48)                1872      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 13)                637       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 2,523\n",
      "Trainable params: 2,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 1ms/step - loss: 0.2499 - acc: 0.5273 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.2493 - acc: 0.5418 - val_loss: 0.2490 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.2472 - acc: 0.5418 - val_loss: 0.2447 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.2391 - acc: 0.5636 - val_loss: 0.2348 - val_acc: 0.5806\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.2244 - acc: 0.6473 - val_loss: 0.2252 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.2092 - acc: 0.7055 - val_loss: 0.2188 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1947 - acc: 0.7200 - val_loss: 0.2094 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1812 - acc: 0.7527 - val_loss: 0.2010 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1725 - acc: 0.7600 - val_loss: 0.2073 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1655 - acc: 0.7673 - val_loss: 0.2033 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1616 - acc: 0.7782 - val_loss: 0.2105 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1572 - acc: 0.7818 - val_loss: 0.2091 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1551 - acc: 0.7964 - val_loss: 0.2150 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1528 - acc: 0.8036 - val_loss: 0.2171 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1505 - acc: 0.8109 - val_loss: 0.2173 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1496 - acc: 0.8073 - val_loss: 0.2196 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1476 - acc: 0.8291 - val_loss: 0.2227 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1449 - acc: 0.8291 - val_loss: 0.2208 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1432 - acc: 0.8182 - val_loss: 0.2248 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1404 - acc: 0.8255 - val_loss: 0.2255 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1389 - acc: 0.8291 - val_loss: 0.2262 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1370 - acc: 0.8255 - val_loss: 0.2267 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1349 - acc: 0.8327 - val_loss: 0.2218 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1338 - acc: 0.8255 - val_loss: 0.2265 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1305 - acc: 0.8364 - val_loss: 0.2192 - val_acc: 0.7419\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1292 - acc: 0.8400 - val_loss: 0.2241 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1265 - acc: 0.8436 - val_loss: 0.2268 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1234 - acc: 0.8582 - val_loss: 0.2215 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1210 - acc: 0.8618 - val_loss: 0.2231 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1192 - acc: 0.8618 - val_loss: 0.2231 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1153 - acc: 0.8655 - val_loss: 0.2207 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1126 - acc: 0.8836 - val_loss: 0.2246 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1105 - acc: 0.8800 - val_loss: 0.2161 - val_acc: 0.7419\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1072 - acc: 0.8764 - val_loss: 0.2208 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1030 - acc: 0.8873 - val_loss: 0.2185 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1011 - acc: 0.8873 - val_loss: 0.2151 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0990 - acc: 0.9055 - val_loss: 0.2170 - val_acc: 0.7419\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0941 - acc: 0.9127 - val_loss: 0.2158 - val_acc: 0.7419\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0908 - acc: 0.9091 - val_loss: 0.2151 - val_acc: 0.7419\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0877 - acc: 0.9127 - val_loss: 0.2094 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0850 - acc: 0.9273 - val_loss: 0.2183 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0808 - acc: 0.9236 - val_loss: 0.2128 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0773 - acc: 0.9236 - val_loss: 0.2143 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0733 - acc: 0.9418 - val_loss: 0.2107 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0709 - acc: 0.9418 - val_loss: 0.2104 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0694 - acc: 0.9382 - val_loss: 0.2117 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0653 - acc: 0.9455 - val_loss: 0.2068 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0615 - acc: 0.9491 - val_loss: 0.2097 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0584 - acc: 0.9527 - val_loss: 0.2062 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0548 - acc: 0.9564 - val_loss: 0.2062 - val_acc: 0.7419\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0517 - acc: 0.9564 - val_loss: 0.2041 - val_acc: 0.7419\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0508 - acc: 0.9600 - val_loss: 0.2076 - val_acc: 0.7419\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0469 - acc: 0.9636 - val_loss: 0.2132 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0450 - acc: 0.9636 - val_loss: 0.2062 - val_acc: 0.7742\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0415 - acc: 0.9709 - val_loss: 0.2152 - val_acc: 0.7419\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0381 - acc: 0.9673 - val_loss: 0.2151 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0367 - acc: 0.9673 - val_loss: 0.2168 - val_acc: 0.7742\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0335 - acc: 0.9745 - val_loss: 0.2206 - val_acc: 0.7742\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0311 - acc: 0.9818 - val_loss: 0.2202 - val_acc: 0.7419\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0299 - acc: 0.9855 - val_loss: 0.2152 - val_acc: 0.8065\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0275 - acc: 0.9818 - val_loss: 0.2140 - val_acc: 0.7742\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0258 - acc: 0.9855 - val_loss: 0.2204 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0244 - acc: 0.9855 - val_loss: 0.2222 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0230 - acc: 0.9927 - val_loss: 0.2180 - val_acc: 0.7419\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0201 - acc: 0.9891 - val_loss: 0.2243 - val_acc: 0.7742\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0188 - acc: 0.9927 - val_loss: 0.2266 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0175 - acc: 0.9927 - val_loss: 0.2286 - val_acc: 0.7419\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.0163 - acc: 0.9927 - val_loss: 0.2370 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0154 - acc: 0.9927 - val_loss: 0.2409 - val_acc: 0.7742\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 149us/step - loss: 0.0141 - acc: 0.9964 - val_loss: 0.2385 - val_acc: 0.7097\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0140 - acc: 0.9927 - val_loss: 0.2379 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0119 - acc: 0.9964 - val_loss: 0.2431 - val_acc: 0.7097\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0122 - acc: 0.9964 - val_loss: 0.2409 - val_acc: 0.7097\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0120 - acc: 0.9964 - val_loss: 0.2437 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.0106 - acc: 0.9964 - val_loss: 0.2402 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0096 - acc: 0.9964 - val_loss: 0.2442 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0091 - acc: 0.9964 - val_loss: 0.2418 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0086 - acc: 0.9964 - val_loss: 0.2425 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0084 - acc: 0.9964 - val_loss: 0.2450 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0079 - acc: 0.9964 - val_loss: 0.2444 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0076 - acc: 0.9964 - val_loss: 0.2424 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0074 - acc: 0.9964 - val_loss: 0.2451 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0072 - acc: 0.9964 - val_loss: 0.2436 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.0068 - acc: 0.9964 - val_loss: 0.2447 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0066 - acc: 0.9964 - val_loss: 0.2450 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0066 - acc: 0.9964 - val_loss: 0.2447 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.0063 - acc: 0.9964 - val_loss: 0.2441 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 143us/step - loss: 0.0062 - acc: 0.9964 - val_loss: 0.2447 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.0060 - acc: 0.9964 - val_loss: 0.2451 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0059 - acc: 0.9964 - val_loss: 0.2482 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0058 - acc: 0.9964 - val_loss: 0.2472 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0057 - acc: 0.9964 - val_loss: 0.2476 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.2470 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.2472 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0054 - acc: 0.9964 - val_loss: 0.2479 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.2480 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.2482 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2466 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2484 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2490 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 50)                1950      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 13)                663       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 2,627\n",
      "Trainable params: 2,627\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 1ms/step - loss: 0.2499 - acc: 0.5309 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.2494 - acc: 0.5418 - val_loss: 0.2492 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.2477 - acc: 0.5455 - val_loss: 0.2465 - val_acc: 0.5806\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.2420 - acc: 0.5964 - val_loss: 0.2375 - val_acc: 0.6774\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.2287 - acc: 0.6982 - val_loss: 0.2196 - val_acc: 0.6774\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.2078 - acc: 0.7418 - val_loss: 0.2071 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1880 - acc: 0.7491 - val_loss: 0.1919 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1756 - acc: 0.7600 - val_loss: 0.1988 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1681 - acc: 0.7527 - val_loss: 0.1967 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1623 - acc: 0.7636 - val_loss: 0.2014 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1608 - acc: 0.7564 - val_loss: 0.2089 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1576 - acc: 0.7709 - val_loss: 0.2073 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1578 - acc: 0.7673 - val_loss: 0.2088 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1533 - acc: 0.7855 - val_loss: 0.2128 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1513 - acc: 0.7855 - val_loss: 0.2101 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1492 - acc: 0.7927 - val_loss: 0.2158 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1469 - acc: 0.8109 - val_loss: 0.2127 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1453 - acc: 0.8036 - val_loss: 0.2115 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1441 - acc: 0.8073 - val_loss: 0.2140 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1408 - acc: 0.8218 - val_loss: 0.2157 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1398 - acc: 0.8109 - val_loss: 0.2160 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1376 - acc: 0.8291 - val_loss: 0.2186 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1351 - acc: 0.8182 - val_loss: 0.2175 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1333 - acc: 0.8182 - val_loss: 0.2204 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1297 - acc: 0.8364 - val_loss: 0.2183 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1279 - acc: 0.8291 - val_loss: 0.2204 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1249 - acc: 0.8582 - val_loss: 0.2178 - val_acc: 0.7419\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1221 - acc: 0.8618 - val_loss: 0.2209 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1196 - acc: 0.8473 - val_loss: 0.2169 - val_acc: 0.7419\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1185 - acc: 0.8655 - val_loss: 0.2206 - val_acc: 0.7419\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1140 - acc: 0.8727 - val_loss: 0.2189 - val_acc: 0.7419\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1111 - acc: 0.8691 - val_loss: 0.2216 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1084 - acc: 0.8800 - val_loss: 0.2152 - val_acc: 0.7419\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1056 - acc: 0.8945 - val_loss: 0.2211 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1021 - acc: 0.9018 - val_loss: 0.2195 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0987 - acc: 0.9091 - val_loss: 0.2215 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0965 - acc: 0.9055 - val_loss: 0.2189 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0926 - acc: 0.9091 - val_loss: 0.2233 - val_acc: 0.6452\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0899 - acc: 0.9127 - val_loss: 0.2226 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0872 - acc: 0.9127 - val_loss: 0.2228 - val_acc: 0.6452\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0840 - acc: 0.9200 - val_loss: 0.2250 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0798 - acc: 0.9345 - val_loss: 0.2255 - val_acc: 0.6452\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0781 - acc: 0.9273 - val_loss: 0.2269 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0735 - acc: 0.9309 - val_loss: 0.2269 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0709 - acc: 0.9345 - val_loss: 0.2357 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0684 - acc: 0.9418 - val_loss: 0.2350 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0633 - acc: 0.9418 - val_loss: 0.2376 - val_acc: 0.6452\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0610 - acc: 0.9491 - val_loss: 0.2395 - val_acc: 0.6452\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0564 - acc: 0.9491 - val_loss: 0.2346 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0529 - acc: 0.9600 - val_loss: 0.2352 - val_acc: 0.6452\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0502 - acc: 0.9564 - val_loss: 0.2326 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0472 - acc: 0.9709 - val_loss: 0.2358 - val_acc: 0.6129\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0442 - acc: 0.9745 - val_loss: 0.2350 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0432 - acc: 0.9709 - val_loss: 0.2460 - val_acc: 0.5806\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0399 - acc: 0.9782 - val_loss: 0.2401 - val_acc: 0.5806\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0374 - acc: 0.9818 - val_loss: 0.2525 - val_acc: 0.6129\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0356 - acc: 0.9782 - val_loss: 0.2387 - val_acc: 0.6452\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0324 - acc: 0.9818 - val_loss: 0.2479 - val_acc: 0.5806\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0303 - acc: 0.9818 - val_loss: 0.2528 - val_acc: 0.6129\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0280 - acc: 0.9818 - val_loss: 0.2533 - val_acc: 0.6129\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0261 - acc: 0.9891 - val_loss: 0.2445 - val_acc: 0.6129\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0247 - acc: 0.9855 - val_loss: 0.2572 - val_acc: 0.5806\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0233 - acc: 0.9891 - val_loss: 0.2477 - val_acc: 0.6129\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0215 - acc: 0.9891 - val_loss: 0.2496 - val_acc: 0.5806\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0189 - acc: 0.9891 - val_loss: 0.2460 - val_acc: 0.6129\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0164 - acc: 0.9964 - val_loss: 0.2451 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0150 - acc: 0.9964 - val_loss: 0.2413 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0130 - acc: 0.9964 - val_loss: 0.2373 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.2355 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.2502 - val_acc: 0.5806\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.2415 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.2433 - val_acc: 0.6129\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.2459 - val_acc: 0.6129\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.2437 - val_acc: 0.6129\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.2485 - val_acc: 0.6129\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.2517 - val_acc: 0.6129\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.2489 - val_acc: 0.6129\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.2543 - val_acc: 0.6129\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.2555 - val_acc: 0.5806\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.2544 - val_acc: 0.6129\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.2563 - val_acc: 0.6129\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.2602 - val_acc: 0.5806\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.2617 - val_acc: 0.5806\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.2611 - val_acc: 0.5806\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 225us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.2628 - val_acc: 0.5806\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.2587 - val_acc: 0.5806\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.2626 - val_acc: 0.5806\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.2650 - val_acc: 0.5806\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.2635 - val_acc: 0.5806\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.2648 - val_acc: 0.5806\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.2660 - val_acc: 0.5806\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.2666 - val_acc: 0.5806\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2681 - val_acc: 0.5806\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2734 - val_acc: 0.5806\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.2713 - val_acc: 0.5806\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2715 - val_acc: 0.5806\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.2709 - val_acc: 0.5806\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.2731 - val_acc: 0.5806\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2738 - val_acc: 0.5806\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2724 - val_acc: 0.5806\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 12)                468       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 19)                247       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 20        \n",
      "=================================================================\n",
      "Total params: 735\n",
      "Trainable params: 735\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 1ms/step - loss: 0.2500 - acc: 0.5345 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.2498 - acc: 0.5418 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.2493 - acc: 0.5418 - val_loss: 0.2491 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 143us/step - loss: 0.2474 - acc: 0.5418 - val_loss: 0.2462 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.2422 - acc: 0.5491 - val_loss: 0.2407 - val_acc: 0.5484\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.2336 - acc: 0.5964 - val_loss: 0.2322 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.2225 - acc: 0.6473 - val_loss: 0.2258 - val_acc: 0.6129\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.2115 - acc: 0.7164 - val_loss: 0.2198 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.2010 - acc: 0.7345 - val_loss: 0.2123 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1908 - acc: 0.7345 - val_loss: 0.2075 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.1832 - acc: 0.7345 - val_loss: 0.2037 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1772 - acc: 0.7527 - val_loss: 0.2063 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 141us/step - loss: 0.1721 - acc: 0.7491 - val_loss: 0.2079 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1698 - acc: 0.7564 - val_loss: 0.2065 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1665 - acc: 0.7636 - val_loss: 0.2096 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1652 - acc: 0.7600 - val_loss: 0.2111 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1650 - acc: 0.7564 - val_loss: 0.2165 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1627 - acc: 0.7600 - val_loss: 0.2165 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1616 - acc: 0.7673 - val_loss: 0.2197 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1607 - acc: 0.7673 - val_loss: 0.2226 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1601 - acc: 0.7673 - val_loss: 0.2247 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.1591 - acc: 0.7782 - val_loss: 0.2249 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1591 - acc: 0.7891 - val_loss: 0.2274 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.1585 - acc: 0.7855 - val_loss: 0.2263 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1576 - acc: 0.7745 - val_loss: 0.2274 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.1571 - acc: 0.7927 - val_loss: 0.2308 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1567 - acc: 0.7927 - val_loss: 0.2301 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1560 - acc: 0.7964 - val_loss: 0.2312 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1554 - acc: 0.7964 - val_loss: 0.2286 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1557 - acc: 0.8036 - val_loss: 0.2316 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1547 - acc: 0.7964 - val_loss: 0.2323 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1554 - acc: 0.8000 - val_loss: 0.2353 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1554 - acc: 0.8000 - val_loss: 0.2322 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1532 - acc: 0.8000 - val_loss: 0.2349 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1532 - acc: 0.7964 - val_loss: 0.2364 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1539 - acc: 0.7964 - val_loss: 0.2317 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.1547 - acc: 0.7891 - val_loss: 0.2347 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1527 - acc: 0.8036 - val_loss: 0.2372 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1519 - acc: 0.7964 - val_loss: 0.2360 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1514 - acc: 0.8073 - val_loss: 0.2368 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1510 - acc: 0.8073 - val_loss: 0.2374 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.1505 - acc: 0.8145 - val_loss: 0.2355 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1513 - acc: 0.8109 - val_loss: 0.2397 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1494 - acc: 0.8182 - val_loss: 0.2373 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1499 - acc: 0.8109 - val_loss: 0.2373 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1491 - acc: 0.8109 - val_loss: 0.2344 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1482 - acc: 0.8073 - val_loss: 0.2372 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1477 - acc: 0.8073 - val_loss: 0.2374 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1474 - acc: 0.8182 - val_loss: 0.2368 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 143us/step - loss: 0.1468 - acc: 0.8218 - val_loss: 0.2392 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 145us/step - loss: 0.1466 - acc: 0.8145 - val_loss: 0.2393 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1470 - acc: 0.8182 - val_loss: 0.2360 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1457 - acc: 0.8182 - val_loss: 0.2382 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1452 - acc: 0.8218 - val_loss: 0.2364 - val_acc: 0.7097\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1446 - acc: 0.8255 - val_loss: 0.2362 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1440 - acc: 0.8218 - val_loss: 0.2369 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1437 - acc: 0.8255 - val_loss: 0.2345 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1426 - acc: 0.8218 - val_loss: 0.2355 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1422 - acc: 0.8182 - val_loss: 0.2355 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1416 - acc: 0.8218 - val_loss: 0.2357 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1413 - acc: 0.8364 - val_loss: 0.2372 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1422 - acc: 0.8145 - val_loss: 0.2382 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1404 - acc: 0.8327 - val_loss: 0.2337 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1392 - acc: 0.8364 - val_loss: 0.2363 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 144us/step - loss: 0.1394 - acc: 0.8436 - val_loss: 0.2348 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1382 - acc: 0.8436 - val_loss: 0.2357 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1376 - acc: 0.8473 - val_loss: 0.2371 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1370 - acc: 0.8400 - val_loss: 0.2356 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1370 - acc: 0.8436 - val_loss: 0.2352 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1362 - acc: 0.8364 - val_loss: 0.2350 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.1362 - acc: 0.8400 - val_loss: 0.2375 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1344 - acc: 0.8473 - val_loss: 0.2367 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1335 - acc: 0.8473 - val_loss: 0.2321 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1341 - acc: 0.8400 - val_loss: 0.2340 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1324 - acc: 0.8436 - val_loss: 0.2331 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1317 - acc: 0.8473 - val_loss: 0.2317 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1303 - acc: 0.8509 - val_loss: 0.2326 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 143us/step - loss: 0.1306 - acc: 0.8509 - val_loss: 0.2315 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 142us/step - loss: 0.1308 - acc: 0.8400 - val_loss: 0.2302 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1276 - acc: 0.8545 - val_loss: 0.2310 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1266 - acc: 0.8545 - val_loss: 0.2303 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1268 - acc: 0.8436 - val_loss: 0.2310 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1253 - acc: 0.8582 - val_loss: 0.2304 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1245 - acc: 0.8545 - val_loss: 0.2315 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1230 - acc: 0.8509 - val_loss: 0.2320 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1225 - acc: 0.8545 - val_loss: 0.2308 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1223 - acc: 0.8582 - val_loss: 0.2327 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1209 - acc: 0.8691 - val_loss: 0.2270 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1188 - acc: 0.8691 - val_loss: 0.2285 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1184 - acc: 0.8655 - val_loss: 0.2293 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1164 - acc: 0.8727 - val_loss: 0.2291 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1174 - acc: 0.8800 - val_loss: 0.2283 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1160 - acc: 0.8836 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1148 - acc: 0.8727 - val_loss: 0.2273 - val_acc: 0.7097\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1143 - acc: 0.8800 - val_loss: 0.2330 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.1121 - acc: 0.8727 - val_loss: 0.2301 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1106 - acc: 0.8873 - val_loss: 0.2311 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1093 - acc: 0.8873 - val_loss: 0.2302 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 143us/step - loss: 0.1086 - acc: 0.8873 - val_loss: 0.2304 - val_acc: 0.6774\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 140us/step - loss: 0.1074 - acc: 0.8873 - val_loss: 0.2294 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 36)                1404      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 20)                740       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 2,165\n",
      "Trainable params: 2,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 1ms/step - loss: 0.2498 - acc: 0.5309 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.2491 - acc: 0.5418 - val_loss: 0.2486 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.2459 - acc: 0.5455 - val_loss: 0.2429 - val_acc: 0.5484\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.2371 - acc: 0.5636 - val_loss: 0.2317 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.2208 - acc: 0.6764 - val_loss: 0.2214 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.2027 - acc: 0.7382 - val_loss: 0.2110 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1882 - acc: 0.7455 - val_loss: 0.2040 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1769 - acc: 0.7455 - val_loss: 0.2063 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1699 - acc: 0.7600 - val_loss: 0.2053 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1664 - acc: 0.7527 - val_loss: 0.2096 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1642 - acc: 0.7600 - val_loss: 0.2115 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1599 - acc: 0.7709 - val_loss: 0.2149 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1592 - acc: 0.7855 - val_loss: 0.2111 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1568 - acc: 0.7891 - val_loss: 0.2141 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1545 - acc: 0.8000 - val_loss: 0.2185 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1524 - acc: 0.8145 - val_loss: 0.2149 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1514 - acc: 0.8000 - val_loss: 0.2177 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1504 - acc: 0.8000 - val_loss: 0.2128 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1488 - acc: 0.8145 - val_loss: 0.2163 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1463 - acc: 0.8145 - val_loss: 0.2184 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1449 - acc: 0.8182 - val_loss: 0.2193 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1437 - acc: 0.8182 - val_loss: 0.2180 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1424 - acc: 0.8255 - val_loss: 0.2219 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1407 - acc: 0.8255 - val_loss: 0.2182 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1397 - acc: 0.8182 - val_loss: 0.2204 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1377 - acc: 0.8255 - val_loss: 0.2198 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1365 - acc: 0.8400 - val_loss: 0.2226 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1355 - acc: 0.8291 - val_loss: 0.2219 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1334 - acc: 0.8436 - val_loss: 0.2202 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1316 - acc: 0.8473 - val_loss: 0.2211 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1303 - acc: 0.8509 - val_loss: 0.2252 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1288 - acc: 0.8436 - val_loss: 0.2214 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1264 - acc: 0.8582 - val_loss: 0.2232 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1249 - acc: 0.8618 - val_loss: 0.2242 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1229 - acc: 0.8655 - val_loss: 0.2202 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1213 - acc: 0.8618 - val_loss: 0.2200 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1201 - acc: 0.8618 - val_loss: 0.2227 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1184 - acc: 0.8655 - val_loss: 0.2176 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1166 - acc: 0.8618 - val_loss: 0.2166 - val_acc: 0.7419\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1156 - acc: 0.8691 - val_loss: 0.2176 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1136 - acc: 0.8727 - val_loss: 0.2160 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1089 - acc: 0.8800 - val_loss: 0.2132 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1068 - acc: 0.8873 - val_loss: 0.2126 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1049 - acc: 0.8909 - val_loss: 0.2057 - val_acc: 0.7419\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1025 - acc: 0.8945 - val_loss: 0.2063 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0990 - acc: 0.8982 - val_loss: 0.2036 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0963 - acc: 0.9055 - val_loss: 0.1962 - val_acc: 0.7419\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0951 - acc: 0.8945 - val_loss: 0.1975 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0909 - acc: 0.9164 - val_loss: 0.1912 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0899 - acc: 0.9055 - val_loss: 0.2050 - val_acc: 0.6452\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0841 - acc: 0.9164 - val_loss: 0.1944 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0813 - acc: 0.9164 - val_loss: 0.1929 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0771 - acc: 0.9236 - val_loss: 0.1946 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0741 - acc: 0.9382 - val_loss: 0.1956 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0704 - acc: 0.9345 - val_loss: 0.1887 - val_acc: 0.7419\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0659 - acc: 0.9455 - val_loss: 0.1892 - val_acc: 0.7419\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0631 - acc: 0.9418 - val_loss: 0.1806 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0574 - acc: 0.9527 - val_loss: 0.1981 - val_acc: 0.7097\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0562 - acc: 0.9527 - val_loss: 0.1867 - val_acc: 0.7419\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0525 - acc: 0.9564 - val_loss: 0.1793 - val_acc: 0.7419\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0481 - acc: 0.9709 - val_loss: 0.1863 - val_acc: 0.7419\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0429 - acc: 0.9673 - val_loss: 0.1844 - val_acc: 0.7419\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0394 - acc: 0.9745 - val_loss: 0.1916 - val_acc: 0.7419\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0370 - acc: 0.9782 - val_loss: 0.1827 - val_acc: 0.7419\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0335 - acc: 0.9855 - val_loss: 0.1825 - val_acc: 0.7419\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0304 - acc: 0.9855 - val_loss: 0.1846 - val_acc: 0.7419\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0268 - acc: 0.9891 - val_loss: 0.1825 - val_acc: 0.7419\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0251 - acc: 0.9891 - val_loss: 0.1826 - val_acc: 0.7419\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0222 - acc: 0.9927 - val_loss: 0.1810 - val_acc: 0.7419\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0206 - acc: 0.9927 - val_loss: 0.1748 - val_acc: 0.7742\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0191 - acc: 0.9927 - val_loss: 0.1766 - val_acc: 0.7742\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0173 - acc: 0.9927 - val_loss: 0.1805 - val_acc: 0.7419\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0166 - acc: 0.9964 - val_loss: 0.1727 - val_acc: 0.7742\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0151 - acc: 0.9964 - val_loss: 0.1789 - val_acc: 0.7742\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0134 - acc: 0.9964 - val_loss: 0.1802 - val_acc: 0.7742\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0125 - acc: 0.9964 - val_loss: 0.1804 - val_acc: 0.7742\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0117 - acc: 0.9964 - val_loss: 0.1834 - val_acc: 0.7742\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0108 - acc: 0.9964 - val_loss: 0.1802 - val_acc: 0.7742\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0101 - acc: 0.9964 - val_loss: 0.1776 - val_acc: 0.7742\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0097 - acc: 0.9964 - val_loss: 0.1776 - val_acc: 0.7742\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0092 - acc: 0.9964 - val_loss: 0.1808 - val_acc: 0.7742\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0088 - acc: 0.9964 - val_loss: 0.1803 - val_acc: 0.7742\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0084 - acc: 0.9964 - val_loss: 0.1817 - val_acc: 0.7742\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0081 - acc: 0.9964 - val_loss: 0.1819 - val_acc: 0.7742\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0077 - acc: 0.9964 - val_loss: 0.1796 - val_acc: 0.7742\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0076 - acc: 0.9964 - val_loss: 0.1825 - val_acc: 0.7742\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0072 - acc: 0.9964 - val_loss: 0.1817 - val_acc: 0.7742\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0069 - acc: 0.9964 - val_loss: 0.1853 - val_acc: 0.7742\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0067 - acc: 0.9964 - val_loss: 0.1846 - val_acc: 0.7742\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0066 - acc: 0.9964 - val_loss: 0.1838 - val_acc: 0.7742\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0064 - acc: 0.9964 - val_loss: 0.1841 - val_acc: 0.7742\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0062 - acc: 0.9964 - val_loss: 0.1857 - val_acc: 0.7742\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0060 - acc: 0.9964 - val_loss: 0.1853 - val_acc: 0.7742\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0059 - acc: 0.9964 - val_loss: 0.1899 - val_acc: 0.7742\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0058 - acc: 0.9964 - val_loss: 0.1873 - val_acc: 0.7419\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0057 - acc: 0.9964 - val_loss: 0.1854 - val_acc: 0.7742\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.1867 - val_acc: 0.7742\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.1879 - val_acc: 0.7742\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0054 - acc: 0.9964 - val_loss: 0.1885 - val_acc: 0.7742\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.1880 - val_acc: 0.7742\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 40)                1560      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 2,401\n",
      "Trainable params: 2,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 1ms/step - loss: 0.2500 - acc: 0.4873 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.2493 - acc: 0.5418 - val_loss: 0.2488 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.2468 - acc: 0.5418 - val_loss: 0.2449 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.2380 - acc: 0.5527 - val_loss: 0.2343 - val_acc: 0.6129\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.2230 - acc: 0.6145 - val_loss: 0.2264 - val_acc: 0.6774\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.2098 - acc: 0.7091 - val_loss: 0.2220 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1989 - acc: 0.7309 - val_loss: 0.2187 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1889 - acc: 0.7491 - val_loss: 0.2130 - val_acc: 0.6774\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 198us/step - loss: 0.1786 - acc: 0.7527 - val_loss: 0.2131 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1709 - acc: 0.7709 - val_loss: 0.2101 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1665 - acc: 0.7782 - val_loss: 0.2144 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1614 - acc: 0.7891 - val_loss: 0.2104 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1572 - acc: 0.7891 - val_loss: 0.2142 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1553 - acc: 0.8000 - val_loss: 0.2148 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1550 - acc: 0.8000 - val_loss: 0.2126 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1514 - acc: 0.8000 - val_loss: 0.2201 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1482 - acc: 0.8255 - val_loss: 0.2212 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1457 - acc: 0.8145 - val_loss: 0.2225 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1446 - acc: 0.8182 - val_loss: 0.2231 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1424 - acc: 0.8218 - val_loss: 0.2240 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1398 - acc: 0.8291 - val_loss: 0.2248 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1385 - acc: 0.8218 - val_loss: 0.2302 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1357 - acc: 0.8436 - val_loss: 0.2285 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1327 - acc: 0.8436 - val_loss: 0.2315 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1321 - acc: 0.8436 - val_loss: 0.2284 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1285 - acc: 0.8509 - val_loss: 0.2330 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1265 - acc: 0.8436 - val_loss: 0.2316 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1241 - acc: 0.8582 - val_loss: 0.2317 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1234 - acc: 0.8436 - val_loss: 0.2337 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1196 - acc: 0.8727 - val_loss: 0.2308 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1157 - acc: 0.8655 - val_loss: 0.2343 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1126 - acc: 0.8727 - val_loss: 0.2350 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1093 - acc: 0.8873 - val_loss: 0.2348 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1062 - acc: 0.8873 - val_loss: 0.2331 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1018 - acc: 0.8982 - val_loss: 0.2333 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0986 - acc: 0.9164 - val_loss: 0.2282 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0951 - acc: 0.9164 - val_loss: 0.2306 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0918 - acc: 0.9200 - val_loss: 0.2313 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0871 - acc: 0.9273 - val_loss: 0.2329 - val_acc: 0.6452\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0834 - acc: 0.9273 - val_loss: 0.2334 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0791 - acc: 0.9309 - val_loss: 0.2337 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0768 - acc: 0.9345 - val_loss: 0.2367 - val_acc: 0.6452\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0718 - acc: 0.9309 - val_loss: 0.2336 - val_acc: 0.6452\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0683 - acc: 0.9345 - val_loss: 0.2374 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0651 - acc: 0.9491 - val_loss: 0.2380 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0622 - acc: 0.9527 - val_loss: 0.2405 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0577 - acc: 0.9527 - val_loss: 0.2334 - val_acc: 0.6452\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0542 - acc: 0.9600 - val_loss: 0.2389 - val_acc: 0.6452\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0518 - acc: 0.9636 - val_loss: 0.2287 - val_acc: 0.6452\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0482 - acc: 0.9709 - val_loss: 0.2330 - val_acc: 0.6452\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0464 - acc: 0.9636 - val_loss: 0.2254 - val_acc: 0.6452\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0420 - acc: 0.9745 - val_loss: 0.2302 - val_acc: 0.6452\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0389 - acc: 0.9745 - val_loss: 0.2337 - val_acc: 0.6452\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0368 - acc: 0.9782 - val_loss: 0.2304 - val_acc: 0.6452\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0341 - acc: 0.9782 - val_loss: 0.2331 - val_acc: 0.6452\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0325 - acc: 0.9818 - val_loss: 0.2358 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0301 - acc: 0.9818 - val_loss: 0.2404 - val_acc: 0.6452\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0268 - acc: 0.9855 - val_loss: 0.2338 - val_acc: 0.6452\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0248 - acc: 0.9855 - val_loss: 0.2376 - val_acc: 0.6452\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0229 - acc: 0.9855 - val_loss: 0.2366 - val_acc: 0.6452\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0214 - acc: 0.9891 - val_loss: 0.2379 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0198 - acc: 0.9891 - val_loss: 0.2421 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0177 - acc: 0.9891 - val_loss: 0.2450 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0170 - acc: 0.9927 - val_loss: 0.2380 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0148 - acc: 0.9927 - val_loss: 0.2417 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0133 - acc: 0.9964 - val_loss: 0.2450 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0123 - acc: 0.9964 - val_loss: 0.2473 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0118 - acc: 0.9964 - val_loss: 0.2509 - val_acc: 0.6452\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 173us/step - loss: 0.0111 - acc: 0.9964 - val_loss: 0.2446 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0100 - acc: 0.9964 - val_loss: 0.2493 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0098 - acc: 0.9964 - val_loss: 0.2505 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0091 - acc: 0.9964 - val_loss: 0.2506 - val_acc: 0.6452\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0086 - acc: 0.9964 - val_loss: 0.2527 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0081 - acc: 0.9964 - val_loss: 0.2500 - val_acc: 0.6452\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0077 - acc: 0.9964 - val_loss: 0.2534 - val_acc: 0.6452\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0075 - acc: 0.9964 - val_loss: 0.2530 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0072 - acc: 0.9964 - val_loss: 0.2548 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0069 - acc: 0.9964 - val_loss: 0.2566 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0066 - acc: 0.9964 - val_loss: 0.2586 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0065 - acc: 0.9964 - val_loss: 0.2588 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0063 - acc: 0.9964 - val_loss: 0.2585 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0061 - acc: 0.9964 - val_loss: 0.2592 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0060 - acc: 0.9964 - val_loss: 0.2587 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0058 - acc: 0.9964 - val_loss: 0.2619 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0057 - acc: 0.9964 - val_loss: 0.2615 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0056 - acc: 0.9964 - val_loss: 0.2621 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.2600 - val_acc: 0.6452\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0054 - acc: 0.9964 - val_loss: 0.2639 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.2630 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.2643 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2656 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.2659 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.2658 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.2662 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0048 - acc: 0.9964 - val_loss: 0.2671 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0048 - acc: 0.9964 - val_loss: 0.2687 - val_acc: 0.6452\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0047 - acc: 0.9964 - val_loss: 0.2686 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0047 - acc: 0.9964 - val_loss: 0.2703 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0046 - acc: 0.9964 - val_loss: 0.2689 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0046 - acc: 0.9964 - val_loss: 0.2703 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 42)                1638      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 14)                602       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 2,255\n",
      "Trainable params: 2,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 1ms/step - loss: 0.2500 - acc: 0.5091 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2494 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.2481 - acc: 0.5418 - val_loss: 0.2473 - val_acc: 0.5484\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.2434 - acc: 0.5818 - val_loss: 0.2397 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.2305 - acc: 0.6836 - val_loss: 0.2299 - val_acc: 0.5806\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.2122 - acc: 0.7200 - val_loss: 0.2136 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1933 - acc: 0.7418 - val_loss: 0.2096 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1788 - acc: 0.7455 - val_loss: 0.1979 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1708 - acc: 0.7709 - val_loss: 0.2049 - val_acc: 0.6452\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1647 - acc: 0.7782 - val_loss: 0.2039 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1597 - acc: 0.7745 - val_loss: 0.2091 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1585 - acc: 0.7782 - val_loss: 0.2135 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1562 - acc: 0.7855 - val_loss: 0.2131 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1525 - acc: 0.7855 - val_loss: 0.2161 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1502 - acc: 0.7927 - val_loss: 0.2177 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1481 - acc: 0.8145 - val_loss: 0.2211 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1451 - acc: 0.8182 - val_loss: 0.2222 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1436 - acc: 0.8145 - val_loss: 0.2255 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1420 - acc: 0.8145 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1381 - acc: 0.8327 - val_loss: 0.2253 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1361 - acc: 0.8400 - val_loss: 0.2264 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1330 - acc: 0.8400 - val_loss: 0.2266 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1311 - acc: 0.8436 - val_loss: 0.2260 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1280 - acc: 0.8545 - val_loss: 0.2241 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1252 - acc: 0.8473 - val_loss: 0.2231 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1216 - acc: 0.8509 - val_loss: 0.2257 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1195 - acc: 0.8545 - val_loss: 0.2260 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1166 - acc: 0.8509 - val_loss: 0.2277 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1131 - acc: 0.8545 - val_loss: 0.2252 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1118 - acc: 0.8618 - val_loss: 0.2270 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1075 - acc: 0.8582 - val_loss: 0.2281 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1041 - acc: 0.8873 - val_loss: 0.2235 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0994 - acc: 0.8836 - val_loss: 0.2239 - val_acc: 0.6452\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0956 - acc: 0.9127 - val_loss: 0.2259 - val_acc: 0.6452\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0941 - acc: 0.8945 - val_loss: 0.2246 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0891 - acc: 0.9164 - val_loss: 0.2241 - val_acc: 0.6452\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0839 - acc: 0.9127 - val_loss: 0.2236 - val_acc: 0.6452\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0788 - acc: 0.9273 - val_loss: 0.2268 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0741 - acc: 0.9382 - val_loss: 0.2226 - val_acc: 0.6452\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0722 - acc: 0.9418 - val_loss: 0.2241 - val_acc: 0.6452\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0684 - acc: 0.9345 - val_loss: 0.2328 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0661 - acc: 0.9491 - val_loss: 0.2290 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0587 - acc: 0.9564 - val_loss: 0.2298 - val_acc: 0.6129\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0554 - acc: 0.9600 - val_loss: 0.2358 - val_acc: 0.5806\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0512 - acc: 0.9564 - val_loss: 0.2304 - val_acc: 0.6129\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0480 - acc: 0.9673 - val_loss: 0.2427 - val_acc: 0.6129\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0452 - acc: 0.9636 - val_loss: 0.2367 - val_acc: 0.6129\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0430 - acc: 0.9709 - val_loss: 0.2414 - val_acc: 0.5484\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0400 - acc: 0.9745 - val_loss: 0.2385 - val_acc: 0.6129\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0363 - acc: 0.9745 - val_loss: 0.2399 - val_acc: 0.6129\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0338 - acc: 0.9745 - val_loss: 0.2495 - val_acc: 0.5806\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0334 - acc: 0.9818 - val_loss: 0.2396 - val_acc: 0.6129\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0287 - acc: 0.9855 - val_loss: 0.2422 - val_acc: 0.6129\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0271 - acc: 0.9891 - val_loss: 0.2420 - val_acc: 0.6129\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0243 - acc: 0.9891 - val_loss: 0.2506 - val_acc: 0.6129\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0226 - acc: 0.9927 - val_loss: 0.2473 - val_acc: 0.6129\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0210 - acc: 0.9927 - val_loss: 0.2657 - val_acc: 0.5484\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0201 - acc: 0.9927 - val_loss: 0.2581 - val_acc: 0.6129\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0181 - acc: 0.9927 - val_loss: 0.2535 - val_acc: 0.6129\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0173 - acc: 0.9927 - val_loss: 0.2595 - val_acc: 0.5806\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0156 - acc: 0.9927 - val_loss: 0.2627 - val_acc: 0.6129\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0149 - acc: 0.9927 - val_loss: 0.2657 - val_acc: 0.5806\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0139 - acc: 0.9927 - val_loss: 0.2679 - val_acc: 0.5806\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0128 - acc: 0.9927 - val_loss: 0.2708 - val_acc: 0.6129\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0117 - acc: 0.9964 - val_loss: 0.2788 - val_acc: 0.5806\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0113 - acc: 0.9964 - val_loss: 0.2841 - val_acc: 0.5484\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0104 - acc: 0.9964 - val_loss: 0.2842 - val_acc: 0.5806\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0097 - acc: 0.9964 - val_loss: 0.2778 - val_acc: 0.5806\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0093 - acc: 0.9964 - val_loss: 0.2881 - val_acc: 0.5484\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0088 - acc: 0.9964 - val_loss: 0.2845 - val_acc: 0.5806\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0084 - acc: 0.9964 - val_loss: 0.2851 - val_acc: 0.5806\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0080 - acc: 0.9964 - val_loss: 0.2860 - val_acc: 0.5806\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0076 - acc: 0.9964 - val_loss: 0.2893 - val_acc: 0.5806\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0074 - acc: 0.9964 - val_loss: 0.2896 - val_acc: 0.5806\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0071 - acc: 0.9964 - val_loss: 0.2917 - val_acc: 0.5806\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0069 - acc: 0.9964 - val_loss: 0.2913 - val_acc: 0.5806\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0067 - acc: 0.9964 - val_loss: 0.2914 - val_acc: 0.5806\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0065 - acc: 0.9964 - val_loss: 0.2897 - val_acc: 0.5806\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0064 - acc: 0.9964 - val_loss: 0.2903 - val_acc: 0.5806\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0062 - acc: 0.9964 - val_loss: 0.2923 - val_acc: 0.5806\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.0061 - acc: 0.9964 - val_loss: 0.2929 - val_acc: 0.5806\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0059 - acc: 0.9964 - val_loss: 0.2944 - val_acc: 0.5484\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0058 - acc: 0.9964 - val_loss: 0.2948 - val_acc: 0.5806\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 153us/step - loss: 0.0057 - acc: 0.9964 - val_loss: 0.2960 - val_acc: 0.5806\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0056 - acc: 0.9964 - val_loss: 0.2966 - val_acc: 0.5484\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.2949 - val_acc: 0.5806\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0054 - acc: 0.9964 - val_loss: 0.2987 - val_acc: 0.5484\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.2973 - val_acc: 0.5484\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.2989 - val_acc: 0.5484\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2993 - val_acc: 0.5484\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2980 - val_acc: 0.5484\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.2990 - val_acc: 0.5484\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.2998 - val_acc: 0.5484\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.3000 - val_acc: 0.5484\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.3012 - val_acc: 0.5484\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0048 - acc: 0.9964 - val_loss: 0.3020 - val_acc: 0.5484\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0047 - acc: 0.9964 - val_loss: 0.3018 - val_acc: 0.5484\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0047 - acc: 0.9964 - val_loss: 0.3017 - val_acc: 0.5484\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0047 - acc: 0.9964 - val_loss: 0.3013 - val_acc: 0.5484\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0046 - acc: 0.9964 - val_loss: 0.3020 - val_acc: 0.5484\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 25)                975       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,246\n",
      "Trainable params: 1,246\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 1ms/step - loss: 0.2499 - acc: 0.5345 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.2495 - acc: 0.5418 - val_loss: 0.2495 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.2485 - acc: 0.5418 - val_loss: 0.2479 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.2449 - acc: 0.5600 - val_loss: 0.2428 - val_acc: 0.6129\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.2359 - acc: 0.6509 - val_loss: 0.2343 - val_acc: 0.6129\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.2224 - acc: 0.6618 - val_loss: 0.2232 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.2068 - acc: 0.7527 - val_loss: 0.2115 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1916 - acc: 0.7527 - val_loss: 0.2072 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1808 - acc: 0.7527 - val_loss: 0.2031 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1733 - acc: 0.7636 - val_loss: 0.2081 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1682 - acc: 0.7673 - val_loss: 0.2034 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1638 - acc: 0.7673 - val_loss: 0.2096 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1612 - acc: 0.7745 - val_loss: 0.2109 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1603 - acc: 0.7709 - val_loss: 0.2129 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1578 - acc: 0.7891 - val_loss: 0.2146 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1566 - acc: 0.7855 - val_loss: 0.2171 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1561 - acc: 0.7745 - val_loss: 0.2196 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1532 - acc: 0.7927 - val_loss: 0.2223 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1524 - acc: 0.7927 - val_loss: 0.2227 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1513 - acc: 0.8000 - val_loss: 0.2239 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1508 - acc: 0.7927 - val_loss: 0.2235 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1500 - acc: 0.7964 - val_loss: 0.2232 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1488 - acc: 0.8073 - val_loss: 0.2275 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1478 - acc: 0.8036 - val_loss: 0.2255 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1473 - acc: 0.8109 - val_loss: 0.2255 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1461 - acc: 0.8109 - val_loss: 0.2259 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1453 - acc: 0.8145 - val_loss: 0.2303 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1443 - acc: 0.8182 - val_loss: 0.2327 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1441 - acc: 0.8073 - val_loss: 0.2289 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1435 - acc: 0.8145 - val_loss: 0.2322 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1427 - acc: 0.8255 - val_loss: 0.2325 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1440 - acc: 0.8182 - val_loss: 0.2303 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1406 - acc: 0.8182 - val_loss: 0.2323 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1395 - acc: 0.8291 - val_loss: 0.2308 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1374 - acc: 0.8364 - val_loss: 0.2324 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1367 - acc: 0.8327 - val_loss: 0.2344 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1359 - acc: 0.8400 - val_loss: 0.2326 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1352 - acc: 0.8327 - val_loss: 0.2317 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1339 - acc: 0.8218 - val_loss: 0.2322 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1335 - acc: 0.8364 - val_loss: 0.2349 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1315 - acc: 0.8436 - val_loss: 0.2347 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1309 - acc: 0.8473 - val_loss: 0.2360 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1291 - acc: 0.8364 - val_loss: 0.2358 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1287 - acc: 0.8436 - val_loss: 0.2381 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1268 - acc: 0.8400 - val_loss: 0.2389 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1263 - acc: 0.8436 - val_loss: 0.2377 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1243 - acc: 0.8545 - val_loss: 0.2393 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1233 - acc: 0.8509 - val_loss: 0.2395 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1216 - acc: 0.8545 - val_loss: 0.2398 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1211 - acc: 0.8545 - val_loss: 0.2383 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1188 - acc: 0.8473 - val_loss: 0.2423 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1176 - acc: 0.8582 - val_loss: 0.2406 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1161 - acc: 0.8800 - val_loss: 0.2420 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.1139 - acc: 0.8691 - val_loss: 0.2440 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1123 - acc: 0.8800 - val_loss: 0.2451 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1110 - acc: 0.8836 - val_loss: 0.2421 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1101 - acc: 0.8618 - val_loss: 0.2467 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1071 - acc: 0.8982 - val_loss: 0.2445 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1050 - acc: 0.8909 - val_loss: 0.2442 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1034 - acc: 0.9127 - val_loss: 0.2474 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1006 - acc: 0.9091 - val_loss: 0.2432 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0985 - acc: 0.9164 - val_loss: 0.2440 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0961 - acc: 0.9127 - val_loss: 0.2423 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0938 - acc: 0.9091 - val_loss: 0.2447 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0920 - acc: 0.9127 - val_loss: 0.2379 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0906 - acc: 0.9127 - val_loss: 0.2477 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0882 - acc: 0.9236 - val_loss: 0.2394 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0855 - acc: 0.9236 - val_loss: 0.2447 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.0835 - acc: 0.9200 - val_loss: 0.2458 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0807 - acc: 0.9309 - val_loss: 0.2449 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0788 - acc: 0.9345 - val_loss: 0.2425 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0776 - acc: 0.9200 - val_loss: 0.2520 - val_acc: 0.6452\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0744 - acc: 0.9455 - val_loss: 0.2420 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0752 - acc: 0.9236 - val_loss: 0.2473 - val_acc: 0.6129\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0709 - acc: 0.9345 - val_loss: 0.2421 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0693 - acc: 0.9418 - val_loss: 0.2414 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0698 - acc: 0.9455 - val_loss: 0.2484 - val_acc: 0.6129\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0650 - acc: 0.9491 - val_loss: 0.2354 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0637 - acc: 0.9455 - val_loss: 0.2331 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0619 - acc: 0.9418 - val_loss: 0.2476 - val_acc: 0.5806\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0630 - acc: 0.9418 - val_loss: 0.2319 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0580 - acc: 0.9564 - val_loss: 0.2393 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0554 - acc: 0.9600 - val_loss: 0.2360 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.0540 - acc: 0.9600 - val_loss: 0.2403 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 146us/step - loss: 0.0523 - acc: 0.9636 - val_loss: 0.2437 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0509 - acc: 0.9636 - val_loss: 0.2419 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0492 - acc: 0.9636 - val_loss: 0.2365 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0473 - acc: 0.9673 - val_loss: 0.2406 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0460 - acc: 0.9673 - val_loss: 0.2423 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0443 - acc: 0.9709 - val_loss: 0.2496 - val_acc: 0.6129\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0445 - acc: 0.9673 - val_loss: 0.2408 - val_acc: 0.7097\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0427 - acc: 0.9673 - val_loss: 0.2397 - val_acc: 0.7097\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0418 - acc: 0.9709 - val_loss: 0.2530 - val_acc: 0.6129\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0406 - acc: 0.9673 - val_loss: 0.2332 - val_acc: 0.7097\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0400 - acc: 0.9709 - val_loss: 0.2517 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0391 - acc: 0.9709 - val_loss: 0.2439 - val_acc: 0.7097\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0378 - acc: 0.9709 - val_loss: 0.2485 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0368 - acc: 0.9709 - val_loss: 0.2568 - val_acc: 0.6129\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 157us/step - loss: 0.0355 - acc: 0.9709 - val_loss: 0.2460 - val_acc: 0.7097\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0361 - acc: 0.9745 - val_loss: 0.2579 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 47)                1833      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 16)                768       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,618\n",
      "Trainable params: 2,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 2ms/step - loss: 0.2499 - acc: 0.5236 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.2494 - acc: 0.5418 - val_loss: 0.2488 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.2469 - acc: 0.5636 - val_loss: 0.2441 - val_acc: 0.6452\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.2381 - acc: 0.6145 - val_loss: 0.2334 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.2202 - acc: 0.7164 - val_loss: 0.2204 - val_acc: 0.6129\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1981 - acc: 0.7127 - val_loss: 0.2122 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1795 - acc: 0.7345 - val_loss: 0.2021 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1705 - acc: 0.7527 - val_loss: 0.2113 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1673 - acc: 0.7418 - val_loss: 0.2075 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1602 - acc: 0.7564 - val_loss: 0.2123 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1596 - acc: 0.7636 - val_loss: 0.2136 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1557 - acc: 0.7745 - val_loss: 0.2166 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1542 - acc: 0.7891 - val_loss: 0.2200 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1517 - acc: 0.7891 - val_loss: 0.2193 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1498 - acc: 0.8036 - val_loss: 0.2220 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1483 - acc: 0.7855 - val_loss: 0.2214 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1474 - acc: 0.7964 - val_loss: 0.2261 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1455 - acc: 0.8109 - val_loss: 0.2238 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1441 - acc: 0.8109 - val_loss: 0.2256 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1398 - acc: 0.8291 - val_loss: 0.2211 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1385 - acc: 0.8291 - val_loss: 0.2225 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1371 - acc: 0.8255 - val_loss: 0.2220 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1338 - acc: 0.8291 - val_loss: 0.2239 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1322 - acc: 0.8327 - val_loss: 0.2219 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1315 - acc: 0.8364 - val_loss: 0.2241 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1282 - acc: 0.8291 - val_loss: 0.2204 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1260 - acc: 0.8400 - val_loss: 0.2208 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1228 - acc: 0.8545 - val_loss: 0.2210 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1188 - acc: 0.8618 - val_loss: 0.2214 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1177 - acc: 0.8545 - val_loss: 0.2248 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1148 - acc: 0.8582 - val_loss: 0.2189 - val_acc: 0.7419\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1109 - acc: 0.8691 - val_loss: 0.2198 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1082 - acc: 0.8764 - val_loss: 0.2235 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1040 - acc: 0.8836 - val_loss: 0.2234 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1016 - acc: 0.8800 - val_loss: 0.2216 - val_acc: 0.7419\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0976 - acc: 0.8909 - val_loss: 0.2231 - val_acc: 0.7419\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0938 - acc: 0.8982 - val_loss: 0.2221 - val_acc: 0.7419\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0899 - acc: 0.9018 - val_loss: 0.2237 - val_acc: 0.7419\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0868 - acc: 0.9200 - val_loss: 0.2213 - val_acc: 0.7419\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0821 - acc: 0.9236 - val_loss: 0.2257 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0788 - acc: 0.9273 - val_loss: 0.2268 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0754 - acc: 0.9309 - val_loss: 0.2268 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0710 - acc: 0.9418 - val_loss: 0.2287 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0669 - acc: 0.9527 - val_loss: 0.2292 - val_acc: 0.7097\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0640 - acc: 0.9564 - val_loss: 0.2287 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0600 - acc: 0.9600 - val_loss: 0.2334 - val_acc: 0.7419\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0568 - acc: 0.9600 - val_loss: 0.2329 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0549 - acc: 0.9636 - val_loss: 0.2292 - val_acc: 0.7419\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0520 - acc: 0.9636 - val_loss: 0.2344 - val_acc: 0.7419\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0508 - acc: 0.9636 - val_loss: 0.2331 - val_acc: 0.7419\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0474 - acc: 0.9709 - val_loss: 0.2340 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0444 - acc: 0.9673 - val_loss: 0.2308 - val_acc: 0.7419\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0423 - acc: 0.9709 - val_loss: 0.2415 - val_acc: 0.7419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0384 - acc: 0.9709 - val_loss: 0.2375 - val_acc: 0.7419\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0356 - acc: 0.9782 - val_loss: 0.2411 - val_acc: 0.7419\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0342 - acc: 0.9782 - val_loss: 0.2400 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0324 - acc: 0.9782 - val_loss: 0.2362 - val_acc: 0.7419\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0294 - acc: 0.9782 - val_loss: 0.2440 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0275 - acc: 0.9782 - val_loss: 0.2389 - val_acc: 0.7097\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0257 - acc: 0.9818 - val_loss: 0.2393 - val_acc: 0.6452\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0236 - acc: 0.9855 - val_loss: 0.2390 - val_acc: 0.7097\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0215 - acc: 0.9855 - val_loss: 0.2418 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0193 - acc: 0.9855 - val_loss: 0.2412 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0175 - acc: 0.9891 - val_loss: 0.2405 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0164 - acc: 0.9927 - val_loss: 0.2412 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0155 - acc: 0.9927 - val_loss: 0.2441 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0143 - acc: 0.9927 - val_loss: 0.2483 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0136 - acc: 0.9927 - val_loss: 0.2440 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0127 - acc: 0.9927 - val_loss: 0.2462 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0122 - acc: 0.9927 - val_loss: 0.2484 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0113 - acc: 0.9927 - val_loss: 0.2461 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0109 - acc: 0.9927 - val_loss: 0.2489 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0104 - acc: 0.9927 - val_loss: 0.2465 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0096 - acc: 0.9927 - val_loss: 0.2455 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0091 - acc: 0.9964 - val_loss: 0.2502 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0084 - acc: 0.9964 - val_loss: 0.2518 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0080 - acc: 0.9964 - val_loss: 0.2510 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0076 - acc: 0.9964 - val_loss: 0.2517 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0073 - acc: 0.9964 - val_loss: 0.2551 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0071 - acc: 0.9964 - val_loss: 0.2543 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0068 - acc: 0.9964 - val_loss: 0.2570 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0066 - acc: 0.9964 - val_loss: 0.2557 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0065 - acc: 0.9964 - val_loss: 0.2589 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0063 - acc: 0.9964 - val_loss: 0.2572 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0061 - acc: 0.9964 - val_loss: 0.2570 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0059 - acc: 0.9964 - val_loss: 0.2593 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0058 - acc: 0.9964 - val_loss: 0.2587 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0057 - acc: 0.9964 - val_loss: 0.2611 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0056 - acc: 0.9964 - val_loss: 0.2613 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.2605 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.2623 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.2624 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.2629 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2631 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.2643 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.2638 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.2645 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.2662 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0048 - acc: 0.9964 - val_loss: 0.2661 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0048 - acc: 0.9964 - val_loss: 0.2672 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 10)                390       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 18)                198       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 607\n",
      "Trainable params: 607\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 2ms/step - loss: 0.2500 - acc: 0.5127 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.2493 - acc: 0.5418 - val_loss: 0.2492 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.2478 - acc: 0.5418 - val_loss: 0.2469 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.2433 - acc: 0.5418 - val_loss: 0.2424 - val_acc: 0.5161\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.2356 - acc: 0.5673 - val_loss: 0.2356 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.2255 - acc: 0.6582 - val_loss: 0.2292 - val_acc: 0.6129\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 153us/step - loss: 0.2147 - acc: 0.6873 - val_loss: 0.2214 - val_acc: 0.6129\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.2042 - acc: 0.7200 - val_loss: 0.2168 - val_acc: 0.6452\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1948 - acc: 0.7382 - val_loss: 0.2156 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1865 - acc: 0.7345 - val_loss: 0.2120 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1787 - acc: 0.7600 - val_loss: 0.2081 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1735 - acc: 0.7527 - val_loss: 0.2083 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1690 - acc: 0.7636 - val_loss: 0.2072 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1660 - acc: 0.7673 - val_loss: 0.2116 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1637 - acc: 0.7709 - val_loss: 0.2125 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1613 - acc: 0.7855 - val_loss: 0.2150 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1593 - acc: 0.7927 - val_loss: 0.2145 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1580 - acc: 0.7927 - val_loss: 0.2179 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1570 - acc: 0.7964 - val_loss: 0.2191 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1557 - acc: 0.7927 - val_loss: 0.2220 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1543 - acc: 0.8109 - val_loss: 0.2220 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1534 - acc: 0.8145 - val_loss: 0.2203 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1525 - acc: 0.8073 - val_loss: 0.2233 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1516 - acc: 0.8182 - val_loss: 0.2209 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1503 - acc: 0.8109 - val_loss: 0.2238 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1492 - acc: 0.8145 - val_loss: 0.2244 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1490 - acc: 0.8218 - val_loss: 0.2220 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1479 - acc: 0.8073 - val_loss: 0.2258 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1471 - acc: 0.8145 - val_loss: 0.2251 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1465 - acc: 0.8109 - val_loss: 0.2243 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1450 - acc: 0.8218 - val_loss: 0.2229 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1437 - acc: 0.8218 - val_loss: 0.2240 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1420 - acc: 0.8218 - val_loss: 0.2242 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1411 - acc: 0.8182 - val_loss: 0.2255 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1412 - acc: 0.8109 - val_loss: 0.2237 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1403 - acc: 0.8109 - val_loss: 0.2241 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1378 - acc: 0.8291 - val_loss: 0.2230 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1367 - acc: 0.8291 - val_loss: 0.2225 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1358 - acc: 0.8327 - val_loss: 0.2237 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1345 - acc: 0.8255 - val_loss: 0.2225 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1338 - acc: 0.8255 - val_loss: 0.2200 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1326 - acc: 0.8327 - val_loss: 0.2202 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1317 - acc: 0.8400 - val_loss: 0.2194 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1305 - acc: 0.8364 - val_loss: 0.2191 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1297 - acc: 0.8400 - val_loss: 0.2200 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1281 - acc: 0.8436 - val_loss: 0.2188 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1274 - acc: 0.8436 - val_loss: 0.2180 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1264 - acc: 0.8473 - val_loss: 0.2158 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1251 - acc: 0.8436 - val_loss: 0.2162 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1243 - acc: 0.8509 - val_loss: 0.2174 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1231 - acc: 0.8545 - val_loss: 0.2190 - val_acc: 0.6452\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1226 - acc: 0.8473 - val_loss: 0.2151 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1222 - acc: 0.8545 - val_loss: 0.2150 - val_acc: 0.6452\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1203 - acc: 0.8473 - val_loss: 0.2185 - val_acc: 0.6452\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 149us/step - loss: 0.1191 - acc: 0.8509 - val_loss: 0.2139 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 147us/step - loss: 0.1181 - acc: 0.8545 - val_loss: 0.2150 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1175 - acc: 0.8618 - val_loss: 0.2168 - val_acc: 0.6452\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1163 - acc: 0.8509 - val_loss: 0.2141 - val_acc: 0.6452\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.1153 - acc: 0.8509 - val_loss: 0.2129 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1146 - acc: 0.8618 - val_loss: 0.2137 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1133 - acc: 0.8509 - val_loss: 0.2167 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1124 - acc: 0.8655 - val_loss: 0.2133 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1112 - acc: 0.8655 - val_loss: 0.2132 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.1103 - acc: 0.8582 - val_loss: 0.2132 - val_acc: 0.7097\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1096 - acc: 0.8764 - val_loss: 0.2144 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1088 - acc: 0.8618 - val_loss: 0.2135 - val_acc: 0.6774\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 173us/step - loss: 0.1089 - acc: 0.8727 - val_loss: 0.2142 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1088 - acc: 0.8691 - val_loss: 0.2143 - val_acc: 0.7097\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1060 - acc: 0.8727 - val_loss: 0.2167 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1046 - acc: 0.8800 - val_loss: 0.2167 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1039 - acc: 0.8800 - val_loss: 0.2140 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1027 - acc: 0.8800 - val_loss: 0.2173 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1022 - acc: 0.8836 - val_loss: 0.2158 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1009 - acc: 0.8800 - val_loss: 0.2179 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 148us/step - loss: 0.1001 - acc: 0.8982 - val_loss: 0.2153 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.1000 - acc: 0.8836 - val_loss: 0.2143 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0993 - acc: 0.8982 - val_loss: 0.2133 - val_acc: 0.7097\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0974 - acc: 0.8982 - val_loss: 0.2170 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0966 - acc: 0.8982 - val_loss: 0.2158 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 151us/step - loss: 0.0962 - acc: 0.8945 - val_loss: 0.2167 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0955 - acc: 0.9055 - val_loss: 0.2181 - val_acc: 0.7097\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0953 - acc: 0.8945 - val_loss: 0.2183 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.0936 - acc: 0.8945 - val_loss: 0.2187 - val_acc: 0.7097\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0931 - acc: 0.9018 - val_loss: 0.2181 - val_acc: 0.7097\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0932 - acc: 0.8982 - val_loss: 0.2203 - val_acc: 0.7097\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0924 - acc: 0.8945 - val_loss: 0.2208 - val_acc: 0.7097\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0904 - acc: 0.8945 - val_loss: 0.2213 - val_acc: 0.7097\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0894 - acc: 0.8982 - val_loss: 0.2199 - val_acc: 0.7097\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0887 - acc: 0.9091 - val_loss: 0.2242 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0884 - acc: 0.9018 - val_loss: 0.2269 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0871 - acc: 0.9091 - val_loss: 0.2271 - val_acc: 0.7097\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0863 - acc: 0.9018 - val_loss: 0.2305 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0866 - acc: 0.8873 - val_loss: 0.2255 - val_acc: 0.7097\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0859 - acc: 0.9127 - val_loss: 0.2294 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0845 - acc: 0.8982 - val_loss: 0.2278 - val_acc: 0.7097\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0843 - acc: 0.9127 - val_loss: 0.2298 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0837 - acc: 0.9127 - val_loss: 0.2285 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0817 - acc: 0.9091 - val_loss: 0.2316 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0816 - acc: 0.9164 - val_loss: 0.2291 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 33)                1287      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 16)                544       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,848\n",
      "Trainable params: 1,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 0s 2ms/step - loss: 0.2499 - acc: 0.5309 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.2494 - acc: 0.5418 - val_loss: 0.2490 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.2472 - acc: 0.5491 - val_loss: 0.2455 - val_acc: 0.6129\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.2400 - acc: 0.6291 - val_loss: 0.2365 - val_acc: 0.6129\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.2259 - acc: 0.6909 - val_loss: 0.2239 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.2056 - acc: 0.7418 - val_loss: 0.2122 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1877 - acc: 0.7382 - val_loss: 0.2063 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1752 - acc: 0.7491 - val_loss: 0.2084 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1673 - acc: 0.7636 - val_loss: 0.2050 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1642 - acc: 0.7527 - val_loss: 0.2085 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1596 - acc: 0.7709 - val_loss: 0.2075 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1570 - acc: 0.7709 - val_loss: 0.2137 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1556 - acc: 0.7782 - val_loss: 0.2154 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1541 - acc: 0.7709 - val_loss: 0.2171 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1524 - acc: 0.7782 - val_loss: 0.2178 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1514 - acc: 0.7818 - val_loss: 0.2150 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1500 - acc: 0.7964 - val_loss: 0.2167 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1481 - acc: 0.7891 - val_loss: 0.2178 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1466 - acc: 0.7964 - val_loss: 0.2191 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1436 - acc: 0.8073 - val_loss: 0.2187 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1436 - acc: 0.8109 - val_loss: 0.2192 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1415 - acc: 0.8145 - val_loss: 0.2202 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1395 - acc: 0.8073 - val_loss: 0.2192 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1377 - acc: 0.8364 - val_loss: 0.2183 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1354 - acc: 0.8255 - val_loss: 0.2194 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1332 - acc: 0.8364 - val_loss: 0.2172 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1322 - acc: 0.8255 - val_loss: 0.2204 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1288 - acc: 0.8436 - val_loss: 0.2214 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1264 - acc: 0.8545 - val_loss: 0.2202 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1250 - acc: 0.8509 - val_loss: 0.2203 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1230 - acc: 0.8509 - val_loss: 0.2213 - val_acc: 0.7419\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1211 - acc: 0.8582 - val_loss: 0.2223 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1184 - acc: 0.8727 - val_loss: 0.2213 - val_acc: 0.7419\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1159 - acc: 0.8800 - val_loss: 0.2195 - val_acc: 0.7419\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1134 - acc: 0.8800 - val_loss: 0.2186 - val_acc: 0.7419\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1106 - acc: 0.8727 - val_loss: 0.2254 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1085 - acc: 0.8800 - val_loss: 0.2227 - val_acc: 0.7419\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1065 - acc: 0.8836 - val_loss: 0.2183 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1041 - acc: 0.8982 - val_loss: 0.2169 - val_acc: 0.7419\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1002 - acc: 0.8836 - val_loss: 0.2197 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0964 - acc: 0.8982 - val_loss: 0.2224 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0939 - acc: 0.9018 - val_loss: 0.2157 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0912 - acc: 0.9127 - val_loss: 0.2195 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0887 - acc: 0.9200 - val_loss: 0.2154 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0888 - acc: 0.9164 - val_loss: 0.2117 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0838 - acc: 0.9345 - val_loss: 0.2136 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0804 - acc: 0.9345 - val_loss: 0.2081 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0771 - acc: 0.9382 - val_loss: 0.2104 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0755 - acc: 0.9309 - val_loss: 0.2097 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0723 - acc: 0.9382 - val_loss: 0.2112 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0699 - acc: 0.9345 - val_loss: 0.2110 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0678 - acc: 0.9382 - val_loss: 0.2101 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0635 - acc: 0.9455 - val_loss: 0.2049 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0619 - acc: 0.9527 - val_loss: 0.1983 - val_acc: 0.7097\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0581 - acc: 0.9491 - val_loss: 0.1991 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0561 - acc: 0.9491 - val_loss: 0.1938 - val_acc: 0.7419\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0517 - acc: 0.9600 - val_loss: 0.1922 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0483 - acc: 0.9636 - val_loss: 0.1964 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0461 - acc: 0.9636 - val_loss: 0.1877 - val_acc: 0.7097\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0431 - acc: 0.9709 - val_loss: 0.1905 - val_acc: 0.7097\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0408 - acc: 0.9709 - val_loss: 0.1922 - val_acc: 0.7742\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0390 - acc: 0.9709 - val_loss: 0.1944 - val_acc: 0.7419\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0355 - acc: 0.9709 - val_loss: 0.1992 - val_acc: 0.7097\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0342 - acc: 0.9782 - val_loss: 0.1998 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0319 - acc: 0.9745 - val_loss: 0.1862 - val_acc: 0.8065\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0312 - acc: 0.9782 - val_loss: 0.1882 - val_acc: 0.7742\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0289 - acc: 0.9818 - val_loss: 0.1844 - val_acc: 0.7742\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0266 - acc: 0.9855 - val_loss: 0.1937 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0251 - acc: 0.9855 - val_loss: 0.1959 - val_acc: 0.7742\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0239 - acc: 0.9818 - val_loss: 0.1986 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0231 - acc: 0.9855 - val_loss: 0.1993 - val_acc: 0.7419\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0205 - acc: 0.9891 - val_loss: 0.2002 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0196 - acc: 0.9891 - val_loss: 0.1999 - val_acc: 0.7097\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0183 - acc: 0.9891 - val_loss: 0.2009 - val_acc: 0.7419\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0181 - acc: 0.9927 - val_loss: 0.2080 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0162 - acc: 0.9927 - val_loss: 0.2080 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0158 - acc: 0.9927 - val_loss: 0.2075 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0147 - acc: 0.9964 - val_loss: 0.2083 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0131 - acc: 0.9964 - val_loss: 0.2058 - val_acc: 0.7419\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0129 - acc: 0.9964 - val_loss: 0.2112 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0121 - acc: 0.9964 - val_loss: 0.2103 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0115 - acc: 0.9964 - val_loss: 0.2186 - val_acc: 0.6452\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 170us/step - loss: 0.0114 - acc: 0.9964 - val_loss: 0.2112 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0101 - acc: 0.9964 - val_loss: 0.2144 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0100 - acc: 0.9964 - val_loss: 0.2146 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0092 - acc: 0.9964 - val_loss: 0.2147 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0091 - acc: 0.9964 - val_loss: 0.2232 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0089 - acc: 0.9964 - val_loss: 0.2169 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0084 - acc: 0.9964 - val_loss: 0.2188 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0079 - acc: 0.9964 - val_loss: 0.2216 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0077 - acc: 0.9964 - val_loss: 0.2183 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0074 - acc: 0.9964 - val_loss: 0.2214 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0074 - acc: 0.9964 - val_loss: 0.2275 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0070 - acc: 0.9964 - val_loss: 0.2225 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0068 - acc: 0.9964 - val_loss: 0.2220 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0067 - acc: 0.9964 - val_loss: 0.2254 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0065 - acc: 0.9964 - val_loss: 0.2236 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0064 - acc: 0.9964 - val_loss: 0.2226 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0062 - acc: 0.9964 - val_loss: 0.2280 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0060 - acc: 0.9964 - val_loss: 0.2279 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 25)                975       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 18)                468       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 1,462\n",
      "Trainable params: 1,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 2ms/step - loss: 0.2499 - acc: 0.5345 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.2495 - acc: 0.5418 - val_loss: 0.2496 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.2484 - acc: 0.5418 - val_loss: 0.2479 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.2433 - acc: 0.5455 - val_loss: 0.2404 - val_acc: 0.5484\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.2305 - acc: 0.6182 - val_loss: 0.2309 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.2155 - acc: 0.6691 - val_loss: 0.2208 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.2007 - acc: 0.7273 - val_loss: 0.2130 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1884 - acc: 0.7382 - val_loss: 0.2067 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1777 - acc: 0.7418 - val_loss: 0.2090 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1710 - acc: 0.7564 - val_loss: 0.2033 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1665 - acc: 0.7600 - val_loss: 0.2123 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1638 - acc: 0.7600 - val_loss: 0.2125 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1633 - acc: 0.7855 - val_loss: 0.2131 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1617 - acc: 0.7745 - val_loss: 0.2257 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1567 - acc: 0.7964 - val_loss: 0.2165 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1564 - acc: 0.7855 - val_loss: 0.2225 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1550 - acc: 0.8000 - val_loss: 0.2230 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1541 - acc: 0.7927 - val_loss: 0.2240 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1523 - acc: 0.8109 - val_loss: 0.2260 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1510 - acc: 0.8036 - val_loss: 0.2233 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1500 - acc: 0.8182 - val_loss: 0.2283 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1491 - acc: 0.8036 - val_loss: 0.2309 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1484 - acc: 0.8109 - val_loss: 0.2298 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1476 - acc: 0.8073 - val_loss: 0.2284 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1459 - acc: 0.8182 - val_loss: 0.2318 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1452 - acc: 0.8073 - val_loss: 0.2305 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1456 - acc: 0.8145 - val_loss: 0.2313 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1438 - acc: 0.8182 - val_loss: 0.2325 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1423 - acc: 0.8327 - val_loss: 0.2374 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1405 - acc: 0.8291 - val_loss: 0.2320 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1397 - acc: 0.8327 - val_loss: 0.2363 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1391 - acc: 0.8291 - val_loss: 0.2335 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1378 - acc: 0.8364 - val_loss: 0.2354 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1368 - acc: 0.8327 - val_loss: 0.2351 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1342 - acc: 0.8364 - val_loss: 0.2335 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1341 - acc: 0.8436 - val_loss: 0.2355 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1333 - acc: 0.8400 - val_loss: 0.2360 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1325 - acc: 0.8400 - val_loss: 0.2378 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1301 - acc: 0.8509 - val_loss: 0.2343 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1284 - acc: 0.8509 - val_loss: 0.2320 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1271 - acc: 0.8509 - val_loss: 0.2350 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1254 - acc: 0.8582 - val_loss: 0.2369 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1252 - acc: 0.8473 - val_loss: 0.2335 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1227 - acc: 0.8582 - val_loss: 0.2338 - val_acc: 0.7097\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1215 - acc: 0.8582 - val_loss: 0.2332 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1195 - acc: 0.8691 - val_loss: 0.2367 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1200 - acc: 0.8545 - val_loss: 0.2337 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1172 - acc: 0.8800 - val_loss: 0.2350 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1144 - acc: 0.8764 - val_loss: 0.2342 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1134 - acc: 0.8800 - val_loss: 0.2348 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1114 - acc: 0.8727 - val_loss: 0.2352 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1097 - acc: 0.8836 - val_loss: 0.2378 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1067 - acc: 0.8945 - val_loss: 0.2357 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1053 - acc: 0.8909 - val_loss: 0.2356 - val_acc: 0.7097\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1034 - acc: 0.8982 - val_loss: 0.2342 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1015 - acc: 0.8982 - val_loss: 0.2330 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1001 - acc: 0.8982 - val_loss: 0.2395 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0981 - acc: 0.9018 - val_loss: 0.2373 - val_acc: 0.7097\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0971 - acc: 0.8982 - val_loss: 0.2386 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0948 - acc: 0.9018 - val_loss: 0.2357 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0915 - acc: 0.9055 - val_loss: 0.2437 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0900 - acc: 0.9091 - val_loss: 0.2442 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0899 - acc: 0.9091 - val_loss: 0.2394 - val_acc: 0.7097\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0851 - acc: 0.9164 - val_loss: 0.2379 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0829 - acc: 0.9200 - val_loss: 0.2418 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0809 - acc: 0.9236 - val_loss: 0.2451 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0782 - acc: 0.9309 - val_loss: 0.2463 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0765 - acc: 0.9345 - val_loss: 0.2445 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0749 - acc: 0.9345 - val_loss: 0.2498 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0728 - acc: 0.9382 - val_loss: 0.2573 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.0745 - acc: 0.9309 - val_loss: 0.2456 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0694 - acc: 0.9418 - val_loss: 0.2527 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0683 - acc: 0.9382 - val_loss: 0.2582 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0664 - acc: 0.9382 - val_loss: 0.2499 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0643 - acc: 0.9455 - val_loss: 0.2494 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0616 - acc: 0.9455 - val_loss: 0.2555 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0592 - acc: 0.9418 - val_loss: 0.2530 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0574 - acc: 0.9491 - val_loss: 0.2431 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0561 - acc: 0.9564 - val_loss: 0.2531 - val_acc: 0.6129\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.0559 - acc: 0.9491 - val_loss: 0.2572 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0518 - acc: 0.9564 - val_loss: 0.2545 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0514 - acc: 0.9527 - val_loss: 0.2582 - val_acc: 0.6129\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.0493 - acc: 0.9600 - val_loss: 0.2522 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0480 - acc: 0.9600 - val_loss: 0.2602 - val_acc: 0.6129\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0457 - acc: 0.9564 - val_loss: 0.2661 - val_acc: 0.6129\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0461 - acc: 0.9636 - val_loss: 0.2531 - val_acc: 0.6129\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0449 - acc: 0.9636 - val_loss: 0.2637 - val_acc: 0.6129\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0440 - acc: 0.9636 - val_loss: 0.2681 - val_acc: 0.6129\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0413 - acc: 0.9636 - val_loss: 0.2607 - val_acc: 0.6129\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0391 - acc: 0.9673 - val_loss: 0.2552 - val_acc: 0.6129\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0398 - acc: 0.9636 - val_loss: 0.2547 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0373 - acc: 0.9673 - val_loss: 0.2585 - val_acc: 0.6129\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0370 - acc: 0.9673 - val_loss: 0.2639 - val_acc: 0.5806\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0364 - acc: 0.9673 - val_loss: 0.2637 - val_acc: 0.6129\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0339 - acc: 0.9673 - val_loss: 0.2572 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0323 - acc: 0.9709 - val_loss: 0.2588 - val_acc: 0.6129\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0308 - acc: 0.9673 - val_loss: 0.2600 - val_acc: 0.6452\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 157us/step - loss: 0.0292 - acc: 0.9782 - val_loss: 0.2641 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0286 - acc: 0.9782 - val_loss: 0.2642 - val_acc: 0.6129\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0276 - acc: 0.9782 - val_loss: 0.2802 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 37)                1443      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 12)                456       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,912\n",
      "Trainable params: 1,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 2ms/step - loss: 0.2499 - acc: 0.5345 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.2489 - acc: 0.5455 - val_loss: 0.2482 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.2460 - acc: 0.5927 - val_loss: 0.2425 - val_acc: 0.6129\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.2360 - acc: 0.7345 - val_loss: 0.2311 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.2176 - acc: 0.7491 - val_loss: 0.2145 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1980 - acc: 0.7309 - val_loss: 0.2030 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1818 - acc: 0.7455 - val_loss: 0.1985 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1732 - acc: 0.7418 - val_loss: 0.2029 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1666 - acc: 0.7455 - val_loss: 0.2048 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1622 - acc: 0.7527 - val_loss: 0.2092 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1596 - acc: 0.7745 - val_loss: 0.2123 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1567 - acc: 0.7636 - val_loss: 0.2172 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1548 - acc: 0.7709 - val_loss: 0.2190 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1531 - acc: 0.7855 - val_loss: 0.2221 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1512 - acc: 0.7782 - val_loss: 0.2239 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1499 - acc: 0.7782 - val_loss: 0.2247 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1478 - acc: 0.7855 - val_loss: 0.2259 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1464 - acc: 0.7927 - val_loss: 0.2266 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1448 - acc: 0.7964 - val_loss: 0.2270 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1426 - acc: 0.8036 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1411 - acc: 0.8073 - val_loss: 0.2277 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1390 - acc: 0.8218 - val_loss: 0.2295 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1372 - acc: 0.8073 - val_loss: 0.2312 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1369 - acc: 0.8109 - val_loss: 0.2323 - val_acc: 0.6452\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1339 - acc: 0.8109 - val_loss: 0.2329 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1321 - acc: 0.8327 - val_loss: 0.2335 - val_acc: 0.6452\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1299 - acc: 0.8509 - val_loss: 0.2335 - val_acc: 0.6452\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1264 - acc: 0.8582 - val_loss: 0.2331 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1243 - acc: 0.8400 - val_loss: 0.2334 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1214 - acc: 0.8545 - val_loss: 0.2349 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1181 - acc: 0.8582 - val_loss: 0.2367 - val_acc: 0.6452\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1167 - acc: 0.8655 - val_loss: 0.2346 - val_acc: 0.6452\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1144 - acc: 0.8691 - val_loss: 0.2395 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1116 - acc: 0.8764 - val_loss: 0.2398 - val_acc: 0.6452\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1080 - acc: 0.8800 - val_loss: 0.2429 - val_acc: 0.6452\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1047 - acc: 0.8982 - val_loss: 0.2429 - val_acc: 0.6452\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1024 - acc: 0.9018 - val_loss: 0.2456 - val_acc: 0.6452\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0983 - acc: 0.9055 - val_loss: 0.2440 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0954 - acc: 0.9200 - val_loss: 0.2425 - val_acc: 0.6452\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0932 - acc: 0.9091 - val_loss: 0.2420 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0885 - acc: 0.9164 - val_loss: 0.2404 - val_acc: 0.6129\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0869 - acc: 0.9164 - val_loss: 0.2457 - val_acc: 0.6452\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0827 - acc: 0.9236 - val_loss: 0.2475 - val_acc: 0.6129\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0797 - acc: 0.9236 - val_loss: 0.2463 - val_acc: 0.6129\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0751 - acc: 0.9273 - val_loss: 0.2412 - val_acc: 0.5806\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0722 - acc: 0.9273 - val_loss: 0.2466 - val_acc: 0.5806\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0708 - acc: 0.9273 - val_loss: 0.2474 - val_acc: 0.6129\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0678 - acc: 0.9455 - val_loss: 0.2469 - val_acc: 0.5806\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0625 - acc: 0.9527 - val_loss: 0.2482 - val_acc: 0.6129\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0593 - acc: 0.9491 - val_loss: 0.2521 - val_acc: 0.5806\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0568 - acc: 0.9527 - val_loss: 0.2547 - val_acc: 0.6129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0558 - acc: 0.9527 - val_loss: 0.2594 - val_acc: 0.5484\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0515 - acc: 0.9564 - val_loss: 0.2551 - val_acc: 0.5806\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0497 - acc: 0.9673 - val_loss: 0.2607 - val_acc: 0.5806\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0461 - acc: 0.9673 - val_loss: 0.2605 - val_acc: 0.6129\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0456 - acc: 0.9709 - val_loss: 0.2671 - val_acc: 0.5484\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0423 - acc: 0.9782 - val_loss: 0.2711 - val_acc: 0.6129\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0419 - acc: 0.9709 - val_loss: 0.2622 - val_acc: 0.5484\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0382 - acc: 0.9855 - val_loss: 0.2732 - val_acc: 0.5806\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0366 - acc: 0.9818 - val_loss: 0.2717 - val_acc: 0.5806\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0340 - acc: 0.9855 - val_loss: 0.2717 - val_acc: 0.6129\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0327 - acc: 0.9891 - val_loss: 0.2786 - val_acc: 0.5806\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0299 - acc: 0.9891 - val_loss: 0.2805 - val_acc: 0.5161\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0279 - acc: 0.9927 - val_loss: 0.2857 - val_acc: 0.5484\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0262 - acc: 0.9927 - val_loss: 0.2869 - val_acc: 0.5161\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0244 - acc: 0.9927 - val_loss: 0.2926 - val_acc: 0.5161\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0230 - acc: 0.9927 - val_loss: 0.2879 - val_acc: 0.5806\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0217 - acc: 0.9927 - val_loss: 0.2914 - val_acc: 0.5161\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0208 - acc: 0.9927 - val_loss: 0.2932 - val_acc: 0.5806\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0195 - acc: 0.9927 - val_loss: 0.2958 - val_acc: 0.5484\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0194 - acc: 0.9927 - val_loss: 0.3021 - val_acc: 0.5161\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0187 - acc: 0.9927 - val_loss: 0.3054 - val_acc: 0.5806\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0176 - acc: 0.9927 - val_loss: 0.3014 - val_acc: 0.5806\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0161 - acc: 0.9927 - val_loss: 0.3012 - val_acc: 0.5806\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0155 - acc: 0.9927 - val_loss: 0.3027 - val_acc: 0.5161\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0142 - acc: 0.9927 - val_loss: 0.2996 - val_acc: 0.6129\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0139 - acc: 0.9964 - val_loss: 0.3069 - val_acc: 0.5806\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0127 - acc: 0.9927 - val_loss: 0.3069 - val_acc: 0.5161\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0119 - acc: 0.9964 - val_loss: 0.3053 - val_acc: 0.5484\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0111 - acc: 0.9964 - val_loss: 0.3062 - val_acc: 0.5806\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0104 - acc: 0.9964 - val_loss: 0.3117 - val_acc: 0.5806\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.3041 - val_acc: 0.5806\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.3070 - val_acc: 0.5806\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0086 - acc: 0.9964 - val_loss: 0.3086 - val_acc: 0.5484\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.3097 - val_acc: 0.6129\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3076 - val_acc: 0.6129\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.3062 - val_acc: 0.5161\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.3122 - val_acc: 0.5806\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.3095 - val_acc: 0.6129\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.3090 - val_acc: 0.6129\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.3126 - val_acc: 0.6129\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.3072 - val_acc: 0.6129\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.3142 - val_acc: 0.5806\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.3130 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.3112 - val_acc: 0.6129\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.3111 - val_acc: 0.6129\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.3139 - val_acc: 0.6129\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.3152 - val_acc: 0.6129\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.3153 - val_acc: 0.5806\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 19)                741       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                200       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 952\n",
      "Trainable params: 952\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 2ms/step - loss: 0.2499 - acc: 0.5382 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.2493 - acc: 0.5418 - val_loss: 0.2494 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.2480 - acc: 0.5418 - val_loss: 0.2477 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.2444 - acc: 0.6000 - val_loss: 0.2434 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.2367 - acc: 0.6982 - val_loss: 0.2359 - val_acc: 0.6452\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 158us/step - loss: 0.2253 - acc: 0.7091 - val_loss: 0.2248 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.2095 - acc: 0.7273 - val_loss: 0.2140 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1945 - acc: 0.7309 - val_loss: 0.2049 - val_acc: 0.6452\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1820 - acc: 0.7600 - val_loss: 0.2065 - val_acc: 0.6452\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1743 - acc: 0.7418 - val_loss: 0.2063 - val_acc: 0.6452\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.1684 - acc: 0.7673 - val_loss: 0.2051 - val_acc: 0.6452\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1640 - acc: 0.7527 - val_loss: 0.2055 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1605 - acc: 0.7636 - val_loss: 0.2118 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1573 - acc: 0.7709 - val_loss: 0.2102 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1552 - acc: 0.7927 - val_loss: 0.2143 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1535 - acc: 0.8036 - val_loss: 0.2163 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1518 - acc: 0.7964 - val_loss: 0.2221 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1495 - acc: 0.8036 - val_loss: 0.2231 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1478 - acc: 0.7964 - val_loss: 0.2236 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1464 - acc: 0.8073 - val_loss: 0.2262 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1453 - acc: 0.8073 - val_loss: 0.2276 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1423 - acc: 0.8145 - val_loss: 0.2302 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1418 - acc: 0.8182 - val_loss: 0.2329 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1402 - acc: 0.8145 - val_loss: 0.2321 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1377 - acc: 0.8255 - val_loss: 0.2340 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1360 - acc: 0.8182 - val_loss: 0.2385 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1347 - acc: 0.8255 - val_loss: 0.2388 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1317 - acc: 0.8182 - val_loss: 0.2406 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1301 - acc: 0.8364 - val_loss: 0.2394 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1284 - acc: 0.8400 - val_loss: 0.2414 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1275 - acc: 0.8364 - val_loss: 0.2406 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1250 - acc: 0.8400 - val_loss: 0.2426 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1221 - acc: 0.8545 - val_loss: 0.2422 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1204 - acc: 0.8582 - val_loss: 0.2442 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1179 - acc: 0.8545 - val_loss: 0.2450 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1151 - acc: 0.8618 - val_loss: 0.2459 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1135 - acc: 0.8727 - val_loss: 0.2453 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1096 - acc: 0.8836 - val_loss: 0.2452 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1085 - acc: 0.8800 - val_loss: 0.2492 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1055 - acc: 0.8945 - val_loss: 0.2461 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1029 - acc: 0.8909 - val_loss: 0.2469 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1025 - acc: 0.9055 - val_loss: 0.2451 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0968 - acc: 0.9127 - val_loss: 0.2479 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0943 - acc: 0.9164 - val_loss: 0.2476 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0918 - acc: 0.9200 - val_loss: 0.2502 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0916 - acc: 0.9236 - val_loss: 0.2452 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0876 - acc: 0.9200 - val_loss: 0.2493 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0850 - acc: 0.9200 - val_loss: 0.2478 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0823 - acc: 0.9273 - val_loss: 0.2492 - val_acc: 0.6452\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0803 - acc: 0.9273 - val_loss: 0.2536 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0776 - acc: 0.9273 - val_loss: 0.2511 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0749 - acc: 0.9236 - val_loss: 0.2528 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0728 - acc: 0.9345 - val_loss: 0.2522 - val_acc: 0.7097\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0716 - acc: 0.9418 - val_loss: 0.2563 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0697 - acc: 0.9455 - val_loss: 0.2543 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0676 - acc: 0.9491 - val_loss: 0.2598 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0658 - acc: 0.9564 - val_loss: 0.2527 - val_acc: 0.7097\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0631 - acc: 0.9564 - val_loss: 0.2561 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0622 - acc: 0.9600 - val_loss: 0.2566 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0607 - acc: 0.9636 - val_loss: 0.2581 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0587 - acc: 0.9600 - val_loss: 0.2582 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 214us/step - loss: 0.0575 - acc: 0.9600 - val_loss: 0.2567 - val_acc: 0.7097\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0550 - acc: 0.9636 - val_loss: 0.2604 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0539 - acc: 0.9636 - val_loss: 0.2622 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0518 - acc: 0.9673 - val_loss: 0.2651 - val_acc: 0.6774\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 184us/step - loss: 0.0504 - acc: 0.9673 - val_loss: 0.2625 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0492 - acc: 0.9709 - val_loss: 0.2687 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0486 - acc: 0.9709 - val_loss: 0.2677 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0465 - acc: 0.9709 - val_loss: 0.2663 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0459 - acc: 0.9673 - val_loss: 0.2672 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0444 - acc: 0.9745 - val_loss: 0.2671 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0430 - acc: 0.9745 - val_loss: 0.2695 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0425 - acc: 0.9745 - val_loss: 0.2717 - val_acc: 0.6452\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0412 - acc: 0.9745 - val_loss: 0.2695 - val_acc: 0.6452\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.0406 - acc: 0.9745 - val_loss: 0.2716 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0399 - acc: 0.9745 - val_loss: 0.2736 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0390 - acc: 0.9745 - val_loss: 0.2722 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0377 - acc: 0.9745 - val_loss: 0.2742 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0370 - acc: 0.9745 - val_loss: 0.2779 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0363 - acc: 0.9745 - val_loss: 0.2745 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0358 - acc: 0.9745 - val_loss: 0.2766 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0354 - acc: 0.9745 - val_loss: 0.2742 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0347 - acc: 0.9745 - val_loss: 0.2769 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0340 - acc: 0.9745 - val_loss: 0.2737 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0336 - acc: 0.9745 - val_loss: 0.2802 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0335 - acc: 0.9745 - val_loss: 0.2744 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0326 - acc: 0.9745 - val_loss: 0.2767 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 152us/step - loss: 0.0319 - acc: 0.9745 - val_loss: 0.2758 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 150us/step - loss: 0.0321 - acc: 0.9745 - val_loss: 0.2766 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0315 - acc: 0.9745 - val_loss: 0.2751 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0310 - acc: 0.9745 - val_loss: 0.2770 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0303 - acc: 0.9745 - val_loss: 0.2782 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0301 - acc: 0.9745 - val_loss: 0.2753 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0296 - acc: 0.9745 - val_loss: 0.2775 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0293 - acc: 0.9745 - val_loss: 0.2753 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0290 - acc: 0.9745 - val_loss: 0.2718 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0285 - acc: 0.9745 - val_loss: 0.2708 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0283 - acc: 0.9745 - val_loss: 0.2672 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0272 - acc: 0.9745 - val_loss: 0.2690 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 25)                975       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 14)                364       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 1,354\n",
      "Trainable params: 1,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 2ms/step - loss: 0.2500 - acc: 0.5127 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2495 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.2486 - acc: 0.5418 - val_loss: 0.2478 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.2452 - acc: 0.5527 - val_loss: 0.2428 - val_acc: 0.5806\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.2371 - acc: 0.6073 - val_loss: 0.2325 - val_acc: 0.6774\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.2247 - acc: 0.7091 - val_loss: 0.2216 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.2088 - acc: 0.7345 - val_loss: 0.2073 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1927 - acc: 0.7382 - val_loss: 0.1986 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1809 - acc: 0.7491 - val_loss: 0.1985 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1719 - acc: 0.7564 - val_loss: 0.1994 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1680 - acc: 0.7636 - val_loss: 0.2037 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1656 - acc: 0.7673 - val_loss: 0.2067 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1620 - acc: 0.7709 - val_loss: 0.2093 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1591 - acc: 0.7673 - val_loss: 0.2063 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1573 - acc: 0.7782 - val_loss: 0.2110 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1561 - acc: 0.7709 - val_loss: 0.2106 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1533 - acc: 0.7818 - val_loss: 0.2096 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1514 - acc: 0.7927 - val_loss: 0.2141 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1500 - acc: 0.8000 - val_loss: 0.2143 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1480 - acc: 0.8036 - val_loss: 0.2142 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1466 - acc: 0.8073 - val_loss: 0.2145 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1442 - acc: 0.8182 - val_loss: 0.2127 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1435 - acc: 0.8255 - val_loss: 0.2137 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1408 - acc: 0.8255 - val_loss: 0.2139 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1397 - acc: 0.8218 - val_loss: 0.2164 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1377 - acc: 0.8255 - val_loss: 0.2144 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1364 - acc: 0.8218 - val_loss: 0.2123 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1343 - acc: 0.8327 - val_loss: 0.2125 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1321 - acc: 0.8291 - val_loss: 0.2088 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1310 - acc: 0.8473 - val_loss: 0.2099 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1291 - acc: 0.8327 - val_loss: 0.2120 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 153us/step - loss: 0.1272 - acc: 0.8400 - val_loss: 0.2084 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1252 - acc: 0.8509 - val_loss: 0.2121 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1225 - acc: 0.8509 - val_loss: 0.2096 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1224 - acc: 0.8436 - val_loss: 0.2086 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1199 - acc: 0.8582 - val_loss: 0.2085 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1168 - acc: 0.8691 - val_loss: 0.2120 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1153 - acc: 0.8509 - val_loss: 0.2101 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1144 - acc: 0.8727 - val_loss: 0.2086 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1103 - acc: 0.8764 - val_loss: 0.2087 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1098 - acc: 0.8727 - val_loss: 0.2095 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1071 - acc: 0.8836 - val_loss: 0.2078 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.1037 - acc: 0.8945 - val_loss: 0.2113 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1027 - acc: 0.8982 - val_loss: 0.2115 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1012 - acc: 0.8836 - val_loss: 0.2060 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0977 - acc: 0.9055 - val_loss: 0.2063 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0960 - acc: 0.9055 - val_loss: 0.2035 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0938 - acc: 0.9127 - val_loss: 0.2039 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0904 - acc: 0.9127 - val_loss: 0.2071 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0878 - acc: 0.9200 - val_loss: 0.2053 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0872 - acc: 0.9091 - val_loss: 0.2066 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0831 - acc: 0.9309 - val_loss: 0.2064 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0802 - acc: 0.9236 - val_loss: 0.2080 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0786 - acc: 0.9309 - val_loss: 0.2104 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0743 - acc: 0.9418 - val_loss: 0.2052 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0729 - acc: 0.9491 - val_loss: 0.2121 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0694 - acc: 0.9491 - val_loss: 0.2120 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0677 - acc: 0.9455 - val_loss: 0.2116 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0664 - acc: 0.9564 - val_loss: 0.2136 - val_acc: 0.6452\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0636 - acc: 0.9564 - val_loss: 0.2205 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0622 - acc: 0.9600 - val_loss: 0.2206 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0607 - acc: 0.9527 - val_loss: 0.2211 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0591 - acc: 0.9564 - val_loss: 0.2204 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0564 - acc: 0.9636 - val_loss: 0.2222 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0548 - acc: 0.9564 - val_loss: 0.2278 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0527 - acc: 0.9564 - val_loss: 0.2251 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0525 - acc: 0.9636 - val_loss: 0.2295 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0506 - acc: 0.9636 - val_loss: 0.2272 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 213us/step - loss: 0.0480 - acc: 0.9673 - val_loss: 0.2292 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0473 - acc: 0.9636 - val_loss: 0.2312 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0455 - acc: 0.9745 - val_loss: 0.2308 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0448 - acc: 0.9709 - val_loss: 0.2338 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0431 - acc: 0.9745 - val_loss: 0.2414 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0431 - acc: 0.9709 - val_loss: 0.2344 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0405 - acc: 0.9673 - val_loss: 0.2379 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0391 - acc: 0.9782 - val_loss: 0.2403 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0378 - acc: 0.9782 - val_loss: 0.2421 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0362 - acc: 0.9782 - val_loss: 0.2410 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0358 - acc: 0.9782 - val_loss: 0.2425 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0343 - acc: 0.9782 - val_loss: 0.2456 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0341 - acc: 0.9782 - val_loss: 0.2431 - val_acc: 0.6774\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 159us/step - loss: 0.0326 - acc: 0.9818 - val_loss: 0.2413 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0335 - acc: 0.9818 - val_loss: 0.2527 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0314 - acc: 0.9818 - val_loss: 0.2516 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0311 - acc: 0.9818 - val_loss: 0.2515 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0301 - acc: 0.9818 - val_loss: 0.2530 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0297 - acc: 0.9818 - val_loss: 0.2523 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0291 - acc: 0.9818 - val_loss: 0.2508 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0286 - acc: 0.9818 - val_loss: 0.2546 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0278 - acc: 0.9818 - val_loss: 0.2542 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0275 - acc: 0.9818 - val_loss: 0.2550 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0268 - acc: 0.9818 - val_loss: 0.2550 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0266 - acc: 0.9818 - val_loss: 0.2587 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0259 - acc: 0.9818 - val_loss: 0.2556 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0257 - acc: 0.9818 - val_loss: 0.2566 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0254 - acc: 0.9818 - val_loss: 0.2599 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0253 - acc: 0.9818 - val_loss: 0.2663 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0247 - acc: 0.9818 - val_loss: 0.2617 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0246 - acc: 0.9818 - val_loss: 0.2615 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0248 - acc: 0.9818 - val_loss: 0.2619 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 35)                1365      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 14)                504       \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 1,884\n",
      "Trainable params: 1,884\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 2ms/step - loss: 0.2500 - acc: 0.5382 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.2495 - acc: 0.5418 - val_loss: 0.2493 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.2477 - acc: 0.5418 - val_loss: 0.2464 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.2410 - acc: 0.5709 - val_loss: 0.2377 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.2271 - acc: 0.6691 - val_loss: 0.2248 - val_acc: 0.6774\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.2086 - acc: 0.7236 - val_loss: 0.2147 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1912 - acc: 0.7236 - val_loss: 0.2054 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1787 - acc: 0.7600 - val_loss: 0.2075 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1690 - acc: 0.7564 - val_loss: 0.2071 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1658 - acc: 0.7818 - val_loss: 0.2122 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1603 - acc: 0.7818 - val_loss: 0.2083 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1583 - acc: 0.7964 - val_loss: 0.2171 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1550 - acc: 0.7855 - val_loss: 0.2166 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1536 - acc: 0.7927 - val_loss: 0.2148 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1514 - acc: 0.8036 - val_loss: 0.2210 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1496 - acc: 0.8036 - val_loss: 0.2193 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1485 - acc: 0.8000 - val_loss: 0.2263 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1474 - acc: 0.8218 - val_loss: 0.2242 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1451 - acc: 0.8145 - val_loss: 0.2251 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1443 - acc: 0.8145 - val_loss: 0.2263 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1424 - acc: 0.8218 - val_loss: 0.2260 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1406 - acc: 0.8255 - val_loss: 0.2299 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1392 - acc: 0.8255 - val_loss: 0.2280 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1377 - acc: 0.8291 - val_loss: 0.2307 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1358 - acc: 0.8327 - val_loss: 0.2312 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1338 - acc: 0.8364 - val_loss: 0.2287 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1324 - acc: 0.8400 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1309 - acc: 0.8400 - val_loss: 0.2326 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1287 - acc: 0.8473 - val_loss: 0.2312 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1276 - acc: 0.8291 - val_loss: 0.2314 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1250 - acc: 0.8509 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1232 - acc: 0.8473 - val_loss: 0.2334 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1212 - acc: 0.8545 - val_loss: 0.2342 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1204 - acc: 0.8509 - val_loss: 0.2310 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1166 - acc: 0.8618 - val_loss: 0.2356 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1147 - acc: 0.8655 - val_loss: 0.2363 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1124 - acc: 0.8800 - val_loss: 0.2377 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1093 - acc: 0.8764 - val_loss: 0.2376 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1075 - acc: 0.8727 - val_loss: 0.2382 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1033 - acc: 0.8982 - val_loss: 0.2392 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1010 - acc: 0.8909 - val_loss: 0.2367 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0983 - acc: 0.8909 - val_loss: 0.2405 - val_acc: 0.6452\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0954 - acc: 0.8945 - val_loss: 0.2420 - val_acc: 0.6452\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0911 - acc: 0.9055 - val_loss: 0.2420 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0898 - acc: 0.9055 - val_loss: 0.2456 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0868 - acc: 0.9055 - val_loss: 0.2456 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0841 - acc: 0.9236 - val_loss: 0.2447 - val_acc: 0.6129\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0822 - acc: 0.9200 - val_loss: 0.2539 - val_acc: 0.6129\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0791 - acc: 0.9345 - val_loss: 0.2521 - val_acc: 0.6129\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0773 - acc: 0.9309 - val_loss: 0.2480 - val_acc: 0.5806\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0739 - acc: 0.9418 - val_loss: 0.2543 - val_acc: 0.6452\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0716 - acc: 0.9455 - val_loss: 0.2557 - val_acc: 0.6129\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0698 - acc: 0.9455 - val_loss: 0.2617 - val_acc: 0.6129\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0682 - acc: 0.9491 - val_loss: 0.2601 - val_acc: 0.5806\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0681 - acc: 0.9455 - val_loss: 0.2646 - val_acc: 0.5806\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0653 - acc: 0.9382 - val_loss: 0.2624 - val_acc: 0.5806\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0615 - acc: 0.9491 - val_loss: 0.2636 - val_acc: 0.5484\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0599 - acc: 0.9527 - val_loss: 0.2635 - val_acc: 0.5484\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0560 - acc: 0.9491 - val_loss: 0.2611 - val_acc: 0.5484\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0542 - acc: 0.9564 - val_loss: 0.2707 - val_acc: 0.5484\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0547 - acc: 0.9491 - val_loss: 0.2703 - val_acc: 0.5806\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0494 - acc: 0.9636 - val_loss: 0.2660 - val_acc: 0.5806\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0486 - acc: 0.9636 - val_loss: 0.2767 - val_acc: 0.5806\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0457 - acc: 0.9600 - val_loss: 0.2743 - val_acc: 0.5806\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0439 - acc: 0.9636 - val_loss: 0.2707 - val_acc: 0.5161\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0419 - acc: 0.9709 - val_loss: 0.2703 - val_acc: 0.5806\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0405 - acc: 0.9709 - val_loss: 0.2714 - val_acc: 0.5161\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0377 - acc: 0.9673 - val_loss: 0.2734 - val_acc: 0.6129\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0370 - acc: 0.9745 - val_loss: 0.2743 - val_acc: 0.6129\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0343 - acc: 0.9818 - val_loss: 0.2893 - val_acc: 0.5806\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0327 - acc: 0.9818 - val_loss: 0.2765 - val_acc: 0.5806\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0305 - acc: 0.9745 - val_loss: 0.2856 - val_acc: 0.6129\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0286 - acc: 0.9855 - val_loss: 0.2895 - val_acc: 0.5806\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0268 - acc: 0.9855 - val_loss: 0.2933 - val_acc: 0.5806\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0250 - acc: 0.9891 - val_loss: 0.2991 - val_acc: 0.5161\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0247 - acc: 0.9891 - val_loss: 0.2973 - val_acc: 0.5484\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0229 - acc: 0.9891 - val_loss: 0.2963 - val_acc: 0.6129\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0226 - acc: 0.9891 - val_loss: 0.2971 - val_acc: 0.5806\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0210 - acc: 0.9891 - val_loss: 0.2914 - val_acc: 0.5484\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0202 - acc: 0.9891 - val_loss: 0.3013 - val_acc: 0.5484\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0194 - acc: 0.9891 - val_loss: 0.2986 - val_acc: 0.6129\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0192 - acc: 0.9891 - val_loss: 0.3072 - val_acc: 0.5484\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0187 - acc: 0.9891 - val_loss: 0.3062 - val_acc: 0.5484\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0182 - acc: 0.9891 - val_loss: 0.3049 - val_acc: 0.5806\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0169 - acc: 0.9891 - val_loss: 0.3050 - val_acc: 0.5484\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0160 - acc: 0.9891 - val_loss: 0.3067 - val_acc: 0.5806\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0155 - acc: 0.9891 - val_loss: 0.3157 - val_acc: 0.5484\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0148 - acc: 0.9891 - val_loss: 0.3201 - val_acc: 0.5806\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0135 - acc: 0.9891 - val_loss: 0.3144 - val_acc: 0.5806\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0120 - acc: 0.9927 - val_loss: 0.3098 - val_acc: 0.5484\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0106 - acc: 0.9964 - val_loss: 0.3116 - val_acc: 0.5484\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0107 - acc: 0.9964 - val_loss: 0.3098 - val_acc: 0.5484\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0097 - acc: 0.9964 - val_loss: 0.3087 - val_acc: 0.5806\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0096 - acc: 0.9964 - val_loss: 0.3058 - val_acc: 0.5806\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0089 - acc: 0.9964 - val_loss: 0.3147 - val_acc: 0.5806\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0084 - acc: 0.9964 - val_loss: 0.3074 - val_acc: 0.5484\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 167us/step - loss: 0.0082 - acc: 0.9964 - val_loss: 0.3135 - val_acc: 0.5806\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0078 - acc: 0.9964 - val_loss: 0.3129 - val_acc: 0.5806\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0076 - acc: 0.9964 - val_loss: 0.3156 - val_acc: 0.5806\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0073 - acc: 0.9964 - val_loss: 0.3095 - val_acc: 0.5806\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 23)                897       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 16)                384       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,298\n",
      "Trainable params: 1,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 2ms/step - loss: 0.2500 - acc: 0.4982 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2496 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.2486 - acc: 0.5418 - val_loss: 0.2481 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.2447 - acc: 0.5491 - val_loss: 0.2429 - val_acc: 0.6129\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.2351 - acc: 0.6145 - val_loss: 0.2336 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.2228 - acc: 0.6655 - val_loss: 0.2218 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.2052 - acc: 0.7309 - val_loss: 0.2147 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1922 - acc: 0.7455 - val_loss: 0.2057 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1794 - acc: 0.7564 - val_loss: 0.2055 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1718 - acc: 0.7564 - val_loss: 0.2046 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1665 - acc: 0.7564 - val_loss: 0.2036 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1634 - acc: 0.7673 - val_loss: 0.2098 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1597 - acc: 0.7709 - val_loss: 0.2124 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1581 - acc: 0.7709 - val_loss: 0.2100 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1563 - acc: 0.7927 - val_loss: 0.2180 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1551 - acc: 0.7891 - val_loss: 0.2211 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1557 - acc: 0.7964 - val_loss: 0.2228 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1529 - acc: 0.7927 - val_loss: 0.2197 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1518 - acc: 0.8000 - val_loss: 0.2268 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1507 - acc: 0.8036 - val_loss: 0.2253 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1496 - acc: 0.8000 - val_loss: 0.2252 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1485 - acc: 0.8073 - val_loss: 0.2262 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1474 - acc: 0.7964 - val_loss: 0.2275 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1482 - acc: 0.8073 - val_loss: 0.2287 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1462 - acc: 0.8000 - val_loss: 0.2324 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1443 - acc: 0.8109 - val_loss: 0.2282 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1433 - acc: 0.8145 - val_loss: 0.2323 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1430 - acc: 0.8182 - val_loss: 0.2331 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1414 - acc: 0.8218 - val_loss: 0.2358 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1406 - acc: 0.8182 - val_loss: 0.2375 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1394 - acc: 0.8218 - val_loss: 0.2389 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1388 - acc: 0.8291 - val_loss: 0.2380 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1371 - acc: 0.8145 - val_loss: 0.2375 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1363 - acc: 0.8109 - val_loss: 0.2411 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1349 - acc: 0.8291 - val_loss: 0.2416 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1332 - acc: 0.8364 - val_loss: 0.2402 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1328 - acc: 0.8218 - val_loss: 0.2412 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1308 - acc: 0.8327 - val_loss: 0.2400 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1292 - acc: 0.8255 - val_loss: 0.2413 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1282 - acc: 0.8436 - val_loss: 0.2464 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1273 - acc: 0.8436 - val_loss: 0.2433 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1253 - acc: 0.8509 - val_loss: 0.2450 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1243 - acc: 0.8509 - val_loss: 0.2433 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1229 - acc: 0.8582 - val_loss: 0.2465 - val_acc: 0.7097\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1205 - acc: 0.8509 - val_loss: 0.2475 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 215us/step - loss: 0.1191 - acc: 0.8655 - val_loss: 0.2473 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1176 - acc: 0.8618 - val_loss: 0.2473 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.1153 - acc: 0.8618 - val_loss: 0.2508 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1130 - acc: 0.8764 - val_loss: 0.2494 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1117 - acc: 0.8691 - val_loss: 0.2521 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1096 - acc: 0.8764 - val_loss: 0.2531 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1077 - acc: 0.8836 - val_loss: 0.2533 - val_acc: 0.6452\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1063 - acc: 0.8764 - val_loss: 0.2535 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1036 - acc: 0.8800 - val_loss: 0.2528 - val_acc: 0.6452\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1017 - acc: 0.9018 - val_loss: 0.2536 - val_acc: 0.6452\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1004 - acc: 0.9018 - val_loss: 0.2543 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0971 - acc: 0.8873 - val_loss: 0.2558 - val_acc: 0.6452\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0967 - acc: 0.8982 - val_loss: 0.2571 - val_acc: 0.6452\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0939 - acc: 0.9055 - val_loss: 0.2592 - val_acc: 0.6452\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0906 - acc: 0.9127 - val_loss: 0.2608 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0895 - acc: 0.9127 - val_loss: 0.2613 - val_acc: 0.6129\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0871 - acc: 0.9091 - val_loss: 0.2686 - val_acc: 0.6129\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0858 - acc: 0.9236 - val_loss: 0.2639 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0829 - acc: 0.9200 - val_loss: 0.2663 - val_acc: 0.6129\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0809 - acc: 0.9309 - val_loss: 0.2721 - val_acc: 0.6129\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0798 - acc: 0.9273 - val_loss: 0.2677 - val_acc: 0.6129\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0783 - acc: 0.9200 - val_loss: 0.2776 - val_acc: 0.6129\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0758 - acc: 0.9382 - val_loss: 0.2719 - val_acc: 0.5806\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0738 - acc: 0.9345 - val_loss: 0.2744 - val_acc: 0.5806\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0727 - acc: 0.9345 - val_loss: 0.2798 - val_acc: 0.6129\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0702 - acc: 0.9455 - val_loss: 0.2747 - val_acc: 0.5806\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0688 - acc: 0.9382 - val_loss: 0.2840 - val_acc: 0.5806\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0681 - acc: 0.9382 - val_loss: 0.2783 - val_acc: 0.5806\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0653 - acc: 0.9455 - val_loss: 0.2800 - val_acc: 0.5484\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0637 - acc: 0.9455 - val_loss: 0.2835 - val_acc: 0.5806\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0615 - acc: 0.9455 - val_loss: 0.2816 - val_acc: 0.5806\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0595 - acc: 0.9455 - val_loss: 0.2878 - val_acc: 0.5806\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0576 - acc: 0.9491 - val_loss: 0.2853 - val_acc: 0.5806\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0570 - acc: 0.9527 - val_loss: 0.2953 - val_acc: 0.5806\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0558 - acc: 0.9491 - val_loss: 0.2882 - val_acc: 0.5806\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0538 - acc: 0.9491 - val_loss: 0.2858 - val_acc: 0.5806\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0544 - acc: 0.9491 - val_loss: 0.2884 - val_acc: 0.5806\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0507 - acc: 0.9564 - val_loss: 0.2976 - val_acc: 0.5806\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0487 - acc: 0.9564 - val_loss: 0.2929 - val_acc: 0.5806\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0477 - acc: 0.9600 - val_loss: 0.2936 - val_acc: 0.5484\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0472 - acc: 0.9564 - val_loss: 0.2939 - val_acc: 0.5806\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0462 - acc: 0.9564 - val_loss: 0.2935 - val_acc: 0.5806\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0448 - acc: 0.9600 - val_loss: 0.2930 - val_acc: 0.5806\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0439 - acc: 0.9636 - val_loss: 0.2954 - val_acc: 0.5806\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0410 - acc: 0.9709 - val_loss: 0.2973 - val_acc: 0.5484\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0396 - acc: 0.9709 - val_loss: 0.3004 - val_acc: 0.5161\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0398 - acc: 0.9709 - val_loss: 0.2901 - val_acc: 0.5806\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0365 - acc: 0.9709 - val_loss: 0.2900 - val_acc: 0.5484\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0359 - acc: 0.9673 - val_loss: 0.2744 - val_acc: 0.5484\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0394 - acc: 0.9491 - val_loss: 0.2993 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0351 - acc: 0.9709 - val_loss: 0.2938 - val_acc: 0.5484\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0336 - acc: 0.9745 - val_loss: 0.2941 - val_acc: 0.5484\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0325 - acc: 0.9782 - val_loss: 0.2912 - val_acc: 0.5161\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0303 - acc: 0.9782 - val_loss: 0.2884 - val_acc: 0.5484\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0295 - acc: 0.9818 - val_loss: 0.2759 - val_acc: 0.5806\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 25)                975       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 17)                442       \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 18        \n",
      "=================================================================\n",
      "Total params: 1,435\n",
      "Trainable params: 1,435\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 2ms/step - loss: 0.2499 - acc: 0.5309 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2496 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.2490 - acc: 0.5418 - val_loss: 0.2485 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.2461 - acc: 0.5455 - val_loss: 0.2438 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.2372 - acc: 0.6291 - val_loss: 0.2346 - val_acc: 0.6452\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 170us/step - loss: 0.2223 - acc: 0.6982 - val_loss: 0.2221 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.2052 - acc: 0.7345 - val_loss: 0.2108 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1915 - acc: 0.7527 - val_loss: 0.2066 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1791 - acc: 0.7418 - val_loss: 0.2048 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1711 - acc: 0.7527 - val_loss: 0.2017 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1652 - acc: 0.7709 - val_loss: 0.2016 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1617 - acc: 0.7636 - val_loss: 0.2057 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1590 - acc: 0.7673 - val_loss: 0.2102 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1572 - acc: 0.7818 - val_loss: 0.2122 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1555 - acc: 0.7818 - val_loss: 0.2123 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1538 - acc: 0.7855 - val_loss: 0.2137 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1524 - acc: 0.8000 - val_loss: 0.2120 - val_acc: 0.7419\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1516 - acc: 0.7891 - val_loss: 0.2200 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1493 - acc: 0.8073 - val_loss: 0.2172 - val_acc: 0.7419\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1474 - acc: 0.8182 - val_loss: 0.2184 - val_acc: 0.7419\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1455 - acc: 0.8145 - val_loss: 0.2203 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1444 - acc: 0.8109 - val_loss: 0.2191 - val_acc: 0.7419\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1430 - acc: 0.8255 - val_loss: 0.2203 - val_acc: 0.7419\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1415 - acc: 0.8400 - val_loss: 0.2213 - val_acc: 0.7419\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1402 - acc: 0.8327 - val_loss: 0.2223 - val_acc: 0.7419\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1396 - acc: 0.8291 - val_loss: 0.2209 - val_acc: 0.7419\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1376 - acc: 0.8291 - val_loss: 0.2228 - val_acc: 0.7419\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1367 - acc: 0.8327 - val_loss: 0.2236 - val_acc: 0.7419\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1351 - acc: 0.8291 - val_loss: 0.2213 - val_acc: 0.7419\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1344 - acc: 0.8327 - val_loss: 0.2225 - val_acc: 0.7419\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1325 - acc: 0.8400 - val_loss: 0.2225 - val_acc: 0.7419\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1313 - acc: 0.8364 - val_loss: 0.2241 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1300 - acc: 0.8400 - val_loss: 0.2228 - val_acc: 0.7419\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1286 - acc: 0.8400 - val_loss: 0.2246 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1270 - acc: 0.8436 - val_loss: 0.2235 - val_acc: 0.7419\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1258 - acc: 0.8436 - val_loss: 0.2233 - val_acc: 0.7419\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1240 - acc: 0.8436 - val_loss: 0.2241 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1220 - acc: 0.8473 - val_loss: 0.2260 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1206 - acc: 0.8509 - val_loss: 0.2247 - val_acc: 0.7419\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1190 - acc: 0.8618 - val_loss: 0.2264 - val_acc: 0.7419\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1178 - acc: 0.8582 - val_loss: 0.2272 - val_acc: 0.7419\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1158 - acc: 0.8582 - val_loss: 0.2293 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1154 - acc: 0.8655 - val_loss: 0.2285 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1119 - acc: 0.8691 - val_loss: 0.2273 - val_acc: 0.7097\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1113 - acc: 0.8727 - val_loss: 0.2309 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1079 - acc: 0.8691 - val_loss: 0.2290 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1055 - acc: 0.8764 - val_loss: 0.2334 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.1033 - acc: 0.8800 - val_loss: 0.2339 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1014 - acc: 0.8945 - val_loss: 0.2361 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0999 - acc: 0.8873 - val_loss: 0.2341 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0960 - acc: 0.9055 - val_loss: 0.2372 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0940 - acc: 0.8945 - val_loss: 0.2380 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0917 - acc: 0.9018 - val_loss: 0.2413 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0889 - acc: 0.9127 - val_loss: 0.2432 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 215us/step - loss: 0.0894 - acc: 0.9018 - val_loss: 0.2424 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0842 - acc: 0.9273 - val_loss: 0.2413 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0818 - acc: 0.9273 - val_loss: 0.2439 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0801 - acc: 0.9309 - val_loss: 0.2463 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0789 - acc: 0.9382 - val_loss: 0.2481 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0747 - acc: 0.9455 - val_loss: 0.2467 - val_acc: 0.7097\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0731 - acc: 0.9382 - val_loss: 0.2479 - val_acc: 0.7097\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0726 - acc: 0.9491 - val_loss: 0.2480 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0689 - acc: 0.9527 - val_loss: 0.2469 - val_acc: 0.7097\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0667 - acc: 0.9527 - val_loss: 0.2499 - val_acc: 0.7097\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0651 - acc: 0.9527 - val_loss: 0.2456 - val_acc: 0.7097\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 164us/step - loss: 0.0631 - acc: 0.9527 - val_loss: 0.2493 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0616 - acc: 0.9564 - val_loss: 0.2462 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0601 - acc: 0.9527 - val_loss: 0.2464 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0577 - acc: 0.9564 - val_loss: 0.2435 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0588 - acc: 0.9527 - val_loss: 0.2432 - val_acc: 0.7097\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0556 - acc: 0.9564 - val_loss: 0.2424 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0535 - acc: 0.9564 - val_loss: 0.2407 - val_acc: 0.7097\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0511 - acc: 0.9600 - val_loss: 0.2376 - val_acc: 0.7097\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0502 - acc: 0.9600 - val_loss: 0.2332 - val_acc: 0.7097\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0487 - acc: 0.9600 - val_loss: 0.2293 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0468 - acc: 0.9600 - val_loss: 0.2215 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0464 - acc: 0.9600 - val_loss: 0.2260 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0446 - acc: 0.9600 - val_loss: 0.2235 - val_acc: 0.7097\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0424 - acc: 0.9636 - val_loss: 0.2237 - val_acc: 0.7097\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0410 - acc: 0.9636 - val_loss: 0.2211 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0395 - acc: 0.9636 - val_loss: 0.2169 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0382 - acc: 0.9673 - val_loss: 0.2159 - val_acc: 0.7097\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0360 - acc: 0.9709 - val_loss: 0.2193 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0348 - acc: 0.9709 - val_loss: 0.2182 - val_acc: 0.7097\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0335 - acc: 0.9709 - val_loss: 0.2202 - val_acc: 0.7097\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0324 - acc: 0.9745 - val_loss: 0.2200 - val_acc: 0.7097\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0312 - acc: 0.9745 - val_loss: 0.2196 - val_acc: 0.7097\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0303 - acc: 0.9745 - val_loss: 0.2192 - val_acc: 0.7097\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0297 - acc: 0.9745 - val_loss: 0.2200 - val_acc: 0.7097\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0292 - acc: 0.9745 - val_loss: 0.2193 - val_acc: 0.7097\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0284 - acc: 0.9782 - val_loss: 0.2216 - val_acc: 0.7097\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0278 - acc: 0.9782 - val_loss: 0.2232 - val_acc: 0.7097\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0271 - acc: 0.9782 - val_loss: 0.2245 - val_acc: 0.7097\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0267 - acc: 0.9782 - val_loss: 0.2230 - val_acc: 0.7097\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0258 - acc: 0.9782 - val_loss: 0.2267 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0251 - acc: 0.9818 - val_loss: 0.2219 - val_acc: 0.7097\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0243 - acc: 0.9818 - val_loss: 0.2237 - val_acc: 0.7097\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0239 - acc: 0.9818 - val_loss: 0.2266 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0235 - acc: 0.9818 - val_loss: 0.2303 - val_acc: 0.7097\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0230 - acc: 0.9818 - val_loss: 0.2263 - val_acc: 0.7097\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 50)                1950      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,471\n",
      "Trainable params: 2,471\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 3ms/step - loss: 0.2500 - acc: 0.5455 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.2495 - acc: 0.5418 - val_loss: 0.2493 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.2482 - acc: 0.5564 - val_loss: 0.2468 - val_acc: 0.6129\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.2435 - acc: 0.6000 - val_loss: 0.2396 - val_acc: 0.7097\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.2314 - acc: 0.7164 - val_loss: 0.2277 - val_acc: 0.6129\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.2138 - acc: 0.7236 - val_loss: 0.2157 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1961 - acc: 0.7273 - val_loss: 0.2068 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1823 - acc: 0.7345 - val_loss: 0.2012 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1723 - acc: 0.7527 - val_loss: 0.2014 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1670 - acc: 0.7709 - val_loss: 0.2059 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1610 - acc: 0.7636 - val_loss: 0.2096 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1588 - acc: 0.7673 - val_loss: 0.2083 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1558 - acc: 0.7782 - val_loss: 0.2142 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1544 - acc: 0.7927 - val_loss: 0.2151 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1522 - acc: 0.7964 - val_loss: 0.2141 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1503 - acc: 0.7964 - val_loss: 0.2142 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1481 - acc: 0.8000 - val_loss: 0.2150 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1469 - acc: 0.7927 - val_loss: 0.2127 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1445 - acc: 0.8109 - val_loss: 0.2183 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1427 - acc: 0.8073 - val_loss: 0.2155 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1404 - acc: 0.8182 - val_loss: 0.2201 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1402 - acc: 0.8255 - val_loss: 0.2207 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1375 - acc: 0.8255 - val_loss: 0.2215 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1345 - acc: 0.8255 - val_loss: 0.2243 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1327 - acc: 0.8291 - val_loss: 0.2255 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1300 - acc: 0.8327 - val_loss: 0.2254 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1279 - acc: 0.8364 - val_loss: 0.2271 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1267 - acc: 0.8545 - val_loss: 0.2252 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1238 - acc: 0.8545 - val_loss: 0.2278 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1210 - acc: 0.8618 - val_loss: 0.2259 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1180 - acc: 0.8691 - val_loss: 0.2279 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1165 - acc: 0.8655 - val_loss: 0.2307 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1133 - acc: 0.8836 - val_loss: 0.2297 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1123 - acc: 0.8764 - val_loss: 0.2315 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.1079 - acc: 0.8836 - val_loss: 0.2324 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1060 - acc: 0.8836 - val_loss: 0.2305 - val_acc: 0.6452\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1032 - acc: 0.8836 - val_loss: 0.2358 - val_acc: 0.6452\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0999 - acc: 0.8873 - val_loss: 0.2363 - val_acc: 0.6452\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0971 - acc: 0.8945 - val_loss: 0.2373 - val_acc: 0.6452\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0952 - acc: 0.8836 - val_loss: 0.2367 - val_acc: 0.6452\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0921 - acc: 0.9091 - val_loss: 0.2355 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0887 - acc: 0.9127 - val_loss: 0.2372 - val_acc: 0.6452\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0860 - acc: 0.9091 - val_loss: 0.2386 - val_acc: 0.6452\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0844 - acc: 0.9200 - val_loss: 0.2414 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0803 - acc: 0.9236 - val_loss: 0.2409 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0781 - acc: 0.9236 - val_loss: 0.2432 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.0763 - acc: 0.9273 - val_loss: 0.2436 - val_acc: 0.6452\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0719 - acc: 0.9382 - val_loss: 0.2472 - val_acc: 0.6452\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0701 - acc: 0.9345 - val_loss: 0.2520 - val_acc: 0.6452\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0675 - acc: 0.9382 - val_loss: 0.2456 - val_acc: 0.6129\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0681 - acc: 0.9345 - val_loss: 0.2529 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0657 - acc: 0.9345 - val_loss: 0.2555 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0621 - acc: 0.9418 - val_loss: 0.2496 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0594 - acc: 0.9527 - val_loss: 0.2515 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0572 - acc: 0.9564 - val_loss: 0.2517 - val_acc: 0.6452\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0554 - acc: 0.9564 - val_loss: 0.2541 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0535 - acc: 0.9636 - val_loss: 0.2555 - val_acc: 0.6452\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0521 - acc: 0.9600 - val_loss: 0.2497 - val_acc: 0.6452\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0515 - acc: 0.9527 - val_loss: 0.2606 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0497 - acc: 0.9600 - val_loss: 0.2622 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0458 - acc: 0.9673 - val_loss: 0.2566 - val_acc: 0.6129\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0445 - acc: 0.9673 - val_loss: 0.2524 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0421 - acc: 0.9709 - val_loss: 0.2522 - val_acc: 0.6129\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0401 - acc: 0.9709 - val_loss: 0.2573 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0390 - acc: 0.9709 - val_loss: 0.2582 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0370 - acc: 0.9745 - val_loss: 0.2603 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0354 - acc: 0.9782 - val_loss: 0.2641 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0339 - acc: 0.9782 - val_loss: 0.2627 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0326 - acc: 0.9745 - val_loss: 0.2602 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0311 - acc: 0.9782 - val_loss: 0.2655 - val_acc: 0.6129\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 276us/step - loss: 0.0306 - acc: 0.9782 - val_loss: 0.2629 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.0282 - acc: 0.9782 - val_loss: 0.2610 - val_acc: 0.5806\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.0272 - acc: 0.9745 - val_loss: 0.2698 - val_acc: 0.6129\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.0249 - acc: 0.9855 - val_loss: 0.2748 - val_acc: 0.6129\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.0225 - acc: 0.9818 - val_loss: 0.2699 - val_acc: 0.6452\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0218 - acc: 0.9891 - val_loss: 0.2821 - val_acc: 0.5806\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0195 - acc: 0.9891 - val_loss: 0.2747 - val_acc: 0.6129\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0182 - acc: 0.9927 - val_loss: 0.2804 - val_acc: 0.5806\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0170 - acc: 0.9927 - val_loss: 0.2763 - val_acc: 0.6129\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0162 - acc: 0.9927 - val_loss: 0.2752 - val_acc: 0.6774\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 220us/step - loss: 0.0153 - acc: 0.9927 - val_loss: 0.2781 - val_acc: 0.6129\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0146 - acc: 0.9927 - val_loss: 0.2806 - val_acc: 0.5806\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.0139 - acc: 0.9927 - val_loss: 0.2812 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0134 - acc: 0.9927 - val_loss: 0.2820 - val_acc: 0.5806\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0128 - acc: 0.9927 - val_loss: 0.2851 - val_acc: 0.6129\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0124 - acc: 0.9927 - val_loss: 0.2819 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.0122 - acc: 0.9927 - val_loss: 0.2815 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.0118 - acc: 0.9927 - val_loss: 0.2831 - val_acc: 0.6129\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0109 - acc: 0.9927 - val_loss: 0.2695 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.0100 - acc: 0.9927 - val_loss: 0.2684 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.0093 - acc: 0.9964 - val_loss: 0.2722 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0090 - acc: 0.9964 - val_loss: 0.2821 - val_acc: 0.6129\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0085 - acc: 0.9964 - val_loss: 0.2802 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0079 - acc: 0.9964 - val_loss: 0.2828 - val_acc: 0.6129\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0076 - acc: 0.9964 - val_loss: 0.2819 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0074 - acc: 0.9964 - val_loss: 0.2760 - val_acc: 0.6129\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0071 - acc: 0.9964 - val_loss: 0.2857 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0066 - acc: 0.9964 - val_loss: 0.2801 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0065 - acc: 0.9964 - val_loss: 0.2898 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0063 - acc: 0.9964 - val_loss: 0.2833 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 15)                585       \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 17)                272       \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 18        \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 3ms/step - loss: 0.2501 - acc: 0.4618 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.2488 - acc: 0.5418 - val_loss: 0.2484 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.2458 - acc: 0.5455 - val_loss: 0.2439 - val_acc: 0.5806\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.2382 - acc: 0.6255 - val_loss: 0.2350 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.2258 - acc: 0.6509 - val_loss: 0.2229 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.2100 - acc: 0.7091 - val_loss: 0.2181 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1963 - acc: 0.7309 - val_loss: 0.2081 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1860 - acc: 0.7382 - val_loss: 0.2082 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1780 - acc: 0.7491 - val_loss: 0.2079 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1721 - acc: 0.7455 - val_loss: 0.2055 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1695 - acc: 0.7527 - val_loss: 0.2099 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1659 - acc: 0.7636 - val_loss: 0.2110 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1668 - acc: 0.7745 - val_loss: 0.2175 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1639 - acc: 0.7636 - val_loss: 0.2115 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1584 - acc: 0.7782 - val_loss: 0.2222 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1600 - acc: 0.7745 - val_loss: 0.2212 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1573 - acc: 0.7891 - val_loss: 0.2231 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1561 - acc: 0.7927 - val_loss: 0.2246 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1542 - acc: 0.7891 - val_loss: 0.2295 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1535 - acc: 0.7818 - val_loss: 0.2294 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1525 - acc: 0.7855 - val_loss: 0.2301 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1515 - acc: 0.7927 - val_loss: 0.2328 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1523 - acc: 0.7891 - val_loss: 0.2344 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1509 - acc: 0.7927 - val_loss: 0.2367 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1496 - acc: 0.8109 - val_loss: 0.2365 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1489 - acc: 0.8073 - val_loss: 0.2392 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1479 - acc: 0.8036 - val_loss: 0.2385 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1486 - acc: 0.8073 - val_loss: 0.2407 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1461 - acc: 0.8109 - val_loss: 0.2392 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1455 - acc: 0.8182 - val_loss: 0.2411 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1452 - acc: 0.8109 - val_loss: 0.2383 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1445 - acc: 0.8145 - val_loss: 0.2415 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1432 - acc: 0.8218 - val_loss: 0.2423 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1427 - acc: 0.8109 - val_loss: 0.2420 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1414 - acc: 0.8182 - val_loss: 0.2441 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1408 - acc: 0.8145 - val_loss: 0.2416 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1405 - acc: 0.8182 - val_loss: 0.2453 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1392 - acc: 0.8182 - val_loss: 0.2434 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1382 - acc: 0.8218 - val_loss: 0.2420 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.1379 - acc: 0.8182 - val_loss: 0.2424 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.1368 - acc: 0.8255 - val_loss: 0.2424 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1354 - acc: 0.8327 - val_loss: 0.2430 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1355 - acc: 0.8255 - val_loss: 0.2422 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1336 - acc: 0.8291 - val_loss: 0.2451 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1333 - acc: 0.8291 - val_loss: 0.2445 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1327 - acc: 0.8364 - val_loss: 0.2443 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.1309 - acc: 0.8327 - val_loss: 0.2463 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1299 - acc: 0.8327 - val_loss: 0.2445 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1296 - acc: 0.8364 - val_loss: 0.2468 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1288 - acc: 0.8364 - val_loss: 0.2472 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.1276 - acc: 0.8364 - val_loss: 0.2473 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1275 - acc: 0.8545 - val_loss: 0.2475 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1258 - acc: 0.8436 - val_loss: 0.2464 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1248 - acc: 0.8582 - val_loss: 0.2456 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.1241 - acc: 0.8618 - val_loss: 0.2480 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.1216 - acc: 0.8545 - val_loss: 0.2456 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.1204 - acc: 0.8582 - val_loss: 0.2466 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.1198 - acc: 0.8618 - val_loss: 0.2477 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1191 - acc: 0.8618 - val_loss: 0.2473 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1175 - acc: 0.8691 - val_loss: 0.2469 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1166 - acc: 0.8836 - val_loss: 0.2481 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1151 - acc: 0.8655 - val_loss: 0.2462 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1137 - acc: 0.8873 - val_loss: 0.2456 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1132 - acc: 0.8800 - val_loss: 0.2441 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1111 - acc: 0.8836 - val_loss: 0.2450 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1098 - acc: 0.8873 - val_loss: 0.2450 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1093 - acc: 0.8873 - val_loss: 0.2451 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.1072 - acc: 0.8982 - val_loss: 0.2468 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.1058 - acc: 0.8982 - val_loss: 0.2473 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1040 - acc: 0.8982 - val_loss: 0.2481 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1029 - acc: 0.9018 - val_loss: 0.2460 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1010 - acc: 0.9018 - val_loss: 0.2435 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1025 - acc: 0.8945 - val_loss: 0.2456 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0979 - acc: 0.9055 - val_loss: 0.2474 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0961 - acc: 0.9091 - val_loss: 0.2438 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0942 - acc: 0.9055 - val_loss: 0.2436 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0930 - acc: 0.8982 - val_loss: 0.2482 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0936 - acc: 0.8945 - val_loss: 0.2471 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0884 - acc: 0.9127 - val_loss: 0.2441 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0864 - acc: 0.9127 - val_loss: 0.2422 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.0858 - acc: 0.9127 - val_loss: 0.2443 - val_acc: 0.7097\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0826 - acc: 0.9164 - val_loss: 0.2444 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0815 - acc: 0.9164 - val_loss: 0.2473 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0809 - acc: 0.9200 - val_loss: 0.2499 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0784 - acc: 0.9200 - val_loss: 0.2473 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.0746 - acc: 0.9273 - val_loss: 0.2479 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.0731 - acc: 0.9309 - val_loss: 0.2544 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0720 - acc: 0.9273 - val_loss: 0.2501 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0709 - acc: 0.9382 - val_loss: 0.2400 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0676 - acc: 0.9491 - val_loss: 0.2508 - val_acc: 0.6129\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0659 - acc: 0.9455 - val_loss: 0.2474 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0646 - acc: 0.9418 - val_loss: 0.2580 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0623 - acc: 0.9491 - val_loss: 0.2429 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0620 - acc: 0.9455 - val_loss: 0.2471 - val_acc: 0.6774\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 166us/step - loss: 0.0593 - acc: 0.9455 - val_loss: 0.2531 - val_acc: 0.5806\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.0573 - acc: 0.9491 - val_loss: 0.2532 - val_acc: 0.6129\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0554 - acc: 0.9564 - val_loss: 0.2565 - val_acc: 0.6129\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0529 - acc: 0.9564 - val_loss: 0.2496 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0531 - acc: 0.9564 - val_loss: 0.2505 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 26)                1014      \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 19)                513       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 20        \n",
      "=================================================================\n",
      "Total params: 1,547\n",
      "Trainable params: 1,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 3ms/step - loss: 0.2499 - acc: 0.5345 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.2495 - acc: 0.5418 - val_loss: 0.2495 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.2482 - acc: 0.5418 - val_loss: 0.2477 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.2432 - acc: 0.5455 - val_loss: 0.2419 - val_acc: 0.5484\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.2322 - acc: 0.6073 - val_loss: 0.2319 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.2167 - acc: 0.6945 - val_loss: 0.2241 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 323us/step - loss: 0.2012 - acc: 0.7127 - val_loss: 0.2150 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 311us/step - loss: 0.1857 - acc: 0.7418 - val_loss: 0.2117 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1762 - acc: 0.7527 - val_loss: 0.2123 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1686 - acc: 0.7745 - val_loss: 0.2140 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1631 - acc: 0.7709 - val_loss: 0.2098 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1600 - acc: 0.7782 - val_loss: 0.2141 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.1565 - acc: 0.7745 - val_loss: 0.2157 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.1576 - acc: 0.7927 - val_loss: 0.2188 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.1524 - acc: 0.7964 - val_loss: 0.2205 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1494 - acc: 0.8182 - val_loss: 0.2214 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1477 - acc: 0.8109 - val_loss: 0.2204 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1457 - acc: 0.8145 - val_loss: 0.2242 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1436 - acc: 0.8109 - val_loss: 0.2259 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.1418 - acc: 0.8291 - val_loss: 0.2244 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1390 - acc: 0.8327 - val_loss: 0.2263 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1377 - acc: 0.8327 - val_loss: 0.2300 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1355 - acc: 0.8400 - val_loss: 0.2299 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1332 - acc: 0.8473 - val_loss: 0.2267 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 262us/step - loss: 0.1309 - acc: 0.8436 - val_loss: 0.2259 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 305us/step - loss: 0.1289 - acc: 0.8473 - val_loss: 0.2285 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.1285 - acc: 0.8473 - val_loss: 0.2291 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1252 - acc: 0.8545 - val_loss: 0.2283 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1216 - acc: 0.8618 - val_loss: 0.2303 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1196 - acc: 0.8618 - val_loss: 0.2299 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 278us/step - loss: 0.1163 - acc: 0.8691 - val_loss: 0.2310 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.1139 - acc: 0.8691 - val_loss: 0.2289 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.1109 - acc: 0.8764 - val_loss: 0.2274 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 296us/step - loss: 0.1075 - acc: 0.8764 - val_loss: 0.2300 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 319us/step - loss: 0.1049 - acc: 0.8836 - val_loss: 0.2303 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 312us/step - loss: 0.1012 - acc: 0.8873 - val_loss: 0.2337 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 306us/step - loss: 0.0978 - acc: 0.8909 - val_loss: 0.2389 - val_acc: 0.6452\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 317us/step - loss: 0.0952 - acc: 0.9055 - val_loss: 0.2373 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 297us/step - loss: 0.0914 - acc: 0.9018 - val_loss: 0.2429 - val_acc: 0.6129\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 280us/step - loss: 0.0878 - acc: 0.9055 - val_loss: 0.2463 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.0842 - acc: 0.9091 - val_loss: 0.2472 - val_acc: 0.6129\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.0831 - acc: 0.9164 - val_loss: 0.2478 - val_acc: 0.6452\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0793 - acc: 0.9200 - val_loss: 0.2562 - val_acc: 0.6129\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0754 - acc: 0.9200 - val_loss: 0.2569 - val_acc: 0.6129\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.0726 - acc: 0.9273 - val_loss: 0.2581 - val_acc: 0.5484\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.0697 - acc: 0.9345 - val_loss: 0.2661 - val_acc: 0.5806\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.0669 - acc: 0.9345 - val_loss: 0.2643 - val_acc: 0.5484\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.0634 - acc: 0.9527 - val_loss: 0.2669 - val_acc: 0.5806\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.0601 - acc: 0.9382 - val_loss: 0.2757 - val_acc: 0.5806\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 261us/step - loss: 0.0571 - acc: 0.9455 - val_loss: 0.2769 - val_acc: 0.5806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0535 - acc: 0.9527 - val_loss: 0.2807 - val_acc: 0.5484\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.0497 - acc: 0.9673 - val_loss: 0.2797 - val_acc: 0.5806\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.0477 - acc: 0.9709 - val_loss: 0.2846 - val_acc: 0.5161\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.0455 - acc: 0.9782 - val_loss: 0.2828 - val_acc: 0.5161\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.0410 - acc: 0.9782 - val_loss: 0.2896 - val_acc: 0.5806\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0389 - acc: 0.9818 - val_loss: 0.2918 - val_acc: 0.5161\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.0365 - acc: 0.9855 - val_loss: 0.2923 - val_acc: 0.5161\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0350 - acc: 0.9818 - val_loss: 0.2929 - val_acc: 0.5806\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 300us/step - loss: 0.0321 - acc: 0.9855 - val_loss: 0.2985 - val_acc: 0.5161\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 278us/step - loss: 0.0300 - acc: 0.9855 - val_loss: 0.2986 - val_acc: 0.5161\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0279 - acc: 0.9855 - val_loss: 0.2961 - val_acc: 0.5806\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0269 - acc: 0.9855 - val_loss: 0.2988 - val_acc: 0.5161\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0245 - acc: 0.9855 - val_loss: 0.2947 - val_acc: 0.5484\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.0232 - acc: 0.9891 - val_loss: 0.3042 - val_acc: 0.5161\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 300us/step - loss: 0.0219 - acc: 0.9927 - val_loss: 0.2986 - val_acc: 0.5806\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 311us/step - loss: 0.0201 - acc: 0.9927 - val_loss: 0.3003 - val_acc: 0.5161\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 312us/step - loss: 0.0185 - acc: 0.9927 - val_loss: 0.3034 - val_acc: 0.5806\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0179 - acc: 0.9927 - val_loss: 0.3053 - val_acc: 0.5484\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.0164 - acc: 0.9927 - val_loss: 0.3038 - val_acc: 0.5161\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0159 - acc: 0.9927 - val_loss: 0.3135 - val_acc: 0.5161\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0144 - acc: 0.9927 - val_loss: 0.3065 - val_acc: 0.5484\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0135 - acc: 0.9927 - val_loss: 0.3103 - val_acc: 0.5806\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0132 - acc: 0.9927 - val_loss: 0.3111 - val_acc: 0.5806\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 214us/step - loss: 0.0132 - acc: 0.9927 - val_loss: 0.3114 - val_acc: 0.5161\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.0126 - acc: 0.9964 - val_loss: 0.3132 - val_acc: 0.5161\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 293us/step - loss: 0.0111 - acc: 0.9964 - val_loss: 0.3155 - val_acc: 0.5161\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.0105 - acc: 0.9964 - val_loss: 0.3184 - val_acc: 0.5484\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0100 - acc: 0.9964 - val_loss: 0.3161 - val_acc: 0.5484\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0092 - acc: 0.9964 - val_loss: 0.3204 - val_acc: 0.5161\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0089 - acc: 0.9964 - val_loss: 0.3207 - val_acc: 0.5161\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0085 - acc: 0.9964 - val_loss: 0.3201 - val_acc: 0.5806\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0082 - acc: 0.9964 - val_loss: 0.3225 - val_acc: 0.5484\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0080 - acc: 0.9964 - val_loss: 0.3239 - val_acc: 0.5484\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0077 - acc: 0.9964 - val_loss: 0.3205 - val_acc: 0.5806\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0076 - acc: 0.9964 - val_loss: 0.3234 - val_acc: 0.5161\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.0073 - acc: 0.9964 - val_loss: 0.3225 - val_acc: 0.5161\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 261us/step - loss: 0.0072 - acc: 0.9964 - val_loss: 0.3243 - val_acc: 0.5806\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0070 - acc: 0.9964 - val_loss: 0.3249 - val_acc: 0.5161\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0068 - acc: 0.9964 - val_loss: 0.3251 - val_acc: 0.5161\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0066 - acc: 0.9964 - val_loss: 0.3247 - val_acc: 0.5161\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0065 - acc: 0.9964 - val_loss: 0.3238 - val_acc: 0.5484\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0063 - acc: 0.9964 - val_loss: 0.3254 - val_acc: 0.5161\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0062 - acc: 0.9964 - val_loss: 0.3272 - val_acc: 0.5161\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.0060 - acc: 0.9964 - val_loss: 0.3259 - val_acc: 0.5484\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0060 - acc: 0.9964 - val_loss: 0.3275 - val_acc: 0.5484\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.0059 - acc: 0.9964 - val_loss: 0.3274 - val_acc: 0.5161\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0058 - acc: 0.9964 - val_loss: 0.3281 - val_acc: 0.5806\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0056 - acc: 0.9964 - val_loss: 0.3293 - val_acc: 0.5161\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0056 - acc: 0.9964 - val_loss: 0.3310 - val_acc: 0.5484\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.3277 - val_acc: 0.5806\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 40)                1560      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 18)                738       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 2,317\n",
      "Trainable params: 2,317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 3ms/step - loss: 0.2499 - acc: 0.5418 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.2494 - acc: 0.5418 - val_loss: 0.2488 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.2471 - acc: 0.5418 - val_loss: 0.2453 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.2389 - acc: 0.5891 - val_loss: 0.2361 - val_acc: 0.6452\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 230us/step - loss: 0.2234 - acc: 0.6582 - val_loss: 0.2247 - val_acc: 0.5806\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.2066 - acc: 0.7345 - val_loss: 0.2160 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1925 - acc: 0.7200 - val_loss: 0.2134 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.1795 - acc: 0.7455 - val_loss: 0.2071 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1707 - acc: 0.7818 - val_loss: 0.2093 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1646 - acc: 0.7709 - val_loss: 0.2114 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.1595 - acc: 0.7818 - val_loss: 0.2191 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1561 - acc: 0.7745 - val_loss: 0.2195 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1523 - acc: 0.8000 - val_loss: 0.2204 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.1501 - acc: 0.8000 - val_loss: 0.2192 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1478 - acc: 0.8182 - val_loss: 0.2267 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1454 - acc: 0.8036 - val_loss: 0.2271 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1416 - acc: 0.8145 - val_loss: 0.2270 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1403 - acc: 0.8218 - val_loss: 0.2253 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1368 - acc: 0.8291 - val_loss: 0.2259 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1351 - acc: 0.8400 - val_loss: 0.2273 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1331 - acc: 0.8436 - val_loss: 0.2237 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1311 - acc: 0.8400 - val_loss: 0.2267 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1289 - acc: 0.8509 - val_loss: 0.2286 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1250 - acc: 0.8545 - val_loss: 0.2255 - val_acc: 0.7419\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1228 - acc: 0.8655 - val_loss: 0.2259 - val_acc: 0.7419\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1199 - acc: 0.8727 - val_loss: 0.2242 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1178 - acc: 0.8655 - val_loss: 0.2201 - val_acc: 0.7419\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1148 - acc: 0.8836 - val_loss: 0.2229 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1109 - acc: 0.8800 - val_loss: 0.2232 - val_acc: 0.7419\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1087 - acc: 0.8873 - val_loss: 0.2227 - val_acc: 0.7419\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1054 - acc: 0.8982 - val_loss: 0.2170 - val_acc: 0.7419\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1015 - acc: 0.9018 - val_loss: 0.2167 - val_acc: 0.7419\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0980 - acc: 0.9055 - val_loss: 0.2155 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0962 - acc: 0.9091 - val_loss: 0.2177 - val_acc: 0.7419\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0927 - acc: 0.9055 - val_loss: 0.2131 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0877 - acc: 0.9091 - val_loss: 0.2153 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0846 - acc: 0.9127 - val_loss: 0.2145 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0814 - acc: 0.9164 - val_loss: 0.2130 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0777 - acc: 0.9236 - val_loss: 0.2131 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0738 - acc: 0.9345 - val_loss: 0.2134 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0748 - acc: 0.9236 - val_loss: 0.2124 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0692 - acc: 0.9345 - val_loss: 0.2128 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0638 - acc: 0.9455 - val_loss: 0.2109 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0606 - acc: 0.9491 - val_loss: 0.2085 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0564 - acc: 0.9491 - val_loss: 0.2042 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0529 - acc: 0.9491 - val_loss: 0.2047 - val_acc: 0.7419\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0506 - acc: 0.9600 - val_loss: 0.2067 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0487 - acc: 0.9600 - val_loss: 0.2061 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0444 - acc: 0.9636 - val_loss: 0.2013 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0435 - acc: 0.9673 - val_loss: 0.2030 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0417 - acc: 0.9709 - val_loss: 0.2116 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0389 - acc: 0.9745 - val_loss: 0.2104 - val_acc: 0.7419\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0371 - acc: 0.9745 - val_loss: 0.2123 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0353 - acc: 0.9745 - val_loss: 0.2096 - val_acc: 0.7419\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0336 - acc: 0.9745 - val_loss: 0.2111 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0320 - acc: 0.9745 - val_loss: 0.2082 - val_acc: 0.7419\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.0299 - acc: 0.9782 - val_loss: 0.2088 - val_acc: 0.7419\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0276 - acc: 0.9818 - val_loss: 0.2126 - val_acc: 0.7419\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0260 - acc: 0.9818 - val_loss: 0.2078 - val_acc: 0.7097\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0239 - acc: 0.9818 - val_loss: 0.2144 - val_acc: 0.7097\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0217 - acc: 0.9818 - val_loss: 0.2142 - val_acc: 0.7419\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0208 - acc: 0.9818 - val_loss: 0.2162 - val_acc: 0.7419\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0195 - acc: 0.9855 - val_loss: 0.2212 - val_acc: 0.7097\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0185 - acc: 0.9891 - val_loss: 0.2157 - val_acc: 0.7419\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 253us/step - loss: 0.0171 - acc: 0.9891 - val_loss: 0.2183 - val_acc: 0.7097\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 268us/step - loss: 0.0163 - acc: 0.9891 - val_loss: 0.2246 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.0160 - acc: 0.9891 - val_loss: 0.2239 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0155 - acc: 0.9891 - val_loss: 0.2228 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 276us/step - loss: 0.0144 - acc: 0.9891 - val_loss: 0.2213 - val_acc: 0.7419\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0131 - acc: 0.9891 - val_loss: 0.2085 - val_acc: 0.7419\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0125 - acc: 0.9927 - val_loss: 0.2110 - val_acc: 0.7419\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0115 - acc: 0.9927 - val_loss: 0.2136 - val_acc: 0.7419\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0110 - acc: 0.9927 - val_loss: 0.2154 - val_acc: 0.7419\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0106 - acc: 0.9927 - val_loss: 0.2191 - val_acc: 0.7097\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0102 - acc: 0.9927 - val_loss: 0.2221 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0099 - acc: 0.9927 - val_loss: 0.2255 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0096 - acc: 0.9927 - val_loss: 0.2259 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0094 - acc: 0.9927 - val_loss: 0.2288 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0092 - acc: 0.9927 - val_loss: 0.2274 - val_acc: 0.7097\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0089 - acc: 0.9927 - val_loss: 0.2279 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0087 - acc: 0.9927 - val_loss: 0.2310 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0084 - acc: 0.9927 - val_loss: 0.2365 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0076 - acc: 0.9927 - val_loss: 0.2405 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0069 - acc: 0.9964 - val_loss: 0.2412 - val_acc: 0.6129\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0064 - acc: 0.9964 - val_loss: 0.2425 - val_acc: 0.6129\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0060 - acc: 0.9964 - val_loss: 0.2437 - val_acc: 0.6129\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0058 - acc: 0.9964 - val_loss: 0.2463 - val_acc: 0.6129\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0056 - acc: 0.9964 - val_loss: 0.2457 - val_acc: 0.6129\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.2447 - val_acc: 0.6129\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0054 - acc: 0.9964 - val_loss: 0.2454 - val_acc: 0.6129\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.2442 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2476 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2471 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.2470 - val_acc: 0.6129\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.2477 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0048 - acc: 0.9964 - val_loss: 0.2474 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.0048 - acc: 0.9964 - val_loss: 0.2479 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0047 - acc: 0.9964 - val_loss: 0.2473 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0046 - acc: 0.9964 - val_loss: 0.2477 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.0046 - acc: 0.9964 - val_loss: 0.2490 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 15)                585       \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 11)                176       \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 773\n",
      "Trainable params: 773\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 3ms/step - loss: 0.2499 - acc: 0.5200 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.2492 - acc: 0.5418 - val_loss: 0.2491 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.2477 - acc: 0.5418 - val_loss: 0.2474 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.2445 - acc: 0.5418 - val_loss: 0.2436 - val_acc: 0.5161\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.2382 - acc: 0.5418 - val_loss: 0.2377 - val_acc: 0.5161\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.2295 - acc: 0.5455 - val_loss: 0.2320 - val_acc: 0.5484\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.2219 - acc: 0.5964 - val_loss: 0.2256 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.2132 - acc: 0.7236 - val_loss: 0.2205 - val_acc: 0.6129\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.2050 - acc: 0.7309 - val_loss: 0.2192 - val_acc: 0.6452\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1983 - acc: 0.7236 - val_loss: 0.2177 - val_acc: 0.6452\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1925 - acc: 0.7345 - val_loss: 0.2136 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1866 - acc: 0.7527 - val_loss: 0.2105 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1815 - acc: 0.7564 - val_loss: 0.2109 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1766 - acc: 0.7745 - val_loss: 0.2099 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1731 - acc: 0.7600 - val_loss: 0.2066 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1693 - acc: 0.7673 - val_loss: 0.2121 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1658 - acc: 0.7818 - val_loss: 0.2085 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1632 - acc: 0.7855 - val_loss: 0.2106 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1611 - acc: 0.7927 - val_loss: 0.2111 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.1598 - acc: 0.7818 - val_loss: 0.2113 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.1574 - acc: 0.7964 - val_loss: 0.2146 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1564 - acc: 0.7964 - val_loss: 0.2163 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1544 - acc: 0.8000 - val_loss: 0.2166 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1530 - acc: 0.7964 - val_loss: 0.2186 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1533 - acc: 0.7964 - val_loss: 0.2149 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1519 - acc: 0.8036 - val_loss: 0.2198 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1501 - acc: 0.8073 - val_loss: 0.2168 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1491 - acc: 0.8109 - val_loss: 0.2185 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1478 - acc: 0.8073 - val_loss: 0.2191 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 159us/step - loss: 0.1468 - acc: 0.8036 - val_loss: 0.2216 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1477 - acc: 0.8182 - val_loss: 0.2208 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1449 - acc: 0.8109 - val_loss: 0.2185 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1441 - acc: 0.8182 - val_loss: 0.2195 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1428 - acc: 0.8145 - val_loss: 0.2223 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1428 - acc: 0.8182 - val_loss: 0.2208 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1410 - acc: 0.8255 - val_loss: 0.2226 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.1405 - acc: 0.8218 - val_loss: 0.2214 - val_acc: 0.7419\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1394 - acc: 0.8255 - val_loss: 0.2200 - val_acc: 0.7419\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.1383 - acc: 0.8291 - val_loss: 0.2232 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1380 - acc: 0.8327 - val_loss: 0.2223 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1365 - acc: 0.8327 - val_loss: 0.2224 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1356 - acc: 0.8291 - val_loss: 0.2211 - val_acc: 0.7419\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1353 - acc: 0.8291 - val_loss: 0.2212 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1344 - acc: 0.8364 - val_loss: 0.2220 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.1331 - acc: 0.8400 - val_loss: 0.2220 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1323 - acc: 0.8400 - val_loss: 0.2207 - val_acc: 0.7419\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.1316 - acc: 0.8400 - val_loss: 0.2197 - val_acc: 0.7419\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1299 - acc: 0.8509 - val_loss: 0.2190 - val_acc: 0.7419\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1289 - acc: 0.8509 - val_loss: 0.2188 - val_acc: 0.7419\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.1284 - acc: 0.8400 - val_loss: 0.2212 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1272 - acc: 0.8509 - val_loss: 0.2210 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1258 - acc: 0.8618 - val_loss: 0.2177 - val_acc: 0.7419\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1253 - acc: 0.8545 - val_loss: 0.2179 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1253 - acc: 0.8509 - val_loss: 0.2175 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1232 - acc: 0.8582 - val_loss: 0.2197 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1223 - acc: 0.8618 - val_loss: 0.2167 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1217 - acc: 0.8618 - val_loss: 0.2165 - val_acc: 0.7097\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1202 - acc: 0.8655 - val_loss: 0.2162 - val_acc: 0.7419\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1209 - acc: 0.8655 - val_loss: 0.2138 - val_acc: 0.7419\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1189 - acc: 0.8618 - val_loss: 0.2159 - val_acc: 0.7097\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1187 - acc: 0.8545 - val_loss: 0.2136 - val_acc: 0.7419\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1177 - acc: 0.8618 - val_loss: 0.2159 - val_acc: 0.7097\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.1157 - acc: 0.8655 - val_loss: 0.2129 - val_acc: 0.7419\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1150 - acc: 0.8618 - val_loss: 0.2152 - val_acc: 0.7097\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1147 - acc: 0.8764 - val_loss: 0.2136 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1125 - acc: 0.8727 - val_loss: 0.2121 - val_acc: 0.7419\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1117 - acc: 0.8691 - val_loss: 0.2136 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1109 - acc: 0.8691 - val_loss: 0.2131 - val_acc: 0.7097\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.1095 - acc: 0.8727 - val_loss: 0.2135 - val_acc: 0.7097\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1096 - acc: 0.8764 - val_loss: 0.2114 - val_acc: 0.7419\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1073 - acc: 0.8800 - val_loss: 0.2126 - val_acc: 0.7419\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1060 - acc: 0.8727 - val_loss: 0.2118 - val_acc: 0.7097\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1050 - acc: 0.8800 - val_loss: 0.2074 - val_acc: 0.7419\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1040 - acc: 0.8764 - val_loss: 0.2095 - val_acc: 0.7419\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.1017 - acc: 0.8800 - val_loss: 0.2065 - val_acc: 0.7419\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1011 - acc: 0.8836 - val_loss: 0.2093 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.0992 - acc: 0.8945 - val_loss: 0.2073 - val_acc: 0.7419\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0980 - acc: 0.8836 - val_loss: 0.2090 - val_acc: 0.7419\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 177us/step - loss: 0.0968 - acc: 0.8909 - val_loss: 0.2078 - val_acc: 0.7419\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.0961 - acc: 0.8945 - val_loss: 0.2112 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0952 - acc: 0.8909 - val_loss: 0.2072 - val_acc: 0.7419\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0932 - acc: 0.8909 - val_loss: 0.2051 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0924 - acc: 0.8945 - val_loss: 0.2076 - val_acc: 0.7097\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0915 - acc: 0.8982 - val_loss: 0.2099 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0895 - acc: 0.9018 - val_loss: 0.2075 - val_acc: 0.7097\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0884 - acc: 0.9055 - val_loss: 0.2117 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 158us/step - loss: 0.0868 - acc: 0.8982 - val_loss: 0.2110 - val_acc: 0.7097\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0875 - acc: 0.9055 - val_loss: 0.2092 - val_acc: 0.7097\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.0856 - acc: 0.9127 - val_loss: 0.2112 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 155us/step - loss: 0.0844 - acc: 0.9164 - val_loss: 0.2114 - val_acc: 0.7097\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.0838 - acc: 0.9200 - val_loss: 0.2114 - val_acc: 0.7097\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 156us/step - loss: 0.0829 - acc: 0.9164 - val_loss: 0.2120 - val_acc: 0.7097\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 160us/step - loss: 0.0825 - acc: 0.9164 - val_loss: 0.2158 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0815 - acc: 0.9273 - val_loss: 0.2116 - val_acc: 0.7097\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.0806 - acc: 0.9273 - val_loss: 0.2128 - val_acc: 0.7097\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 154us/step - loss: 0.0796 - acc: 0.9273 - val_loss: 0.2136 - val_acc: 0.7097\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 162us/step - loss: 0.0790 - acc: 0.9236 - val_loss: 0.2123 - val_acc: 0.7097\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.0790 - acc: 0.9200 - val_loss: 0.2151 - val_acc: 0.7097\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 157us/step - loss: 0.0784 - acc: 0.9200 - val_loss: 0.2130 - val_acc: 0.7097\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 20)                780       \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,221\n",
      "Trainable params: 1,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 3ms/step - loss: 0.2499 - acc: 0.5273 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.2488 - acc: 0.5418 - val_loss: 0.2482 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.2453 - acc: 0.5455 - val_loss: 0.2431 - val_acc: 0.5484\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.2362 - acc: 0.6000 - val_loss: 0.2323 - val_acc: 0.6129\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 165us/step - loss: 0.2203 - acc: 0.6691 - val_loss: 0.2195 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.2027 - acc: 0.7200 - val_loss: 0.2120 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1876 - acc: 0.7345 - val_loss: 0.2030 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1775 - acc: 0.7382 - val_loss: 0.2060 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.1710 - acc: 0.7527 - val_loss: 0.2045 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1660 - acc: 0.7491 - val_loss: 0.2083 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1616 - acc: 0.7600 - val_loss: 0.2142 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1597 - acc: 0.7709 - val_loss: 0.2135 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1583 - acc: 0.7709 - val_loss: 0.2175 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1587 - acc: 0.7600 - val_loss: 0.2209 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.1585 - acc: 0.7491 - val_loss: 0.2196 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1544 - acc: 0.7818 - val_loss: 0.2206 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1523 - acc: 0.7855 - val_loss: 0.2255 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1517 - acc: 0.7891 - val_loss: 0.2291 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1503 - acc: 0.8000 - val_loss: 0.2266 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1488 - acc: 0.7927 - val_loss: 0.2312 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1469 - acc: 0.8109 - val_loss: 0.2291 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1464 - acc: 0.7927 - val_loss: 0.2339 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1442 - acc: 0.8036 - val_loss: 0.2312 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1434 - acc: 0.8109 - val_loss: 0.2353 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1417 - acc: 0.8182 - val_loss: 0.2369 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1407 - acc: 0.8145 - val_loss: 0.2358 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 214us/step - loss: 0.1388 - acc: 0.8073 - val_loss: 0.2392 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 215us/step - loss: 0.1374 - acc: 0.8255 - val_loss: 0.2389 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1359 - acc: 0.8291 - val_loss: 0.2392 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1338 - acc: 0.8218 - val_loss: 0.2365 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1317 - acc: 0.8291 - val_loss: 0.2382 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1306 - acc: 0.8364 - val_loss: 0.2410 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1283 - acc: 0.8364 - val_loss: 0.2422 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1271 - acc: 0.8291 - val_loss: 0.2432 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1242 - acc: 0.8473 - val_loss: 0.2443 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1232 - acc: 0.8545 - val_loss: 0.2472 - val_acc: 0.6452\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1226 - acc: 0.8473 - val_loss: 0.2443 - val_acc: 0.6452\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1187 - acc: 0.8545 - val_loss: 0.2466 - val_acc: 0.6452\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1173 - acc: 0.8618 - val_loss: 0.2496 - val_acc: 0.6452\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1148 - acc: 0.8618 - val_loss: 0.2529 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1136 - acc: 0.8618 - val_loss: 0.2535 - val_acc: 0.6452\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1112 - acc: 0.8655 - val_loss: 0.2563 - val_acc: 0.6452\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1099 - acc: 0.8618 - val_loss: 0.2568 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.1067 - acc: 0.8800 - val_loss: 0.2591 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1046 - acc: 0.8800 - val_loss: 0.2646 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1032 - acc: 0.8800 - val_loss: 0.2645 - val_acc: 0.6452\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1008 - acc: 0.8836 - val_loss: 0.2678 - val_acc: 0.6452\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0988 - acc: 0.8873 - val_loss: 0.2703 - val_acc: 0.6129\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0966 - acc: 0.8909 - val_loss: 0.2734 - val_acc: 0.5806\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0954 - acc: 0.8982 - val_loss: 0.2766 - val_acc: 0.5806\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0928 - acc: 0.8982 - val_loss: 0.2747 - val_acc: 0.6129\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0917 - acc: 0.8982 - val_loss: 0.2857 - val_acc: 0.5484\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0881 - acc: 0.8982 - val_loss: 0.2834 - val_acc: 0.5806\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0862 - acc: 0.9018 - val_loss: 0.2943 - val_acc: 0.5484\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.0841 - acc: 0.9127 - val_loss: 0.2957 - val_acc: 0.5484\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0809 - acc: 0.9236 - val_loss: 0.2978 - val_acc: 0.5806\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0793 - acc: 0.9236 - val_loss: 0.2955 - val_acc: 0.5484\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0763 - acc: 0.9273 - val_loss: 0.3020 - val_acc: 0.5484\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0748 - acc: 0.9309 - val_loss: 0.2946 - val_acc: 0.6129\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0718 - acc: 0.9382 - val_loss: 0.3057 - val_acc: 0.5484\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.0694 - acc: 0.9309 - val_loss: 0.3075 - val_acc: 0.5484\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.0676 - acc: 0.9418 - val_loss: 0.3150 - val_acc: 0.5484\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.0648 - acc: 0.9455 - val_loss: 0.3091 - val_acc: 0.5806\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0645 - acc: 0.9491 - val_loss: 0.3053 - val_acc: 0.5806\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0615 - acc: 0.9418 - val_loss: 0.3194 - val_acc: 0.5484\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0582 - acc: 0.9527 - val_loss: 0.3117 - val_acc: 0.5806\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0583 - acc: 0.9564 - val_loss: 0.3069 - val_acc: 0.5806\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0565 - acc: 0.9564 - val_loss: 0.3164 - val_acc: 0.5484\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0545 - acc: 0.9600 - val_loss: 0.3311 - val_acc: 0.5484\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0514 - acc: 0.9600 - val_loss: 0.3192 - val_acc: 0.5484\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0508 - acc: 0.9636 - val_loss: 0.3228 - val_acc: 0.5484\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0482 - acc: 0.9636 - val_loss: 0.3228 - val_acc: 0.5161\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0464 - acc: 0.9564 - val_loss: 0.3274 - val_acc: 0.4839\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.0466 - acc: 0.9636 - val_loss: 0.3306 - val_acc: 0.4839\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0450 - acc: 0.9600 - val_loss: 0.3300 - val_acc: 0.4839\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0432 - acc: 0.9636 - val_loss: 0.3216 - val_acc: 0.5484\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.0418 - acc: 0.9636 - val_loss: 0.3343 - val_acc: 0.5161\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0405 - acc: 0.9709 - val_loss: 0.3299 - val_acc: 0.5484\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.0387 - acc: 0.9745 - val_loss: 0.3255 - val_acc: 0.5161\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.0378 - acc: 0.9745 - val_loss: 0.3286 - val_acc: 0.5484\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 304us/step - loss: 0.0365 - acc: 0.9745 - val_loss: 0.3312 - val_acc: 0.5484\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.0359 - acc: 0.9709 - val_loss: 0.3297 - val_acc: 0.5484\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.0352 - acc: 0.9745 - val_loss: 0.3403 - val_acc: 0.4839\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0345 - acc: 0.9745 - val_loss: 0.3242 - val_acc: 0.5484\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0340 - acc: 0.9745 - val_loss: 0.3179 - val_acc: 0.5484\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0320 - acc: 0.9745 - val_loss: 0.3344 - val_acc: 0.5484\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0318 - acc: 0.9745 - val_loss: 0.3360 - val_acc: 0.5484\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0313 - acc: 0.9745 - val_loss: 0.3265 - val_acc: 0.5484\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0299 - acc: 0.9745 - val_loss: 0.3282 - val_acc: 0.5806\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0291 - acc: 0.9745 - val_loss: 0.3365 - val_acc: 0.5484\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0280 - acc: 0.9745 - val_loss: 0.3341 - val_acc: 0.5806\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.0272 - acc: 0.9782 - val_loss: 0.3280 - val_acc: 0.5806\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.0259 - acc: 0.9782 - val_loss: 0.3318 - val_acc: 0.5806\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 277us/step - loss: 0.0251 - acc: 0.9818 - val_loss: 0.3319 - val_acc: 0.5806\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.0248 - acc: 0.9818 - val_loss: 0.3285 - val_acc: 0.5806\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.0231 - acc: 0.9818 - val_loss: 0.3284 - val_acc: 0.5806\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0225 - acc: 0.9818 - val_loss: 0.3300 - val_acc: 0.5806\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0215 - acc: 0.9818 - val_loss: 0.3283 - val_acc: 0.5806\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 261us/step - loss: 0.0207 - acc: 0.9818 - val_loss: 0.3254 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_73 (Dense)             (None, 19)                741       \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 14)                280       \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 1,036\n",
      "Trainable params: 1,036\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 4ms/step - loss: 0.2500 - acc: 0.5309 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2495 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.2485 - acc: 0.5418 - val_loss: 0.2481 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.2452 - acc: 0.5527 - val_loss: 0.2433 - val_acc: 0.6129\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.2367 - acc: 0.6218 - val_loss: 0.2351 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.2247 - acc: 0.7018 - val_loss: 0.2250 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.2097 - acc: 0.7273 - val_loss: 0.2153 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1949 - acc: 0.7309 - val_loss: 0.2077 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1834 - acc: 0.7455 - val_loss: 0.2038 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1765 - acc: 0.7491 - val_loss: 0.2021 - val_acc: 0.6452\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1701 - acc: 0.7418 - val_loss: 0.2028 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1654 - acc: 0.7600 - val_loss: 0.2016 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 163us/step - loss: 0.1642 - acc: 0.7673 - val_loss: 0.2060 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1606 - acc: 0.7636 - val_loss: 0.2075 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1583 - acc: 0.7709 - val_loss: 0.2085 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1566 - acc: 0.7745 - val_loss: 0.2096 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 170us/step - loss: 0.1551 - acc: 0.7818 - val_loss: 0.2131 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1543 - acc: 0.8000 - val_loss: 0.2133 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 169us/step - loss: 0.1524 - acc: 0.8073 - val_loss: 0.2153 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1518 - acc: 0.8000 - val_loss: 0.2159 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 171us/step - loss: 0.1506 - acc: 0.8000 - val_loss: 0.2156 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 167us/step - loss: 0.1504 - acc: 0.7891 - val_loss: 0.2190 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 161us/step - loss: 0.1494 - acc: 0.7855 - val_loss: 0.2177 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1484 - acc: 0.8036 - val_loss: 0.2170 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1478 - acc: 0.8036 - val_loss: 0.2172 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1467 - acc: 0.8145 - val_loss: 0.2194 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.1462 - acc: 0.8145 - val_loss: 0.2208 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.1450 - acc: 0.8145 - val_loss: 0.2203 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1446 - acc: 0.8255 - val_loss: 0.2226 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1438 - acc: 0.8255 - val_loss: 0.2213 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1429 - acc: 0.8182 - val_loss: 0.2236 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1433 - acc: 0.8109 - val_loss: 0.2233 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1412 - acc: 0.8218 - val_loss: 0.2218 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 168us/step - loss: 0.1404 - acc: 0.8291 - val_loss: 0.2229 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1407 - acc: 0.8255 - val_loss: 0.2224 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.1387 - acc: 0.8182 - val_loss: 0.2237 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1378 - acc: 0.8364 - val_loss: 0.2213 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.1371 - acc: 0.8255 - val_loss: 0.2227 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1357 - acc: 0.8364 - val_loss: 0.2229 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1348 - acc: 0.8291 - val_loss: 0.2218 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1348 - acc: 0.8218 - val_loss: 0.2237 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1329 - acc: 0.8291 - val_loss: 0.2230 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1320 - acc: 0.8255 - val_loss: 0.2228 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 166us/step - loss: 0.1309 - acc: 0.8364 - val_loss: 0.2257 - val_acc: 0.7097\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 164us/step - loss: 0.1296 - acc: 0.8327 - val_loss: 0.2262 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1297 - acc: 0.8400 - val_loss: 0.2262 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1288 - acc: 0.8364 - val_loss: 0.2275 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.1281 - acc: 0.8473 - val_loss: 0.2238 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1266 - acc: 0.8400 - val_loss: 0.2249 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1262 - acc: 0.8545 - val_loss: 0.2281 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1254 - acc: 0.8327 - val_loss: 0.2256 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1241 - acc: 0.8509 - val_loss: 0.2263 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1233 - acc: 0.8291 - val_loss: 0.2282 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1205 - acc: 0.8582 - val_loss: 0.2284 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.1188 - acc: 0.8655 - val_loss: 0.2282 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.1181 - acc: 0.8545 - val_loss: 0.2296 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.1171 - acc: 0.8618 - val_loss: 0.2309 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1151 - acc: 0.8582 - val_loss: 0.2263 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1138 - acc: 0.8655 - val_loss: 0.2262 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 298us/step - loss: 0.1126 - acc: 0.8618 - val_loss: 0.2291 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 262us/step - loss: 0.1112 - acc: 0.8691 - val_loss: 0.2311 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.1097 - acc: 0.8764 - val_loss: 0.2308 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.1082 - acc: 0.8727 - val_loss: 0.2321 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1080 - acc: 0.8727 - val_loss: 0.2324 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1076 - acc: 0.8800 - val_loss: 0.2311 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1039 - acc: 0.8727 - val_loss: 0.2319 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1020 - acc: 0.8873 - val_loss: 0.2344 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0991 - acc: 0.8945 - val_loss: 0.2335 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0981 - acc: 0.8909 - val_loss: 0.2321 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0965 - acc: 0.9018 - val_loss: 0.2324 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0941 - acc: 0.9018 - val_loss: 0.2297 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0929 - acc: 0.9018 - val_loss: 0.2291 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0904 - acc: 0.9018 - val_loss: 0.2340 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0885 - acc: 0.9164 - val_loss: 0.2301 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0867 - acc: 0.9091 - val_loss: 0.2335 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0842 - acc: 0.9164 - val_loss: 0.2302 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0824 - acc: 0.9273 - val_loss: 0.2279 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0809 - acc: 0.9236 - val_loss: 0.2335 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0772 - acc: 0.9273 - val_loss: 0.2307 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.0758 - acc: 0.9273 - val_loss: 0.2304 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0732 - acc: 0.9236 - val_loss: 0.2301 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0707 - acc: 0.9455 - val_loss: 0.2198 - val_acc: 0.6129\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0686 - acc: 0.9382 - val_loss: 0.2121 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0668 - acc: 0.9382 - val_loss: 0.2202 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0637 - acc: 0.9527 - val_loss: 0.2147 - val_acc: 0.6129\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0618 - acc: 0.9527 - val_loss: 0.2182 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0617 - acc: 0.9491 - val_loss: 0.2104 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 276us/step - loss: 0.0577 - acc: 0.9600 - val_loss: 0.2111 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.0560 - acc: 0.9636 - val_loss: 0.2248 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0554 - acc: 0.9636 - val_loss: 0.2192 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0529 - acc: 0.9673 - val_loss: 0.2129 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0512 - acc: 0.9636 - val_loss: 0.2165 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0510 - acc: 0.9673 - val_loss: 0.2135 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0493 - acc: 0.9600 - val_loss: 0.2220 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0469 - acc: 0.9709 - val_loss: 0.2105 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0461 - acc: 0.9636 - val_loss: 0.2235 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0448 - acc: 0.9709 - val_loss: 0.2156 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0437 - acc: 0.9673 - val_loss: 0.2253 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0416 - acc: 0.9745 - val_loss: 0.2112 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0428 - acc: 0.9636 - val_loss: 0.2290 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_76 (Dense)             (None, 38)                1482      \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 16)                624       \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,123\n",
      "Trainable params: 2,123\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 3ms/step - loss: 0.2499 - acc: 0.5273 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.2495 - acc: 0.5418 - val_loss: 0.2494 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 176us/step - loss: 0.2484 - acc: 0.5564 - val_loss: 0.2478 - val_acc: 0.5484\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 260us/step - loss: 0.2449 - acc: 0.6582 - val_loss: 0.2414 - val_acc: 0.6774\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.2356 - acc: 0.7127 - val_loss: 0.2287 - val_acc: 0.7097\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.2179 - acc: 0.7527 - val_loss: 0.2141 - val_acc: 0.7097\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.1977 - acc: 0.7273 - val_loss: 0.2010 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 284us/step - loss: 0.1809 - acc: 0.7636 - val_loss: 0.1985 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.1719 - acc: 0.7709 - val_loss: 0.1994 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.1664 - acc: 0.7745 - val_loss: 0.2030 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1618 - acc: 0.7782 - val_loss: 0.2051 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.1601 - acc: 0.7745 - val_loss: 0.2095 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1567 - acc: 0.7818 - val_loss: 0.2120 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.1559 - acc: 0.7891 - val_loss: 0.2142 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1524 - acc: 0.7891 - val_loss: 0.2155 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1513 - acc: 0.7964 - val_loss: 0.2207 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1501 - acc: 0.7964 - val_loss: 0.2166 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1483 - acc: 0.8036 - val_loss: 0.2166 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1465 - acc: 0.8145 - val_loss: 0.2185 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1441 - acc: 0.8073 - val_loss: 0.2196 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1425 - acc: 0.8145 - val_loss: 0.2222 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1405 - acc: 0.8218 - val_loss: 0.2176 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1376 - acc: 0.8182 - val_loss: 0.2203 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1350 - acc: 0.8291 - val_loss: 0.2219 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1324 - acc: 0.8291 - val_loss: 0.2171 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1306 - acc: 0.8364 - val_loss: 0.2199 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1285 - acc: 0.8400 - val_loss: 0.2183 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1260 - acc: 0.8473 - val_loss: 0.2170 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1247 - acc: 0.8436 - val_loss: 0.2143 - val_acc: 0.7419\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.1214 - acc: 0.8582 - val_loss: 0.2202 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.1205 - acc: 0.8545 - val_loss: 0.2203 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1175 - acc: 0.8509 - val_loss: 0.2165 - val_acc: 0.7419\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1151 - acc: 0.8655 - val_loss: 0.2195 - val_acc: 0.7419\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1137 - acc: 0.8655 - val_loss: 0.2198 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1107 - acc: 0.8764 - val_loss: 0.2194 - val_acc: 0.7419\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.1073 - acc: 0.8800 - val_loss: 0.2194 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1054 - acc: 0.8945 - val_loss: 0.2205 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.1041 - acc: 0.8836 - val_loss: 0.2201 - val_acc: 0.7419\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1002 - acc: 0.8873 - val_loss: 0.2226 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0977 - acc: 0.8982 - val_loss: 0.2176 - val_acc: 0.7419\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.0965 - acc: 0.8945 - val_loss: 0.2218 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 321us/step - loss: 0.0930 - acc: 0.9164 - val_loss: 0.2147 - val_acc: 0.7419\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 284us/step - loss: 0.0904 - acc: 0.9164 - val_loss: 0.2159 - val_acc: 0.7419\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 285us/step - loss: 0.0871 - acc: 0.9200 - val_loss: 0.2134 - val_acc: 0.7419\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0841 - acc: 0.9127 - val_loss: 0.2161 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.0826 - acc: 0.9164 - val_loss: 0.2175 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 172us/step - loss: 0.0786 - acc: 0.9200 - val_loss: 0.2182 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.0772 - acc: 0.9200 - val_loss: 0.2102 - val_acc: 0.7419\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0749 - acc: 0.9236 - val_loss: 0.2147 - val_acc: 0.7419\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0717 - acc: 0.9309 - val_loss: 0.2161 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0684 - acc: 0.9382 - val_loss: 0.2104 - val_acc: 0.7419\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.0658 - acc: 0.9418 - val_loss: 0.2108 - val_acc: 0.7419\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0618 - acc: 0.9491 - val_loss: 0.2146 - val_acc: 0.7419\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0602 - acc: 0.9564 - val_loss: 0.2101 - val_acc: 0.7419\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0569 - acc: 0.9527 - val_loss: 0.2141 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.0531 - acc: 0.9673 - val_loss: 0.2115 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.0512 - acc: 0.9709 - val_loss: 0.2148 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0506 - acc: 0.9636 - val_loss: 0.2067 - val_acc: 0.7419\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0464 - acc: 0.9745 - val_loss: 0.2112 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0437 - acc: 0.9673 - val_loss: 0.2169 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0421 - acc: 0.9709 - val_loss: 0.2090 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0411 - acc: 0.9745 - val_loss: 0.2133 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0367 - acc: 0.9745 - val_loss: 0.2149 - val_acc: 0.6774\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 198us/step - loss: 0.0345 - acc: 0.9782 - val_loss: 0.2160 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0345 - acc: 0.9782 - val_loss: 0.2146 - val_acc: 0.7097\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0316 - acc: 0.9818 - val_loss: 0.2121 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0294 - acc: 0.9818 - val_loss: 0.2124 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0291 - acc: 0.9818 - val_loss: 0.2197 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0265 - acc: 0.9818 - val_loss: 0.2232 - val_acc: 0.7097\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0262 - acc: 0.9818 - val_loss: 0.2248 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0241 - acc: 0.9855 - val_loss: 0.2204 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0226 - acc: 0.9855 - val_loss: 0.2202 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0219 - acc: 0.9818 - val_loss: 0.2140 - val_acc: 0.7097\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0202 - acc: 0.9855 - val_loss: 0.2121 - val_acc: 0.7097\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0182 - acc: 0.9927 - val_loss: 0.2126 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 215us/step - loss: 0.0165 - acc: 0.9927 - val_loss: 0.2159 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.0157 - acc: 0.9927 - val_loss: 0.2114 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.0151 - acc: 0.9927 - val_loss: 0.2149 - val_acc: 0.7097\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0144 - acc: 0.9927 - val_loss: 0.2107 - val_acc: 0.7097\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0136 - acc: 0.9927 - val_loss: 0.2165 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.0123 - acc: 0.9927 - val_loss: 0.2144 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0106 - acc: 0.9927 - val_loss: 0.2176 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0102 - acc: 0.9964 - val_loss: 0.2204 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0081 - acc: 0.9964 - val_loss: 0.2233 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.2222 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.2212 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.2260 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.2236 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.2304 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.2345 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.2308 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.2297 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.2315 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.2358 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.2321 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.2355 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.2389 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.2423 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.2393 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_79 (Dense)             (None, 13)                507       \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 15)                210       \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 733\n",
      "Trainable params: 733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 4ms/step - loss: 0.2501 - acc: 0.4364 - val_loss: 0.2500 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.2498 - acc: 0.5418 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 214us/step - loss: 0.2491 - acc: 0.5418 - val_loss: 0.2488 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.2472 - acc: 0.5418 - val_loss: 0.2461 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.2424 - acc: 0.5491 - val_loss: 0.2404 - val_acc: 0.5484\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.2335 - acc: 0.5964 - val_loss: 0.2322 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.2214 - acc: 0.6618 - val_loss: 0.2238 - val_acc: 0.6129\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.2091 - acc: 0.7091 - val_loss: 0.2174 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1977 - acc: 0.7164 - val_loss: 0.2105 - val_acc: 0.6452\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1890 - acc: 0.7236 - val_loss: 0.2085 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.1819 - acc: 0.7527 - val_loss: 0.2059 - val_acc: 0.6452\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.1754 - acc: 0.7564 - val_loss: 0.2080 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.1723 - acc: 0.7600 - val_loss: 0.2066 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1684 - acc: 0.7564 - val_loss: 0.2113 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.1657 - acc: 0.7600 - val_loss: 0.2108 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1649 - acc: 0.7491 - val_loss: 0.2139 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 213us/step - loss: 0.1625 - acc: 0.7636 - val_loss: 0.2171 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.1603 - acc: 0.7636 - val_loss: 0.2203 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.1593 - acc: 0.7782 - val_loss: 0.2202 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1584 - acc: 0.7782 - val_loss: 0.2239 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.1574 - acc: 0.7818 - val_loss: 0.2230 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1573 - acc: 0.7745 - val_loss: 0.2259 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1557 - acc: 0.7891 - val_loss: 0.2237 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1551 - acc: 0.7855 - val_loss: 0.2270 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1547 - acc: 0.7927 - val_loss: 0.2291 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1549 - acc: 0.7891 - val_loss: 0.2289 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1536 - acc: 0.8000 - val_loss: 0.2331 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1527 - acc: 0.8000 - val_loss: 0.2295 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1527 - acc: 0.8036 - val_loss: 0.2318 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1517 - acc: 0.8000 - val_loss: 0.2314 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1520 - acc: 0.8073 - val_loss: 0.2349 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1509 - acc: 0.8109 - val_loss: 0.2339 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1508 - acc: 0.8073 - val_loss: 0.2332 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1517 - acc: 0.8000 - val_loss: 0.2357 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1496 - acc: 0.8036 - val_loss: 0.2336 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1502 - acc: 0.8000 - val_loss: 0.2350 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1485 - acc: 0.8109 - val_loss: 0.2338 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1474 - acc: 0.8109 - val_loss: 0.2329 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.1475 - acc: 0.8145 - val_loss: 0.2360 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1468 - acc: 0.8109 - val_loss: 0.2362 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1469 - acc: 0.8073 - val_loss: 0.2358 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1457 - acc: 0.8182 - val_loss: 0.2365 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1451 - acc: 0.8182 - val_loss: 0.2363 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.1446 - acc: 0.8218 - val_loss: 0.2392 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.1444 - acc: 0.8145 - val_loss: 0.2391 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 279us/step - loss: 0.1440 - acc: 0.8145 - val_loss: 0.2401 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 287us/step - loss: 0.1444 - acc: 0.8145 - val_loss: 0.2403 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.1426 - acc: 0.8218 - val_loss: 0.2395 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1432 - acc: 0.8182 - val_loss: 0.2395 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1421 - acc: 0.8218 - val_loss: 0.2370 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1415 - acc: 0.8218 - val_loss: 0.2403 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.1405 - acc: 0.8255 - val_loss: 0.2391 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1401 - acc: 0.8327 - val_loss: 0.2416 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1397 - acc: 0.8255 - val_loss: 0.2395 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1389 - acc: 0.8255 - val_loss: 0.2415 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1385 - acc: 0.8218 - val_loss: 0.2412 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1377 - acc: 0.8291 - val_loss: 0.2408 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1373 - acc: 0.8327 - val_loss: 0.2434 - val_acc: 0.6452\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1370 - acc: 0.8291 - val_loss: 0.2438 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1367 - acc: 0.8291 - val_loss: 0.2441 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1355 - acc: 0.8436 - val_loss: 0.2438 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1350 - acc: 0.8364 - val_loss: 0.2442 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1353 - acc: 0.8400 - val_loss: 0.2463 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1340 - acc: 0.8436 - val_loss: 0.2471 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1330 - acc: 0.8436 - val_loss: 0.2457 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 313us/step - loss: 0.1332 - acc: 0.8364 - val_loss: 0.2475 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 306us/step - loss: 0.1342 - acc: 0.8400 - val_loss: 0.2472 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.1314 - acc: 0.8364 - val_loss: 0.2490 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1306 - acc: 0.8436 - val_loss: 0.2477 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1304 - acc: 0.8473 - val_loss: 0.2480 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1296 - acc: 0.8473 - val_loss: 0.2458 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1292 - acc: 0.8545 - val_loss: 0.2465 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1283 - acc: 0.8582 - val_loss: 0.2475 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1273 - acc: 0.8545 - val_loss: 0.2503 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1265 - acc: 0.8582 - val_loss: 0.2500 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.1266 - acc: 0.8436 - val_loss: 0.2502 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1254 - acc: 0.8545 - val_loss: 0.2507 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.1241 - acc: 0.8509 - val_loss: 0.2510 - val_acc: 0.6774\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 192us/step - loss: 0.1235 - acc: 0.8545 - val_loss: 0.2499 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1238 - acc: 0.8582 - val_loss: 0.2511 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1219 - acc: 0.8509 - val_loss: 0.2493 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1210 - acc: 0.8582 - val_loss: 0.2525 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1206 - acc: 0.8618 - val_loss: 0.2530 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1194 - acc: 0.8727 - val_loss: 0.2521 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1189 - acc: 0.8655 - val_loss: 0.2514 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1182 - acc: 0.8764 - val_loss: 0.2532 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1178 - acc: 0.8618 - val_loss: 0.2501 - val_acc: 0.6452\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 173us/step - loss: 0.1185 - acc: 0.8691 - val_loss: 0.2536 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1165 - acc: 0.8691 - val_loss: 0.2483 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1145 - acc: 0.8727 - val_loss: 0.2508 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 177us/step - loss: 0.1140 - acc: 0.8727 - val_loss: 0.2526 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1131 - acc: 0.8764 - val_loss: 0.2534 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1123 - acc: 0.8691 - val_loss: 0.2536 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1106 - acc: 0.8727 - val_loss: 0.2563 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1099 - acc: 0.8800 - val_loss: 0.2567 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 174us/step - loss: 0.1097 - acc: 0.8800 - val_loss: 0.2566 - val_acc: 0.6452\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1088 - acc: 0.8764 - val_loss: 0.2533 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1077 - acc: 0.8764 - val_loss: 0.2555 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1067 - acc: 0.8873 - val_loss: 0.2590 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1059 - acc: 0.8764 - val_loss: 0.2550 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_82 (Dense)             (None, 28)                1092      \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 14)                406       \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 1,513\n",
      "Trainable params: 1,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 4ms/step - loss: 0.2500 - acc: 0.5055 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2496 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.2488 - acc: 0.5418 - val_loss: 0.2483 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.2459 - acc: 0.5673 - val_loss: 0.2439 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.2391 - acc: 0.6545 - val_loss: 0.2334 - val_acc: 0.6774\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.2247 - acc: 0.7491 - val_loss: 0.2202 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.2065 - acc: 0.7382 - val_loss: 0.2025 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.1896 - acc: 0.7564 - val_loss: 0.1980 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1776 - acc: 0.7527 - val_loss: 0.1969 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1725 - acc: 0.7491 - val_loss: 0.1933 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1662 - acc: 0.7600 - val_loss: 0.1974 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1633 - acc: 0.7709 - val_loss: 0.2031 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1622 - acc: 0.7636 - val_loss: 0.2053 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.1598 - acc: 0.7709 - val_loss: 0.2081 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.1583 - acc: 0.7709 - val_loss: 0.2128 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1576 - acc: 0.7745 - val_loss: 0.2119 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1567 - acc: 0.7745 - val_loss: 0.2124 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1562 - acc: 0.7818 - val_loss: 0.2136 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1548 - acc: 0.7891 - val_loss: 0.2164 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 277us/step - loss: 0.1537 - acc: 0.7891 - val_loss: 0.2161 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.1536 - acc: 0.7745 - val_loss: 0.2167 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.1524 - acc: 0.7855 - val_loss: 0.2157 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.1507 - acc: 0.8000 - val_loss: 0.2160 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1496 - acc: 0.8073 - val_loss: 0.2199 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 268us/step - loss: 0.1491 - acc: 0.8036 - val_loss: 0.2198 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.1485 - acc: 0.8073 - val_loss: 0.2209 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1487 - acc: 0.8000 - val_loss: 0.2196 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1465 - acc: 0.8073 - val_loss: 0.2222 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1452 - acc: 0.8109 - val_loss: 0.2234 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 308us/step - loss: 0.1446 - acc: 0.8182 - val_loss: 0.2225 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 298us/step - loss: 0.1448 - acc: 0.8145 - val_loss: 0.2223 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 286us/step - loss: 0.1436 - acc: 0.8073 - val_loss: 0.2240 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.1415 - acc: 0.8182 - val_loss: 0.2220 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1412 - acc: 0.8255 - val_loss: 0.2235 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1399 - acc: 0.8109 - val_loss: 0.2227 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1393 - acc: 0.8291 - val_loss: 0.2216 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.1377 - acc: 0.8218 - val_loss: 0.2208 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1367 - acc: 0.8364 - val_loss: 0.2237 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1365 - acc: 0.8255 - val_loss: 0.2208 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.1340 - acc: 0.8327 - val_loss: 0.2210 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 310us/step - loss: 0.1331 - acc: 0.8255 - val_loss: 0.2224 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 301us/step - loss: 0.1313 - acc: 0.8364 - val_loss: 0.2207 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 300us/step - loss: 0.1295 - acc: 0.8327 - val_loss: 0.2221 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 325us/step - loss: 0.1306 - acc: 0.8364 - val_loss: 0.2237 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.1271 - acc: 0.8400 - val_loss: 0.2226 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1265 - acc: 0.8473 - val_loss: 0.2232 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.1267 - acc: 0.8327 - val_loss: 0.2212 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.1223 - acc: 0.8509 - val_loss: 0.2209 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.1196 - acc: 0.8473 - val_loss: 0.2226 - val_acc: 0.6452\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.1195 - acc: 0.8545 - val_loss: 0.2227 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 310us/step - loss: 0.1172 - acc: 0.8509 - val_loss: 0.2239 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.1150 - acc: 0.8691 - val_loss: 0.2255 - val_acc: 0.6452\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1137 - acc: 0.8727 - val_loss: 0.2241 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.1121 - acc: 0.8655 - val_loss: 0.2245 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.1091 - acc: 0.8727 - val_loss: 0.2229 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 283us/step - loss: 0.1071 - acc: 0.8909 - val_loss: 0.2268 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.1049 - acc: 0.8909 - val_loss: 0.2287 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.1031 - acc: 0.9055 - val_loss: 0.2262 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1019 - acc: 0.8909 - val_loss: 0.2283 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0976 - acc: 0.9127 - val_loss: 0.2313 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.0954 - acc: 0.9164 - val_loss: 0.2312 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0935 - acc: 0.9055 - val_loss: 0.2260 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0924 - acc: 0.9200 - val_loss: 0.2261 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0890 - acc: 0.9200 - val_loss: 0.2278 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0856 - acc: 0.9236 - val_loss: 0.2308 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.0834 - acc: 0.9345 - val_loss: 0.2287 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.0820 - acc: 0.9309 - val_loss: 0.2244 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0798 - acc: 0.9273 - val_loss: 0.2284 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0768 - acc: 0.9418 - val_loss: 0.2237 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0743 - acc: 0.9455 - val_loss: 0.2278 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0734 - acc: 0.9418 - val_loss: 0.2259 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0694 - acc: 0.9455 - val_loss: 0.2209 - val_acc: 0.6452\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0675 - acc: 0.9491 - val_loss: 0.2239 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0660 - acc: 0.9491 - val_loss: 0.2215 - val_acc: 0.6452\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.0643 - acc: 0.9491 - val_loss: 0.2248 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0616 - acc: 0.9600 - val_loss: 0.2276 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0594 - acc: 0.9564 - val_loss: 0.2268 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0572 - acc: 0.9673 - val_loss: 0.2247 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0590 - acc: 0.9636 - val_loss: 0.2330 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0530 - acc: 0.9636 - val_loss: 0.2321 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.0524 - acc: 0.9709 - val_loss: 0.2375 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.0508 - acc: 0.9709 - val_loss: 0.2382 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0487 - acc: 0.9709 - val_loss: 0.2335 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0468 - acc: 0.9709 - val_loss: 0.2309 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0466 - acc: 0.9709 - val_loss: 0.2397 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0439 - acc: 0.9709 - val_loss: 0.2367 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 181us/step - loss: 0.0432 - acc: 0.9709 - val_loss: 0.2412 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.0415 - acc: 0.9709 - val_loss: 0.2442 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.0375 - acc: 0.9745 - val_loss: 0.2518 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.0351 - acc: 0.9818 - val_loss: 0.2436 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0350 - acc: 0.9818 - val_loss: 0.2494 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0329 - acc: 0.9818 - val_loss: 0.2493 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0313 - acc: 0.9855 - val_loss: 0.2539 - val_acc: 0.6774\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 210us/step - loss: 0.0309 - acc: 0.9818 - val_loss: 0.2549 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0289 - acc: 0.9855 - val_loss: 0.2503 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0291 - acc: 0.9818 - val_loss: 0.2580 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0284 - acc: 0.9855 - val_loss: 0.2614 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0276 - acc: 0.9891 - val_loss: 0.2609 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0257 - acc: 0.9855 - val_loss: 0.2587 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0251 - acc: 0.9855 - val_loss: 0.2585 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_85 (Dense)             (None, 35)                1365      \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 10)                360       \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,736\n",
      "Trainable params: 1,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 4ms/step - loss: 0.2499 - acc: 0.5382 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.2493 - acc: 0.5418 - val_loss: 0.2493 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.2479 - acc: 0.5418 - val_loss: 0.2468 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.2430 - acc: 0.5418 - val_loss: 0.2416 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.2343 - acc: 0.5527 - val_loss: 0.2329 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.2219 - acc: 0.6327 - val_loss: 0.2244 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.2095 - acc: 0.7273 - val_loss: 0.2177 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1981 - acc: 0.7309 - val_loss: 0.2139 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1882 - acc: 0.7455 - val_loss: 0.2079 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.1797 - acc: 0.7418 - val_loss: 0.2072 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1738 - acc: 0.7527 - val_loss: 0.2062 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.1688 - acc: 0.7745 - val_loss: 0.2055 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.1646 - acc: 0.7600 - val_loss: 0.2109 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.1620 - acc: 0.7709 - val_loss: 0.2105 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1604 - acc: 0.7855 - val_loss: 0.2101 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1578 - acc: 0.7782 - val_loss: 0.2145 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1569 - acc: 0.7782 - val_loss: 0.2157 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 262us/step - loss: 0.1557 - acc: 0.7891 - val_loss: 0.2185 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.1547 - acc: 0.7927 - val_loss: 0.2217 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.1539 - acc: 0.7891 - val_loss: 0.2216 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1531 - acc: 0.7927 - val_loss: 0.2225 - val_acc: 0.6452\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1513 - acc: 0.7964 - val_loss: 0.2220 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 180us/step - loss: 0.1506 - acc: 0.7927 - val_loss: 0.2227 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1504 - acc: 0.8000 - val_loss: 0.2223 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1496 - acc: 0.8036 - val_loss: 0.2245 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 178us/step - loss: 0.1482 - acc: 0.8000 - val_loss: 0.2231 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 175us/step - loss: 0.1470 - acc: 0.8000 - val_loss: 0.2249 - val_acc: 0.6452\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1461 - acc: 0.8036 - val_loss: 0.2258 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.1449 - acc: 0.8073 - val_loss: 0.2255 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.1444 - acc: 0.8036 - val_loss: 0.2251 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 309us/step - loss: 0.1442 - acc: 0.8000 - val_loss: 0.2229 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 340us/step - loss: 0.1428 - acc: 0.8000 - val_loss: 0.2249 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1417 - acc: 0.8036 - val_loss: 0.2247 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 179us/step - loss: 0.1405 - acc: 0.8000 - val_loss: 0.2252 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.1397 - acc: 0.8000 - val_loss: 0.2239 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1394 - acc: 0.8073 - val_loss: 0.2281 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1382 - acc: 0.8073 - val_loss: 0.2258 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1373 - acc: 0.8073 - val_loss: 0.2219 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1366 - acc: 0.8109 - val_loss: 0.2266 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.1374 - acc: 0.8182 - val_loss: 0.2222 - val_acc: 0.7419\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 307us/step - loss: 0.1342 - acc: 0.8218 - val_loss: 0.2235 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 287us/step - loss: 0.1338 - acc: 0.8218 - val_loss: 0.2280 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 296us/step - loss: 0.1335 - acc: 0.8291 - val_loss: 0.2243 - val_acc: 0.7419\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1318 - acc: 0.8255 - val_loss: 0.2250 - val_acc: 0.7097\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1302 - acc: 0.8400 - val_loss: 0.2236 - val_acc: 0.7419\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1296 - acc: 0.8436 - val_loss: 0.2283 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1285 - acc: 0.8327 - val_loss: 0.2250 - val_acc: 0.7419\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1287 - acc: 0.8400 - val_loss: 0.2245 - val_acc: 0.7419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1268 - acc: 0.8473 - val_loss: 0.2225 - val_acc: 0.7419\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.1252 - acc: 0.8473 - val_loss: 0.2274 - val_acc: 0.7419\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.1235 - acc: 0.8509 - val_loss: 0.2241 - val_acc: 0.7419\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1220 - acc: 0.8655 - val_loss: 0.2280 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1208 - acc: 0.8618 - val_loss: 0.2245 - val_acc: 0.7419\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.1194 - acc: 0.8655 - val_loss: 0.2269 - val_acc: 0.7419\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.1187 - acc: 0.8618 - val_loss: 0.2245 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.1173 - acc: 0.8727 - val_loss: 0.2286 - val_acc: 0.7419\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1171 - acc: 0.8655 - val_loss: 0.2219 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 262us/step - loss: 0.1158 - acc: 0.8691 - val_loss: 0.2259 - val_acc: 0.7097\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1130 - acc: 0.8727 - val_loss: 0.2286 - val_acc: 0.7097\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1124 - acc: 0.8764 - val_loss: 0.2267 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1117 - acc: 0.8727 - val_loss: 0.2314 - val_acc: 0.7097\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.1091 - acc: 0.8800 - val_loss: 0.2304 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1067 - acc: 0.8836 - val_loss: 0.2267 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1056 - acc: 0.8909 - val_loss: 0.2317 - val_acc: 0.7097\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1045 - acc: 0.8873 - val_loss: 0.2321 - val_acc: 0.7097\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.1026 - acc: 0.8909 - val_loss: 0.2342 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.1011 - acc: 0.8873 - val_loss: 0.2366 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.0997 - acc: 0.8945 - val_loss: 0.2369 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.0980 - acc: 0.9018 - val_loss: 0.2381 - val_acc: 0.7097\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 277us/step - loss: 0.0968 - acc: 0.8945 - val_loss: 0.2400 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.0945 - acc: 0.9018 - val_loss: 0.2399 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.0926 - acc: 0.9055 - val_loss: 0.2390 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0913 - acc: 0.9091 - val_loss: 0.2420 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.0893 - acc: 0.9164 - val_loss: 0.2403 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0874 - acc: 0.9127 - val_loss: 0.2464 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.0872 - acc: 0.9164 - val_loss: 0.2451 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.0847 - acc: 0.9200 - val_loss: 0.2414 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.0818 - acc: 0.9200 - val_loss: 0.2456 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0798 - acc: 0.9200 - val_loss: 0.2418 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.0778 - acc: 0.9236 - val_loss: 0.2423 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.0755 - acc: 0.9200 - val_loss: 0.2474 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 301us/step - loss: 0.0723 - acc: 0.9236 - val_loss: 0.2461 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 296us/step - loss: 0.0709 - acc: 0.9236 - val_loss: 0.2563 - val_acc: 0.6129\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0681 - acc: 0.9273 - val_loss: 0.2521 - val_acc: 0.6129\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.0642 - acc: 0.9345 - val_loss: 0.2514 - val_acc: 0.6129\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.0611 - acc: 0.9382 - val_loss: 0.2563 - val_acc: 0.6129\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0588 - acc: 0.9345 - val_loss: 0.2563 - val_acc: 0.5806\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0569 - acc: 0.9382 - val_loss: 0.2581 - val_acc: 0.5484\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.0543 - acc: 0.9491 - val_loss: 0.2533 - val_acc: 0.5806\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.0539 - acc: 0.9491 - val_loss: 0.2645 - val_acc: 0.5806\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 298us/step - loss: 0.0498 - acc: 0.9564 - val_loss: 0.2688 - val_acc: 0.5484\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 315us/step - loss: 0.0465 - acc: 0.9636 - val_loss: 0.2600 - val_acc: 0.5484\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 342us/step - loss: 0.0438 - acc: 0.9673 - val_loss: 0.2648 - val_acc: 0.5484\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.0417 - acc: 0.9673 - val_loss: 0.2619 - val_acc: 0.5484\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.0411 - acc: 0.9673 - val_loss: 0.2662 - val_acc: 0.5484\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 328us/step - loss: 0.0400 - acc: 0.9673 - val_loss: 0.2776 - val_acc: 0.5484\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 380us/step - loss: 0.0368 - acc: 0.9673 - val_loss: 0.2652 - val_acc: 0.5484\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 304us/step - loss: 0.0350 - acc: 0.9673 - val_loss: 0.2804 - val_acc: 0.5484\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 320us/step - loss: 0.0344 - acc: 0.9673 - val_loss: 0.2674 - val_acc: 0.6129\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.0325 - acc: 0.9673 - val_loss: 0.2766 - val_acc: 0.5484\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_88 (Dense)             (None, 28)                1092      \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 10)                290       \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 4ms/step - loss: 0.2499 - acc: 0.5236 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 333us/step - loss: 0.2495 - acc: 0.5418 - val_loss: 0.2494 - val_acc: 0.5161\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 311us/step - loss: 0.2481 - acc: 0.5418 - val_loss: 0.2473 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 331us/step - loss: 0.2435 - acc: 0.5418 - val_loss: 0.2425 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 328us/step - loss: 0.2340 - acc: 0.5782 - val_loss: 0.2343 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.2212 - acc: 0.6836 - val_loss: 0.2258 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 280us/step - loss: 0.2086 - acc: 0.7200 - val_loss: 0.2227 - val_acc: 0.6129\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 403us/step - loss: 0.1967 - acc: 0.7091 - val_loss: 0.2137 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 465us/step - loss: 0.1873 - acc: 0.7527 - val_loss: 0.2126 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 383us/step - loss: 0.1784 - acc: 0.7636 - val_loss: 0.2109 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 331us/step - loss: 0.1721 - acc: 0.7600 - val_loss: 0.2089 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.1678 - acc: 0.7491 - val_loss: 0.2139 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 262us/step - loss: 0.1641 - acc: 0.7673 - val_loss: 0.2139 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 332us/step - loss: 0.1604 - acc: 0.7745 - val_loss: 0.2155 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 373us/step - loss: 0.1592 - acc: 0.7745 - val_loss: 0.2189 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 337us/step - loss: 0.1570 - acc: 0.7782 - val_loss: 0.2190 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 343us/step - loss: 0.1561 - acc: 0.7855 - val_loss: 0.2234 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 365us/step - loss: 0.1550 - acc: 0.7855 - val_loss: 0.2215 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 327us/step - loss: 0.1531 - acc: 0.7891 - val_loss: 0.2269 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 296us/step - loss: 0.1520 - acc: 0.7745 - val_loss: 0.2229 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 293us/step - loss: 0.1494 - acc: 0.8073 - val_loss: 0.2254 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 319us/step - loss: 0.1488 - acc: 0.7964 - val_loss: 0.2279 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 308us/step - loss: 0.1477 - acc: 0.7964 - val_loss: 0.2247 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.1460 - acc: 0.8036 - val_loss: 0.2254 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 330us/step - loss: 0.1455 - acc: 0.8073 - val_loss: 0.2276 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 367us/step - loss: 0.1436 - acc: 0.8109 - val_loss: 0.2255 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 326us/step - loss: 0.1435 - acc: 0.8073 - val_loss: 0.2274 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 296us/step - loss: 0.1426 - acc: 0.8073 - val_loss: 0.2269 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 283us/step - loss: 0.1414 - acc: 0.8073 - val_loss: 0.2289 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 341us/step - loss: 0.1410 - acc: 0.8182 - val_loss: 0.2263 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 406us/step - loss: 0.1387 - acc: 0.8145 - val_loss: 0.2295 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 341us/step - loss: 0.1374 - acc: 0.8218 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.1369 - acc: 0.8145 - val_loss: 0.2315 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 268us/step - loss: 0.1359 - acc: 0.8291 - val_loss: 0.2278 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.1341 - acc: 0.8218 - val_loss: 0.2269 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.1336 - acc: 0.8255 - val_loss: 0.2315 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.1314 - acc: 0.8218 - val_loss: 0.2284 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.1312 - acc: 0.8327 - val_loss: 0.2262 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.1290 - acc: 0.8473 - val_loss: 0.2264 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 276us/step - loss: 0.1293 - acc: 0.8255 - val_loss: 0.2263 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.1271 - acc: 0.8436 - val_loss: 0.2270 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 312us/step - loss: 0.1258 - acc: 0.8436 - val_loss: 0.2263 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.1240 - acc: 0.8436 - val_loss: 0.2245 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1221 - acc: 0.8545 - val_loss: 0.2246 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1202 - acc: 0.8655 - val_loss: 0.2263 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1193 - acc: 0.8582 - val_loss: 0.2261 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1184 - acc: 0.8582 - val_loss: 0.2237 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1159 - acc: 0.8691 - val_loss: 0.2215 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 280us/step - loss: 0.1135 - acc: 0.8764 - val_loss: 0.2242 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.1122 - acc: 0.8727 - val_loss: 0.2231 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1101 - acc: 0.8727 - val_loss: 0.2264 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1088 - acc: 0.8800 - val_loss: 0.2255 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1063 - acc: 0.8800 - val_loss: 0.2249 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1044 - acc: 0.8873 - val_loss: 0.2238 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.1028 - acc: 0.8873 - val_loss: 0.2233 - val_acc: 0.7419\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1007 - acc: 0.8800 - val_loss: 0.2254 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.0977 - acc: 0.8982 - val_loss: 0.2257 - val_acc: 0.6129\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.0960 - acc: 0.8982 - val_loss: 0.2257 - val_acc: 0.6129\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 261us/step - loss: 0.0926 - acc: 0.9055 - val_loss: 0.2277 - val_acc: 0.6129\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.0903 - acc: 0.9055 - val_loss: 0.2300 - val_acc: 0.6452\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.0877 - acc: 0.9091 - val_loss: 0.2291 - val_acc: 0.6129\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 299us/step - loss: 0.0858 - acc: 0.9164 - val_loss: 0.2314 - val_acc: 0.6452\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 286us/step - loss: 0.0824 - acc: 0.9236 - val_loss: 0.2296 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 328us/step - loss: 0.0798 - acc: 0.9200 - val_loss: 0.2335 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.0787 - acc: 0.9273 - val_loss: 0.2345 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 309us/step - loss: 0.0750 - acc: 0.9345 - val_loss: 0.2344 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.0742 - acc: 0.9382 - val_loss: 0.2366 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.0703 - acc: 0.9309 - val_loss: 0.2346 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0712 - acc: 0.9273 - val_loss: 0.2360 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0689 - acc: 0.9345 - val_loss: 0.2362 - val_acc: 0.6129\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0627 - acc: 0.9491 - val_loss: 0.2361 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.0625 - acc: 0.9491 - val_loss: 0.2340 - val_acc: 0.6452\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.0592 - acc: 0.9564 - val_loss: 0.2420 - val_acc: 0.5806\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 262us/step - loss: 0.0583 - acc: 0.9527 - val_loss: 0.2488 - val_acc: 0.6129\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0594 - acc: 0.9491 - val_loss: 0.2410 - val_acc: 0.6452\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.0529 - acc: 0.9600 - val_loss: 0.2437 - val_acc: 0.6129\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.0521 - acc: 0.9600 - val_loss: 0.2393 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.0497 - acc: 0.9600 - val_loss: 0.2413 - val_acc: 0.6129\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.0474 - acc: 0.9636 - val_loss: 0.2450 - val_acc: 0.6129\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.0451 - acc: 0.9600 - val_loss: 0.2459 - val_acc: 0.6129\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.0427 - acc: 0.9673 - val_loss: 0.2529 - val_acc: 0.6129\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 262us/step - loss: 0.0406 - acc: 0.9709 - val_loss: 0.2543 - val_acc: 0.6129\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.0382 - acc: 0.9745 - val_loss: 0.2576 - val_acc: 0.5806\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.0362 - acc: 0.9745 - val_loss: 0.2601 - val_acc: 0.5806\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.0335 - acc: 0.9782 - val_loss: 0.2609 - val_acc: 0.5806\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 303us/step - loss: 0.0323 - acc: 0.9782 - val_loss: 0.2626 - val_acc: 0.5806\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.0312 - acc: 0.9782 - val_loss: 0.2704 - val_acc: 0.5806\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 278us/step - loss: 0.0295 - acc: 0.9818 - val_loss: 0.2661 - val_acc: 0.6129\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 298us/step - loss: 0.0281 - acc: 0.9818 - val_loss: 0.2722 - val_acc: 0.5806\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 279us/step - loss: 0.0266 - acc: 0.9818 - val_loss: 0.2716 - val_acc: 0.5806\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 285us/step - loss: 0.0246 - acc: 0.9855 - val_loss: 0.2729 - val_acc: 0.5806\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0237 - acc: 0.9855 - val_loss: 0.2671 - val_acc: 0.5806\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0237 - acc: 0.9855 - val_loss: 0.2716 - val_acc: 0.5806\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.0220 - acc: 0.9891 - val_loss: 0.2814 - val_acc: 0.5806\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0217 - acc: 0.9855 - val_loss: 0.2702 - val_acc: 0.5806\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0205 - acc: 0.9891 - val_loss: 0.2853 - val_acc: 0.5161\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0199 - acc: 0.9855 - val_loss: 0.2788 - val_acc: 0.5806\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0188 - acc: 0.9855 - val_loss: 0.2783 - val_acc: 0.5806\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.0183 - acc: 0.9891 - val_loss: 0.2872 - val_acc: 0.5806\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0175 - acc: 0.9891 - val_loss: 0.2836 - val_acc: 0.5806\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_91 (Dense)             (None, 37)                1443      \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 12)                456       \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,912\n",
      "Trainable params: 1,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 5ms/step - loss: 0.2500 - acc: 0.5309 - val_loss: 0.2500 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 345us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 404us/step - loss: 0.2490 - acc: 0.5418 - val_loss: 0.2486 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 359us/step - loss: 0.2466 - acc: 0.5636 - val_loss: 0.2444 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 328us/step - loss: 0.2392 - acc: 0.7127 - val_loss: 0.2366 - val_acc: 0.6129\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 300us/step - loss: 0.2262 - acc: 0.7055 - val_loss: 0.2232 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 296us/step - loss: 0.2078 - acc: 0.7382 - val_loss: 0.2105 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 302us/step - loss: 0.1911 - acc: 0.7455 - val_loss: 0.2019 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 319us/step - loss: 0.1776 - acc: 0.7673 - val_loss: 0.2028 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 310us/step - loss: 0.1683 - acc: 0.7673 - val_loss: 0.2051 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 429us/step - loss: 0.1627 - acc: 0.7636 - val_loss: 0.2013 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 409us/step - loss: 0.1608 - acc: 0.7709 - val_loss: 0.2045 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 365us/step - loss: 0.1566 - acc: 0.7818 - val_loss: 0.2088 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 374us/step - loss: 0.1545 - acc: 0.7891 - val_loss: 0.2102 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 352us/step - loss: 0.1529 - acc: 0.7927 - val_loss: 0.2123 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 350us/step - loss: 0.1507 - acc: 0.7964 - val_loss: 0.2129 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 353us/step - loss: 0.1519 - acc: 0.7818 - val_loss: 0.2126 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 394us/step - loss: 0.1469 - acc: 0.8073 - val_loss: 0.2142 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 316us/step - loss: 0.1453 - acc: 0.8182 - val_loss: 0.2190 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 322us/step - loss: 0.1439 - acc: 0.8218 - val_loss: 0.2225 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 355us/step - loss: 0.1425 - acc: 0.8291 - val_loss: 0.2195 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 289us/step - loss: 0.1398 - acc: 0.8255 - val_loss: 0.2187 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 371us/step - loss: 0.1372 - acc: 0.8327 - val_loss: 0.2193 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 358us/step - loss: 0.1364 - acc: 0.8255 - val_loss: 0.2212 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 361us/step - loss: 0.1336 - acc: 0.8400 - val_loss: 0.2218 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 370us/step - loss: 0.1322 - acc: 0.8473 - val_loss: 0.2217 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 334us/step - loss: 0.1301 - acc: 0.8400 - val_loss: 0.2248 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 313us/step - loss: 0.1286 - acc: 0.8509 - val_loss: 0.2216 - val_acc: 0.7419\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 299us/step - loss: 0.1263 - acc: 0.8436 - val_loss: 0.2235 - val_acc: 0.7419\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 310us/step - loss: 0.1245 - acc: 0.8436 - val_loss: 0.2239 - val_acc: 0.7419\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 293us/step - loss: 0.1218 - acc: 0.8618 - val_loss: 0.2234 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 305us/step - loss: 0.1191 - acc: 0.8618 - val_loss: 0.2205 - val_acc: 0.7419\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 295us/step - loss: 0.1174 - acc: 0.8691 - val_loss: 0.2240 - val_acc: 0.7419\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.1147 - acc: 0.8727 - val_loss: 0.2231 - val_acc: 0.7419\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 322us/step - loss: 0.1125 - acc: 0.8764 - val_loss: 0.2223 - val_acc: 0.7419\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 303us/step - loss: 0.1099 - acc: 0.8727 - val_loss: 0.2243 - val_acc: 0.7419\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 318us/step - loss: 0.1068 - acc: 0.8800 - val_loss: 0.2249 - val_acc: 0.7419\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 297us/step - loss: 0.1040 - acc: 0.8800 - val_loss: 0.2283 - val_acc: 0.7419\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 314us/step - loss: 0.1014 - acc: 0.8800 - val_loss: 0.2251 - val_acc: 0.7419\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 341us/step - loss: 0.0998 - acc: 0.8945 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 348us/step - loss: 0.0969 - acc: 0.8909 - val_loss: 0.2302 - val_acc: 0.7419\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 346us/step - loss: 0.0907 - acc: 0.9055 - val_loss: 0.2252 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 367us/step - loss: 0.0901 - acc: 0.9018 - val_loss: 0.2285 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 369us/step - loss: 0.0859 - acc: 0.9200 - val_loss: 0.2281 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 322us/step - loss: 0.0817 - acc: 0.9091 - val_loss: 0.2260 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 406us/step - loss: 0.0796 - acc: 0.9309 - val_loss: 0.2369 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 406us/step - loss: 0.0742 - acc: 0.9418 - val_loss: 0.2294 - val_acc: 0.6452\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 377us/step - loss: 0.0708 - acc: 0.9455 - val_loss: 0.2276 - val_acc: 0.6452\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 368us/step - loss: 0.0666 - acc: 0.9527 - val_loss: 0.2297 - val_acc: 0.6129\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 349us/step - loss: 0.0634 - acc: 0.9491 - val_loss: 0.2292 - val_acc: 0.6452\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 341us/step - loss: 0.0606 - acc: 0.9564 - val_loss: 0.2263 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 308us/step - loss: 0.0571 - acc: 0.9636 - val_loss: 0.2258 - val_acc: 0.6129\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.0536 - acc: 0.9600 - val_loss: 0.2268 - val_acc: 0.6452\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 356us/step - loss: 0.0500 - acc: 0.9636 - val_loss: 0.2309 - val_acc: 0.6452\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 363us/step - loss: 0.0456 - acc: 0.9745 - val_loss: 0.2324 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 377us/step - loss: 0.0440 - acc: 0.9745 - val_loss: 0.2289 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 349us/step - loss: 0.0413 - acc: 0.9782 - val_loss: 0.2288 - val_acc: 0.6452\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 362us/step - loss: 0.0381 - acc: 0.9818 - val_loss: 0.2308 - val_acc: 0.6452\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 413us/step - loss: 0.0346 - acc: 0.9855 - val_loss: 0.2302 - val_acc: 0.6452\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 301us/step - loss: 0.0329 - acc: 0.9818 - val_loss: 0.2359 - val_acc: 0.6452\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 297us/step - loss: 0.0295 - acc: 0.9855 - val_loss: 0.2365 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 301us/step - loss: 0.0289 - acc: 0.9855 - val_loss: 0.2384 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 304us/step - loss: 0.0261 - acc: 0.9927 - val_loss: 0.2422 - val_acc: 0.6129\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 317us/step - loss: 0.0243 - acc: 0.9927 - val_loss: 0.2357 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 341us/step - loss: 0.0225 - acc: 0.9927 - val_loss: 0.2459 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 311us/step - loss: 0.0212 - acc: 0.9927 - val_loss: 0.2361 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 310us/step - loss: 0.0199 - acc: 0.9927 - val_loss: 0.2422 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 312us/step - loss: 0.0183 - acc: 0.9927 - val_loss: 0.2437 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.0173 - acc: 0.9927 - val_loss: 0.2445 - val_acc: 0.6129\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 286us/step - loss: 0.0166 - acc: 0.9927 - val_loss: 0.2481 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 277us/step - loss: 0.0157 - acc: 0.9927 - val_loss: 0.2478 - val_acc: 0.6129\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.0151 - acc: 0.9927 - val_loss: 0.2473 - val_acc: 0.6129\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.0142 - acc: 0.9927 - val_loss: 0.2524 - val_acc: 0.6129\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 373us/step - loss: 0.0136 - acc: 0.9927 - val_loss: 0.2525 - val_acc: 0.6452\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.0131 - acc: 0.9927 - val_loss: 0.2511 - val_acc: 0.6129\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 281us/step - loss: 0.0126 - acc: 0.9927 - val_loss: 0.2543 - val_acc: 0.5806\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 350us/step - loss: 0.0119 - acc: 0.9927 - val_loss: 0.2529 - val_acc: 0.6452\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 327us/step - loss: 0.0116 - acc: 0.9927 - val_loss: 0.2519 - val_acc: 0.6129\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.0110 - acc: 0.9927 - val_loss: 0.2552 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 301us/step - loss: 0.0105 - acc: 0.9927 - val_loss: 0.2560 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.0104 - acc: 0.9927 - val_loss: 0.2559 - val_acc: 0.5806\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.0093 - acc: 0.9964 - val_loss: 0.2550 - val_acc: 0.5806\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 302us/step - loss: 0.0087 - acc: 0.9964 - val_loss: 0.2579 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 308us/step - loss: 0.0078 - acc: 0.9964 - val_loss: 0.2572 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 284us/step - loss: 0.0061 - acc: 0.9964 - val_loss: 0.2573 - val_acc: 0.6129\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.2605 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 293us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.2644 - val_acc: 0.6452\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.2646 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.2629 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.2651 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.2655 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 284us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.2673 - val_acc: 0.6129\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 297us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.2690 - val_acc: 0.6129\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.2669 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.2688 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.2733 - val_acc: 0.5806\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.2714 - val_acc: 0.5806\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 281us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.2731 - val_acc: 0.5806\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 319us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2729 - val_acc: 0.6129\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 366us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.2728 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_94 (Dense)             (None, 14)                546       \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 20)                300       \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 867\n",
      "Trainable params: 867\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 5ms/step - loss: 0.2499 - acc: 0.5382 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 296us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.2489 - acc: 0.5418 - val_loss: 0.2488 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.2464 - acc: 0.5418 - val_loss: 0.2451 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 279us/step - loss: 0.2400 - acc: 0.5418 - val_loss: 0.2389 - val_acc: 0.5161\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 329us/step - loss: 0.2311 - acc: 0.5418 - val_loss: 0.2318 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 315us/step - loss: 0.2197 - acc: 0.6364 - val_loss: 0.2266 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 314us/step - loss: 0.2110 - acc: 0.6945 - val_loss: 0.2230 - val_acc: 0.6129\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.2029 - acc: 0.7345 - val_loss: 0.2196 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1957 - acc: 0.7491 - val_loss: 0.2185 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1892 - acc: 0.7455 - val_loss: 0.2159 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.1834 - acc: 0.7636 - val_loss: 0.2173 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.1783 - acc: 0.7491 - val_loss: 0.2138 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 300us/step - loss: 0.1739 - acc: 0.7636 - val_loss: 0.2148 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 374us/step - loss: 0.1701 - acc: 0.7782 - val_loss: 0.2132 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 331us/step - loss: 0.1666 - acc: 0.7818 - val_loss: 0.2111 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 311us/step - loss: 0.1644 - acc: 0.7855 - val_loss: 0.2127 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 276us/step - loss: 0.1609 - acc: 0.7891 - val_loss: 0.2119 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.1591 - acc: 0.7927 - val_loss: 0.2142 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.1580 - acc: 0.7964 - val_loss: 0.2167 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.1556 - acc: 0.7855 - val_loss: 0.2176 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1546 - acc: 0.8036 - val_loss: 0.2140 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.1539 - acc: 0.7927 - val_loss: 0.2171 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1523 - acc: 0.8000 - val_loss: 0.2234 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1513 - acc: 0.7964 - val_loss: 0.2212 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1502 - acc: 0.8073 - val_loss: 0.2242 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.1505 - acc: 0.8036 - val_loss: 0.2242 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1484 - acc: 0.8145 - val_loss: 0.2229 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1482 - acc: 0.8073 - val_loss: 0.2251 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1473 - acc: 0.8073 - val_loss: 0.2239 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 287us/step - loss: 0.1468 - acc: 0.8145 - val_loss: 0.2249 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 261us/step - loss: 0.1460 - acc: 0.8145 - val_loss: 0.2284 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.1454 - acc: 0.8073 - val_loss: 0.2283 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1447 - acc: 0.8145 - val_loss: 0.2290 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.1437 - acc: 0.8145 - val_loss: 0.2311 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 337us/step - loss: 0.1425 - acc: 0.8182 - val_loss: 0.2311 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 380us/step - loss: 0.1425 - acc: 0.8145 - val_loss: 0.2315 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 363us/step - loss: 0.1413 - acc: 0.8145 - val_loss: 0.2326 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 306us/step - loss: 0.1402 - acc: 0.8218 - val_loss: 0.2363 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 287us/step - loss: 0.1398 - acc: 0.8109 - val_loss: 0.2355 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 302us/step - loss: 0.1383 - acc: 0.8182 - val_loss: 0.2332 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 295us/step - loss: 0.1381 - acc: 0.8255 - val_loss: 0.2348 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 278us/step - loss: 0.1373 - acc: 0.8218 - val_loss: 0.2350 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 311us/step - loss: 0.1372 - acc: 0.8291 - val_loss: 0.2373 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 314us/step - loss: 0.1359 - acc: 0.8218 - val_loss: 0.2386 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 278us/step - loss: 0.1349 - acc: 0.8218 - val_loss: 0.2369 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 308us/step - loss: 0.1345 - acc: 0.8364 - val_loss: 0.2376 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 332us/step - loss: 0.1335 - acc: 0.8255 - val_loss: 0.2404 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 329us/step - loss: 0.1330 - acc: 0.8327 - val_loss: 0.2377 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 356us/step - loss: 0.1331 - acc: 0.8400 - val_loss: 0.2406 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 307us/step - loss: 0.1315 - acc: 0.8364 - val_loss: 0.2423 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1317 - acc: 0.8473 - val_loss: 0.2440 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.1315 - acc: 0.8436 - val_loss: 0.2409 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.1300 - acc: 0.8436 - val_loss: 0.2407 - val_acc: 0.7097\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.1306 - acc: 0.8400 - val_loss: 0.2416 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.1290 - acc: 0.8509 - val_loss: 0.2408 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1283 - acc: 0.8509 - val_loss: 0.2402 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.1262 - acc: 0.8582 - val_loss: 0.2426 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1260 - acc: 0.8618 - val_loss: 0.2416 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.1252 - acc: 0.8545 - val_loss: 0.2437 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1240 - acc: 0.8691 - val_loss: 0.2424 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.1226 - acc: 0.8655 - val_loss: 0.2432 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1223 - acc: 0.8691 - val_loss: 0.2427 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1212 - acc: 0.8691 - val_loss: 0.2439 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1214 - acc: 0.8727 - val_loss: 0.2431 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.1204 - acc: 0.8655 - val_loss: 0.2417 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.1199 - acc: 0.8764 - val_loss: 0.2427 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.1183 - acc: 0.8764 - val_loss: 0.2426 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1174 - acc: 0.8727 - val_loss: 0.2384 - val_acc: 0.7097\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1170 - acc: 0.8800 - val_loss: 0.2428 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1157 - acc: 0.8836 - val_loss: 0.2358 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1151 - acc: 0.8764 - val_loss: 0.2409 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.1140 - acc: 0.8764 - val_loss: 0.2395 - val_acc: 0.7097\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.1131 - acc: 0.8800 - val_loss: 0.2353 - val_acc: 0.7097\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1115 - acc: 0.8836 - val_loss: 0.2384 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.1119 - acc: 0.8800 - val_loss: 0.2334 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1122 - acc: 0.8836 - val_loss: 0.2357 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1092 - acc: 0.8836 - val_loss: 0.2346 - val_acc: 0.7097\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1079 - acc: 0.8836 - val_loss: 0.2350 - val_acc: 0.7097\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1066 - acc: 0.8873 - val_loss: 0.2368 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.1065 - acc: 0.8873 - val_loss: 0.2356 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.1045 - acc: 0.8909 - val_loss: 0.2342 - val_acc: 0.7097\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 288us/step - loss: 0.1033 - acc: 0.8836 - val_loss: 0.2347 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.1029 - acc: 0.8982 - val_loss: 0.2363 - val_acc: 0.7097\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1017 - acc: 0.8945 - val_loss: 0.2330 - val_acc: 0.7097\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1012 - acc: 0.8982 - val_loss: 0.2311 - val_acc: 0.7097\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0997 - acc: 0.8982 - val_loss: 0.2297 - val_acc: 0.7097\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0980 - acc: 0.9055 - val_loss: 0.2313 - val_acc: 0.7419\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0974 - acc: 0.8982 - val_loss: 0.2313 - val_acc: 0.7097\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0971 - acc: 0.9055 - val_loss: 0.2312 - val_acc: 0.7097\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0955 - acc: 0.9055 - val_loss: 0.2316 - val_acc: 0.7097\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0942 - acc: 0.9055 - val_loss: 0.2307 - val_acc: 0.7097\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 221us/step - loss: 0.0932 - acc: 0.9091 - val_loss: 0.2309 - val_acc: 0.7097\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0930 - acc: 0.9055 - val_loss: 0.2296 - val_acc: 0.7097\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0916 - acc: 0.9091 - val_loss: 0.2275 - val_acc: 0.7097\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0905 - acc: 0.9055 - val_loss: 0.2282 - val_acc: 0.7097\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0898 - acc: 0.9055 - val_loss: 0.2214 - val_acc: 0.7097\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0889 - acc: 0.9091 - val_loss: 0.2253 - val_acc: 0.7097\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 300us/step - loss: 0.0875 - acc: 0.9091 - val_loss: 0.2244 - val_acc: 0.7097\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 277us/step - loss: 0.0867 - acc: 0.9091 - val_loss: 0.2209 - val_acc: 0.7097\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_97 (Dense)             (None, 26)                1014      \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 13)                351       \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 1,379\n",
      "Trainable params: 1,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 4ms/step - loss: 0.2499 - acc: 0.5273 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.2490 - acc: 0.5418 - val_loss: 0.2487 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.2469 - acc: 0.5418 - val_loss: 0.2454 - val_acc: 0.5484\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.2411 - acc: 0.6109 - val_loss: 0.2384 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.2300 - acc: 0.6873 - val_loss: 0.2278 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.2146 - acc: 0.7127 - val_loss: 0.2154 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.1980 - acc: 0.7273 - val_loss: 0.2074 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1848 - acc: 0.7418 - val_loss: 0.2040 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1764 - acc: 0.7527 - val_loss: 0.1986 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 213us/step - loss: 0.1706 - acc: 0.7455 - val_loss: 0.2043 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.1660 - acc: 0.7636 - val_loss: 0.2020 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.1633 - acc: 0.7709 - val_loss: 0.2074 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.1612 - acc: 0.7709 - val_loss: 0.2061 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 353us/step - loss: 0.1592 - acc: 0.7564 - val_loss: 0.2085 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 329us/step - loss: 0.1588 - acc: 0.7636 - val_loss: 0.2125 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 350us/step - loss: 0.1564 - acc: 0.7855 - val_loss: 0.2121 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 387us/step - loss: 0.1566 - acc: 0.7745 - val_loss: 0.2122 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 306us/step - loss: 0.1547 - acc: 0.7891 - val_loss: 0.2171 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.1535 - acc: 0.7891 - val_loss: 0.2207 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1522 - acc: 0.8000 - val_loss: 0.2171 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1523 - acc: 0.8000 - val_loss: 0.2190 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.1504 - acc: 0.7964 - val_loss: 0.2194 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1498 - acc: 0.8036 - val_loss: 0.2212 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 276us/step - loss: 0.1493 - acc: 0.8036 - val_loss: 0.2221 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.1480 - acc: 0.8036 - val_loss: 0.2222 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.1476 - acc: 0.8073 - val_loss: 0.2204 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.1468 - acc: 0.8036 - val_loss: 0.2205 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 315us/step - loss: 0.1478 - acc: 0.7891 - val_loss: 0.2230 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.1453 - acc: 0.8145 - val_loss: 0.2212 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.1440 - acc: 0.8109 - val_loss: 0.2222 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 283us/step - loss: 0.1428 - acc: 0.8073 - val_loss: 0.2216 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 312us/step - loss: 0.1426 - acc: 0.8182 - val_loss: 0.2200 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 350us/step - loss: 0.1419 - acc: 0.8109 - val_loss: 0.2205 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.1411 - acc: 0.8073 - val_loss: 0.2228 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1398 - acc: 0.8327 - val_loss: 0.2248 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1389 - acc: 0.8218 - val_loss: 0.2231 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 295us/step - loss: 0.1386 - acc: 0.8218 - val_loss: 0.2253 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1366 - acc: 0.8255 - val_loss: 0.2254 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.1361 - acc: 0.8291 - val_loss: 0.2247 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.1339 - acc: 0.8364 - val_loss: 0.2255 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1350 - acc: 0.8182 - val_loss: 0.2259 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.1321 - acc: 0.8327 - val_loss: 0.2246 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1308 - acc: 0.8291 - val_loss: 0.2243 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 214us/step - loss: 0.1296 - acc: 0.8364 - val_loss: 0.2232 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1293 - acc: 0.8364 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1276 - acc: 0.8364 - val_loss: 0.2281 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1258 - acc: 0.8436 - val_loss: 0.2267 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1247 - acc: 0.8436 - val_loss: 0.2267 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1229 - acc: 0.8509 - val_loss: 0.2240 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1222 - acc: 0.8509 - val_loss: 0.2260 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 279us/step - loss: 0.1205 - acc: 0.8509 - val_loss: 0.2235 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.1193 - acc: 0.8509 - val_loss: 0.2243 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.1179 - acc: 0.8691 - val_loss: 0.2266 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.1150 - acc: 0.8727 - val_loss: 0.2248 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.1138 - acc: 0.8727 - val_loss: 0.2255 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1123 - acc: 0.8836 - val_loss: 0.2234 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.1102 - acc: 0.8836 - val_loss: 0.2245 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1096 - acc: 0.8873 - val_loss: 0.2266 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1076 - acc: 0.8873 - val_loss: 0.2270 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1048 - acc: 0.8982 - val_loss: 0.2261 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1040 - acc: 0.9018 - val_loss: 0.2281 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1017 - acc: 0.8800 - val_loss: 0.2277 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1007 - acc: 0.9018 - val_loss: 0.2268 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0976 - acc: 0.8945 - val_loss: 0.2235 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0947 - acc: 0.8945 - val_loss: 0.2257 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0924 - acc: 0.9055 - val_loss: 0.2248 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0902 - acc: 0.9055 - val_loss: 0.2243 - val_acc: 0.6129\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0889 - acc: 0.9055 - val_loss: 0.2195 - val_acc: 0.6129\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0874 - acc: 0.9055 - val_loss: 0.2251 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0835 - acc: 0.9127 - val_loss: 0.2231 - val_acc: 0.6129\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.0808 - acc: 0.9236 - val_loss: 0.2278 - val_acc: 0.6129\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.0783 - acc: 0.9200 - val_loss: 0.2225 - val_acc: 0.5806\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.0757 - acc: 0.9382 - val_loss: 0.2224 - val_acc: 0.6129\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.0730 - acc: 0.9309 - val_loss: 0.2212 - val_acc: 0.5806\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0709 - acc: 0.9418 - val_loss: 0.2274 - val_acc: 0.5806\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0674 - acc: 0.9455 - val_loss: 0.2284 - val_acc: 0.5806\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0639 - acc: 0.9491 - val_loss: 0.2301 - val_acc: 0.5806\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0619 - acc: 0.9564 - val_loss: 0.2315 - val_acc: 0.5806\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0617 - acc: 0.9564 - val_loss: 0.2272 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0590 - acc: 0.9600 - val_loss: 0.2338 - val_acc: 0.5806\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0547 - acc: 0.9527 - val_loss: 0.2404 - val_acc: 0.5806\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.0509 - acc: 0.9709 - val_loss: 0.2388 - val_acc: 0.5484\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.0492 - acc: 0.9709 - val_loss: 0.2344 - val_acc: 0.5484\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0479 - acc: 0.9709 - val_loss: 0.2437 - val_acc: 0.5806\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0450 - acc: 0.9709 - val_loss: 0.2520 - val_acc: 0.5806\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0420 - acc: 0.9745 - val_loss: 0.2470 - val_acc: 0.5484\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0441 - acc: 0.9636 - val_loss: 0.2478 - val_acc: 0.5484\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0389 - acc: 0.9782 - val_loss: 0.2482 - val_acc: 0.6129\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0373 - acc: 0.9855 - val_loss: 0.2527 - val_acc: 0.5806\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.0350 - acc: 0.9818 - val_loss: 0.2546 - val_acc: 0.6129\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0328 - acc: 0.9891 - val_loss: 0.2552 - val_acc: 0.5806\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0326 - acc: 0.9927 - val_loss: 0.2581 - val_acc: 0.6129\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0316 - acc: 0.9855 - val_loss: 0.2615 - val_acc: 0.5484\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0323 - acc: 0.9818 - val_loss: 0.2669 - val_acc: 0.5484\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0289 - acc: 0.9927 - val_loss: 0.2672 - val_acc: 0.5484\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0271 - acc: 0.9927 - val_loss: 0.2675 - val_acc: 0.5806\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0253 - acc: 0.9927 - val_loss: 0.2643 - val_acc: 0.5806\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0244 - acc: 0.9927 - val_loss: 0.2671 - val_acc: 0.6129\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0239 - acc: 0.9927 - val_loss: 0.2701 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_100 (Dense)            (None, 26)                1014      \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 12)                324       \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,351\n",
      "Trainable params: 1,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 4ms/step - loss: 0.2499 - acc: 0.5273 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 195us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2494 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.2484 - acc: 0.5673 - val_loss: 0.2471 - val_acc: 0.6452\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.2444 - acc: 0.6182 - val_loss: 0.2418 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.2346 - acc: 0.7018 - val_loss: 0.2312 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.2195 - acc: 0.7273 - val_loss: 0.2178 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.2009 - acc: 0.7418 - val_loss: 0.2077 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1857 - acc: 0.7564 - val_loss: 0.2020 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1765 - acc: 0.7382 - val_loss: 0.2014 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.1687 - acc: 0.7636 - val_loss: 0.2011 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1657 - acc: 0.7527 - val_loss: 0.2038 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1619 - acc: 0.7673 - val_loss: 0.2069 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1593 - acc: 0.7709 - val_loss: 0.2093 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1573 - acc: 0.7709 - val_loss: 0.2121 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1568 - acc: 0.7891 - val_loss: 0.2136 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1552 - acc: 0.7745 - val_loss: 0.2164 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 183us/step - loss: 0.1531 - acc: 0.7964 - val_loss: 0.2156 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1511 - acc: 0.7818 - val_loss: 0.2176 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1505 - acc: 0.8000 - val_loss: 0.2193 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 182us/step - loss: 0.1508 - acc: 0.7927 - val_loss: 0.2211 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.1489 - acc: 0.8073 - val_loss: 0.2218 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 190us/step - loss: 0.1478 - acc: 0.8073 - val_loss: 0.2195 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.1464 - acc: 0.8073 - val_loss: 0.2219 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1445 - acc: 0.8182 - val_loss: 0.2240 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.1433 - acc: 0.8218 - val_loss: 0.2223 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 185us/step - loss: 0.1420 - acc: 0.8109 - val_loss: 0.2242 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1427 - acc: 0.7964 - val_loss: 0.2233 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1393 - acc: 0.8291 - val_loss: 0.2257 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1385 - acc: 0.8182 - val_loss: 0.2255 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1387 - acc: 0.8291 - val_loss: 0.2236 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1361 - acc: 0.8327 - val_loss: 0.2243 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.1348 - acc: 0.8327 - val_loss: 0.2256 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.1343 - acc: 0.8255 - val_loss: 0.2274 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.1333 - acc: 0.8291 - val_loss: 0.2305 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1314 - acc: 0.8327 - val_loss: 0.2295 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1298 - acc: 0.8364 - val_loss: 0.2301 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1281 - acc: 0.8364 - val_loss: 0.2314 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1275 - acc: 0.8436 - val_loss: 0.2315 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1259 - acc: 0.8364 - val_loss: 0.2312 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 215us/step - loss: 0.1252 - acc: 0.8436 - val_loss: 0.2317 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1239 - acc: 0.8509 - val_loss: 0.2312 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1205 - acc: 0.8655 - val_loss: 0.2302 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.1191 - acc: 0.8618 - val_loss: 0.2322 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1187 - acc: 0.8473 - val_loss: 0.2330 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1160 - acc: 0.8909 - val_loss: 0.2341 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1146 - acc: 0.8618 - val_loss: 0.2367 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1130 - acc: 0.8800 - val_loss: 0.2337 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1108 - acc: 0.9018 - val_loss: 0.2331 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1101 - acc: 0.8836 - val_loss: 0.2342 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.1074 - acc: 0.8909 - val_loss: 0.2362 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.1045 - acc: 0.9091 - val_loss: 0.2359 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 213us/step - loss: 0.1028 - acc: 0.9055 - val_loss: 0.2378 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1007 - acc: 0.9091 - val_loss: 0.2354 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.0978 - acc: 0.9127 - val_loss: 0.2393 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0966 - acc: 0.9091 - val_loss: 0.2361 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0939 - acc: 0.9091 - val_loss: 0.2390 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0917 - acc: 0.9200 - val_loss: 0.2366 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.0891 - acc: 0.9164 - val_loss: 0.2359 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0868 - acc: 0.9164 - val_loss: 0.2350 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0849 - acc: 0.9236 - val_loss: 0.2370 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0845 - acc: 0.9309 - val_loss: 0.2401 - val_acc: 0.6774\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 206us/step - loss: 0.0820 - acc: 0.9345 - val_loss: 0.2412 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0784 - acc: 0.9309 - val_loss: 0.2404 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0777 - acc: 0.9345 - val_loss: 0.2405 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0745 - acc: 0.9273 - val_loss: 0.2439 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0726 - acc: 0.9382 - val_loss: 0.2402 - val_acc: 0.6129\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.0708 - acc: 0.9418 - val_loss: 0.2390 - val_acc: 0.6129\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0679 - acc: 0.9418 - val_loss: 0.2403 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0669 - acc: 0.9455 - val_loss: 0.2430 - val_acc: 0.5806\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 189us/step - loss: 0.0645 - acc: 0.9455 - val_loss: 0.2396 - val_acc: 0.5806\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0627 - acc: 0.9491 - val_loss: 0.2419 - val_acc: 0.6129\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0603 - acc: 0.9491 - val_loss: 0.2460 - val_acc: 0.5484\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0586 - acc: 0.9527 - val_loss: 0.2404 - val_acc: 0.5806\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0569 - acc: 0.9564 - val_loss: 0.2428 - val_acc: 0.5484\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0548 - acc: 0.9527 - val_loss: 0.2424 - val_acc: 0.5484\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 187us/step - loss: 0.0534 - acc: 0.9564 - val_loss: 0.2439 - val_acc: 0.5484\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0536 - acc: 0.9527 - val_loss: 0.2540 - val_acc: 0.5484\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0497 - acc: 0.9600 - val_loss: 0.2442 - val_acc: 0.5484\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.0469 - acc: 0.9636 - val_loss: 0.2458 - val_acc: 0.5806\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0450 - acc: 0.9673 - val_loss: 0.2474 - val_acc: 0.5484\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0429 - acc: 0.9709 - val_loss: 0.2542 - val_acc: 0.5484\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0412 - acc: 0.9673 - val_loss: 0.2525 - val_acc: 0.5484\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0400 - acc: 0.9673 - val_loss: 0.2448 - val_acc: 0.6129\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0388 - acc: 0.9709 - val_loss: 0.2439 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0379 - acc: 0.9745 - val_loss: 0.2593 - val_acc: 0.5484\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0341 - acc: 0.9745 - val_loss: 0.2541 - val_acc: 0.5484\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0326 - acc: 0.9782 - val_loss: 0.2500 - val_acc: 0.6452\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0327 - acc: 0.9782 - val_loss: 0.2590 - val_acc: 0.5806\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.0296 - acc: 0.9818 - val_loss: 0.2526 - val_acc: 0.6129\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0284 - acc: 0.9855 - val_loss: 0.2612 - val_acc: 0.6129\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0271 - acc: 0.9855 - val_loss: 0.2595 - val_acc: 0.6129\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0246 - acc: 0.9855 - val_loss: 0.2591 - val_acc: 0.6129\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0235 - acc: 0.9891 - val_loss: 0.2571 - val_acc: 0.6129\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0223 - acc: 0.9927 - val_loss: 0.2657 - val_acc: 0.5484\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 184us/step - loss: 0.0209 - acc: 0.9927 - val_loss: 0.2678 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 188us/step - loss: 0.0205 - acc: 0.9891 - val_loss: 0.2658 - val_acc: 0.6129\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0198 - acc: 0.9927 - val_loss: 0.2661 - val_acc: 0.6129\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 186us/step - loss: 0.0187 - acc: 0.9927 - val_loss: 0.2678 - val_acc: 0.6129\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0174 - acc: 0.9927 - val_loss: 0.2786 - val_acc: 0.5806\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0166 - acc: 0.9927 - val_loss: 0.2663 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_103 (Dense)            (None, 35)                1365      \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 14)                504       \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 1,884\n",
      "Trainable params: 1,884\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 5ms/step - loss: 0.2499 - acc: 0.5345 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.2495 - acc: 0.5418 - val_loss: 0.2494 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.2483 - acc: 0.5418 - val_loss: 0.2470 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.2439 - acc: 0.5564 - val_loss: 0.2412 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.2333 - acc: 0.6436 - val_loss: 0.2295 - val_acc: 0.6129\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.2165 - acc: 0.7127 - val_loss: 0.2180 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.2004 - acc: 0.7273 - val_loss: 0.2071 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1858 - acc: 0.7673 - val_loss: 0.2054 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1747 - acc: 0.7491 - val_loss: 0.2029 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1673 - acc: 0.7673 - val_loss: 0.2076 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1627 - acc: 0.7673 - val_loss: 0.2056 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1598 - acc: 0.7782 - val_loss: 0.2091 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.1574 - acc: 0.7782 - val_loss: 0.2095 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1551 - acc: 0.7964 - val_loss: 0.2158 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.1529 - acc: 0.7818 - val_loss: 0.2182 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.1500 - acc: 0.8000 - val_loss: 0.2199 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1490 - acc: 0.8000 - val_loss: 0.2218 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1472 - acc: 0.8036 - val_loss: 0.2219 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 191us/step - loss: 0.1465 - acc: 0.8109 - val_loss: 0.2236 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1440 - acc: 0.8145 - val_loss: 0.2251 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1428 - acc: 0.8182 - val_loss: 0.2242 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1412 - acc: 0.8182 - val_loss: 0.2251 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1403 - acc: 0.8000 - val_loss: 0.2245 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1367 - acc: 0.8255 - val_loss: 0.2241 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1357 - acc: 0.8218 - val_loss: 0.2269 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.1344 - acc: 0.8400 - val_loss: 0.2311 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.1329 - acc: 0.8291 - val_loss: 0.2276 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.1298 - acc: 0.8473 - val_loss: 0.2279 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.1281 - acc: 0.8364 - val_loss: 0.2267 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1264 - acc: 0.8473 - val_loss: 0.2293 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1258 - acc: 0.8436 - val_loss: 0.2269 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1219 - acc: 0.8436 - val_loss: 0.2275 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.1206 - acc: 0.8400 - val_loss: 0.2279 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 262us/step - loss: 0.1188 - acc: 0.8545 - val_loss: 0.2291 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1161 - acc: 0.8473 - val_loss: 0.2313 - val_acc: 0.6452\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1145 - acc: 0.8618 - val_loss: 0.2291 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1124 - acc: 0.8764 - val_loss: 0.2273 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1083 - acc: 0.8764 - val_loss: 0.2313 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1062 - acc: 0.8836 - val_loss: 0.2292 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1031 - acc: 0.8836 - val_loss: 0.2344 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1014 - acc: 0.8836 - val_loss: 0.2360 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1015 - acc: 0.8909 - val_loss: 0.2355 - val_acc: 0.6129\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0955 - acc: 0.8982 - val_loss: 0.2313 - val_acc: 0.6452\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0922 - acc: 0.9127 - val_loss: 0.2299 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0891 - acc: 0.9055 - val_loss: 0.2288 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.0858 - acc: 0.9164 - val_loss: 0.2331 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.0828 - acc: 0.9236 - val_loss: 0.2300 - val_acc: 0.6452\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0808 - acc: 0.9164 - val_loss: 0.2334 - val_acc: 0.6452\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.0785 - acc: 0.9236 - val_loss: 0.2343 - val_acc: 0.6452\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0759 - acc: 0.9309 - val_loss: 0.2321 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0742 - acc: 0.9309 - val_loss: 0.2429 - val_acc: 0.6452\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0706 - acc: 0.9345 - val_loss: 0.2324 - val_acc: 0.6452\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0669 - acc: 0.9382 - val_loss: 0.2323 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0653 - acc: 0.9491 - val_loss: 0.2380 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0617 - acc: 0.9527 - val_loss: 0.2352 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.0605 - acc: 0.9527 - val_loss: 0.2408 - val_acc: 0.6129\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0567 - acc: 0.9564 - val_loss: 0.2387 - val_acc: 0.6452\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0524 - acc: 0.9636 - val_loss: 0.2420 - val_acc: 0.6129\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0514 - acc: 0.9673 - val_loss: 0.2373 - val_acc: 0.6129\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0484 - acc: 0.9709 - val_loss: 0.2374 - val_acc: 0.6452\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0459 - acc: 0.9745 - val_loss: 0.2403 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0430 - acc: 0.9782 - val_loss: 0.2475 - val_acc: 0.6129\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0397 - acc: 0.9782 - val_loss: 0.2487 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0375 - acc: 0.9782 - val_loss: 0.2438 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0368 - acc: 0.9782 - val_loss: 0.2501 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0360 - acc: 0.9818 - val_loss: 0.2481 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0326 - acc: 0.9855 - val_loss: 0.2471 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0301 - acc: 0.9818 - val_loss: 0.2501 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0285 - acc: 0.9855 - val_loss: 0.2480 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0276 - acc: 0.9927 - val_loss: 0.2535 - val_acc: 0.6129\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0244 - acc: 0.9891 - val_loss: 0.2501 - val_acc: 0.6129\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0223 - acc: 0.9855 - val_loss: 0.2508 - val_acc: 0.6129\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0197 - acc: 0.9891 - val_loss: 0.2530 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.0182 - acc: 0.9964 - val_loss: 0.2554 - val_acc: 0.6452\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.0160 - acc: 0.9927 - val_loss: 0.2571 - val_acc: 0.6129\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.2603 - val_acc: 0.6774\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 257us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.2577 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.2624 - val_acc: 0.6129\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.2592 - val_acc: 0.6129\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.2651 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.2649 - val_acc: 0.5806\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.2659 - val_acc: 0.5806\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.2678 - val_acc: 0.5806\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.2684 - val_acc: 0.5806\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.2698 - val_acc: 0.5806\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.2714 - val_acc: 0.6129\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.2711 - val_acc: 0.5806\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.2710 - val_acc: 0.5806\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.2731 - val_acc: 0.5806\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.2735 - val_acc: 0.5806\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.2736 - val_acc: 0.5806\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.2793 - val_acc: 0.5806\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.2721 - val_acc: 0.5806\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.2747 - val_acc: 0.6129\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.2763 - val_acc: 0.5806\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.2754 - val_acc: 0.5806\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.2755 - val_acc: 0.6129\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.2721 - val_acc: 0.6129\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.2758 - val_acc: 0.6129\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.2767 - val_acc: 0.5806\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_106 (Dense)            (None, 21)                819       \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 14)                308       \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 1,142\n",
      "Trainable params: 1,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 5ms/step - loss: 0.2499 - acc: 0.5273 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2497 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.2492 - acc: 0.5418 - val_loss: 0.2489 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.2474 - acc: 0.5418 - val_loss: 0.2465 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.2428 - acc: 0.5418 - val_loss: 0.2409 - val_acc: 0.5161\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.2338 - acc: 0.5600 - val_loss: 0.2325 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.2213 - acc: 0.6655 - val_loss: 0.2241 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.2099 - acc: 0.7200 - val_loss: 0.2209 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.2014 - acc: 0.7345 - val_loss: 0.2179 - val_acc: 0.6452\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.1939 - acc: 0.7600 - val_loss: 0.2112 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.1889 - acc: 0.7418 - val_loss: 0.2153 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1798 - acc: 0.7745 - val_loss: 0.2087 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.1755 - acc: 0.7745 - val_loss: 0.2135 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1697 - acc: 0.7745 - val_loss: 0.2109 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.1657 - acc: 0.7891 - val_loss: 0.2097 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.1627 - acc: 0.7891 - val_loss: 0.2086 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.1601 - acc: 0.7855 - val_loss: 0.2115 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1578 - acc: 0.7964 - val_loss: 0.2117 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1582 - acc: 0.7855 - val_loss: 0.2155 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1543 - acc: 0.8000 - val_loss: 0.2136 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1529 - acc: 0.7964 - val_loss: 0.2132 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.1523 - acc: 0.8036 - val_loss: 0.2172 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1500 - acc: 0.8036 - val_loss: 0.2177 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1492 - acc: 0.8000 - val_loss: 0.2202 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1486 - acc: 0.7964 - val_loss: 0.2211 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1472 - acc: 0.8109 - val_loss: 0.2222 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1461 - acc: 0.8145 - val_loss: 0.2223 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1454 - acc: 0.8109 - val_loss: 0.2254 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 203us/step - loss: 0.1439 - acc: 0.8145 - val_loss: 0.2252 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1427 - acc: 0.8145 - val_loss: 0.2248 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1425 - acc: 0.8182 - val_loss: 0.2287 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1411 - acc: 0.8182 - val_loss: 0.2277 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1400 - acc: 0.8182 - val_loss: 0.2277 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1388 - acc: 0.8291 - val_loss: 0.2287 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1383 - acc: 0.8218 - val_loss: 0.2301 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1368 - acc: 0.8327 - val_loss: 0.2308 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1387 - acc: 0.8218 - val_loss: 0.2307 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.1356 - acc: 0.8364 - val_loss: 0.2295 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1339 - acc: 0.8364 - val_loss: 0.2329 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1328 - acc: 0.8364 - val_loss: 0.2326 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.1317 - acc: 0.8400 - val_loss: 0.2327 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.1303 - acc: 0.8473 - val_loss: 0.2345 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.1294 - acc: 0.8400 - val_loss: 0.2376 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1289 - acc: 0.8473 - val_loss: 0.2344 - val_acc: 0.7097\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.1285 - acc: 0.8473 - val_loss: 0.2367 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1273 - acc: 0.8473 - val_loss: 0.2358 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.1272 - acc: 0.8545 - val_loss: 0.2357 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1251 - acc: 0.8509 - val_loss: 0.2383 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.1234 - acc: 0.8618 - val_loss: 0.2392 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1218 - acc: 0.8509 - val_loss: 0.2381 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.1203 - acc: 0.8691 - val_loss: 0.2388 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1194 - acc: 0.8618 - val_loss: 0.2406 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1179 - acc: 0.8618 - val_loss: 0.2418 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1169 - acc: 0.8655 - val_loss: 0.2426 - val_acc: 0.7097\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.1163 - acc: 0.8727 - val_loss: 0.2411 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.1134 - acc: 0.8727 - val_loss: 0.2443 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.1124 - acc: 0.8764 - val_loss: 0.2455 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.1118 - acc: 0.8691 - val_loss: 0.2443 - val_acc: 0.7097\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1105 - acc: 0.8764 - val_loss: 0.2480 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1094 - acc: 0.8836 - val_loss: 0.2469 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.1060 - acc: 0.8873 - val_loss: 0.2432 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1049 - acc: 0.8909 - val_loss: 0.2489 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 204us/step - loss: 0.1025 - acc: 0.8873 - val_loss: 0.2494 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.1012 - acc: 0.8945 - val_loss: 0.2462 - val_acc: 0.7097\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 198us/step - loss: 0.0998 - acc: 0.9018 - val_loss: 0.2464 - val_acc: 0.7097\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 197us/step - loss: 0.0981 - acc: 0.9018 - val_loss: 0.2503 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0977 - acc: 0.9018 - val_loss: 0.2501 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0957 - acc: 0.9055 - val_loss: 0.2482 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0933 - acc: 0.9091 - val_loss: 0.2514 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.0920 - acc: 0.9018 - val_loss: 0.2495 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0908 - acc: 0.9127 - val_loss: 0.2463 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.0891 - acc: 0.9055 - val_loss: 0.2456 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0862 - acc: 0.9200 - val_loss: 0.2499 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0840 - acc: 0.9200 - val_loss: 0.2509 - val_acc: 0.6452\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0827 - acc: 0.9236 - val_loss: 0.2502 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.0801 - acc: 0.9345 - val_loss: 0.2491 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.0781 - acc: 0.9345 - val_loss: 0.2515 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0757 - acc: 0.9418 - val_loss: 0.2554 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0747 - acc: 0.9345 - val_loss: 0.2560 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 196us/step - loss: 0.0733 - acc: 0.9382 - val_loss: 0.2560 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0710 - acc: 0.9455 - val_loss: 0.2537 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 201us/step - loss: 0.0710 - acc: 0.9382 - val_loss: 0.2605 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0688 - acc: 0.9455 - val_loss: 0.2621 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0677 - acc: 0.9418 - val_loss: 0.2608 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0645 - acc: 0.9455 - val_loss: 0.2657 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 200us/step - loss: 0.0640 - acc: 0.9455 - val_loss: 0.2629 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 207us/step - loss: 0.0614 - acc: 0.9491 - val_loss: 0.2682 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 208us/step - loss: 0.0612 - acc: 0.9491 - val_loss: 0.2654 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0601 - acc: 0.9491 - val_loss: 0.2689 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0576 - acc: 0.9527 - val_loss: 0.2727 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0559 - acc: 0.9527 - val_loss: 0.2700 - val_acc: 0.6774\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 201us/step - loss: 0.0554 - acc: 0.9527 - val_loss: 0.2738 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0537 - acc: 0.9564 - val_loss: 0.2738 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 199us/step - loss: 0.0507 - acc: 0.9600 - val_loss: 0.2753 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0499 - acc: 0.9600 - val_loss: 0.2771 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0495 - acc: 0.9564 - val_loss: 0.2736 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 194us/step - loss: 0.0476 - acc: 0.9636 - val_loss: 0.2721 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 192us/step - loss: 0.0455 - acc: 0.9673 - val_loss: 0.2749 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 193us/step - loss: 0.0443 - acc: 0.9673 - val_loss: 0.2795 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.0445 - acc: 0.9636 - val_loss: 0.2827 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_109 (Dense)            (None, 37)                1443      \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 11)                418       \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 1,873\n",
      "Trainable params: 1,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 1s 5ms/step - loss: 0.2499 - acc: 0.5418 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 205us/step - loss: 0.2494 - acc: 0.5418 - val_loss: 0.2493 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.2473 - acc: 0.5418 - val_loss: 0.2462 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 195us/step - loss: 0.2406 - acc: 0.5418 - val_loss: 0.2391 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 202us/step - loss: 0.2284 - acc: 0.5782 - val_loss: 0.2306 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.2157 - acc: 0.6582 - val_loss: 0.2245 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 278us/step - loss: 0.2053 - acc: 0.7273 - val_loss: 0.2219 - val_acc: 0.6129\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 285us/step - loss: 0.1959 - acc: 0.7382 - val_loss: 0.2213 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.1892 - acc: 0.7309 - val_loss: 0.2177 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 206us/step - loss: 0.1816 - acc: 0.7455 - val_loss: 0.2173 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1764 - acc: 0.7527 - val_loss: 0.2153 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1703 - acc: 0.7855 - val_loss: 0.2152 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.1670 - acc: 0.7891 - val_loss: 0.2154 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1640 - acc: 0.7964 - val_loss: 0.2172 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.1608 - acc: 0.7891 - val_loss: 0.2196 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1582 - acc: 0.7855 - val_loss: 0.2162 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1567 - acc: 0.7964 - val_loss: 0.2193 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.1548 - acc: 0.7964 - val_loss: 0.2184 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 297us/step - loss: 0.1536 - acc: 0.8000 - val_loss: 0.2254 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1521 - acc: 0.8000 - val_loss: 0.2242 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 303us/step - loss: 0.1503 - acc: 0.7964 - val_loss: 0.2262 - val_acc: 0.6452\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 324us/step - loss: 0.1508 - acc: 0.7927 - val_loss: 0.2254 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 360us/step - loss: 0.1482 - acc: 0.8073 - val_loss: 0.2276 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 331us/step - loss: 0.1482 - acc: 0.8073 - val_loss: 0.2299 - val_acc: 0.6452\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.1454 - acc: 0.8036 - val_loss: 0.2310 - val_acc: 0.6452\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1446 - acc: 0.8036 - val_loss: 0.2275 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1445 - acc: 0.8182 - val_loss: 0.2292 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 283us/step - loss: 0.1425 - acc: 0.8109 - val_loss: 0.2305 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 287us/step - loss: 0.1420 - acc: 0.8255 - val_loss: 0.2309 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1404 - acc: 0.8218 - val_loss: 0.2327 - val_acc: 0.6452\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1398 - acc: 0.8255 - val_loss: 0.2332 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.1378 - acc: 0.8291 - val_loss: 0.2293 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.1382 - acc: 0.8255 - val_loss: 0.2339 - val_acc: 0.6452\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1374 - acc: 0.8364 - val_loss: 0.2308 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1349 - acc: 0.8291 - val_loss: 0.2349 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 297us/step - loss: 0.1347 - acc: 0.8364 - val_loss: 0.2323 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.1334 - acc: 0.8473 - val_loss: 0.2405 - val_acc: 0.6452\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.1320 - acc: 0.8364 - val_loss: 0.2341 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 310us/step - loss: 0.1304 - acc: 0.8509 - val_loss: 0.2348 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 295us/step - loss: 0.1296 - acc: 0.8436 - val_loss: 0.2362 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.1288 - acc: 0.8436 - val_loss: 0.2399 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.1273 - acc: 0.8582 - val_loss: 0.2392 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 276us/step - loss: 0.1256 - acc: 0.8655 - val_loss: 0.2384 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 285us/step - loss: 0.1246 - acc: 0.8545 - val_loss: 0.2399 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1229 - acc: 0.8545 - val_loss: 0.2372 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 314us/step - loss: 0.1220 - acc: 0.8582 - val_loss: 0.2399 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 311us/step - loss: 0.1204 - acc: 0.8655 - val_loss: 0.2359 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 394us/step - loss: 0.1187 - acc: 0.8655 - val_loss: 0.2378 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 342us/step - loss: 0.1165 - acc: 0.8691 - val_loss: 0.2383 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 302us/step - loss: 0.1156 - acc: 0.8691 - val_loss: 0.2428 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.1143 - acc: 0.8655 - val_loss: 0.2403 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 296us/step - loss: 0.1125 - acc: 0.8764 - val_loss: 0.2434 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 302us/step - loss: 0.1128 - acc: 0.8836 - val_loss: 0.2410 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.1100 - acc: 0.8800 - val_loss: 0.2347 - val_acc: 0.7097\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 302us/step - loss: 0.1077 - acc: 0.8909 - val_loss: 0.2391 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 548us/step - loss: 0.1060 - acc: 0.8982 - val_loss: 0.2396 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 345us/step - loss: 0.1042 - acc: 0.8909 - val_loss: 0.2375 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 318us/step - loss: 0.1027 - acc: 0.9018 - val_loss: 0.2404 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 337us/step - loss: 0.1009 - acc: 0.8982 - val_loss: 0.2408 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 329us/step - loss: 0.0996 - acc: 0.9018 - val_loss: 0.2372 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 451us/step - loss: 0.0984 - acc: 0.9091 - val_loss: 0.2428 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 413us/step - loss: 0.0975 - acc: 0.9055 - val_loss: 0.2457 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 349us/step - loss: 0.0960 - acc: 0.9018 - val_loss: 0.2410 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 337us/step - loss: 0.0936 - acc: 0.9164 - val_loss: 0.2423 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 399us/step - loss: 0.0923 - acc: 0.9091 - val_loss: 0.2414 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 436us/step - loss: 0.0907 - acc: 0.9164 - val_loss: 0.2435 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 374us/step - loss: 0.0896 - acc: 0.9127 - val_loss: 0.2376 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 368us/step - loss: 0.0877 - acc: 0.9164 - val_loss: 0.2363 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 345us/step - loss: 0.0864 - acc: 0.9127 - val_loss: 0.2369 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 330us/step - loss: 0.0848 - acc: 0.9164 - val_loss: 0.2372 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 326us/step - loss: 0.0811 - acc: 0.9236 - val_loss: 0.2316 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 323us/step - loss: 0.0800 - acc: 0.9236 - val_loss: 0.2348 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 319us/step - loss: 0.0783 - acc: 0.9236 - val_loss: 0.2341 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 317us/step - loss: 0.0772 - acc: 0.9345 - val_loss: 0.2314 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 368us/step - loss: 0.0751 - acc: 0.9273 - val_loss: 0.2323 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 329us/step - loss: 0.0732 - acc: 0.9345 - val_loss: 0.2347 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 341us/step - loss: 0.0716 - acc: 0.9382 - val_loss: 0.2313 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 308us/step - loss: 0.0714 - acc: 0.9345 - val_loss: 0.2379 - val_acc: 0.7097\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 315us/step - loss: 0.0698 - acc: 0.9345 - val_loss: 0.2339 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 346us/step - loss: 0.0683 - acc: 0.9382 - val_loss: 0.2243 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 305us/step - loss: 0.0665 - acc: 0.9382 - val_loss: 0.2312 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 299us/step - loss: 0.0647 - acc: 0.9382 - val_loss: 0.2294 - val_acc: 0.7419\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 360us/step - loss: 0.0629 - acc: 0.9382 - val_loss: 0.2255 - val_acc: 0.7419\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 391us/step - loss: 0.0614 - acc: 0.9382 - val_loss: 0.2271 - val_acc: 0.7419\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 325us/step - loss: 0.0606 - acc: 0.9418 - val_loss: 0.2251 - val_acc: 0.7419\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 337us/step - loss: 0.0583 - acc: 0.9418 - val_loss: 0.2298 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 374us/step - loss: 0.0579 - acc: 0.9418 - val_loss: 0.2330 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 324us/step - loss: 0.0547 - acc: 0.9418 - val_loss: 0.2284 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 377us/step - loss: 0.0546 - acc: 0.9382 - val_loss: 0.2359 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 342us/step - loss: 0.0522 - acc: 0.9491 - val_loss: 0.2417 - val_acc: 0.6129\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 360us/step - loss: 0.0509 - acc: 0.9527 - val_loss: 0.2421 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 334us/step - loss: 0.0480 - acc: 0.9527 - val_loss: 0.2443 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 411us/step - loss: 0.0464 - acc: 0.9564 - val_loss: 0.2489 - val_acc: 0.6129\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 362us/step - loss: 0.0440 - acc: 0.9600 - val_loss: 0.2452 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 358us/step - loss: 0.0433 - acc: 0.9600 - val_loss: 0.2360 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 383us/step - loss: 0.0435 - acc: 0.9564 - val_loss: 0.2455 - val_acc: 0.6129\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 357us/step - loss: 0.0402 - acc: 0.9636 - val_loss: 0.2380 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 364us/step - loss: 0.0394 - acc: 0.9636 - val_loss: 0.2379 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 349us/step - loss: 0.0382 - acc: 0.9673 - val_loss: 0.2417 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 368us/step - loss: 0.0367 - acc: 0.9673 - val_loss: 0.2474 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_112 (Dense)            (None, 45)                1755      \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 18)                828       \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 2,602\n",
      "Trainable params: 2,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 2s 7ms/step - loss: 0.2499 - acc: 0.5273 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 349us/step - loss: 0.2495 - acc: 0.5418 - val_loss: 0.2494 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 374us/step - loss: 0.2483 - acc: 0.5600 - val_loss: 0.2477 - val_acc: 0.6129\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 349us/step - loss: 0.2439 - acc: 0.6255 - val_loss: 0.2410 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 364us/step - loss: 0.2322 - acc: 0.7164 - val_loss: 0.2281 - val_acc: 0.6774\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 386us/step - loss: 0.2131 - acc: 0.7345 - val_loss: 0.2126 - val_acc: 0.7097\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 399us/step - loss: 0.1924 - acc: 0.7382 - val_loss: 0.1993 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 328us/step - loss: 0.1772 - acc: 0.7600 - val_loss: 0.1997 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 313us/step - loss: 0.1698 - acc: 0.7382 - val_loss: 0.1992 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 312us/step - loss: 0.1637 - acc: 0.7636 - val_loss: 0.2057 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 340us/step - loss: 0.1592 - acc: 0.7745 - val_loss: 0.2107 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 352us/step - loss: 0.1580 - acc: 0.7709 - val_loss: 0.2154 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 383us/step - loss: 0.1534 - acc: 0.7782 - val_loss: 0.2153 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 380us/step - loss: 0.1520 - acc: 0.7745 - val_loss: 0.2173 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 373us/step - loss: 0.1492 - acc: 0.7818 - val_loss: 0.2192 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 396us/step - loss: 0.1471 - acc: 0.7964 - val_loss: 0.2208 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 362us/step - loss: 0.1451 - acc: 0.7891 - val_loss: 0.2204 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 307us/step - loss: 0.1428 - acc: 0.7964 - val_loss: 0.2240 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 329us/step - loss: 0.1407 - acc: 0.8036 - val_loss: 0.2195 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 463us/step - loss: 0.1383 - acc: 0.8291 - val_loss: 0.2192 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 320us/step - loss: 0.1356 - acc: 0.8182 - val_loss: 0.2180 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 316us/step - loss: 0.1348 - acc: 0.8291 - val_loss: 0.2222 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 329us/step - loss: 0.1307 - acc: 0.8291 - val_loss: 0.2204 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 302us/step - loss: 0.1278 - acc: 0.8473 - val_loss: 0.2197 - val_acc: 0.7419\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 285us/step - loss: 0.1264 - acc: 0.8509 - val_loss: 0.2193 - val_acc: 0.7419\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 325us/step - loss: 0.1234 - acc: 0.8509 - val_loss: 0.2202 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 334us/step - loss: 0.1214 - acc: 0.8545 - val_loss: 0.2250 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 340us/step - loss: 0.1201 - acc: 0.8473 - val_loss: 0.2194 - val_acc: 0.7419\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 362us/step - loss: 0.1138 - acc: 0.8618 - val_loss: 0.2205 - val_acc: 0.7419\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 286us/step - loss: 0.1108 - acc: 0.8655 - val_loss: 0.2187 - val_acc: 0.7419\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 289us/step - loss: 0.1082 - acc: 0.8727 - val_loss: 0.2202 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 296us/step - loss: 0.1044 - acc: 0.8727 - val_loss: 0.2191 - val_acc: 0.7419\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 298us/step - loss: 0.1010 - acc: 0.8836 - val_loss: 0.2182 - val_acc: 0.7419\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 289us/step - loss: 0.0982 - acc: 0.8909 - val_loss: 0.2191 - val_acc: 0.7419\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.0948 - acc: 0.9091 - val_loss: 0.2221 - val_acc: 0.7419\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.0897 - acc: 0.9055 - val_loss: 0.2151 - val_acc: 0.7419\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 286us/step - loss: 0.0861 - acc: 0.9091 - val_loss: 0.2141 - val_acc: 0.7419\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.0817 - acc: 0.9236 - val_loss: 0.2212 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.0781 - acc: 0.9164 - val_loss: 0.2184 - val_acc: 0.7419\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 299us/step - loss: 0.0753 - acc: 0.9309 - val_loss: 0.2166 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.0715 - acc: 0.9455 - val_loss: 0.2098 - val_acc: 0.7419\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 293us/step - loss: 0.0682 - acc: 0.9418 - val_loss: 0.2149 - val_acc: 0.7419\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 298us/step - loss: 0.0639 - acc: 0.9455 - val_loss: 0.2158 - val_acc: 0.6452\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 345us/step - loss: 0.0629 - acc: 0.9455 - val_loss: 0.2113 - val_acc: 0.7419\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 319us/step - loss: 0.0560 - acc: 0.9600 - val_loss: 0.2065 - val_acc: 0.7419\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 332us/step - loss: 0.0536 - acc: 0.9673 - val_loss: 0.2109 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 303us/step - loss: 0.0495 - acc: 0.9673 - val_loss: 0.2088 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 317us/step - loss: 0.0446 - acc: 0.9709 - val_loss: 0.2141 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 299us/step - loss: 0.0420 - acc: 0.9673 - val_loss: 0.2079 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 297us/step - loss: 0.0361 - acc: 0.9818 - val_loss: 0.2043 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 355us/step - loss: 0.0328 - acc: 0.9855 - val_loss: 0.2039 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 349us/step - loss: 0.0306 - acc: 0.9891 - val_loss: 0.2050 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 415us/step - loss: 0.0267 - acc: 0.9964 - val_loss: 0.2035 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 376us/step - loss: 0.0235 - acc: 0.9964 - val_loss: 0.2093 - val_acc: 0.6129\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 355us/step - loss: 0.0225 - acc: 0.9964 - val_loss: 0.2082 - val_acc: 0.6452\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 335us/step - loss: 0.0199 - acc: 0.9964 - val_loss: 0.2129 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 322us/step - loss: 0.0191 - acc: 0.9964 - val_loss: 0.2070 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 348us/step - loss: 0.0169 - acc: 0.9964 - val_loss: 0.2085 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 466us/step - loss: 0.0154 - acc: 0.9964 - val_loss: 0.2060 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 375us/step - loss: 0.0145 - acc: 0.9964 - val_loss: 0.2072 - val_acc: 0.6774\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 332us/step - loss: 0.0133 - acc: 0.9964 - val_loss: 0.2084 - val_acc: 0.7097\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 301us/step - loss: 0.0124 - acc: 0.9964 - val_loss: 0.2092 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.0115 - acc: 0.9964 - val_loss: 0.2091 - val_acc: 0.7097\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.0104 - acc: 0.9964 - val_loss: 0.2070 - val_acc: 0.7097\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 308us/step - loss: 0.0092 - acc: 0.9964 - val_loss: 0.2140 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 303us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.2204 - val_acc: 0.7419\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 299us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.2222 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 352us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.2216 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 401us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.2204 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 426us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.2231 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 420us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.2270 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 366us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 481us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.2234 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 402us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.2296 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 322us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.2294 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 320us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 347us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.2309 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 508us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.2319 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 508us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.2339 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 487us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.2335 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 433us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.2333 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 497us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.2353 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 491us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.2347 - val_acc: 0.7097 \n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 410us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2355 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 503us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.2376 - val_acc: 0.7097\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 445us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.2372 - val_acc: 0.7097\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 377us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2380 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 389us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.2386 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 396us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2392 - val_acc: 0.7097\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 458us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2393 - val_acc: 0.7097\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 447us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2410 - val_acc: 0.7097\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 572us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2398 - val_acc: 0.7097\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 498us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2408 - val_acc: 0.7097\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 560us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2419 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 408us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2430 - val_acc: 0.7097\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 417us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2424 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 526us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2433 - val_acc: 0.7097\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 515us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.2430 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 542us/step - loss: 9.7314e-04 - acc: 1.0000 - val_loss: 0.2436 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 566us/step - loss: 9.3622e-04 - acc: 1.0000 - val_loss: 0.2436 - val_acc: 0.7097\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_115 (Dense)            (None, 43)                1677      \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 15)                660       \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 2,353\n",
      "Trainable params: 2,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 2s 9ms/step - loss: 0.2499 - acc: 0.5164 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 331us/step - loss: 0.2493 - acc: 0.5418 - val_loss: 0.2490 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 325us/step - loss: 0.2470 - acc: 0.5455 - val_loss: 0.2450 - val_acc: 0.5484\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 378us/step - loss: 0.2383 - acc: 0.5855 - val_loss: 0.2365 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 320us/step - loss: 0.2220 - acc: 0.6764 - val_loss: 0.2239 - val_acc: 0.5806\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 328us/step - loss: 0.2024 - acc: 0.7273 - val_loss: 0.2121 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 316us/step - loss: 0.1854 - acc: 0.7382 - val_loss: 0.2040 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 416us/step - loss: 0.1735 - acc: 0.7418 - val_loss: 0.2100 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 373us/step - loss: 0.1671 - acc: 0.7491 - val_loss: 0.2130 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 324us/step - loss: 0.1640 - acc: 0.7527 - val_loss: 0.2070 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 346us/step - loss: 0.1599 - acc: 0.7600 - val_loss: 0.2183 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 311us/step - loss: 0.1581 - acc: 0.7745 - val_loss: 0.2236 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 350us/step - loss: 0.1547 - acc: 0.7782 - val_loss: 0.2218 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 306us/step - loss: 0.1543 - acc: 0.7745 - val_loss: 0.2242 - val_acc: 0.6774\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 296us/step - loss: 0.1522 - acc: 0.8036 - val_loss: 0.2250 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 318us/step - loss: 0.1504 - acc: 0.7855 - val_loss: 0.2303 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 399us/step - loss: 0.1504 - acc: 0.8036 - val_loss: 0.2249 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 378us/step - loss: 0.1490 - acc: 0.8000 - val_loss: 0.2336 - val_acc: 0.6452\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 372us/step - loss: 0.1453 - acc: 0.8000 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 432us/step - loss: 0.1436 - acc: 0.8036 - val_loss: 0.2294 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 332us/step - loss: 0.1415 - acc: 0.8218 - val_loss: 0.2291 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 295us/step - loss: 0.1400 - acc: 0.8255 - val_loss: 0.2313 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 300us/step - loss: 0.1387 - acc: 0.8364 - val_loss: 0.2320 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.1379 - acc: 0.8218 - val_loss: 0.2335 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.1363 - acc: 0.8364 - val_loss: 0.2336 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.1323 - acc: 0.8400 - val_loss: 0.2324 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 328us/step - loss: 0.1311 - acc: 0.8364 - val_loss: 0.2332 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 288us/step - loss: 0.1299 - acc: 0.8291 - val_loss: 0.2310 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 284us/step - loss: 0.1273 - acc: 0.8473 - val_loss: 0.2330 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 286us/step - loss: 0.1250 - acc: 0.8509 - val_loss: 0.2382 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.1246 - acc: 0.8436 - val_loss: 0.2357 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.1212 - acc: 0.8473 - val_loss: 0.2368 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.1188 - acc: 0.8545 - val_loss: 0.2325 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 284us/step - loss: 0.1160 - acc: 0.8691 - val_loss: 0.2347 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 316us/step - loss: 0.1128 - acc: 0.8691 - val_loss: 0.2389 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.1110 - acc: 0.8764 - val_loss: 0.2332 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 287us/step - loss: 0.1075 - acc: 0.8836 - val_loss: 0.2384 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 317us/step - loss: 0.1043 - acc: 0.8909 - val_loss: 0.2390 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 342us/step - loss: 0.1025 - acc: 0.8909 - val_loss: 0.2387 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.0984 - acc: 0.8982 - val_loss: 0.2400 - val_acc: 0.6452\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.0967 - acc: 0.8909 - val_loss: 0.2400 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.0916 - acc: 0.9018 - val_loss: 0.2422 - val_acc: 0.6129\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 297us/step - loss: 0.0879 - acc: 0.9091 - val_loss: 0.2361 - val_acc: 0.6452\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.0844 - acc: 0.9164 - val_loss: 0.2384 - val_acc: 0.6129\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.0807 - acc: 0.9200 - val_loss: 0.2398 - val_acc: 0.6129\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.0791 - acc: 0.9309 - val_loss: 0.2430 - val_acc: 0.5806\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 278us/step - loss: 0.0746 - acc: 0.9418 - val_loss: 0.2369 - val_acc: 0.6129\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.0703 - acc: 0.9382 - val_loss: 0.2453 - val_acc: 0.6129\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.0685 - acc: 0.9418 - val_loss: 0.2415 - val_acc: 0.6452\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.0634 - acc: 0.9491 - val_loss: 0.2461 - val_acc: 0.6452\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.0595 - acc: 0.9600 - val_loss: 0.2431 - val_acc: 0.6129\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.0585 - acc: 0.9564 - val_loss: 0.2486 - val_acc: 0.5484\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 301us/step - loss: 0.0522 - acc: 0.9600 - val_loss: 0.2447 - val_acc: 0.5484\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 307us/step - loss: 0.0489 - acc: 0.9709 - val_loss: 0.2529 - val_acc: 0.6129\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 325us/step - loss: 0.0444 - acc: 0.9709 - val_loss: 0.2541 - val_acc: 0.5484\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 391us/step - loss: 0.0429 - acc: 0.9673 - val_loss: 0.2524 - val_acc: 0.5484\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 458us/step - loss: 0.0386 - acc: 0.9709 - val_loss: 0.2550 - val_acc: 0.5161\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 283us/step - loss: 0.0353 - acc: 0.9818 - val_loss: 0.2594 - val_acc: 0.6129\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 268us/step - loss: 0.0324 - acc: 0.9782 - val_loss: 0.2588 - val_acc: 0.5806\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.0293 - acc: 0.9782 - val_loss: 0.2651 - val_acc: 0.5161\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.0273 - acc: 0.9855 - val_loss: 0.2550 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 278us/step - loss: 0.0254 - acc: 0.9855 - val_loss: 0.2573 - val_acc: 0.6129\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 313us/step - loss: 0.0235 - acc: 0.9891 - val_loss: 0.2681 - val_acc: 0.6129\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 304us/step - loss: 0.0204 - acc: 0.9927 - val_loss: 0.2614 - val_acc: 0.6129\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 280us/step - loss: 0.0185 - acc: 0.9927 - val_loss: 0.2674 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.0173 - acc: 0.9927 - val_loss: 0.2668 - val_acc: 0.6129\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.0158 - acc: 0.9964 - val_loss: 0.2668 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 278us/step - loss: 0.0148 - acc: 0.9964 - val_loss: 0.2627 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 309us/step - loss: 0.0137 - acc: 0.9964 - val_loss: 0.2669 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.0129 - acc: 0.9964 - val_loss: 0.2661 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.0123 - acc: 0.9964 - val_loss: 0.2682 - val_acc: 0.6129\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.0121 - acc: 0.9964 - val_loss: 0.2755 - val_acc: 0.6129\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.0107 - acc: 0.9964 - val_loss: 0.2734 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.0101 - acc: 0.9964 - val_loss: 0.2707 - val_acc: 0.6452\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 264us/step - loss: 0.0096 - acc: 0.9964 - val_loss: 0.2727 - val_acc: 0.6452\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.0090 - acc: 0.9964 - val_loss: 0.2726 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.0089 - acc: 0.9964 - val_loss: 0.2744 - val_acc: 0.6129\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.0084 - acc: 0.9964 - val_loss: 0.2781 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.0081 - acc: 0.9964 - val_loss: 0.2717 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.0077 - acc: 0.9964 - val_loss: 0.2760 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.0076 - acc: 0.9964 - val_loss: 0.2775 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.0072 - acc: 0.9964 - val_loss: 0.2784 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 287us/step - loss: 0.0070 - acc: 0.9964 - val_loss: 0.2745 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 323us/step - loss: 0.0068 - acc: 0.9964 - val_loss: 0.2780 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 347us/step - loss: 0.0066 - acc: 0.9964 - val_loss: 0.2799 - val_acc: 0.6129\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.0065 - acc: 0.9964 - val_loss: 0.2812 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 302us/step - loss: 0.0063 - acc: 0.9964 - val_loss: 0.2801 - val_acc: 0.6129\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 363us/step - loss: 0.0062 - acc: 0.9964 - val_loss: 0.2813 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.0061 - acc: 0.9964 - val_loss: 0.2816 - val_acc: 0.6129\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.0059 - acc: 0.9964 - val_loss: 0.2793 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 302us/step - loss: 0.0057 - acc: 0.9964 - val_loss: 0.2819 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 302us/step - loss: 0.0057 - acc: 0.9964 - val_loss: 0.2822 - val_acc: 0.6129\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 296us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.2818 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 303us/step - loss: 0.0054 - acc: 0.9964 - val_loss: 0.2833 - val_acc: 0.6129\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 301us/step - loss: 0.0054 - acc: 0.9964 - val_loss: 0.2826 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 298us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.2850 - val_acc: 0.6129\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.2852 - val_acc: 0.6129\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.2880 - val_acc: 0.6129\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2818 - val_acc: 0.6129\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 283us/step - loss: 0.0050 - acc: 0.9964 - val_loss: 0.2839 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_118 (Dense)            (None, 39)                1521      \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 10)                400       \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,932\n",
      "Trainable params: 1,932\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 2s 6ms/step - loss: 0.2499 - acc: 0.5382 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 326us/step - loss: 0.2494 - acc: 0.5418 - val_loss: 0.2490 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.2475 - acc: 0.5418 - val_loss: 0.2460 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 315us/step - loss: 0.2419 - acc: 0.5418 - val_loss: 0.2384 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 289us/step - loss: 0.2298 - acc: 0.5418 - val_loss: 0.2286 - val_acc: 0.5161\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 299us/step - loss: 0.2176 - acc: 0.5418 - val_loss: 0.2277 - val_acc: 0.5161\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 302us/step - loss: 0.2096 - acc: 0.5564 - val_loss: 0.2267 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 277us/step - loss: 0.2044 - acc: 0.7309 - val_loss: 0.2286 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 304us/step - loss: 0.2003 - acc: 0.7345 - val_loss: 0.2290 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 288us/step - loss: 0.1965 - acc: 0.7418 - val_loss: 0.2295 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 301us/step - loss: 0.1927 - acc: 0.7673 - val_loss: 0.2290 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.1905 - acc: 0.7600 - val_loss: 0.2259 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.1871 - acc: 0.8000 - val_loss: 0.2244 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.1849 - acc: 0.7964 - val_loss: 0.2283 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.1824 - acc: 0.8000 - val_loss: 0.2308 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.1796 - acc: 0.8109 - val_loss: 0.2294 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 284us/step - loss: 0.1772 - acc: 0.8218 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 326us/step - loss: 0.1755 - acc: 0.8182 - val_loss: 0.2327 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 313us/step - loss: 0.1736 - acc: 0.8218 - val_loss: 0.2317 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 311us/step - loss: 0.1708 - acc: 0.8291 - val_loss: 0.2326 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.1691 - acc: 0.8255 - val_loss: 0.2314 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 262us/step - loss: 0.1668 - acc: 0.8400 - val_loss: 0.2313 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 277us/step - loss: 0.1649 - acc: 0.8436 - val_loss: 0.2330 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 374us/step - loss: 0.1626 - acc: 0.8473 - val_loss: 0.2325 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 367us/step - loss: 0.1614 - acc: 0.8436 - val_loss: 0.2299 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 348us/step - loss: 0.1590 - acc: 0.8400 - val_loss: 0.2326 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 332us/step - loss: 0.1560 - acc: 0.8509 - val_loss: 0.2327 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 293us/step - loss: 0.1540 - acc: 0.8582 - val_loss: 0.2262 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 339us/step - loss: 0.1521 - acc: 0.8545 - val_loss: 0.2305 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 484us/step - loss: 0.1489 - acc: 0.8545 - val_loss: 0.2292 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 388us/step - loss: 0.1465 - acc: 0.8618 - val_loss: 0.2307 - val_acc: 0.6452\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 394us/step - loss: 0.1442 - acc: 0.8655 - val_loss: 0.2265 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 357us/step - loss: 0.1422 - acc: 0.8727 - val_loss: 0.2333 - val_acc: 0.6452\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 371us/step - loss: 0.1392 - acc: 0.8655 - val_loss: 0.2280 - val_acc: 0.6452\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 423us/step - loss: 0.1365 - acc: 0.8764 - val_loss: 0.2315 - val_acc: 0.6452\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 501us/step - loss: 0.1343 - acc: 0.8764 - val_loss: 0.2281 - val_acc: 0.6452\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 396us/step - loss: 0.1313 - acc: 0.8764 - val_loss: 0.2306 - val_acc: 0.6452\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 414us/step - loss: 0.1282 - acc: 0.8800 - val_loss: 0.2250 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 484us/step - loss: 0.1261 - acc: 0.8873 - val_loss: 0.2268 - val_acc: 0.6452\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 408us/step - loss: 0.1224 - acc: 0.8909 - val_loss: 0.2253 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 441us/step - loss: 0.1203 - acc: 0.8982 - val_loss: 0.2263 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 436us/step - loss: 0.1174 - acc: 0.9018 - val_loss: 0.2251 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 352us/step - loss: 0.1141 - acc: 0.9018 - val_loss: 0.2183 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 373us/step - loss: 0.1117 - acc: 0.9055 - val_loss: 0.2241 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 420us/step - loss: 0.1088 - acc: 0.9055 - val_loss: 0.2231 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 286us/step - loss: 0.1069 - acc: 0.9164 - val_loss: 0.2284 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 411us/step - loss: 0.1042 - acc: 0.9127 - val_loss: 0.2244 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 359us/step - loss: 0.1009 - acc: 0.9164 - val_loss: 0.2222 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 312us/step - loss: 0.0969 - acc: 0.9091 - val_loss: 0.2297 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 432us/step - loss: 0.0940 - acc: 0.9236 - val_loss: 0.2258 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 399us/step - loss: 0.0919 - acc: 0.9309 - val_loss: 0.2298 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 386us/step - loss: 0.0889 - acc: 0.9309 - val_loss: 0.2341 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 428us/step - loss: 0.0866 - acc: 0.9382 - val_loss: 0.2303 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 442us/step - loss: 0.0838 - acc: 0.9382 - val_loss: 0.2359 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 409us/step - loss: 0.0819 - acc: 0.9418 - val_loss: 0.2399 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 295us/step - loss: 0.0798 - acc: 0.9418 - val_loss: 0.2403 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 293us/step - loss: 0.0778 - acc: 0.9455 - val_loss: 0.2445 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 301us/step - loss: 0.0754 - acc: 0.9455 - val_loss: 0.2409 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 301us/step - loss: 0.0745 - acc: 0.9455 - val_loss: 0.2434 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 312us/step - loss: 0.0737 - acc: 0.9491 - val_loss: 0.2452 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 320us/step - loss: 0.0719 - acc: 0.9491 - val_loss: 0.2488 - val_acc: 0.7097\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 337us/step - loss: 0.0704 - acc: 0.9491 - val_loss: 0.2490 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.0685 - acc: 0.9491 - val_loss: 0.2518 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 283us/step - loss: 0.0676 - acc: 0.9491 - val_loss: 0.2504 - val_acc: 0.6452\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.0666 - acc: 0.9491 - val_loss: 0.2517 - val_acc: 0.7097\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 288us/step - loss: 0.0656 - acc: 0.9491 - val_loss: 0.2518 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 316us/step - loss: 0.0649 - acc: 0.9491 - val_loss: 0.2500 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 322us/step - loss: 0.0640 - acc: 0.9491 - val_loss: 0.2506 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 281us/step - loss: 0.0633 - acc: 0.9491 - val_loss: 0.2502 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 293us/step - loss: 0.0631 - acc: 0.9491 - val_loss: 0.2516 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 334us/step - loss: 0.0622 - acc: 0.9491 - val_loss: 0.2520 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 371us/step - loss: 0.0617 - acc: 0.9491 - val_loss: 0.2489 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 322us/step - loss: 0.0610 - acc: 0.9491 - val_loss: 0.2512 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 293us/step - loss: 0.0604 - acc: 0.9491 - val_loss: 0.2510 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.0600 - acc: 0.9491 - val_loss: 0.2499 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 289us/step - loss: 0.0596 - acc: 0.9491 - val_loss: 0.2542 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 285us/step - loss: 0.0591 - acc: 0.9491 - val_loss: 0.2503 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.0588 - acc: 0.9491 - val_loss: 0.2524 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 328us/step - loss: 0.0583 - acc: 0.9491 - val_loss: 0.2523 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 330us/step - loss: 0.0581 - acc: 0.9491 - val_loss: 0.2544 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 301us/step - loss: 0.0574 - acc: 0.9491 - val_loss: 0.2525 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 331us/step - loss: 0.0571 - acc: 0.9491 - val_loss: 0.2528 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 347us/step - loss: 0.0567 - acc: 0.9491 - val_loss: 0.2520 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 318us/step - loss: 0.0564 - acc: 0.9491 - val_loss: 0.2520 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 324us/step - loss: 0.0562 - acc: 0.9491 - val_loss: 0.2543 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 325us/step - loss: 0.0559 - acc: 0.9491 - val_loss: 0.2553 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 326us/step - loss: 0.0555 - acc: 0.9491 - val_loss: 0.2567 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 317us/step - loss: 0.0552 - acc: 0.9491 - val_loss: 0.2536 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 327us/step - loss: 0.0550 - acc: 0.9491 - val_loss: 0.2556 - val_acc: 0.6774\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 295us/step - loss: 0.0546 - acc: 0.9491 - val_loss: 0.2547 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.0544 - acc: 0.9491 - val_loss: 0.2571 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 286us/step - loss: 0.0542 - acc: 0.9491 - val_loss: 0.2499 - val_acc: 0.7097\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 295us/step - loss: 0.0540 - acc: 0.9491 - val_loss: 0.2522 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 351us/step - loss: 0.0538 - acc: 0.9491 - val_loss: 0.2576 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 338us/step - loss: 0.0534 - acc: 0.9491 - val_loss: 0.2571 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 293us/step - loss: 0.0532 - acc: 0.9491 - val_loss: 0.2565 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.0532 - acc: 0.9491 - val_loss: 0.2641 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 365us/step - loss: 0.0521 - acc: 0.9491 - val_loss: 0.2714 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 384us/step - loss: 0.0508 - acc: 0.9527 - val_loss: 0.2676 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 312us/step - loss: 0.0490 - acc: 0.9564 - val_loss: 0.2690 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_121 (Dense)            (None, 35)                1365      \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 12)                432       \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,810\n",
      "Trainable params: 1,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 2s 7ms/step - loss: 0.2499 - acc: 0.5309 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 327us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2493 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 276us/step - loss: 0.2481 - acc: 0.5418 - val_loss: 0.2476 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.2441 - acc: 0.5418 - val_loss: 0.2425 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 338us/step - loss: 0.2359 - acc: 0.5418 - val_loss: 0.2341 - val_acc: 0.5161\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 307us/step - loss: 0.2248 - acc: 0.5673 - val_loss: 0.2277 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 309us/step - loss: 0.2152 - acc: 0.6545 - val_loss: 0.2226 - val_acc: 0.6129\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 371us/step - loss: 0.2065 - acc: 0.7236 - val_loss: 0.2200 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 373us/step - loss: 0.1991 - acc: 0.7273 - val_loss: 0.2173 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 329us/step - loss: 0.1927 - acc: 0.7418 - val_loss: 0.2149 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 363us/step - loss: 0.1862 - acc: 0.7455 - val_loss: 0.2174 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 402us/step - loss: 0.1788 - acc: 0.7636 - val_loss: 0.2097 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 374us/step - loss: 0.1725 - acc: 0.7564 - val_loss: 0.2091 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 295us/step - loss: 0.1671 - acc: 0.7709 - val_loss: 0.2118 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 403us/step - loss: 0.1631 - acc: 0.7745 - val_loss: 0.2127 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 442us/step - loss: 0.1613 - acc: 0.7818 - val_loss: 0.2154 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 396us/step - loss: 0.1592 - acc: 0.7855 - val_loss: 0.2160 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 375us/step - loss: 0.1570 - acc: 0.7891 - val_loss: 0.2211 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 280us/step - loss: 0.1563 - acc: 0.7927 - val_loss: 0.2194 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 295us/step - loss: 0.1540 - acc: 0.7855 - val_loss: 0.2225 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.1524 - acc: 0.7964 - val_loss: 0.2249 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.1515 - acc: 0.7927 - val_loss: 0.2250 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 426us/step - loss: 0.1499 - acc: 0.8109 - val_loss: 0.2294 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 325us/step - loss: 0.1486 - acc: 0.8036 - val_loss: 0.2316 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 310us/step - loss: 0.1474 - acc: 0.8073 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 318us/step - loss: 0.1468 - acc: 0.8073 - val_loss: 0.2307 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 297us/step - loss: 0.1454 - acc: 0.8073 - val_loss: 0.2336 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 286us/step - loss: 0.1454 - acc: 0.8218 - val_loss: 0.2329 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 313us/step - loss: 0.1438 - acc: 0.8145 - val_loss: 0.2335 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 344us/step - loss: 0.1422 - acc: 0.8109 - val_loss: 0.2341 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 314us/step - loss: 0.1411 - acc: 0.8182 - val_loss: 0.2347 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 317us/step - loss: 0.1409 - acc: 0.8327 - val_loss: 0.2348 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.1388 - acc: 0.8400 - val_loss: 0.2349 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 303us/step - loss: 0.1376 - acc: 0.8473 - val_loss: 0.2356 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 304us/step - loss: 0.1369 - acc: 0.8327 - val_loss: 0.2388 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 300us/step - loss: 0.1353 - acc: 0.8436 - val_loss: 0.2375 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.1340 - acc: 0.8473 - val_loss: 0.2372 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.1324 - acc: 0.8509 - val_loss: 0.2397 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 283us/step - loss: 0.1315 - acc: 0.8509 - val_loss: 0.2356 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.1302 - acc: 0.8545 - val_loss: 0.2386 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 308us/step - loss: 0.1293 - acc: 0.8509 - val_loss: 0.2385 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 288us/step - loss: 0.1272 - acc: 0.8618 - val_loss: 0.2393 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.1254 - acc: 0.8582 - val_loss: 0.2389 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 305us/step - loss: 0.1244 - acc: 0.8618 - val_loss: 0.2372 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 363us/step - loss: 0.1225 - acc: 0.8691 - val_loss: 0.2403 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 342us/step - loss: 0.1218 - acc: 0.8618 - val_loss: 0.2405 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 312us/step - loss: 0.1186 - acc: 0.8655 - val_loss: 0.2410 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 289us/step - loss: 0.1169 - acc: 0.8691 - val_loss: 0.2417 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 300us/step - loss: 0.1147 - acc: 0.8727 - val_loss: 0.2433 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.1126 - acc: 0.8691 - val_loss: 0.2447 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 327us/step - loss: 0.1105 - acc: 0.8800 - val_loss: 0.2449 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.1092 - acc: 0.8764 - val_loss: 0.2440 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.1075 - acc: 0.8836 - val_loss: 0.2454 - val_acc: 0.7097\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.1049 - acc: 0.8909 - val_loss: 0.2459 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.1032 - acc: 0.8945 - val_loss: 0.2472 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.1010 - acc: 0.8982 - val_loss: 0.2495 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 328us/step - loss: 0.0986 - acc: 0.9055 - val_loss: 0.2484 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 268us/step - loss: 0.0973 - acc: 0.9164 - val_loss: 0.2441 - val_acc: 0.7097\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 324us/step - loss: 0.0936 - acc: 0.9200 - val_loss: 0.2482 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 329us/step - loss: 0.0913 - acc: 0.9164 - val_loss: 0.2481 - val_acc: 0.6452\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 284us/step - loss: 0.0898 - acc: 0.9236 - val_loss: 0.2487 - val_acc: 0.6452\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.0859 - acc: 0.9345 - val_loss: 0.2503 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 368us/step - loss: 0.0841 - acc: 0.9345 - val_loss: 0.2520 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 322us/step - loss: 0.0839 - acc: 0.9273 - val_loss: 0.2559 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 299us/step - loss: 0.0792 - acc: 0.9345 - val_loss: 0.2542 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 293us/step - loss: 0.0769 - acc: 0.9382 - val_loss: 0.2541 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 285us/step - loss: 0.0746 - acc: 0.9345 - val_loss: 0.2531 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.0721 - acc: 0.9382 - val_loss: 0.2540 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 304us/step - loss: 0.0682 - acc: 0.9418 - val_loss: 0.2547 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.0653 - acc: 0.9455 - val_loss: 0.2553 - val_acc: 0.6452\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 298us/step - loss: 0.0632 - acc: 0.9527 - val_loss: 0.2577 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 287us/step - loss: 0.0607 - acc: 0.9527 - val_loss: 0.2619 - val_acc: 0.6129\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 298us/step - loss: 0.0584 - acc: 0.9636 - val_loss: 0.2530 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 306us/step - loss: 0.0562 - acc: 0.9636 - val_loss: 0.2559 - val_acc: 0.6452\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 422us/step - loss: 0.0538 - acc: 0.9600 - val_loss: 0.2613 - val_acc: 0.6129\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 452us/step - loss: 0.0504 - acc: 0.9673 - val_loss: 0.2555 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 460us/step - loss: 0.0490 - acc: 0.9600 - val_loss: 0.2592 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 424us/step - loss: 0.0469 - acc: 0.9709 - val_loss: 0.2608 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 519us/step - loss: 0.0448 - acc: 0.9709 - val_loss: 0.2610 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 447us/step - loss: 0.0427 - acc: 0.9709 - val_loss: 0.2582 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 431us/step - loss: 0.0411 - acc: 0.9745 - val_loss: 0.2604 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 421us/step - loss: 0.0402 - acc: 0.9782 - val_loss: 0.2560 - val_acc: 0.6129\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 551us/step - loss: 0.0378 - acc: 0.9745 - val_loss: 0.2599 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 413us/step - loss: 0.0368 - acc: 0.9745 - val_loss: 0.2629 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 307us/step - loss: 0.0347 - acc: 0.9782 - val_loss: 0.2647 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 299us/step - loss: 0.0333 - acc: 0.9782 - val_loss: 0.2629 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 298us/step - loss: 0.0316 - acc: 0.9782 - val_loss: 0.2680 - val_acc: 0.6452\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 299us/step - loss: 0.0290 - acc: 0.9818 - val_loss: 0.2691 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 312us/step - loss: 0.0274 - acc: 0.9855 - val_loss: 0.2711 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.0264 - acc: 0.9855 - val_loss: 0.2707 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 284us/step - loss: 0.0253 - acc: 0.9855 - val_loss: 0.2695 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.0249 - acc: 0.9855 - val_loss: 0.2709 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.0237 - acc: 0.9855 - val_loss: 0.2722 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 367us/step - loss: 0.0229 - acc: 0.9855 - val_loss: 0.2762 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 329us/step - loss: 0.0221 - acc: 0.9855 - val_loss: 0.2781 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 313us/step - loss: 0.0213 - acc: 0.9855 - val_loss: 0.2760 - val_acc: 0.6452\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 298us/step - loss: 0.0207 - acc: 0.9855 - val_loss: 0.2725 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 277us/step - loss: 0.0205 - acc: 0.9855 - val_loss: 0.2774 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.0198 - acc: 0.9855 - val_loss: 0.2750 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 315us/step - loss: 0.0193 - acc: 0.9855 - val_loss: 0.2782 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_124 (Dense)            (None, 20)                780       \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 19)                399       \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 1)                 20        \n",
      "=================================================================\n",
      "Total params: 1,199\n",
      "Trainable params: 1,199\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 2s 7ms/step - loss: 0.2499 - acc: 0.5418 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 286us/step - loss: 0.2495 - acc: 0.5418 - val_loss: 0.2494 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 364us/step - loss: 0.2480 - acc: 0.5455 - val_loss: 0.2471 - val_acc: 0.5484\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 343us/step - loss: 0.2432 - acc: 0.5782 - val_loss: 0.2403 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 326us/step - loss: 0.2328 - acc: 0.6582 - val_loss: 0.2296 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 334us/step - loss: 0.2175 - acc: 0.7018 - val_loss: 0.2160 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 285us/step - loss: 0.2006 - acc: 0.7273 - val_loss: 0.2041 - val_acc: 0.7097\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 303us/step - loss: 0.1854 - acc: 0.7382 - val_loss: 0.1968 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 303us/step - loss: 0.1754 - acc: 0.7382 - val_loss: 0.2006 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 325us/step - loss: 0.1701 - acc: 0.7418 - val_loss: 0.2057 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 398us/step - loss: 0.1669 - acc: 0.7564 - val_loss: 0.2045 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 328us/step - loss: 0.1639 - acc: 0.7636 - val_loss: 0.2068 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.1621 - acc: 0.7564 - val_loss: 0.2111 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.1613 - acc: 0.7709 - val_loss: 0.2130 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.1589 - acc: 0.7709 - val_loss: 0.2134 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 296us/step - loss: 0.1584 - acc: 0.7673 - val_loss: 0.2154 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 446us/step - loss: 0.1569 - acc: 0.7782 - val_loss: 0.2183 - val_acc: 0.6452\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 339us/step - loss: 0.1567 - acc: 0.7782 - val_loss: 0.2206 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 388us/step - loss: 0.1564 - acc: 0.7818 - val_loss: 0.2206 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 361us/step - loss: 0.1546 - acc: 0.7855 - val_loss: 0.2222 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 385us/step - loss: 0.1534 - acc: 0.7964 - val_loss: 0.2209 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 418us/step - loss: 0.1525 - acc: 0.7927 - val_loss: 0.2243 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 384us/step - loss: 0.1515 - acc: 0.7927 - val_loss: 0.2241 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 389us/step - loss: 0.1509 - acc: 0.7927 - val_loss: 0.2237 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 327us/step - loss: 0.1496 - acc: 0.7891 - val_loss: 0.2213 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 302us/step - loss: 0.1490 - acc: 0.8000 - val_loss: 0.2235 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 281us/step - loss: 0.1473 - acc: 0.8036 - val_loss: 0.2247 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.1472 - acc: 0.8000 - val_loss: 0.2263 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 287us/step - loss: 0.1457 - acc: 0.8073 - val_loss: 0.2255 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 300us/step - loss: 0.1454 - acc: 0.8000 - val_loss: 0.2263 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 295us/step - loss: 0.1435 - acc: 0.8073 - val_loss: 0.2254 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.1426 - acc: 0.8109 - val_loss: 0.2258 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 305us/step - loss: 0.1418 - acc: 0.8073 - val_loss: 0.2270 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.1399 - acc: 0.8109 - val_loss: 0.2278 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 278us/step - loss: 0.1389 - acc: 0.8182 - val_loss: 0.2255 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 323us/step - loss: 0.1376 - acc: 0.8145 - val_loss: 0.2267 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 276us/step - loss: 0.1368 - acc: 0.8145 - val_loss: 0.2277 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 298us/step - loss: 0.1346 - acc: 0.8182 - val_loss: 0.2282 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 296us/step - loss: 0.1348 - acc: 0.8182 - val_loss: 0.2258 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.1321 - acc: 0.8327 - val_loss: 0.2258 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 278us/step - loss: 0.1308 - acc: 0.8291 - val_loss: 0.2254 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 295us/step - loss: 0.1300 - acc: 0.8436 - val_loss: 0.2284 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 301us/step - loss: 0.1285 - acc: 0.8509 - val_loss: 0.2283 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 300us/step - loss: 0.1270 - acc: 0.8364 - val_loss: 0.2289 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.1250 - acc: 0.8436 - val_loss: 0.2306 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 262us/step - loss: 0.1239 - acc: 0.8509 - val_loss: 0.2282 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.1218 - acc: 0.8618 - val_loss: 0.2278 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 276us/step - loss: 0.1204 - acc: 0.8618 - val_loss: 0.2247 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 313us/step - loss: 0.1187 - acc: 0.8655 - val_loss: 0.2292 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 262us/step - loss: 0.1168 - acc: 0.8691 - val_loss: 0.2261 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 285us/step - loss: 0.1153 - acc: 0.8691 - val_loss: 0.2292 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 277us/step - loss: 0.1137 - acc: 0.8800 - val_loss: 0.2275 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 261us/step - loss: 0.1124 - acc: 0.8873 - val_loss: 0.2292 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.1106 - acc: 0.8836 - val_loss: 0.2321 - val_acc: 0.6452\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1095 - acc: 0.8873 - val_loss: 0.2276 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1062 - acc: 0.8945 - val_loss: 0.2312 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.1049 - acc: 0.9018 - val_loss: 0.2301 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1031 - acc: 0.8945 - val_loss: 0.2287 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1010 - acc: 0.9091 - val_loss: 0.2279 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.0985 - acc: 0.9164 - val_loss: 0.2268 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 285us/step - loss: 0.0959 - acc: 0.9091 - val_loss: 0.2275 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 285us/step - loss: 0.0943 - acc: 0.9091 - val_loss: 0.2257 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 301us/step - loss: 0.0931 - acc: 0.9164 - val_loss: 0.2281 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 297us/step - loss: 0.0919 - acc: 0.9200 - val_loss: 0.2277 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 298us/step - loss: 0.0899 - acc: 0.9164 - val_loss: 0.2279 - val_acc: 0.6452\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.0869 - acc: 0.9236 - val_loss: 0.2282 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.0834 - acc: 0.9273 - val_loss: 0.2229 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0813 - acc: 0.9309 - val_loss: 0.2210 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.0805 - acc: 0.9345 - val_loss: 0.2252 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.0785 - acc: 0.9309 - val_loss: 0.2239 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 261us/step - loss: 0.0765 - acc: 0.9309 - val_loss: 0.2157 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 283us/step - loss: 0.0736 - acc: 0.9418 - val_loss: 0.2148 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 280us/step - loss: 0.0726 - acc: 0.9345 - val_loss: 0.2174 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.0699 - acc: 0.9345 - val_loss: 0.2140 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.0675 - acc: 0.9382 - val_loss: 0.2136 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.0657 - acc: 0.9382 - val_loss: 0.2172 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.0623 - acc: 0.9418 - val_loss: 0.2147 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0614 - acc: 0.9491 - val_loss: 0.2156 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.0598 - acc: 0.9491 - val_loss: 0.2124 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.0575 - acc: 0.9491 - val_loss: 0.2122 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.0553 - acc: 0.9564 - val_loss: 0.2087 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0563 - acc: 0.9455 - val_loss: 0.2232 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0525 - acc: 0.9600 - val_loss: 0.2127 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0499 - acc: 0.9527 - val_loss: 0.2186 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.0483 - acc: 0.9564 - val_loss: 0.2236 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.0468 - acc: 0.9600 - val_loss: 0.2124 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0447 - acc: 0.9636 - val_loss: 0.2167 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0422 - acc: 0.9673 - val_loss: 0.2139 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0400 - acc: 0.9636 - val_loss: 0.2131 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0383 - acc: 0.9673 - val_loss: 0.2248 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0371 - acc: 0.9673 - val_loss: 0.2303 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0344 - acc: 0.9745 - val_loss: 0.2114 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0313 - acc: 0.9782 - val_loss: 0.2135 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0290 - acc: 0.9818 - val_loss: 0.2163 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0287 - acc: 0.9855 - val_loss: 0.2220 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0254 - acc: 0.9855 - val_loss: 0.2157 - val_acc: 0.6452\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0247 - acc: 0.9818 - val_loss: 0.2208 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0237 - acc: 0.9818 - val_loss: 0.2253 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0227 - acc: 0.9855 - val_loss: 0.2340 - val_acc: 0.5806\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0224 - acc: 0.9818 - val_loss: 0.2174 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_127 (Dense)            (None, 16)                624       \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 12)                204       \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 841\n",
      "Trainable params: 841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 2s 6ms/step - loss: 0.2499 - acc: 0.5309 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 283us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2495 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.2487 - acc: 0.5418 - val_loss: 0.2484 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.2465 - acc: 0.5418 - val_loss: 0.2452 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.2409 - acc: 0.5564 - val_loss: 0.2388 - val_acc: 0.6129\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.2316 - acc: 0.6182 - val_loss: 0.2295 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.2188 - acc: 0.6982 - val_loss: 0.2190 - val_acc: 0.6129\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.2049 - acc: 0.7091 - val_loss: 0.2111 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.1918 - acc: 0.7236 - val_loss: 0.2042 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1817 - acc: 0.7455 - val_loss: 0.2025 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1743 - acc: 0.7527 - val_loss: 0.2035 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1702 - acc: 0.7600 - val_loss: 0.2073 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 268us/step - loss: 0.1665 - acc: 0.7673 - val_loss: 0.2074 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1653 - acc: 0.7564 - val_loss: 0.2090 - val_acc: 0.6774\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 221us/step - loss: 0.1623 - acc: 0.7709 - val_loss: 0.2102 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 261us/step - loss: 0.1609 - acc: 0.7709 - val_loss: 0.2130 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.1605 - acc: 0.7673 - val_loss: 0.2150 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.1588 - acc: 0.7745 - val_loss: 0.2173 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1582 - acc: 0.7673 - val_loss: 0.2193 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1566 - acc: 0.7745 - val_loss: 0.2212 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.1570 - acc: 0.7964 - val_loss: 0.2231 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1554 - acc: 0.7782 - val_loss: 0.2241 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.1551 - acc: 0.7891 - val_loss: 0.2226 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1544 - acc: 0.7891 - val_loss: 0.2250 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1544 - acc: 0.7818 - val_loss: 0.2265 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1536 - acc: 0.7927 - val_loss: 0.2275 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1536 - acc: 0.7855 - val_loss: 0.2254 - val_acc: 0.6452\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.1519 - acc: 0.7927 - val_loss: 0.2270 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1521 - acc: 0.7927 - val_loss: 0.2275 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1499 - acc: 0.7927 - val_loss: 0.2251 - val_acc: 0.6452\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.1505 - acc: 0.7964 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 300us/step - loss: 0.1490 - acc: 0.8000 - val_loss: 0.2287 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 306us/step - loss: 0.1486 - acc: 0.8000 - val_loss: 0.2298 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 309us/step - loss: 0.1489 - acc: 0.8000 - val_loss: 0.2306 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 318us/step - loss: 0.1468 - acc: 0.7927 - val_loss: 0.2294 - val_acc: 0.6452\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 315us/step - loss: 0.1474 - acc: 0.8000 - val_loss: 0.2316 - val_acc: 0.6452\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1459 - acc: 0.8000 - val_loss: 0.2298 - val_acc: 0.6452\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1457 - acc: 0.8036 - val_loss: 0.2315 - val_acc: 0.6452\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1440 - acc: 0.8109 - val_loss: 0.2312 - val_acc: 0.6452\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1429 - acc: 0.8036 - val_loss: 0.2311 - val_acc: 0.6452\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1425 - acc: 0.8073 - val_loss: 0.2319 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 284us/step - loss: 0.1414 - acc: 0.8073 - val_loss: 0.2308 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.1415 - acc: 0.8109 - val_loss: 0.2312 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 277us/step - loss: 0.1400 - acc: 0.8109 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 280us/step - loss: 0.1392 - acc: 0.8145 - val_loss: 0.2343 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1380 - acc: 0.8145 - val_loss: 0.2331 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1378 - acc: 0.8218 - val_loss: 0.2332 - val_acc: 0.6452\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1360 - acc: 0.8218 - val_loss: 0.2326 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1352 - acc: 0.8291 - val_loss: 0.2307 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1342 - acc: 0.8182 - val_loss: 0.2312 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1331 - acc: 0.8364 - val_loss: 0.2319 - val_acc: 0.6452\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.1325 - acc: 0.8327 - val_loss: 0.2318 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.1311 - acc: 0.8364 - val_loss: 0.2305 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1297 - acc: 0.8400 - val_loss: 0.2308 - val_acc: 0.6452\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1282 - acc: 0.8364 - val_loss: 0.2292 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1273 - acc: 0.8400 - val_loss: 0.2331 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1266 - acc: 0.8400 - val_loss: 0.2339 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1252 - acc: 0.8509 - val_loss: 0.2314 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1235 - acc: 0.8436 - val_loss: 0.2325 - val_acc: 0.6452\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1227 - acc: 0.8436 - val_loss: 0.2313 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.1215 - acc: 0.8436 - val_loss: 0.2305 - val_acc: 0.7097\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1206 - acc: 0.8582 - val_loss: 0.2310 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 284us/step - loss: 0.1192 - acc: 0.8582 - val_loss: 0.2316 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.1172 - acc: 0.8582 - val_loss: 0.2314 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1165 - acc: 0.8655 - val_loss: 0.2312 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1146 - acc: 0.8655 - val_loss: 0.2302 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1136 - acc: 0.8655 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1127 - acc: 0.8655 - val_loss: 0.2322 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1114 - acc: 0.8764 - val_loss: 0.2307 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1086 - acc: 0.8727 - val_loss: 0.2313 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1068 - acc: 0.8836 - val_loss: 0.2335 - val_acc: 0.6452\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1060 - acc: 0.8909 - val_loss: 0.2330 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1039 - acc: 0.8873 - val_loss: 0.2326 - val_acc: 0.6452\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 283us/step - loss: 0.1025 - acc: 0.8945 - val_loss: 0.2346 - val_acc: 0.6774\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 284us/step - loss: 0.1008 - acc: 0.8945 - val_loss: 0.2369 - val_acc: 0.6452\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.0996 - acc: 0.8945 - val_loss: 0.2342 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 286us/step - loss: 0.0973 - acc: 0.8982 - val_loss: 0.2337 - val_acc: 0.6129\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 280us/step - loss: 0.0953 - acc: 0.9018 - val_loss: 0.2344 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.0939 - acc: 0.8982 - val_loss: 0.2355 - val_acc: 0.6129\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.0925 - acc: 0.8982 - val_loss: 0.2398 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.0892 - acc: 0.9127 - val_loss: 0.2392 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0880 - acc: 0.9127 - val_loss: 0.2388 - val_acc: 0.6129\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0869 - acc: 0.9055 - val_loss: 0.2407 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0840 - acc: 0.9273 - val_loss: 0.2413 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0819 - acc: 0.9200 - val_loss: 0.2449 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0801 - acc: 0.9164 - val_loss: 0.2433 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.0780 - acc: 0.9164 - val_loss: 0.2436 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 284us/step - loss: 0.0748 - acc: 0.9345 - val_loss: 0.2373 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.0744 - acc: 0.9345 - val_loss: 0.2442 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.0705 - acc: 0.9418 - val_loss: 0.2381 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0685 - acc: 0.9527 - val_loss: 0.2389 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0667 - acc: 0.9527 - val_loss: 0.2415 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0653 - acc: 0.9527 - val_loss: 0.2380 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0629 - acc: 0.9527 - val_loss: 0.2394 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0610 - acc: 0.9564 - val_loss: 0.2377 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0589 - acc: 0.9600 - val_loss: 0.2425 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0574 - acc: 0.9564 - val_loss: 0.2461 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0560 - acc: 0.9673 - val_loss: 0.2454 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0536 - acc: 0.9709 - val_loss: 0.2407 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.0514 - acc: 0.9709 - val_loss: 0.2455 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_130 (Dense)            (None, 13)                507       \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 14)                196       \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 718\n",
      "Trainable params: 718\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 2s 6ms/step - loss: 0.2500 - acc: 0.4618 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.2497 - acc: 0.5418 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.2492 - acc: 0.5418 - val_loss: 0.2490 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.2474 - acc: 0.5418 - val_loss: 0.2467 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.2426 - acc: 0.5455 - val_loss: 0.2418 - val_acc: 0.5484\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.2342 - acc: 0.5745 - val_loss: 0.2339 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.2231 - acc: 0.6509 - val_loss: 0.2267 - val_acc: 0.6129\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.2108 - acc: 0.7018 - val_loss: 0.2186 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 268us/step - loss: 0.2009 - acc: 0.7236 - val_loss: 0.2140 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1912 - acc: 0.7455 - val_loss: 0.2090 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.1826 - acc: 0.7527 - val_loss: 0.2065 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.1757 - acc: 0.7564 - val_loss: 0.2054 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1708 - acc: 0.7636 - val_loss: 0.2077 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1676 - acc: 0.7636 - val_loss: 0.2066 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1646 - acc: 0.7855 - val_loss: 0.2128 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1631 - acc: 0.7782 - val_loss: 0.2116 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1605 - acc: 0.7709 - val_loss: 0.2126 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1595 - acc: 0.7855 - val_loss: 0.2182 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1587 - acc: 0.7782 - val_loss: 0.2176 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1569 - acc: 0.7964 - val_loss: 0.2211 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.1561 - acc: 0.7855 - val_loss: 0.2192 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1551 - acc: 0.7855 - val_loss: 0.2214 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1534 - acc: 0.8036 - val_loss: 0.2210 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1524 - acc: 0.8000 - val_loss: 0.2212 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.1521 - acc: 0.8000 - val_loss: 0.2244 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1513 - acc: 0.7927 - val_loss: 0.2237 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1501 - acc: 0.8109 - val_loss: 0.2244 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1504 - acc: 0.8109 - val_loss: 0.2267 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 300us/step - loss: 0.1488 - acc: 0.8182 - val_loss: 0.2252 - val_acc: 0.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 280us/step - loss: 0.1480 - acc: 0.8145 - val_loss: 0.2271 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 283us/step - loss: 0.1485 - acc: 0.7855 - val_loss: 0.2269 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.1469 - acc: 0.8109 - val_loss: 0.2292 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1457 - acc: 0.8109 - val_loss: 0.2267 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1464 - acc: 0.8109 - val_loss: 0.2281 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1457 - acc: 0.8145 - val_loss: 0.2290 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1446 - acc: 0.8182 - val_loss: 0.2275 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1435 - acc: 0.8255 - val_loss: 0.2279 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1426 - acc: 0.8109 - val_loss: 0.2312 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.1428 - acc: 0.8182 - val_loss: 0.2305 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1414 - acc: 0.8218 - val_loss: 0.2295 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 319us/step - loss: 0.1411 - acc: 0.8255 - val_loss: 0.2271 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 322us/step - loss: 0.1401 - acc: 0.8218 - val_loss: 0.2297 - val_acc: 0.7097\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 300us/step - loss: 0.1403 - acc: 0.8145 - val_loss: 0.2291 - val_acc: 0.7097\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 284us/step - loss: 0.1384 - acc: 0.8255 - val_loss: 0.2293 - val_acc: 0.7097\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1393 - acc: 0.8218 - val_loss: 0.2287 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1392 - acc: 0.8036 - val_loss: 0.2294 - val_acc: 0.7097\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1369 - acc: 0.8218 - val_loss: 0.2306 - val_acc: 0.7097\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.1360 - acc: 0.8255 - val_loss: 0.2294 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1355 - acc: 0.8218 - val_loss: 0.2303 - val_acc: 0.7097\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1346 - acc: 0.8218 - val_loss: 0.2291 - val_acc: 0.7097\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1345 - acc: 0.8218 - val_loss: 0.2294 - val_acc: 0.7097\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.1334 - acc: 0.8291 - val_loss: 0.2293 - val_acc: 0.7097\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1334 - acc: 0.8218 - val_loss: 0.2304 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1325 - acc: 0.8327 - val_loss: 0.2308 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1322 - acc: 0.8255 - val_loss: 0.2305 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1311 - acc: 0.8364 - val_loss: 0.2305 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.1307 - acc: 0.8291 - val_loss: 0.2320 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1291 - acc: 0.8327 - val_loss: 0.2307 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1286 - acc: 0.8436 - val_loss: 0.2320 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1280 - acc: 0.8400 - val_loss: 0.2312 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1275 - acc: 0.8473 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1262 - acc: 0.8545 - val_loss: 0.2315 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 299us/step - loss: 0.1255 - acc: 0.8473 - val_loss: 0.2308 - val_acc: 0.6774\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 277us/step - loss: 0.1251 - acc: 0.8473 - val_loss: 0.2326 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.1250 - acc: 0.8400 - val_loss: 0.2326 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.1238 - acc: 0.8509 - val_loss: 0.2301 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1231 - acc: 0.8509 - val_loss: 0.2293 - val_acc: 0.6774\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1216 - acc: 0.8582 - val_loss: 0.2299 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.1208 - acc: 0.8618 - val_loss: 0.2303 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 330us/step - loss: 0.1194 - acc: 0.8655 - val_loss: 0.2317 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1190 - acc: 0.8727 - val_loss: 0.2316 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1177 - acc: 0.8691 - val_loss: 0.2308 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.1162 - acc: 0.8691 - val_loss: 0.2312 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 341us/step - loss: 0.1158 - acc: 0.8691 - val_loss: 0.2295 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.1144 - acc: 0.8691 - val_loss: 0.2327 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.1134 - acc: 0.8727 - val_loss: 0.2339 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 268us/step - loss: 0.1119 - acc: 0.8618 - val_loss: 0.2354 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.1102 - acc: 0.8727 - val_loss: 0.2354 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 276us/step - loss: 0.1099 - acc: 0.8800 - val_loss: 0.2367 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.1086 - acc: 0.8727 - val_loss: 0.2387 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1065 - acc: 0.8764 - val_loss: 0.2377 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1062 - acc: 0.8836 - val_loss: 0.2376 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.1041 - acc: 0.8800 - val_loss: 0.2369 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 308us/step - loss: 0.1025 - acc: 0.8945 - val_loss: 0.2381 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.1021 - acc: 0.8800 - val_loss: 0.2365 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1012 - acc: 0.8836 - val_loss: 0.2368 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0986 - acc: 0.9018 - val_loss: 0.2371 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.0968 - acc: 0.9055 - val_loss: 0.2353 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.0951 - acc: 0.8945 - val_loss: 0.2389 - val_acc: 0.6774\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 249us/step - loss: 0.0937 - acc: 0.8945 - val_loss: 0.2372 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.0924 - acc: 0.8873 - val_loss: 0.2394 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.0910 - acc: 0.9018 - val_loss: 0.2407 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0890 - acc: 0.9127 - val_loss: 0.2398 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0880 - acc: 0.9091 - val_loss: 0.2377 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0877 - acc: 0.9164 - val_loss: 0.2387 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0840 - acc: 0.9127 - val_loss: 0.2385 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.0829 - acc: 0.9164 - val_loss: 0.2388 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 300us/step - loss: 0.0809 - acc: 0.9164 - val_loss: 0.2357 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 387us/step - loss: 0.0794 - acc: 0.9055 - val_loss: 0.2404 - val_acc: 0.6774\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 311us/step - loss: 0.0777 - acc: 0.9236 - val_loss: 0.2339 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_133 (Dense)            (None, 35)                1365      \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 13)                468       \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 1,847\n",
      "Trainable params: 1,847\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 2s 7ms/step - loss: 0.2498 - acc: 0.5382 - val_loss: 0.2496 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 387us/step - loss: 0.2491 - acc: 0.5418 - val_loss: 0.2486 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 342us/step - loss: 0.2467 - acc: 0.5418 - val_loss: 0.2453 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 374us/step - loss: 0.2388 - acc: 0.5855 - val_loss: 0.2367 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 310us/step - loss: 0.2253 - acc: 0.6145 - val_loss: 0.2266 - val_acc: 0.5806\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 268us/step - loss: 0.2103 - acc: 0.7164 - val_loss: 0.2201 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.1972 - acc: 0.7309 - val_loss: 0.2138 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1886 - acc: 0.7491 - val_loss: 0.2138 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1770 - acc: 0.7527 - val_loss: 0.2082 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1698 - acc: 0.7564 - val_loss: 0.2135 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1665 - acc: 0.7564 - val_loss: 0.2130 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1643 - acc: 0.7709 - val_loss: 0.2183 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.1611 - acc: 0.7818 - val_loss: 0.2220 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.1584 - acc: 0.7782 - val_loss: 0.2207 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 288us/step - loss: 0.1562 - acc: 0.7927 - val_loss: 0.2207 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1559 - acc: 0.7891 - val_loss: 0.2223 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1542 - acc: 0.7855 - val_loss: 0.2267 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 303us/step - loss: 0.1532 - acc: 0.8000 - val_loss: 0.2242 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.1520 - acc: 0.8036 - val_loss: 0.2255 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.1526 - acc: 0.7891 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.1499 - acc: 0.8073 - val_loss: 0.2277 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 320us/step - loss: 0.1494 - acc: 0.8073 - val_loss: 0.2320 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.1479 - acc: 0.8109 - val_loss: 0.2278 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 287us/step - loss: 0.1465 - acc: 0.8073 - val_loss: 0.2320 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.1460 - acc: 0.8036 - val_loss: 0.2315 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.1447 - acc: 0.8182 - val_loss: 0.2338 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.1437 - acc: 0.8255 - val_loss: 0.2339 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1454 - acc: 0.8182 - val_loss: 0.2336 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1416 - acc: 0.8218 - val_loss: 0.2349 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.1414 - acc: 0.8218 - val_loss: 0.2370 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1392 - acc: 0.8255 - val_loss: 0.2317 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1383 - acc: 0.8291 - val_loss: 0.2373 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.1371 - acc: 0.8327 - val_loss: 0.2354 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 296us/step - loss: 0.1363 - acc: 0.8182 - val_loss: 0.2333 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.1374 - acc: 0.8327 - val_loss: 0.2352 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1342 - acc: 0.8327 - val_loss: 0.2352 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 300us/step - loss: 0.1330 - acc: 0.8327 - val_loss: 0.2396 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.1318 - acc: 0.8400 - val_loss: 0.2352 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 299us/step - loss: 0.1305 - acc: 0.8436 - val_loss: 0.2385 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 302us/step - loss: 0.1294 - acc: 0.8436 - val_loss: 0.2350 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 297us/step - loss: 0.1268 - acc: 0.8473 - val_loss: 0.2376 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 321us/step - loss: 0.1261 - acc: 0.8473 - val_loss: 0.2361 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.1257 - acc: 0.8400 - val_loss: 0.2374 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.1234 - acc: 0.8473 - val_loss: 0.2380 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1218 - acc: 0.8509 - val_loss: 0.2381 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1200 - acc: 0.8545 - val_loss: 0.2353 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.1193 - acc: 0.8618 - val_loss: 0.2348 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1170 - acc: 0.8618 - val_loss: 0.2298 - val_acc: 0.7419\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1149 - acc: 0.8764 - val_loss: 0.2352 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1137 - acc: 0.8727 - val_loss: 0.2334 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1114 - acc: 0.8800 - val_loss: 0.2360 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1099 - acc: 0.8873 - val_loss: 0.2336 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1080 - acc: 0.8836 - val_loss: 0.2352 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1064 - acc: 0.8909 - val_loss: 0.2345 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1044 - acc: 0.8982 - val_loss: 0.2318 - val_acc: 0.6774\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1019 - acc: 0.9018 - val_loss: 0.2321 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1004 - acc: 0.9018 - val_loss: 0.2325 - val_acc: 0.6774\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0995 - acc: 0.8982 - val_loss: 0.2337 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0966 - acc: 0.9055 - val_loss: 0.2269 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0944 - acc: 0.9091 - val_loss: 0.2271 - val_acc: 0.6774\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.0944 - acc: 0.9055 - val_loss: 0.2333 - val_acc: 0.7097\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0898 - acc: 0.9164 - val_loss: 0.2238 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0866 - acc: 0.9200 - val_loss: 0.2282 - val_acc: 0.7097\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0844 - acc: 0.9164 - val_loss: 0.2252 - val_acc: 0.7097\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0821 - acc: 0.9200 - val_loss: 0.2245 - val_acc: 0.7097\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0790 - acc: 0.9345 - val_loss: 0.2169 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0778 - acc: 0.9345 - val_loss: 0.2127 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0748 - acc: 0.9309 - val_loss: 0.2062 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.0712 - acc: 0.9345 - val_loss: 0.2080 - val_acc: 0.7097\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0688 - acc: 0.9418 - val_loss: 0.2075 - val_acc: 0.7419\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0662 - acc: 0.9345 - val_loss: 0.2073 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 277us/step - loss: 0.0626 - acc: 0.9491 - val_loss: 0.2033 - val_acc: 0.7097\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 293us/step - loss: 0.0597 - acc: 0.9491 - val_loss: 0.2074 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 278us/step - loss: 0.0575 - acc: 0.9455 - val_loss: 0.2101 - val_acc: 0.6452\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.0535 - acc: 0.9564 - val_loss: 0.2127 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 279us/step - loss: 0.0524 - acc: 0.9527 - val_loss: 0.2146 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 279us/step - loss: 0.0510 - acc: 0.9491 - val_loss: 0.2021 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0490 - acc: 0.9527 - val_loss: 0.2068 - val_acc: 0.7097\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.0453 - acc: 0.9600 - val_loss: 0.2244 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.0458 - acc: 0.9600 - val_loss: 0.2076 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.0421 - acc: 0.9636 - val_loss: 0.2136 - val_acc: 0.6774\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.0438 - acc: 0.9564 - val_loss: 0.2130 - val_acc: 0.7097\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 268us/step - loss: 0.0397 - acc: 0.9636 - val_loss: 0.2181 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0378 - acc: 0.9673 - val_loss: 0.2167 - val_acc: 0.7097\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0365 - acc: 0.9673 - val_loss: 0.2179 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0350 - acc: 0.9673 - val_loss: 0.2163 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.0347 - acc: 0.9673 - val_loss: 0.2214 - val_acc: 0.7097\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.0335 - acc: 0.9673 - val_loss: 0.2207 - val_acc: 0.7097\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0322 - acc: 0.9673 - val_loss: 0.2288 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.0314 - acc: 0.9673 - val_loss: 0.2279 - val_acc: 0.7097\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.0297 - acc: 0.9745 - val_loss: 0.2285 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0290 - acc: 0.9673 - val_loss: 0.2184 - val_acc: 0.7097\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0278 - acc: 0.9709 - val_loss: 0.2272 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0262 - acc: 0.9745 - val_loss: 0.2311 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.0264 - acc: 0.9709 - val_loss: 0.2261 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0242 - acc: 0.9782 - val_loss: 0.2308 - val_acc: 0.6774\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0230 - acc: 0.9782 - val_loss: 0.2270 - val_acc: 0.6774\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0229 - acc: 0.9745 - val_loss: 0.2306 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.0228 - acc: 0.9782 - val_loss: 0.2245 - val_acc: 0.7097\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.0209 - acc: 0.9745 - val_loss: 0.2293 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_136 (Dense)            (None, 35)                1365      \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 17)                612       \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 1)                 18        \n",
      "=================================================================\n",
      "Total params: 1,995\n",
      "Trainable params: 1,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 2s 6ms/step - loss: 0.2499 - acc: 0.5418 - val_loss: 0.2498 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.2493 - acc: 0.5418 - val_loss: 0.2491 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 285us/step - loss: 0.2476 - acc: 0.5418 - val_loss: 0.2461 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.2407 - acc: 0.5527 - val_loss: 0.2376 - val_acc: 0.5806\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 216us/step - loss: 0.2291 - acc: 0.6073 - val_loss: 0.2238 - val_acc: 0.6774\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.2133 - acc: 0.7127 - val_loss: 0.2179 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.2002 - acc: 0.7055 - val_loss: 0.2094 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.1868 - acc: 0.7491 - val_loss: 0.2044 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.1776 - acc: 0.7382 - val_loss: 0.2057 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.1713 - acc: 0.7564 - val_loss: 0.2136 - val_acc: 0.6452\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1661 - acc: 0.7527 - val_loss: 0.2099 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1641 - acc: 0.7673 - val_loss: 0.2127 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1611 - acc: 0.7709 - val_loss: 0.2168 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.1594 - acc: 0.7673 - val_loss: 0.2205 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1580 - acc: 0.7782 - val_loss: 0.2214 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1562 - acc: 0.7855 - val_loss: 0.2255 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1571 - acc: 0.7745 - val_loss: 0.2265 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 289us/step - loss: 0.1532 - acc: 0.7891 - val_loss: 0.2300 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1553 - acc: 0.7782 - val_loss: 0.2254 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1510 - acc: 0.7964 - val_loss: 0.2328 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.1498 - acc: 0.8000 - val_loss: 0.2282 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 318us/step - loss: 0.1493 - acc: 0.8073 - val_loss: 0.2287 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 313us/step - loss: 0.1479 - acc: 0.8036 - val_loss: 0.2335 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 319us/step - loss: 0.1486 - acc: 0.8073 - val_loss: 0.2299 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.1451 - acc: 0.8073 - val_loss: 0.2299 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1447 - acc: 0.8182 - val_loss: 0.2299 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1452 - acc: 0.8145 - val_loss: 0.2310 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1412 - acc: 0.8182 - val_loss: 0.2283 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.1409 - acc: 0.8182 - val_loss: 0.2299 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.1395 - acc: 0.8291 - val_loss: 0.2283 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1375 - acc: 0.8327 - val_loss: 0.2310 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1365 - acc: 0.8327 - val_loss: 0.2313 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.1353 - acc: 0.8364 - val_loss: 0.2336 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1337 - acc: 0.8291 - val_loss: 0.2337 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1335 - acc: 0.8327 - val_loss: 0.2347 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1306 - acc: 0.8364 - val_loss: 0.2355 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1286 - acc: 0.8327 - val_loss: 0.2325 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1279 - acc: 0.8436 - val_loss: 0.2338 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1254 - acc: 0.8545 - val_loss: 0.2346 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.1245 - acc: 0.8364 - val_loss: 0.2361 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1222 - acc: 0.8582 - val_loss: 0.2354 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.1202 - acc: 0.8582 - val_loss: 0.2351 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.1190 - acc: 0.8545 - val_loss: 0.2365 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1161 - acc: 0.8655 - val_loss: 0.2375 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.1141 - acc: 0.8655 - val_loss: 0.2372 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.1112 - acc: 0.8800 - val_loss: 0.2395 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1090 - acc: 0.8873 - val_loss: 0.2376 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1068 - acc: 0.8909 - val_loss: 0.2406 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1044 - acc: 0.8945 - val_loss: 0.2404 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1017 - acc: 0.8945 - val_loss: 0.2407 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0992 - acc: 0.8982 - val_loss: 0.2430 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.0963 - acc: 0.9091 - val_loss: 0.2443 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0937 - acc: 0.9055 - val_loss: 0.2430 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.0909 - acc: 0.9091 - val_loss: 0.2453 - val_acc: 0.6452\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0924 - acc: 0.9055 - val_loss: 0.2418 - val_acc: 0.7419\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0865 - acc: 0.9164 - val_loss: 0.2460 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0831 - acc: 0.9273 - val_loss: 0.2420 - val_acc: 0.6452\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 217us/step - loss: 0.0802 - acc: 0.9236 - val_loss: 0.2409 - val_acc: 0.6452\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0775 - acc: 0.9309 - val_loss: 0.2403 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.0742 - acc: 0.9200 - val_loss: 0.2370 - val_acc: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.0708 - acc: 0.9345 - val_loss: 0.2419 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0684 - acc: 0.9455 - val_loss: 0.2411 - val_acc: 0.6774\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0660 - acc: 0.9455 - val_loss: 0.2364 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0623 - acc: 0.9491 - val_loss: 0.2368 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0598 - acc: 0.9527 - val_loss: 0.2428 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0577 - acc: 0.9636 - val_loss: 0.2313 - val_acc: 0.6774\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.0561 - acc: 0.9636 - val_loss: 0.2432 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0525 - acc: 0.9636 - val_loss: 0.2423 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0508 - acc: 0.9673 - val_loss: 0.2451 - val_acc: 0.6774\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0479 - acc: 0.9709 - val_loss: 0.2471 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0462 - acc: 0.9673 - val_loss: 0.2464 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.0462 - acc: 0.9709 - val_loss: 0.2478 - val_acc: 0.6774\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0438 - acc: 0.9709 - val_loss: 0.2460 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0419 - acc: 0.9709 - val_loss: 0.2505 - val_acc: 0.6452\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0405 - acc: 0.9745 - val_loss: 0.2534 - val_acc: 0.6774\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.0388 - acc: 0.9745 - val_loss: 0.2527 - val_acc: 0.6774\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0377 - acc: 0.9745 - val_loss: 0.2495 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0374 - acc: 0.9745 - val_loss: 0.2500 - val_acc: 0.7097\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0357 - acc: 0.9745 - val_loss: 0.2506 - val_acc: 0.6129\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 261us/step - loss: 0.0356 - acc: 0.9745 - val_loss: 0.2496 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 255us/step - loss: 0.0336 - acc: 0.9745 - val_loss: 0.2472 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.0324 - acc: 0.9745 - val_loss: 0.2479 - val_acc: 0.6774\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.0318 - acc: 0.9745 - val_loss: 0.2492 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0300 - acc: 0.9745 - val_loss: 0.2483 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0294 - acc: 0.9782 - val_loss: 0.2482 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 253us/step - loss: 0.0290 - acc: 0.9709 - val_loss: 0.2512 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0276 - acc: 0.9782 - val_loss: 0.2463 - val_acc: 0.6774\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.0260 - acc: 0.9782 - val_loss: 0.2524 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0235 - acc: 0.9855 - val_loss: 0.2490 - val_acc: 0.6774\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0228 - acc: 0.9855 - val_loss: 0.2488 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.0214 - acc: 0.9855 - val_loss: 0.2590 - val_acc: 0.6774\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.0217 - acc: 0.9855 - val_loss: 0.2511 - val_acc: 0.6774\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0208 - acc: 0.9855 - val_loss: 0.2563 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0195 - acc: 0.9891 - val_loss: 0.2569 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0185 - acc: 0.9891 - val_loss: 0.2529 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0177 - acc: 0.9891 - val_loss: 0.2511 - val_acc: 0.6452\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0172 - acc: 0.9891 - val_loss: 0.2608 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.0171 - acc: 0.9891 - val_loss: 0.2567 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.0165 - acc: 0.9891 - val_loss: 0.2604 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 262us/step - loss: 0.0158 - acc: 0.9891 - val_loss: 0.2634 - val_acc: 0.6452\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_139 (Dense)            (None, 13)                507       \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 15)                210       \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 733\n",
      "Trainable params: 733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 2s 6ms/step - loss: 0.2499 - acc: 0.5127 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2496 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.2490 - acc: 0.5418 - val_loss: 0.2486 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.2469 - acc: 0.5600 - val_loss: 0.2457 - val_acc: 0.5806\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.2420 - acc: 0.6073 - val_loss: 0.2393 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.2335 - acc: 0.7018 - val_loss: 0.2297 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.2202 - acc: 0.7164 - val_loss: 0.2216 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.2072 - acc: 0.7382 - val_loss: 0.2116 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1938 - acc: 0.7418 - val_loss: 0.2041 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1830 - acc: 0.7564 - val_loss: 0.2027 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 297us/step - loss: 0.1758 - acc: 0.7418 - val_loss: 0.2029 - val_acc: 0.7097\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 320us/step - loss: 0.1711 - acc: 0.7527 - val_loss: 0.2013 - val_acc: 0.7097\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1677 - acc: 0.7527 - val_loss: 0.2078 - val_acc: 0.7097\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.1648 - acc: 0.7745 - val_loss: 0.2044 - val_acc: 0.7097\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 246us/step - loss: 0.1619 - acc: 0.7673 - val_loss: 0.2096 - val_acc: 0.7097\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1595 - acc: 0.7782 - val_loss: 0.2118 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1592 - acc: 0.7673 - val_loss: 0.2143 - val_acc: 0.7097\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.1568 - acc: 0.7709 - val_loss: 0.2144 - val_acc: 0.7097\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1553 - acc: 0.7891 - val_loss: 0.2159 - val_acc: 0.7097\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.1549 - acc: 0.7818 - val_loss: 0.2164 - val_acc: 0.7097\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.1542 - acc: 0.8000 - val_loss: 0.2166 - val_acc: 0.7097\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 263us/step - loss: 0.1523 - acc: 0.8036 - val_loss: 0.2181 - val_acc: 0.7097\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1512 - acc: 0.7891 - val_loss: 0.2184 - val_acc: 0.7097\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1508 - acc: 0.7964 - val_loss: 0.2178 - val_acc: 0.7097\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.1492 - acc: 0.8109 - val_loss: 0.2194 - val_acc: 0.7097\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.1484 - acc: 0.8000 - val_loss: 0.2171 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 287us/step - loss: 0.1479 - acc: 0.7964 - val_loss: 0.2183 - val_acc: 0.7097\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1475 - acc: 0.8073 - val_loss: 0.2187 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1458 - acc: 0.8145 - val_loss: 0.2179 - val_acc: 0.7097\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1460 - acc: 0.8182 - val_loss: 0.2172 - val_acc: 0.7097\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 249us/step - loss: 0.1448 - acc: 0.8073 - val_loss: 0.2180 - val_acc: 0.7097\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1445 - acc: 0.8145 - val_loss: 0.2176 - val_acc: 0.7097\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1425 - acc: 0.8182 - val_loss: 0.2169 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 301us/step - loss: 0.1413 - acc: 0.8255 - val_loss: 0.2178 - val_acc: 0.7097\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 288us/step - loss: 0.1407 - acc: 0.8327 - val_loss: 0.2169 - val_acc: 0.7097\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 297us/step - loss: 0.1391 - acc: 0.8291 - val_loss: 0.2177 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.1381 - acc: 0.8436 - val_loss: 0.2168 - val_acc: 0.7097\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1374 - acc: 0.8327 - val_loss: 0.2160 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.1367 - acc: 0.8364 - val_loss: 0.2182 - val_acc: 0.7097\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1358 - acc: 0.8436 - val_loss: 0.2178 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 286us/step - loss: 0.1340 - acc: 0.8364 - val_loss: 0.2207 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.1340 - acc: 0.8255 - val_loss: 0.2188 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.1327 - acc: 0.8400 - val_loss: 0.2196 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 273us/step - loss: 0.1317 - acc: 0.8364 - val_loss: 0.2183 - val_acc: 0.7097\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.1297 - acc: 0.8473 - val_loss: 0.2175 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 264us/step - loss: 0.1300 - acc: 0.8327 - val_loss: 0.2195 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 272us/step - loss: 0.1277 - acc: 0.8436 - val_loss: 0.2176 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1270 - acc: 0.8400 - val_loss: 0.2185 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1257 - acc: 0.8545 - val_loss: 0.2203 - val_acc: 0.6774\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1248 - acc: 0.8509 - val_loss: 0.2199 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.1236 - acc: 0.8509 - val_loss: 0.2198 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.1232 - acc: 0.8545 - val_loss: 0.2178 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 286us/step - loss: 0.1211 - acc: 0.8582 - val_loss: 0.2202 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 267us/step - loss: 0.1197 - acc: 0.8618 - val_loss: 0.2189 - val_acc: 0.6774\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.1186 - acc: 0.8691 - val_loss: 0.2194 - val_acc: 0.7097\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1171 - acc: 0.8618 - val_loss: 0.2198 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.1158 - acc: 0.8691 - val_loss: 0.2182 - val_acc: 0.7097\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 287us/step - loss: 0.1153 - acc: 0.8764 - val_loss: 0.2193 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.1136 - acc: 0.8836 - val_loss: 0.2208 - val_acc: 0.6774\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.1121 - acc: 0.8618 - val_loss: 0.2188 - val_acc: 0.7097\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 283us/step - loss: 0.1114 - acc: 0.8909 - val_loss: 0.2185 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.1101 - acc: 0.8800 - val_loss: 0.2202 - val_acc: 0.7097\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.1082 - acc: 0.8836 - val_loss: 0.2175 - val_acc: 0.7097\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.1071 - acc: 0.8909 - val_loss: 0.2182 - val_acc: 0.7097\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.1052 - acc: 0.8909 - val_loss: 0.2182 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.1049 - acc: 0.8800 - val_loss: 0.2130 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1022 - acc: 0.8909 - val_loss: 0.2123 - val_acc: 0.7097\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1008 - acc: 0.8909 - val_loss: 0.2137 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 288us/step - loss: 0.0986 - acc: 0.8873 - val_loss: 0.2140 - val_acc: 0.7097\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.0967 - acc: 0.8873 - val_loss: 0.2124 - val_acc: 0.7097\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 284us/step - loss: 0.0950 - acc: 0.8982 - val_loss: 0.2093 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 288us/step - loss: 0.0933 - acc: 0.8982 - val_loss: 0.2117 - val_acc: 0.7097\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 288us/step - loss: 0.0916 - acc: 0.9018 - val_loss: 0.2121 - val_acc: 0.7097\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 289us/step - loss: 0.0898 - acc: 0.9018 - val_loss: 0.2124 - val_acc: 0.7419\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 257us/step - loss: 0.0890 - acc: 0.9091 - val_loss: 0.2120 - val_acc: 0.7419\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0869 - acc: 0.9127 - val_loss: 0.2129 - val_acc: 0.7419\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 242us/step - loss: 0.0853 - acc: 0.9091 - val_loss: 0.2094 - val_acc: 0.7419\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.0840 - acc: 0.9164 - val_loss: 0.2087 - val_acc: 0.7419\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0839 - acc: 0.9236 - val_loss: 0.2128 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0802 - acc: 0.9273 - val_loss: 0.2078 - val_acc: 0.7419\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0783 - acc: 0.9273 - val_loss: 0.2139 - val_acc: 0.7419\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0773 - acc: 0.9273 - val_loss: 0.2148 - val_acc: 0.7419\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0757 - acc: 0.9382 - val_loss: 0.2138 - val_acc: 0.7097\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.0737 - acc: 0.9382 - val_loss: 0.2110 - val_acc: 0.7419\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0725 - acc: 0.9382 - val_loss: 0.2141 - val_acc: 0.7097\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.0718 - acc: 0.9382 - val_loss: 0.2110 - val_acc: 0.7419\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.0688 - acc: 0.9418 - val_loss: 0.2123 - val_acc: 0.7419\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.0683 - acc: 0.9382 - val_loss: 0.2120 - val_acc: 0.7742\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0682 - acc: 0.9455 - val_loss: 0.2066 - val_acc: 0.7419\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0656 - acc: 0.9382 - val_loss: 0.2109 - val_acc: 0.7742\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0645 - acc: 0.9491 - val_loss: 0.2092 - val_acc: 0.7742\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0625 - acc: 0.9455 - val_loss: 0.2092 - val_acc: 0.7742\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0616 - acc: 0.9455 - val_loss: 0.2077 - val_acc: 0.7742\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0611 - acc: 0.9345 - val_loss: 0.2071 - val_acc: 0.7742\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0602 - acc: 0.9455 - val_loss: 0.2117 - val_acc: 0.7742\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0580 - acc: 0.9455 - val_loss: 0.2114 - val_acc: 0.7742\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0557 - acc: 0.9491 - val_loss: 0.2089 - val_acc: 0.7742\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0535 - acc: 0.9527 - val_loss: 0.2091 - val_acc: 0.7419\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0527 - acc: 0.9455 - val_loss: 0.2099 - val_acc: 0.7419\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0526 - acc: 0.9455 - val_loss: 0.2104 - val_acc: 0.7419\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_142 (Dense)            (None, 47)                1833      \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 15)                720       \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 2,569\n",
      "Trainable params: 2,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 2s 6ms/step - loss: 0.2500 - acc: 0.5164 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2492 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.2483 - acc: 0.5564 - val_loss: 0.2466 - val_acc: 0.6452\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.2433 - acc: 0.7236 - val_loss: 0.2402 - val_acc: 0.6129\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.2303 - acc: 0.7418 - val_loss: 0.2242 - val_acc: 0.7097\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.2075 - acc: 0.7564 - val_loss: 0.2076 - val_acc: 0.6774\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.1868 - acc: 0.7564 - val_loss: 0.2046 - val_acc: 0.6774\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.1747 - acc: 0.7455 - val_loss: 0.2045 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1664 - acc: 0.7745 - val_loss: 0.2087 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1610 - acc: 0.7673 - val_loss: 0.2105 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1587 - acc: 0.7891 - val_loss: 0.2154 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 274us/step - loss: 0.1573 - acc: 0.7709 - val_loss: 0.2169 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1536 - acc: 0.8036 - val_loss: 0.2187 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.1501 - acc: 0.7891 - val_loss: 0.2197 - val_acc: 0.7097\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 257us/step - loss: 0.1466 - acc: 0.8109 - val_loss: 0.2236 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1450 - acc: 0.8218 - val_loss: 0.2316 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1433 - acc: 0.8182 - val_loss: 0.2275 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1399 - acc: 0.8291 - val_loss: 0.2273 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 245us/step - loss: 0.1368 - acc: 0.8327 - val_loss: 0.2328 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 256us/step - loss: 0.1347 - acc: 0.8327 - val_loss: 0.2317 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 244us/step - loss: 0.1308 - acc: 0.8436 - val_loss: 0.2338 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1279 - acc: 0.8473 - val_loss: 0.2310 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.1254 - acc: 0.8509 - val_loss: 0.2324 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1218 - acc: 0.8582 - val_loss: 0.2328 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1172 - acc: 0.8618 - val_loss: 0.2334 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 286us/step - loss: 0.1135 - acc: 0.8691 - val_loss: 0.2323 - val_acc: 0.6774\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 261us/step - loss: 0.1101 - acc: 0.8800 - val_loss: 0.2339 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1071 - acc: 0.8873 - val_loss: 0.2308 - val_acc: 0.6452\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1019 - acc: 0.8982 - val_loss: 0.2353 - val_acc: 0.6452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 284us/step - loss: 0.0972 - acc: 0.9018 - val_loss: 0.2334 - val_acc: 0.6452\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0920 - acc: 0.9127 - val_loss: 0.2359 - val_acc: 0.6452\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0886 - acc: 0.9164 - val_loss: 0.2324 - val_acc: 0.6129\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 269us/step - loss: 0.0833 - acc: 0.9200 - val_loss: 0.2403 - val_acc: 0.5806\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 297us/step - loss: 0.0808 - acc: 0.9273 - val_loss: 0.2369 - val_acc: 0.6129\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 317us/step - loss: 0.0724 - acc: 0.9418 - val_loss: 0.2343 - val_acc: 0.6452\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 287us/step - loss: 0.0680 - acc: 0.9345 - val_loss: 0.2407 - val_acc: 0.6452\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0642 - acc: 0.9527 - val_loss: 0.2376 - val_acc: 0.6452\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0581 - acc: 0.9527 - val_loss: 0.2418 - val_acc: 0.6452\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0531 - acc: 0.9600 - val_loss: 0.2433 - val_acc: 0.6452\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0488 - acc: 0.9709 - val_loss: 0.2435 - val_acc: 0.6452\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0447 - acc: 0.9709 - val_loss: 0.2387 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0414 - acc: 0.9782 - val_loss: 0.2372 - val_acc: 0.6452\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.0382 - acc: 0.9855 - val_loss: 0.2428 - val_acc: 0.6452\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.0337 - acc: 0.9891 - val_loss: 0.2397 - val_acc: 0.6129\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.0321 - acc: 0.9891 - val_loss: 0.2380 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0294 - acc: 0.9891 - val_loss: 0.2413 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0275 - acc: 0.9891 - val_loss: 0.2430 - val_acc: 0.6129\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0250 - acc: 0.9891 - val_loss: 0.2447 - val_acc: 0.6129\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0215 - acc: 0.9891 - val_loss: 0.2481 - val_acc: 0.6452\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0207 - acc: 0.9927 - val_loss: 0.2447 - val_acc: 0.6129\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0177 - acc: 0.9927 - val_loss: 0.2476 - val_acc: 0.6129\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 209us/step - loss: 0.0164 - acc: 0.9964 - val_loss: 0.2525 - val_acc: 0.6129\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0148 - acc: 0.9964 - val_loss: 0.2561 - val_acc: 0.6129\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0134 - acc: 0.9964 - val_loss: 0.2525 - val_acc: 0.6129\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0122 - acc: 0.9964 - val_loss: 0.2589 - val_acc: 0.6129\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0117 - acc: 0.9964 - val_loss: 0.2577 - val_acc: 0.6452\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0108 - acc: 0.9964 - val_loss: 0.2631 - val_acc: 0.6129\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.0102 - acc: 0.9964 - val_loss: 0.2604 - val_acc: 0.6452\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.0098 - acc: 0.9964 - val_loss: 0.2649 - val_acc: 0.6129\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0091 - acc: 0.9964 - val_loss: 0.2651 - val_acc: 0.6129\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0087 - acc: 0.9964 - val_loss: 0.2678 - val_acc: 0.6129\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0083 - acc: 0.9964 - val_loss: 0.2674 - val_acc: 0.6129\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0080 - acc: 0.9964 - val_loss: 0.2712 - val_acc: 0.6129\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.0076 - acc: 0.9964 - val_loss: 0.2715 - val_acc: 0.6129\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0073 - acc: 0.9964 - val_loss: 0.2742 - val_acc: 0.6129\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.0071 - acc: 0.9964 - val_loss: 0.2731 - val_acc: 0.6129\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0068 - acc: 0.9964 - val_loss: 0.2761 - val_acc: 0.6129\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0066 - acc: 0.9964 - val_loss: 0.2744 - val_acc: 0.6129\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0064 - acc: 0.9964 - val_loss: 0.2792 - val_acc: 0.6129\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0062 - acc: 0.9964 - val_loss: 0.2792 - val_acc: 0.6129\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0061 - acc: 0.9964 - val_loss: 0.2803 - val_acc: 0.6129\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0059 - acc: 0.9964 - val_loss: 0.2804 - val_acc: 0.6129\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0057 - acc: 0.9964 - val_loss: 0.2825 - val_acc: 0.6129\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0056 - acc: 0.9964 - val_loss: 0.2830 - val_acc: 0.6129\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0055 - acc: 0.9964 - val_loss: 0.2835 - val_acc: 0.6129\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 213us/step - loss: 0.0053 - acc: 0.9964 - val_loss: 0.2861 - val_acc: 0.6129\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0052 - acc: 0.9964 - val_loss: 0.2851 - val_acc: 0.6129\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 214us/step - loss: 0.0051 - acc: 0.9964 - val_loss: 0.2857 - val_acc: 0.6129\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.0049 - acc: 0.9964 - val_loss: 0.2854 - val_acc: 0.6129\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.0048 - acc: 0.9964 - val_loss: 0.2868 - val_acc: 0.6129\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 214us/step - loss: 0.0046 - acc: 0.9964 - val_loss: 0.2885 - val_acc: 0.6129\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 211us/step - loss: 0.0045 - acc: 0.9964 - val_loss: 0.2884 - val_acc: 0.6129\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0042 - acc: 0.9964 - val_loss: 0.2879 - val_acc: 0.6129\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0032 - acc: 0.9964 - val_loss: 0.2899 - val_acc: 0.6129\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.2882 - val_acc: 0.6129\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2905 - val_acc: 0.6129\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2934 - val_acc: 0.6129\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2926 - val_acc: 0.6129\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2947 - val_acc: 0.6129\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 226us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2961 - val_acc: 0.6129\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2962 - val_acc: 0.6129\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.2974 - val_acc: 0.6129\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 9.6703e-04 - acc: 1.0000 - val_loss: 0.2990 - val_acc: 0.6129\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 9.2820e-04 - acc: 1.0000 - val_loss: 0.2991 - val_acc: 0.6129\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 8.8024e-04 - acc: 1.0000 - val_loss: 0.2993 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 8.3699e-04 - acc: 1.0000 - val_loss: 0.2998 - val_acc: 0.6129\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 220us/step - loss: 8.0419e-04 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.6129\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 7.6966e-04 - acc: 1.0000 - val_loss: 0.3003 - val_acc: 0.6129\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 7.4539e-04 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.6129\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 7.1057e-04 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.6129\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_145 (Dense)            (None, 15)                585       \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 858\n",
      "Trainable params: 858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 2s 6ms/step - loss: 0.2500 - acc: 0.4764 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.2496 - acc: 0.5418 - val_loss: 0.2496 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.2483 - acc: 0.5418 - val_loss: 0.2484 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.2450 - acc: 0.5418 - val_loss: 0.2449 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 268us/step - loss: 0.2374 - acc: 0.5564 - val_loss: 0.2387 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.2252 - acc: 0.6545 - val_loss: 0.2318 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.2121 - acc: 0.6909 - val_loss: 0.2250 - val_acc: 0.5806\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.2003 - acc: 0.7455 - val_loss: 0.2182 - val_acc: 0.6129\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.1897 - acc: 0.7455 - val_loss: 0.2170 - val_acc: 0.6452\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 276us/step - loss: 0.1823 - acc: 0.7455 - val_loss: 0.2150 - val_acc: 0.6452\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.1743 - acc: 0.7636 - val_loss: 0.2184 - val_acc: 0.6452\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1693 - acc: 0.7782 - val_loss: 0.2178 - val_acc: 0.6452\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 254us/step - loss: 0.1654 - acc: 0.7891 - val_loss: 0.2161 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1614 - acc: 0.7855 - val_loss: 0.2217 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 282us/step - loss: 0.1592 - acc: 0.8036 - val_loss: 0.2246 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.1558 - acc: 0.7964 - val_loss: 0.2262 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1546 - acc: 0.7964 - val_loss: 0.2275 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1528 - acc: 0.7964 - val_loss: 0.2266 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1510 - acc: 0.8036 - val_loss: 0.2316 - val_acc: 0.6452\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1493 - acc: 0.8109 - val_loss: 0.2289 - val_acc: 0.6452\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1477 - acc: 0.8109 - val_loss: 0.2298 - val_acc: 0.6452\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1463 - acc: 0.8109 - val_loss: 0.2316 - val_acc: 0.6452\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1456 - acc: 0.8182 - val_loss: 0.2308 - val_acc: 0.6452\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.1439 - acc: 0.8109 - val_loss: 0.2342 - val_acc: 0.6452\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1432 - acc: 0.8182 - val_loss: 0.2343 - val_acc: 0.6452\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1422 - acc: 0.8145 - val_loss: 0.2353 - val_acc: 0.6452\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 281us/step - loss: 0.1407 - acc: 0.8255 - val_loss: 0.2348 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1398 - acc: 0.8291 - val_loss: 0.2374 - val_acc: 0.6452\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1394 - acc: 0.8291 - val_loss: 0.2364 - val_acc: 0.6452\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1381 - acc: 0.8400 - val_loss: 0.2371 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.1358 - acc: 0.8364 - val_loss: 0.2370 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1343 - acc: 0.8327 - val_loss: 0.2374 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 311us/step - loss: 0.1327 - acc: 0.8364 - val_loss: 0.2414 - val_acc: 0.6452\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.1310 - acc: 0.8436 - val_loss: 0.2410 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.1304 - acc: 0.8473 - val_loss: 0.2391 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 275us/step - loss: 0.1294 - acc: 0.8436 - val_loss: 0.2382 - val_acc: 0.7097\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1289 - acc: 0.8436 - val_loss: 0.2393 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1255 - acc: 0.8545 - val_loss: 0.2403 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.1238 - acc: 0.8618 - val_loss: 0.2432 - val_acc: 0.6452\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1232 - acc: 0.8545 - val_loss: 0.2445 - val_acc: 0.7097\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1240 - acc: 0.8582 - val_loss: 0.2455 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1219 - acc: 0.8545 - val_loss: 0.2459 - val_acc: 0.6452\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1188 - acc: 0.8618 - val_loss: 0.2465 - val_acc: 0.6774\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 0s 223us/step - loss: 0.1177 - acc: 0.8582 - val_loss: 0.2503 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 266us/step - loss: 0.1171 - acc: 0.8509 - val_loss: 0.2485 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 252us/step - loss: 0.1147 - acc: 0.8655 - val_loss: 0.2526 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1142 - acc: 0.8582 - val_loss: 0.2531 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1117 - acc: 0.8655 - val_loss: 0.2528 - val_acc: 0.6774\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 279us/step - loss: 0.1103 - acc: 0.8655 - val_loss: 0.2582 - val_acc: 0.6452\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.1088 - acc: 0.8691 - val_loss: 0.2561 - val_acc: 0.6774\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.1076 - acc: 0.8764 - val_loss: 0.2581 - val_acc: 0.6774\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1067 - acc: 0.8800 - val_loss: 0.2588 - val_acc: 0.6774\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1052 - acc: 0.8764 - val_loss: 0.2604 - val_acc: 0.6774\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1026 - acc: 0.8873 - val_loss: 0.2619 - val_acc: 0.6452\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 288us/step - loss: 0.1019 - acc: 0.8873 - val_loss: 0.2633 - val_acc: 0.6452\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1007 - acc: 0.8982 - val_loss: 0.2605 - val_acc: 0.6774\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0989 - acc: 0.8909 - val_loss: 0.2603 - val_acc: 0.6452\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0977 - acc: 0.8945 - val_loss: 0.2644 - val_acc: 0.6774\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0967 - acc: 0.8945 - val_loss: 0.2636 - val_acc: 0.6452\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0943 - acc: 0.9018 - val_loss: 0.2623 - val_acc: 0.6452\n",
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0942 - acc: 0.9018 - val_loss: 0.2645 - val_acc: 0.6774\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0910 - acc: 0.9055 - val_loss: 0.2640 - val_acc: 0.6452\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0904 - acc: 0.8982 - val_loss: 0.2676 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0892 - acc: 0.9055 - val_loss: 0.2647 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0872 - acc: 0.9055 - val_loss: 0.2658 - val_acc: 0.6774\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.0848 - acc: 0.9127 - val_loss: 0.2592 - val_acc: 0.7097\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 258us/step - loss: 0.0854 - acc: 0.9164 - val_loss: 0.2591 - val_acc: 0.6452\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 265us/step - loss: 0.0821 - acc: 0.9164 - val_loss: 0.2612 - val_acc: 0.7097\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 277us/step - loss: 0.0808 - acc: 0.9200 - val_loss: 0.2602 - val_acc: 0.7097\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 276us/step - loss: 0.0781 - acc: 0.9236 - val_loss: 0.2639 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0772 - acc: 0.9273 - val_loss: 0.2587 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0756 - acc: 0.9236 - val_loss: 0.2604 - val_acc: 0.7097\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 247us/step - loss: 0.0735 - acc: 0.9309 - val_loss: 0.2601 - val_acc: 0.6774\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0718 - acc: 0.9309 - val_loss: 0.2603 - val_acc: 0.6774\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0715 - acc: 0.9345 - val_loss: 0.2564 - val_acc: 0.7097\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 248us/step - loss: 0.0693 - acc: 0.9382 - val_loss: 0.2566 - val_acc: 0.7097\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0694 - acc: 0.9345 - val_loss: 0.2601 - val_acc: 0.6452\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0698 - acc: 0.9345 - val_loss: 0.2593 - val_acc: 0.6774\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0662 - acc: 0.9382 - val_loss: 0.2611 - val_acc: 0.6774\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0637 - acc: 0.9418 - val_loss: 0.2574 - val_acc: 0.6774\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0628 - acc: 0.9382 - val_loss: 0.2599 - val_acc: 0.6452\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0638 - acc: 0.9345 - val_loss: 0.2588 - val_acc: 0.6452\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0624 - acc: 0.9382 - val_loss: 0.2596 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0602 - acc: 0.9455 - val_loss: 0.2629 - val_acc: 0.6774\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0581 - acc: 0.9418 - val_loss: 0.2531 - val_acc: 0.6774\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0566 - acc: 0.9455 - val_loss: 0.2507 - val_acc: 0.6452\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0566 - acc: 0.9455 - val_loss: 0.2564 - val_acc: 0.6452\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0534 - acc: 0.9527 - val_loss: 0.2550 - val_acc: 0.6774\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0524 - acc: 0.9564 - val_loss: 0.2586 - val_acc: 0.6452\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0519 - acc: 0.9527 - val_loss: 0.2551 - val_acc: 0.6774\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0511 - acc: 0.9564 - val_loss: 0.2622 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0539 - acc: 0.9564 - val_loss: 0.2643 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0513 - acc: 0.9491 - val_loss: 0.2585 - val_acc: 0.6774\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0479 - acc: 0.9600 - val_loss: 0.2610 - val_acc: 0.6774\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0473 - acc: 0.9564 - val_loss: 0.2623 - val_acc: 0.6774\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.0461 - acc: 0.9600 - val_loss: 0.2601 - val_acc: 0.6452\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0459 - acc: 0.9600 - val_loss: 0.2677 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0456 - acc: 0.9600 - val_loss: 0.2623 - val_acc: 0.6774\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0445 - acc: 0.9564 - val_loss: 0.2632 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 239us/step - loss: 0.0426 - acc: 0.9636 - val_loss: 0.2638 - val_acc: 0.6774\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_148 (Dense)            (None, 30)                1170      \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,491\n",
      "Trainable params: 1,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 275 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 2s 6ms/step - loss: 0.2499 - acc: 0.5455 - val_loss: 0.2499 - val_acc: 0.5161\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 0s 240us/step - loss: 0.2494 - acc: 0.5418 - val_loss: 0.2495 - val_acc: 0.5161\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.2478 - acc: 0.5418 - val_loss: 0.2470 - val_acc: 0.5161\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.2424 - acc: 0.5455 - val_loss: 0.2410 - val_acc: 0.5161\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.2323 - acc: 0.6036 - val_loss: 0.2324 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.2191 - acc: 0.6727 - val_loss: 0.2253 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 0s 250us/step - loss: 0.2069 - acc: 0.7164 - val_loss: 0.2194 - val_acc: 0.6452\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1962 - acc: 0.7273 - val_loss: 0.2184 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1873 - acc: 0.7491 - val_loss: 0.2140 - val_acc: 0.6774\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1788 - acc: 0.7600 - val_loss: 0.2126 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.1728 - acc: 0.7636 - val_loss: 0.2077 - val_acc: 0.6774\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 0s 260us/step - loss: 0.1677 - acc: 0.7673 - val_loss: 0.2131 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.1641 - acc: 0.7818 - val_loss: 0.2124 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.1613 - acc: 0.7782 - val_loss: 0.2199 - val_acc: 0.6774\n",
      "Epoch 15/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1581 - acc: 0.7782 - val_loss: 0.2217 - val_acc: 0.6774\n",
      "Epoch 16/100\n",
      "275/275 [==============================] - 0s 237us/step - loss: 0.1559 - acc: 0.7855 - val_loss: 0.2192 - val_acc: 0.6774\n",
      "Epoch 17/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.1535 - acc: 0.7891 - val_loss: 0.2258 - val_acc: 0.6774\n",
      "Epoch 18/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1515 - acc: 0.8000 - val_loss: 0.2236 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1510 - acc: 0.7964 - val_loss: 0.2264 - val_acc: 0.6774\n",
      "Epoch 20/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1486 - acc: 0.8000 - val_loss: 0.2285 - val_acc: 0.6774\n",
      "Epoch 21/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1466 - acc: 0.8000 - val_loss: 0.2273 - val_acc: 0.6774\n",
      "Epoch 22/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1451 - acc: 0.8000 - val_loss: 0.2336 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1433 - acc: 0.8182 - val_loss: 0.2336 - val_acc: 0.6774\n",
      "Epoch 24/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1417 - acc: 0.8109 - val_loss: 0.2329 - val_acc: 0.6774\n",
      "Epoch 25/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.1413 - acc: 0.8182 - val_loss: 0.2305 - val_acc: 0.6774\n",
      "Epoch 26/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.1395 - acc: 0.8109 - val_loss: 0.2304 - val_acc: 0.7097\n",
      "Epoch 27/100\n",
      "275/275 [==============================] - 0s 259us/step - loss: 0.1366 - acc: 0.8255 - val_loss: 0.2355 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.1353 - acc: 0.8255 - val_loss: 0.2341 - val_acc: 0.6774\n",
      "Epoch 29/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1342 - acc: 0.8364 - val_loss: 0.2383 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "275/275 [==============================] - 0s 271us/step - loss: 0.1329 - acc: 0.8327 - val_loss: 0.2387 - val_acc: 0.6774\n",
      "Epoch 31/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1304 - acc: 0.8291 - val_loss: 0.2400 - val_acc: 0.6774\n",
      "Epoch 32/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1290 - acc: 0.8291 - val_loss: 0.2370 - val_acc: 0.6774\n",
      "Epoch 33/100\n",
      "275/275 [==============================] - 0s 246us/step - loss: 0.1273 - acc: 0.8364 - val_loss: 0.2399 - val_acc: 0.6774\n",
      "Epoch 34/100\n",
      "275/275 [==============================] - 0s 292us/step - loss: 0.1249 - acc: 0.8400 - val_loss: 0.2414 - val_acc: 0.6774\n",
      "Epoch 35/100\n",
      "275/275 [==============================] - 0s 291us/step - loss: 0.1231 - acc: 0.8509 - val_loss: 0.2410 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "275/275 [==============================] - 0s 299us/step - loss: 0.1208 - acc: 0.8618 - val_loss: 0.2421 - val_acc: 0.6774\n",
      "Epoch 37/100\n",
      "275/275 [==============================] - 0s 251us/step - loss: 0.1184 - acc: 0.8655 - val_loss: 0.2452 - val_acc: 0.6774\n",
      "Epoch 38/100\n",
      "275/275 [==============================] - 0s 212us/step - loss: 0.1177 - acc: 0.8655 - val_loss: 0.2484 - val_acc: 0.6774\n",
      "Epoch 39/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.1165 - acc: 0.8800 - val_loss: 0.2456 - val_acc: 0.6774\n",
      "Epoch 40/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.1122 - acc: 0.8764 - val_loss: 0.2444 - val_acc: 0.6774\n",
      "Epoch 41/100\n",
      "275/275 [==============================] - 0s 213us/step - loss: 0.1106 - acc: 0.8800 - val_loss: 0.2458 - val_acc: 0.6774\n",
      "Epoch 42/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.1087 - acc: 0.8873 - val_loss: 0.2396 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.1056 - acc: 0.8982 - val_loss: 0.2433 - val_acc: 0.6774\n",
      "Epoch 44/100\n",
      "275/275 [==============================] - 0s 243us/step - loss: 0.1029 - acc: 0.8945 - val_loss: 0.2429 - val_acc: 0.6774\n",
      "Epoch 45/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.1006 - acc: 0.8982 - val_loss: 0.2468 - val_acc: 0.6774\n",
      "Epoch 46/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0983 - acc: 0.8909 - val_loss: 0.2419 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0965 - acc: 0.9127 - val_loss: 0.2427 - val_acc: 0.6774\n",
      "Epoch 48/100\n",
      "275/275 [==============================] - 0s 230us/step - loss: 0.0920 - acc: 0.9164 - val_loss: 0.2441 - val_acc: 0.6452\n",
      "Epoch 49/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0903 - acc: 0.9091 - val_loss: 0.2439 - val_acc: 0.6129\n",
      "Epoch 50/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0885 - acc: 0.9164 - val_loss: 0.2392 - val_acc: 0.6129\n",
      "Epoch 51/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0847 - acc: 0.9164 - val_loss: 0.2429 - val_acc: 0.5806\n",
      "Epoch 52/100\n",
      "275/275 [==============================] - 0s 223us/step - loss: 0.0819 - acc: 0.9236 - val_loss: 0.2451 - val_acc: 0.5806\n",
      "Epoch 53/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0786 - acc: 0.9309 - val_loss: 0.2439 - val_acc: 0.6129\n",
      "Epoch 54/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0762 - acc: 0.9309 - val_loss: 0.2341 - val_acc: 0.5484\n",
      "Epoch 55/100\n",
      "275/275 [==============================] - 0s 234us/step - loss: 0.0736 - acc: 0.9345 - val_loss: 0.2384 - val_acc: 0.5484\n",
      "Epoch 56/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0702 - acc: 0.9382 - val_loss: 0.2367 - val_acc: 0.5484\n",
      "Epoch 57/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0683 - acc: 0.9455 - val_loss: 0.2359 - val_acc: 0.5484\n",
      "Epoch 58/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0650 - acc: 0.9455 - val_loss: 0.2401 - val_acc: 0.5484\n",
      "Epoch 59/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0628 - acc: 0.9527 - val_loss: 0.2443 - val_acc: 0.5806\n",
      "Epoch 60/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0599 - acc: 0.9564 - val_loss: 0.2386 - val_acc: 0.5484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "275/275 [==============================] - 0s 238us/step - loss: 0.0579 - acc: 0.9564 - val_loss: 0.2393 - val_acc: 0.6129\n",
      "Epoch 62/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0560 - acc: 0.9564 - val_loss: 0.2462 - val_acc: 0.5161\n",
      "Epoch 63/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0530 - acc: 0.9636 - val_loss: 0.2466 - val_acc: 0.5806\n",
      "Epoch 64/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0506 - acc: 0.9673 - val_loss: 0.2507 - val_acc: 0.6129\n",
      "Epoch 65/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0496 - acc: 0.9673 - val_loss: 0.2438 - val_acc: 0.6129\n",
      "Epoch 66/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0482 - acc: 0.9636 - val_loss: 0.2438 - val_acc: 0.6129\n",
      "Epoch 67/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0462 - acc: 0.9636 - val_loss: 0.2532 - val_acc: 0.6129\n",
      "Epoch 68/100\n",
      "275/275 [==============================] - 0s 218us/step - loss: 0.0444 - acc: 0.9673 - val_loss: 0.2537 - val_acc: 0.6129\n",
      "Epoch 69/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0402 - acc: 0.9673 - val_loss: 0.2635 - val_acc: 0.5484\n",
      "Epoch 70/100\n",
      "275/275 [==============================] - 0s 241us/step - loss: 0.0382 - acc: 0.9782 - val_loss: 0.2676 - val_acc: 0.6129\n",
      "Epoch 71/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0356 - acc: 0.9745 - val_loss: 0.2644 - val_acc: 0.5806\n",
      "Epoch 72/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0332 - acc: 0.9855 - val_loss: 0.2655 - val_acc: 0.5806\n",
      "Epoch 73/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0324 - acc: 0.9855 - val_loss: 0.2669 - val_acc: 0.5806\n",
      "Epoch 74/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0299 - acc: 0.9855 - val_loss: 0.2626 - val_acc: 0.5806\n",
      "Epoch 75/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0283 - acc: 0.9891 - val_loss: 0.2615 - val_acc: 0.5806\n",
      "Epoch 76/100\n",
      "275/275 [==============================] - 0s 221us/step - loss: 0.0266 - acc: 0.9891 - val_loss: 0.2548 - val_acc: 0.5806\n",
      "Epoch 77/100\n",
      "275/275 [==============================] - 0s 233us/step - loss: 0.0252 - acc: 0.9891 - val_loss: 0.2601 - val_acc: 0.6129\n",
      "Epoch 78/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0244 - acc: 0.9891 - val_loss: 0.2594 - val_acc: 0.5806\n",
      "Epoch 79/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0234 - acc: 0.9891 - val_loss: 0.2613 - val_acc: 0.5806\n",
      "Epoch 80/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0217 - acc: 0.9927 - val_loss: 0.2601 - val_acc: 0.5806\n",
      "Epoch 81/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0202 - acc: 0.9927 - val_loss: 0.2580 - val_acc: 0.5806\n",
      "Epoch 82/100\n",
      "275/275 [==============================] - 0s 235us/step - loss: 0.0194 - acc: 0.9927 - val_loss: 0.2699 - val_acc: 0.6129\n",
      "Epoch 83/100\n",
      "275/275 [==============================] - 0s 224us/step - loss: 0.0193 - acc: 0.9927 - val_loss: 0.2629 - val_acc: 0.5806\n",
      "Epoch 84/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0185 - acc: 0.9927 - val_loss: 0.2743 - val_acc: 0.6129\n",
      "Epoch 85/100\n",
      "275/275 [==============================] - 0s 219us/step - loss: 0.0175 - acc: 0.9927 - val_loss: 0.2753 - val_acc: 0.6129\n",
      "Epoch 86/100\n",
      "275/275 [==============================] - 0s 227us/step - loss: 0.0168 - acc: 0.9927 - val_loss: 0.2657 - val_acc: 0.5806\n",
      "Epoch 87/100\n",
      "275/275 [==============================] - 0s 213us/step - loss: 0.0158 - acc: 0.9927 - val_loss: 0.2788 - val_acc: 0.6129\n",
      "Epoch 88/100\n",
      "275/275 [==============================] - 0s 210us/step - loss: 0.0157 - acc: 0.9927 - val_loss: 0.2738 - val_acc: 0.6129\n",
      "Epoch 89/100\n",
      "275/275 [==============================] - 0s 225us/step - loss: 0.0148 - acc: 0.9927 - val_loss: 0.2792 - val_acc: 0.6129\n",
      "Epoch 90/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0146 - acc: 0.9927 - val_loss: 0.2754 - val_acc: 0.5806\n",
      "Epoch 91/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0140 - acc: 0.9927 - val_loss: 0.2817 - val_acc: 0.6129\n",
      "Epoch 92/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0144 - acc: 0.9927 - val_loss: 0.2790 - val_acc: 0.6129\n",
      "Epoch 93/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0132 - acc: 0.9927 - val_loss: 0.2804 - val_acc: 0.6129\n",
      "Epoch 94/100\n",
      "275/275 [==============================] - 0s 229us/step - loss: 0.0130 - acc: 0.9927 - val_loss: 0.2802 - val_acc: 0.6129\n",
      "Epoch 95/100\n",
      "275/275 [==============================] - 0s 222us/step - loss: 0.0124 - acc: 0.9927 - val_loss: 0.2861 - val_acc: 0.6129\n",
      "Epoch 96/100\n",
      "275/275 [==============================] - 0s 236us/step - loss: 0.0123 - acc: 0.9927 - val_loss: 0.2875 - val_acc: 0.6129\n",
      "Epoch 97/100\n",
      "275/275 [==============================] - 0s 228us/step - loss: 0.0119 - acc: 0.9927 - val_loss: 0.2892 - val_acc: 0.5806\n",
      "Epoch 98/100\n",
      "275/275 [==============================] - 0s 226us/step - loss: 0.0118 - acc: 0.9927 - val_loss: 0.2912 - val_acc: 0.6129\n",
      "Epoch 99/100\n",
      "275/275 [==============================] - 0s 231us/step - loss: 0.0114 - acc: 0.9927 - val_loss: 0.2906 - val_acc: 0.6129\n",
      "Epoch 100/100\n",
      "275/275 [==============================] - 0s 232us/step - loss: 0.0112 - acc: 0.9927 - val_loss: 0.2905 - val_acc: 0.6129\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time as tm\n",
    "import datetime\n",
    "import pickle\n",
    "from keras.optimizers import Adam\n",
    "      \n",
    "        \n",
    "def create_file_name():\n",
    "    ts = tm.time()\n",
    "    name = datetime.datetime.fromtimestamp(ts).strftime('%Y%m%d%H%M%S') + '_ann'\n",
    "    return name\n",
    "\n",
    "path='./Netze/'\n",
    "\n",
    "\n",
    "for i in range(0,50):\n",
    "    \n",
    "    units1 = random.randrange(10,51,1) #\n",
    "    units2 = random.randrange(10,21,1) \n",
    "    name_file=create_file_name()\n",
    "    \n",
    "    #opt=Adam(lr=learning_rate))\n",
    "    \n",
    "    # Initialising the ANN\n",
    "    regressor = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    regressor.add(Dense(units = units1, kernel_initializer = 'uniform', activation = 'relu', input_shape = (38,)))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    regressor.add(Dense(units = units2, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # Adding the output layer\n",
    "    regressor.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    #Summary anzeigen\n",
    "    regressor.summary()\n",
    "\n",
    "    # Compiling the ANN - wie soll es lernen\n",
    "    regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "\n",
    "    # Fitting the ANN to the Training set \n",
    "    #input = data[:,0:4] output= (data[:,4]\n",
    "    history = regressor.fit(data[:,0:38], data[:,38], batch_size = 10, epochs = 100, validation_split = 0.1)\n",
    "    \n",
    "    \n",
    "    with open(path + name_file + '.pkl', 'wb') as output:\n",
    "        ann_net = {'history_val_loss':history.history['val_loss'],'history_loss':history.history['loss'],'units1':units1,'units2':units2}\n",
    "        pickle.dump(ann_net, output)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if os.path.exists(path):\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename[(len(filename)-3):len(filename)] == 'pkl':\n",
    "                #print(\"file: \", filename)\n",
    "                with open(path + filename, 'rb') as input:\n",
    "                    ann_net = pickle.load(input)\n",
    "\n",
    "                    plt.plot(ann_net['history_loss'])\n",
    "else:\n",
    "    print('FAIL')\n",
    "\n",
    "plt.title('Verlauf der Kostenfunktion - ANN')\n",
    "plt.ylabel('Kostenfunktion C')\n",
    "plt.xlabel('Epochen')\n",
    "figure = plt.gcf() # get current figure\n",
    "figure.set_size_inches(8, 6)\n",
    "\n",
    "pic_name=create_file_name()+'_bild'\n",
    "plt.savefig(path + pic_name + '.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAGDCAYAAACydsMvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xd81dX9+PHXufve3JudkJ2QBAgBIkvEAagodeOqqypiW6vW7var7a972Np+W3/tr7ZW66gLK0VcqKh1I8geISELsndyM+5e5/fHvQnZCUKAlvN8PO6D3M84n/P5cO/9vD9nCikliqIoiqKcejQnOgOKoiiKopwYKghQFEVRlFOUCgIURVEU5RSlggBFURRFOUWpIEBRFEVRTlEqCFAURVGUU5QKAhRFURTlFKWCAOU/hhDiXCFE/TFKa4oQ4kMhRK8Q4vcT2P42IcTHx+LY/ymEEGYhxKtCiG4hxNqjTCtHCCGFELoJbv8FIcRbR3NM5bCJXn8hxPtCiC8dr3wpJ54KApRJIYR4Uwjx8xGWrxRCNE/0ZjCJ7gDagWgp5XeO98GH/thGAhy7EOKGo0jzWAcq1wJTgAQp5eePYbqDjHSDklI+K6VcMVnHnECehBDioBCiZIR17wshPEKIzAHLLhBCVA94Xy2EaBVCRA1Y9iUhxPufMT8n+/dJ+Q+lggBlsvwDuFkIIYYsvwV4VkoZOJLEJuFHLhsokcdhyEwhhHac9SuAl4DVUsrnJzs/RyAbKD/S/6v/EkuBZCBXCHH6COudwI/GSUMLfOMY5eeYfp8UpY8KApTJ8hKQACzpWyCEiAMuA56KvDcKIf5XCFErhGgRQjwshDBH1p0rhKgXQtwrhGgGnhh6ACHEfUKIqkiRfokQ4qoB634qhHhmwPv+p00hxJPAKuB/hBAOIcQFI6SdIIR4RQjRI4TYCuQNWV8ghHhbCNEphCgTQlw3YN2TQoi/CiFeF0I4gfNGu0hCiMuAF4CbpJQvDVh+lhBiW6QofpsQ4qwB626LPKX2CiEORYrOZwIPA2dGzqnrCK7xdyJPrU1CiNWRdT8DfgxcH0nvi2Nd08j794UQvxBCbIrk7S0hROIo531N5Gl5NvBhZHFX5FhnDi3VGOd6TPi4R2AV8DLweuTvof4E3CiEyBthXZ/fAd8VQsQeZV5gYt+nS4UQuyKf2TohxE+P5oBCCI0Q4odCiJrI5+MpIURMZJ1JCPGMEKJDCNEV+T+ZElk37PN5NPlQJpcKApRJIaV0E7653Tpg8XXAASnlnsj73wDTgblAPpBO+MbTJwWIJ/xEescIh6ki/KMYA/wMeEYIkTqBvN0GPAv8VkpplVK+M8JmDwEeIBW4PfICQISLeN8GniP8tHgD8BchROGA/W8CfgXYgNGK6C8HngaulVK+PiD9eGAD4RtNAvAHYEMkMImKLL9YSmkDzgJ2SylLgTuBzZFz6rvxTOQax0SWfxF4SAgRJ6X8CXA/8M9Ieo+Ncg5D3QSsjlwXA/DdoRtEAo0HgAuklMWEn7oBYiPH2jxk+1Gvx5Ecd6KEEBbCVSHPRl43CCEMQzZrAB4l/LkbzXbg/aPJS58Jfp+ckfWxwKXAXUKIK4/isLdFXucBuYAV+HNk3SrCn5tMwv8ndwLu0T6fR5EHZZKpIECZTP8ArhVCmCLvb40sQwghCN/YvyWl7JRS9hK+6QysEw8BP5FSeiM/goNIKddKKRullCEp5T+BCmDR0WZahIvvrwF+LKV0Rm5U/xiwyWVAtZTyCSllQEq5C1gHDKw3f1lKuSmSN88ohzovkudNQ5ZfClRIKZ+OpL8GOEA4aIDwdZkthDBLKZuklPtHOY+JXGM/8HMppT8SiDiAGWNcnvE8IaUsH3DTmjtk/TeB7wHnSikrJ5jmeNdjIsc9ElcDXuAtwsGHPpKHoX4NXC6EmDVGWj8GviaESDqK/PQZ9fsEIKV8X0q5L/KZ2wusAZYdxfG+APxBSnlQSukAvk84INIR/twkAPlSyqCUcoeUsiey34Q+n8rJQQUByqSRUn5MuPHdlZFi00WEn54BkgALsCNSnNgFvBlZ3qdtjBsoQohbhRC7B+w/GzjaYuC+vOmAugHLagb8nQ2c0XfcyLG/QPipus/AfUfzI8I3m5eEEMYBy9OGHK/v+OlSSidwPeEnryYhxAYhRMEY5zHeNe4YUp/sIvzE91k1j5PW94CHpJRH0stj1OtxBMcFQAjxRqTKwTFGMfUq4IVIwOEhHOANqxKQUrYRfjIe1mBvwDbFwGvAfaNtE8nXwwPy9YNR0hrr+4QQ4gwhxHtCiDYhRDfhz8jRfB+GXvcawt+LKYRLsDYCzwshGoUQvxVC6I/w86mcBFQQoEy2pwg/sdwMbJRStkSWtwNuYJaUMjbyipFSDvzxHrXRnhAim3Bx7D2EW6/HAsVAX8MpJ+EbYJ8UJq4NCBAu6uyTNeDvOuCDAfnuK8a+ayJ5H8AJXEK4WHWtEEIfWd5IONAYKItwETRSyo1SygsJV1UcIHwdRjrmRK7xkTiaa9pnBfBDIcQ1A5aNd63GvB5HQkp5ceT/yiqlfHboeiFEBnA+4UZ4zSLcHuVa4JJR2hn8jnCJzoIxDvsT4MsMDlqG5uvOAfm6f4y0Rvs+QTggeAXIlFLGEG4jMrQh4ZEYet2zCH8vWiIlRz+TUhYSLvK/LJKvsT6fyklIBQHKZHsKuIDwj+DAossQ4R+HB4UQyQBCiHQhxOcmmG4U4ZtHW2Tf1YRLAvrsBpYKIbIijZm+P9EMSymDwIvAT4UQlkhd/8AnwdeA6UKIW4QQ+sjrdBFunHdEIkX0FxG+QTwXqYp4PZL+TSLckPF6oBB4TYTHN1gZqXv1Ei6+D0WSawEy+uqvj8E1HuozX9MB9kfO9yEhxBWRZW2Rc8gdZZ9Rr8dnOP54bgHKCVeJzI28pgP1wI1DN5ZSdgG/B/5ntAQj1R7/BL5+DPI34vcpwgZ0Sik9QohFhNtJHI01wLeEEFOFEFYOtxEJCCHOE0LMiXxeewhXD4TG+XwqJyEVBCiTSkpZDXxC+Kb9ypDV9wKVwBYhRA/wDhOsj5ZSlhD+8d1M+OY3hwF161LKtwn/8O4FdnDkN4x7CBcpNwNPMqB3QuTGvYJw3XpjZJsHAOOwVCZ2Ll3AhYRvNk8BdsJPVt8BOgjfYC6TUrYT/s5+O3LcTsJ1vn0lEO8Svsk2CyHaI8s+8zUeIZ9He0370tlD+PweFUJcLKV0EW5EuSlSbbF4yPYdjH49jrVVwF+klM0DX4SfqkfqJQDwRyA4Tro/J/wdOCrjfJ/uBn4uhOgl3BbhhaM83OOEi/0/BA4Rbij7tci6FOBfhAOAUuCDyLZjfT6Vk5CQk99NWlEURVGUk5AqCVAURVGUU5QaalJRFOUUIoRwjLLqYinlR8c1M8oJp6oDFEVRFOUUpaoDFEVRFOUUdUpUByQmJsqcnJwTnQ1FURRFOS527NjRLqUcd6TKUyIIyMnJYfv27Sc6G4qiKIpyXAghho6yOSJVHaAoiqIopygVBCiKoijKKUoFAYqiKIpyilJBgKIoiqKcolQQoCiKoiinKBUEKIqiKMopalKDACHERUKIMiFEpRDivhHW3ymE2CeE2C2E+DgyZStCiBwhhDuyfLcQ4uEB+yyI7FMphPiTEOJo5stWFEVRlFPWpAUBkXmmHwIuJjz39419N/kBnpNSzpFSzgV+C/xhwLoqKeXcyOvOAcv/Sngu7WmR10WTdQ6KoiiK8t9sMksCFgGVUsqDUkof8DywcuAGUsqeAW+jgDEnMhBCpALRUsotMjzpwVPAlcc224qiKIpyapjMICAdqBvwvj6ybBAhxFeFEFWESwK+PmDVVCHELiHEB0KIJQPSrB8vzUi6dwghtgshtre1tR3NeSiKoijKf6UT3jBQSvmQlDIPuBf4YWRxE5AlpZwHfBt4TggRfYTpPiKlXCilXJiUNO7wyYqiKIpyypnMIKAByBzwPiOybDTPEynal1J6pZQdkb93AFXA9Mj+GUeQpqIoiqKc1Lq7d+JyTWio/2NuMoOAbcA0IcRUIYQBuAF4ZeAGQohpA95eClRElidFGhYihMgl3ADwoJSyCegRQiyO9Aq4FXh5Es9BURRFUSZNT88+du1eTemB75+Q40/aLIJSyoAQ4h5gI6AFHpdS7hdC/BzYLqV8BbhHCHEB4AfswKrI7kuBnwsh/EAIuFNK2RlZdzfwJGAG3oi8FEVRFOU/isNRzu49q9HrY5hV+L8nJA8i3Mj+v9vChQulmkpYURRFOVm4XNXs2HkjAAvmP4/Fkn1M0xdC7JBSLhxvu0krCVAURVEUZTiPp5Fdu25BSj/z56855gHAkTjhvQMURVEU5T+Vw1HGBx/Op6trYqXN7e3vsWPnDfgDPcyd+yTWqGnj7zSJVBCgKIqiKJ9RTe2jBALdVNf8dcztPJ5G9u67iz17v4RGY2TevKeIts0+TrkcnaoOUBRFUZTPwOttpaXlNfT6eDo63sfprCQqKn/YdrV1T1BV9XtAkpf7XbKyvohGYzj+GR6BKglQFEVRlM+gvv5ppAxwWtGjaDRGauseH7ZNe8f7VFT8kri4M1h8xkZycu46aQIAUEGAoiiKohyxYNBDQ+MaEhOXExMzl9SUq2luXo/P1z5gGzdlZT/BYsmnaM5fMZszxkjxxFBBgKIoiqIcoebm9fj9drIybwcgM3M1oZCP+obn+rc5VP1nPJ56Cmb84qR6+h9IBQGKoijKKUNKyVjj43h97bS0vIZ3wBP9SGnU1j2JzTqL2NhFAERF5ZGQcB719U8TDHpxOMqprf07qSnXEBe36Jifx7GiGgYqiqIopwQpJfuK7yEYcDB37hMIMfw5uLT0Pjo63gMg2lZEQuJ5JCaej806i/Bo9dDZ+SEuVyWFM/+3fxlAVtYX2bXrZpqb19PUvB6dzkZ+/n3H5+Q+IxUEKIqiKKeExsbnaWt7E4CWlldJSVk5aL3dvpWOjvfIzLgNvT6O9o73OXToTxw69EfM5hxSUlaSMuUKauuewGBIZsqUSwftHxe7GKu1kPKKXxIKuZlZ8AAGQ/xxO7/PQgUBiqIoygnhq++l59+1JHxhJkI3ubXTbnc9FZW/Ji7uTAKBHiqrfktS0gq0WjMQLiWorPotRmMKeXnfQ6s1MXXqPfh8nbS3v0Nz88v9AQFAbu63h9XzCyHIyvoiJSXfITbmdFJTr5nUczoWVBCgKIqinBCuXa14Sjvxt7gwpFsn7ThShig9EC6Wn1nwAB5PAzt33Uht7WNMnXoPAG3tb9HTs4uCgvvRak39+xoM8aSlXUda2nV4PE20tLxKb+9+MtJvHvFYU5IvxemsID3t+kFVBScrFQQoiqIoJ4S3pgeAQNvkBgENDc9ht2+mYMavMJvTMZvTSUr6HDW1fyMt7Tr0+niqqn6PxZJHasroT+8mUyrZ2XeMeSyNRk9+3veO9SlMGtU7QFEURTnuQr4g/kYHAIF296Qdx+2upbLqAeLjl5CWdn3/8vy8/yEU8lN18A80Na/D5aoiP++7aDSn1rPxqXW2iqIoyknBV9cLofDf/rbJCQJ6eospKfkeoGFmwf2DiuctlhwyM26ltu5x2tvfISZ6HomJF05KPk5mqiRAURRFOe58kaoAfabtmJcEBAIOyst/wbZtV+H3dzJn9p8wmdKGbZeTcw96fSx+v528vP/5j6jDP9ZUSYCiKIpy3PlqetAlWzBm2nBub0FKedQ3YSklrW1vUlHxS7zeFtLTbyIv97vo9dH923hrewi5ApgL4tHro5lV+AccjtKTekCfyaSCAEVRFOW4kiGJt6YXS1EiuiQz0hck1OtDG20cdZ9g0EtT01qamtZhiy4iM2MVJjJxfNyA5bQk3JYqKirup6t7G1brTObMfoiYmLnD0rGvqyDQ4iL26nysi1JJSFhKQsLSyTzdk5oKAhRFUZTjKtDqQnoCGLKj0UaH+9r729wjBgHBoIuGhjXU1D6Kz9dGVNR0GhteoGdHGSllt6Pxmumo/ZhDeT9Br09gxoxfkJZ63YgN/AJ2D4EWFxqLjq71lQiNhqiFUyb9fE9mKghQFEVRjqu+roHu2AqaWtYSx7UE2tyQFztou97eUnbtvhW/v5O4uLOYPev/YtPMw/5SKd7SXrwxdYRMHnQNcWSffxc52V9Bp7ONelxPWScAiV+aQ/cbh7CvKwetIGpe8uSd7ElOBQGKoijKMFJK7P+qwFKUiGnGsR361lfdg4jSsL/+HgKBXmK1K/G39QKph7fxdbB331fQaAwsXLCWmJj5hLwBmn+3nZAnQMzFOVjOWkT7+1vw/1tDZtzF6HSm0Q8KeA7Y0cab0KdGkXBLIR1P7sf+QhlCA5bTTs1AQPUOUBRFUYYJdntx7WjBvr4S6Q8d8f6BQC/7S77Dtu3X4nbXDlrnrenGFVMKAvKn3YvX0kRX9d7+2f1CIT/7ir+Gz9dG0Zy/EhMzHwB/s4uQw0/8dTOwLctEqzcSX7QwnGZV15j5kf4Q3qouTDPiEEKgMWhJuG0Whqxo7OsqCXkDR3yO/w1UEKAoiqIM429wAhDs8uLY3HhE+3b37OHTrZfT0vIqTmcFW7ddRWfnJgACPV6CnV56rbuYVfgHsrO+jD7JiuyEurrHAaio+BVdXZ9SUPBroqOL+tPt60qoT43qX6ZLtqCx6vEe7B4zT96DXUh/CFPB4VINjUFLzCVTkb4grj1tR3SOx9JrrV180Nl7Qo6tggBFURRlGF+jAwQYc2PoebeOkMs/7j5Shqip+Rs7dlwHMsj8+WtYdPorGI1J7N6zmrq6J2na+RoAcYXzSEw8D4DY7CL0niQqyn9Haen3qW94mqysL5GacuWg9APtbtCALu5wsb8QAmNuDN6qrv6ShJF4yuwIvQZTbsyg5YYsG/oUC86tzRO+NsdKICT5ZVUjX9pfzSN1JyYIUUGAoiiKMoy/0YEu0UzsFXlIb4Ce9+rG3aei8tdUVv2WxMQLWLToNWJjFmCxZLNwwb9ISDiP8opfYC/didQGyF5wW/9+uuQohNQQyxk0Nr1AfPwS8vP+Z1j6gXY32jjTsBkHjbmxBHt8BDo8I+ZLSon7QCfGvFiEXjtonRCCqEWp+Osd+Bocw/YN9vro3liNfX0FHWsO0P5EMR3PlhLs9Y17PcbS7gtw494q/lzbyq1pCTw+J+eo0vusVBCgKIpyEvK3uQh0jnxTOy7Hb3SiT7OiT4nCMn8Kjk8ax8yPlJKWlldISlrBnNl/Rq+Pwd/sxLW7Fa0miqI5f2Xq1G9i652HISMGjf5wu3R9Yng63/yEH5KTfRezZ/0RIbTDjhFod/dvO5AxL/x0P1q7gEC7m2CnB9OMuBHXW+Ylg06Dc2vTsHPq/GcZve/X4d7fgb++l6DDj7u0k8615cjQ6CUPY9ne2cPnth1ga7eTBwsy+e2MTIyaE3M7Vr0DFEVRTkKdzx1AY9GR9OWi8TeeAOkP4SpuR59oRp8aNexpeqCg00+w24shLTyzX/SKbFx72uh5q5r4GwpG3MfpLMfnaycx4XyEEPibnbT+bS/SHUD/UQOxK/PISb+bxq7NmIoG34x1SeEbu+g2kTfvuyPnX0oCHW6MQ4rzAXSJZjQ2A96D3VjPSB223nPADjBqLweNWYelKBHXrjZiLslFYwwHIK6drXgru4hdmYf1zMPDDju2NNH1UiWOTxqxnZM+YpojKXO4efijzZh2bGZ+YgpfvekG5kZHjb/jJFJBgKIoyklGBkP4W10IrQYZkgjN0Y9pb3+pEteOlvAbrUCfGoVxagzRF2ajMQx+6vY3hYvF9WnhG5QuxojtnHR636/DuiRjxGl/O+2fABAXdxaBTg9tjxUjdBpiVubR814dbX/ZgzE/FkISQ3b0oH01Jh0aq37MOQRCvT6kL4RuhJIAIQTGvBi8lV0jDj/sKetEl2xBFz96F8KoM1Jx7WzFtacV66JUgg4f3RsOYsiOJmpIYBF1RgqecjvdbxzCmBvTHyz5Q5Jnmzp4rL6NGJ2WQquZwigThY1e1vl7adz9MXltDWCJIr25Dt+B/bDoxA5XrKoDFEVRTjKBDg8EJdIXPCaT6zi3NePa0YJ1aQYJN8/Edk46Qq/F8VHD4cBgAH9juGeAPu3wzT5q6RSkKUD7y3tGbIBnt2/GbM7CEEii7bF9yECIpC/OxnpmGinfWYB1aUa4Bb8AQ1b0sP11SebwgEGj6JtpcKQgAMCUF0vI4R+WRsgbxHuoG1PByFUBfQxZNnRTDjcQ7Hr1ICFvkLir84cFYUII4q6Zhsaip/P5AwS8AV5qsbN0ayn3lddj02nRCcHW6g5inqsg7cVD3PFqM59rDrF46bn86DvfZtq0aWzcuJHGxiPreXGsqSBAURTlJBNodfX/7as/uq5jvkYH9perMObHEnNRDubZicRcPJXkrxShSzDhKbOPuI82xoA2Sh/OT6CXfWV30pqzhlBtCM+BzkHbh0IB7PZPibMspf2xYkK9PhJXz0KfEi5J0Bh1xF4ylSnfmk/i6tn96Q6kT7QQaHcNW96nLxjSJYwcBPRVEwxtF+Ct7IKgHHfAIyEE1kUp+Osd9Lxbi3tPG9HnZaKfMri4/mN7L5fvqODS0kM8OC+KQKubp5/cxZ0lNZg0Gp6eM5XX5ubztMvC0x85mNvlY4uunF6Dh3P9hSysTwZXkCuvvJKoqCjWrl2Lx3Pi2n6oIEBRFOUk42+J3Ax1Gvz1w1usT1TIE6Dz2VI0Fh3xN8wY9kRrmhEf7lrnDw4+fqOjvxTA7W5g+47PY+/agqbIj8/ShP21cmTwcGlAb+8+gn430R+di7/NRcIthRhHeNrXJ1kwTR/5iVyXZCbkDIzaFTHQ4QadQBs78iRD2ngT2ljjsPEC3KUdCKMWY87w/AzV10Cw560adMkWbOdmDlr/UoudG/ccpNXnJ16vpTrNxDszLFx4yMPWdxw8++9u5jxbRf1vt9D92kHqQm28HrOX9EsLKfw/y4m5dCqe8k5aHtyBttHHtddeS1dXF6+88sqY3RsnkwoCFEVRTjL+VhfaOCOGdOuI3dYmIjzsbzkBu4eEmwrQWg3DtjHNiAuPpDfgxhnyBQm0udGnWenp2cv2HVfj9TYz97THKZz1AG3T1xLqCODcdrhffaf9E5LLr0fW64i7ZhqmaWMXvY+kr5jfP0r1R6DNjS7BPGr7iP7xAg52IUMS6Q9if7kS1/YWzLMSENrxb3caix5LUSIIiLtm2qDGkw/XtnJnSQ0LrUYeidPyS5vg/yaZufSSLPQXpODO19Gk6+JQWy3NvW1ssVWhvSKVO759F2eeeSYGowHbkgymfH0+GpuBjqdLSTUmsHz5ckpKSti2bdsRX7NjQTUMVBRFOckEWlzop0ShSzDh3NqMDEqE9sgaB7p2tOIu7iDm4qkYc4a3qIdwEbrQa/CU2fuLy/3NTpCgS9GzffcqdLpo5s17BmvUNAAMM6Lw1B2i5209lrlJaEw63DvbiatdgfXsNKLmf7ZZ+fp6CATa3COWIgQ63OgSLWOmYcyLDTfu29VK7wd1BFrdWM9JJ+ZzORPKQygUoiyxjbbsJuaKbLKIJiglP69q5G91bVxpCFG07T3WtwxvRwFgs9nIPz2f/Px8Vk6fjl4/QrVHsoWk22fT8uddtP+jhMV3n05NTQ2tra0TyuOxNqlBgBDiIuCPgBb4u5TyN0PW3wl8FQgCDuAOKWWJEOJC4DeAAfAB35NSvhvZ533Cs0z0hYsrpJQn5uopiqIcYzIo8be7ME6Pw5AahWNTI4E2V3/9+oTS8AfpebsaQ6YN69LRu7AJvRZjXmxkdr084HCjQIepmECghzmzH+oPAABSUlZSlf9ncj79Kb0f1GOcacO6/RyCqV3EXHLOZztpCLfc14gRG0LKkCTQ4cE0M2HMNPrGC7CvLUdjM5D4xdkTLpVwOp2sX7+eyspK9Ho9Ox8vwZOZwztZBTRojXyppxHjvp04TSauueYabDYbXq8Xr9dLIBAgPT2d5OTkYT0TRqKNMZJwSyFtj+zF/lwZ1636PHrj8JKa42HSggARHunhIeBCoB7YJoR4RUpZMmCz56SUD0e2vwL4A3AR0A5cLqVsFELMBjYCAz/JX5BSbp+svCuKopwogU43BCT6ZAv6jHC9vK++94iCAMfmJoLdPuKumzHuTck0I46uA534IwPx+BsdCLOOdu+b6PVxxMYO7sKWlLSCA3E/wp/bSO9HGhzbQwQNPVivij3i0oqBhFaDLt5EoG1448CgPdxbQj9Ko8A+ulhTeIIgo5bYlfkjNkDsT1NKPrE7eLHVTm11DdN2fYLe72V3wVz2JGZQVFfB3LpKLm2owxIbi7uzg+kzZ3LZZZcRFXX0ffuNWdHEXT0N+wvlON6oJe7K/KNO87OYzJKARUCllPIggBDieWAl0B8ESCl7BmwfBcjI8l0Dlu8HzEIIo5TSO4n5VRRFOeH6egbop1jCdeBGLb56B1ELJ7Z/yBOg9/06jNPjMOXFjrt9X0M9T1kn+sR0fI0O9Klm2jr+TXLyxWg0g28TOl0UyUkraPQ+Qnbtzwi5QjQu+gtnpK0/shMdgS7R3N8VcKC+4YBH6x4YCoXw+Xx4PB4CFydiNpsR5vDYB2uaOtjT6yZGp+1/lTk9vNRqp93jY3FdOXOqywhabTiXrWBWYhLn6nWcd/pMphLgvX//m6qqKq666iqKioom9KQ/UVHzp+BvduH4sB59ShTWxcMHOppskxkEpAMDB5uuB84YupEQ4qvAtwkX/Z8/QjrXADuHBABPCCGCwDrgl/JENatUFEU5xvyRIECXHG4Ed6SNA3s/rCfkCky4HlyXYEaXZMZTZse6OA1/swvt3ADBoIPkpM+NuE9KykqaW15Gd7mXls6XMCbHotMNH0DoSOmSzHgq7cMGSOorHehrN9Dd3c3Bgwc5ePAg1dXV9PYO70ap0+kIWqOp0hmxxyZSkpyBUx/uWWAQgkt0AaaWbMbd0U5RURGXXnopRuPwngdXX331UZ/XWGIuyiHQ4uwfoOl4O+ENA6WUDwEPCSFuAn4IrOpbJ4SYBTwArBiwyxeklA1CCBvhIOAW4Kmh6Qoh7gB6X9IbAAAgAElEQVTuAMjKypq8E1AURTmGAi0utLFGNMbwz7M+w4rjk0ZkIDTmUL8QnuzG8VED5tOSRhzVbyC3u4HW1g2kpd2AaUY8ji2N+BsdEAjhMO1Fq7USH3/WiPvGxZ2NXp9Ak+EfdBo3kxN394TOTUpJIBAYscEcRG7yAUnQ7hk0HkCgw4MwaGm0N/PaMxtoiTTMs1gs5ObmEh8fj8lkwmQyYTQacblcvHGwlkOtbWR7neRWNnH6wf3k5uczdXYRvW0tbP1wE1qLhRtuuIGCgpGHQj4ehEaQcEshHEVVytGYzCCgARjYyTIjsmw0zwN/7XsjhMgA1gO3Simr+pZLKRsi//YKIZ4jXO0wLAiQUj4CPAKwcOFCVVKgKMp/BH+LC13y4VbwhgwbBCT+Fte4N/aed2uRQUnMhdmjbuP1tVNd/RcaGtYgpQ+3p56cGd/C8XEDvR/VA9CueYvExPPQaEbuk6/R6EiZcjl19U8CEB83crAwUF1dHW+88QZ2u5077riDuLjhDfa06eG69u49zSScPxWAVq8f0ebCYwrwzBNPEB0dzYoVK8jNzSU5OZlWfxC/lKQb9WiEQEZa8/81Wc8tcxfxs+kZtLe1sXv3bvbs2UNleTkARUVFXHTRRVgsY/c4OB7GC+4m02QGAduAaUKIqYRv/jcANw3cQAgxTUpZEXl7KVARWR4LbADuk1JuGrC9DoiVUrYLIfTAZcA7k3gOiqIox40MSfxtbqz5h+vy+278vvreQUFA0OnHUx4e7U8AMhDC+WkzUadPGbHuPBTyc+jQn6itewIpfaSmXkso5KOhYQ3p829CGDS497WDDlyGA+Qmjf10n5Kykrr6J9FoTMTEzB11u56eHt555x327t2L1WolFAqxbt06Vq9ejVZ7eM4CKSWvb3mbqcKI7m0HbzVvwThtBve1uXnpkIe2kJ1Z82dx2WWXYTKF5wDY2N7NF4sPEZBg1ghyLUZsWi1bup3clp7I/dPS0QhBcnIyK1asYPny5VRVVWEwGMjJyRn3/+NUMGlBgJQyIIS4h3DLfi3wuJRyvxDi58B2KeUrwD1CiAsAP2DncFXAPUA+8GMhxI8jy1YATmBjJADQEg4AHp2sc1AURTmegnYPBELoB5QEaONNCLMO/4B2ATIYov3v+/A3OQftLwxaopePXArQ0PAs1TV/ITn5UvJyv4XFMhW/3057+7tUHrqfzLx78ZR2EoztQaPTk5iwbMy82mxziIqajtmcOWqJwc6dO3njjTcIhUIsWbKEc845h/LyctatW8eHH37Ieeed17/tpk2b2LdvH5nTlpBcbsBVe4iy8le4WQqsgfOoyk7i6quXoIlMufvvjh6+VFzNHKuFG1PjqXJ5qXB5qHb7+Eb2FO6bmjKsEZ9Wq2X69OljntepZlLbBEgpXwdeH7LsxwP+/sYo+/0S+OUoyS44ZhlUFEU5ifQNF6ybcjgIEEJgyLAOmkOg9706/E1O4j4/HWN2dP+QsxqzbsSRAaUMUlv3JDEx85kz+0/9y/X6OHKnfoPyip+TmtEKpTpcllIS4pei1Y5dTC6EYP68Z9FoRq7f37p1K6+//jpTp07l8ssvJz4+PBjRnDlzqKys5MMPPyQ3N5fs7GzKy8t55513mDVrFgsuXUrT/Vs5N/c8btDWstrjR7NPsD7aTEl1C/fmpvJhZy+3Fx+iIMrEmtNyidWf8OZt/7HUsMGKoignib6eAQNLAgAM6Tb8zS6kP4SvwUHPu3VY5iUTtSBc9K9PsqBPsowYAAC0tb+Dx1NHVuYXh61LT78JiyWfGvEn0IIjeg9Jo/QKGMpgiEensw1bvmXLFl5//XVmzJjBF77whf4AoM8ll1xCbGwsL774InV1daxbt46UlBRWrlyJ1qLHMjsBua+D3vgUrpsTHqdgZlYsD9a08M3SWlbtO0iu2cg/5+apAOAoqaunKIpykgi0uNDGGNCYBv80GzKsEJL4GnrpeqkSTZSO2MtzJ5xube3jmEwZJCVdOGydRqNn+rQfsHvP7dQtvx83h0hM/POI6djtdmpqaujq6sJut9PV1dXfQj8vL4/4+Hg2b97Mxo0bKSgo4Nprr0WnG36bMRqNXHPNNTz22GM8/vjjWCwWbrzxRgyGcBDjKkrAtLuN73uNGLt8eIBvzc+mrraJ55s7mW4x8cLcPOJVAHDU1BVUFEU5SfhbB/cM6KPPCD9t2/9VQaDdTcKthWgso4+GN1BPz166u7czbdoPCQ/kOlxCwjISEpbR0fEB8fFL0OuHzzXgcDh4+OGH8XrDQ7bYbDZiY2NpbGyktLQUgJiYGLq7u5k5cybXXnvtoIZ/Q2VkZLB8+XI++OADrr/+emJiDh/zMb2Xi8yC82u8BJK0aCw6dFEGHizI4pw4G+fF20gy6AkEQ9z34j6unp/OWXmJE7oeymAqCFAURTnGZFDi+KSBqNNThj3Vj7pPSBJodRG1KGXYOm2MAY1VT6DdjWV+MubCscfQH6i27nG0WitpqdeOud20/P+D3f4pKSlXjrj+vffew+/3c/vtt5OWltb/hC+lpKOjg6qqKg4ePMjMmTO58MILxwwA+pxzzjksXrx4UGlBTyDI002d5E23kb6nB2+Pr7+3g1YIrks5XLXwz+11/GtHPVVtDtbfrYKAz0IFAYqiKMeYt7qb7g2HQIJtacaE9gl2eZH+EPopw8elF0JgyI7GX9dL7OV5E86Hx9NIa+vrZGbcNmLd/UBRUXksXbIdjcY0bF1zczM7d+7kjDPOGDb4mhCCxMREEhMTOeOMYYPCjmtodcHTjR04giHmLsmBvfsIdHiwZA+fVdDhDfDg2+VYDFp21Xaxt76Loozxh0lWBlMNAxVFUY6xQHO46557f8eE9+kfLnjKyK3y46+dTvLX56Exh2+aLS2vUXrgB4w1anp9/dNIKcnIuHXc47e3t/Pww4/z6aefDloupeTNN9/EZDKxbNnY3QY/KyklvYEgB11e/l7fxjmxVmZnxGKMjJcw0rgHf/uginaHj0dvXYjFoOWpzTWTkrf/dqokQFEU5Rjr6+rnq+0h2OtDaxt/mthAZB990siT5PTd/PvUNzxHV9enpExZSVzc8CfwQMBJQ+MakpMvwmweuzTC7XazZs0aOjo6ePPNN/F4PCxbtgwhBGVlZVRXV3PJJZdgNo89i99EuYIhPujsYUNbN1u6HbT5AnhDh4OZBwvCg81GLUzBW9HVP2dAn6ZuN49+dJCVc9M4Oz+Rq+en88L2en5wyUzio07MlLz/qVQQoCiKcoz5W1xobAZCvT7cJR1Yzxh/djh/ixONzTChBn+hkJ+enj0A1NQ+OmIQ0ND4HIFAL1mZq8dMKxgM8sILL2C321m1ahW7d+/m/fffx+v1snz5ct566y2SkpJYsODoh2gpcbj5fXUz73b04g6FiNVpWRZvI91oINGgI8mgI89iZH50uErEPCeReAowzxzcBuL3b5UTkvDdFTMAuPXMHJ7ZUss/t9Vx17kTry5RVBCgKIpyTEkp8Tc7scxLxlNux71/gkFAqwv9KFUBQ/U6SgiFPNiss+joeA+HswJr1LT+9T5fB9XVD5GQsIyYmPljpvXmm29y6NAhVq5cydSpU8nOzsZoNLJ582aqqqro7Ozk5ptvnlBDv7Fs7nJw696D6DWC61LiuDQpljNjreg1o0+cIzQCy2lJg5btb+xm3c567liaS2Z8+HpNn2LjzNwEntlSwx1Lc9GOkaYymGoToCiKcgwFu31IbxB9ShTmWQl4q7oIeQJj7iP9IfzNTvQpwxsFjqS7awcAMwt/i0Zjorb274PWHzr0/wgGXeTnf3/MdLZu3cq2bds4++yzmTdvHgAajYaLL76YJUuW0NrayrRp08jPz59Qvkbzdns3N+6pIsWo5+2FM3hgRiZL421jBgAjkVJy/+ulxJr13H3u4DytOiubhi43/y5tOaq8Hg9dLh/+YOhEZwNQJQGKoijjklJCIITQj/807G8JNwrUp1jQp1hwfNSAp6wTy2nJo+7jre2BgMSYN7x//ki6undgMmVgsxaQlvp5GhqfJy/32xiNU3A6K2lofI60tBsHlQ4MVVxczBtvvMH06dNZvnz5oHVCCJYvX05OTg6pqeOXYoxlfYudr5XWUGg181xRHomGz37bqWx1sKmygx9eOpMY8+BqkwtmTiE1xsTTW2pYMWt4N8uTxb76Dn730l9YMtXJ0mlmAoFeAoFeom2zmTr1a8c9P6okQFEUZRyOjxtp+vVWQu6xn+gBAs2Hh/41ZEWjserH7SXgreoCAcap4wcBUkq6u3cQG7MQgKys25EySF3dkwBUVP4ajcZM7tSvj5rG7t27WbduHZmZmVxzzTX9k/IMlZeX95mm2g1JybZuJ98vr+fukhpOj4li3dz8owoAAD6qaAfg4jnDAxOdVsPNi7P5qKKdylbHsPXHSmuvh5+8XIzLN/5nYSApJaWHXqF4z+WsKnySHNO/aGp6ia6urXg89QSCzvETmQSqJEBRFGUcrp0thFwBXDtbsJ6dPua2/hYn2ujDDfzMhQm4drch/SGEfuSbrfdgN/p064QGFvJ46vD52oiJDTfUM5uzSE6+iPqG54iOPo2OjvfJz7sXg2HkAYW2bdvGhg0byM3N5YYbbugfqvdoBaVkR7eTDW3dvNrWRaPXj1ETHtznN9MzMGmgueVV2trewu/rxO+34/PbEUJDdtaXSU+/CY1m7Lx8XNlObmIU6bEj91K4/vRM/vhOBY99fIhfXz3nmJxXV9d2KqseIC3telKmXMmLOxv4x+Ya5mTEcu2CiY0BYbdvpazi1zgdewmFUnBF/ZKvr7fy0yvmsOqsnGOSz89KlQQoiqKMIdDhDk/ZK8DxadOY/fIh3DNAN6Bu3zQrAekL4qnqGnH7kC+Ir64XU97ggW5KSkqorKwctn1XpD1AbMzh1vrZWV8mGHRQvP+bmEyZZGauGrYfwObNm9mwYQPTpk0bNFb/ZyGlpMsf4M22br5ZWkvRpv1csauSJxramWMz89DMLIrPns0fZ2bh6v6EbduuZP/+b9LdvYuQDGAyZ5KYcC5mczblFb9gy6cX0dq6cdTr6w+G2HKwg7PzRx8ZMNFq5IZFmazdXkd1+7F5sq6re5Lu7p2Ult7Llk8vpLnpRTQiyOv7mkbcPhSSPLHpEC/vbqC520N7+7vs3PUFWuwN/KPkC+QUvMjlZ9zInIw41mytHffzNNlUSYCiKMoY3MXhImjb+Vn0/rsW36FujLkjj0wnQxJ/iwvrmYeLq015sQijFndxO+aC+GH7+Kp7ICgxDggCpJRs2LABnU7HN7/5TYQ43ICuq3s7Op2NqAH1/dHRRcTGnkFX16fk59+LRmMcdIxAIMBbb73F1q1bmTlzJtdcc82IE/uMRUrJH2ta+NDuoNnrp93jYHZoCzZ6cGsTWRmTzRmJuZwTH4sh2IHXt5fe1jYqWl7Bbv8EkymdwsLfkzLlCoTQDEq3o+N9KqseYF/x3cTELGT2rAcxmdIGHX9XbRcuX3DMIADgnvPzWbu9nj+8Xc6fbpw3wXMLjjivQiDQS3vHu2Sk30J8/DlUHfwjS5IfZsbZSTxZcjPd7rnD2iZ8UN7Gz14tASDbVst9i/6E3ZfFzz75Kr+5dhFnT5sCwA2nZ/GD9fvYVdfF/Ky4CeVzMqggQFEUZQyu4g706VZsyzJwbGrE8WnzqEFAoNMDgcFD/wqdBlNBPJ7STmRIIoa0iPce7AJNeFjgPu3t7Tid4SfZ+vp6MjMz+9d1d+8gJnreoBspwPTpP6aj/V2Sky4atNxut7N27VoaGxtZvHjxhMf1H+qJhnZ+c6iZ880t3CLfZqp8Gz2Ruvcg0Bl+7R6yn14fz7RpPyQj/aZhwQn0DTt8HvHxS2hq+hcVlb9m+47PM2/uP4iKOtwD4OPKdjQCzswbe94EoyzjK+dY+b/vNfKVZbnMShu7nUVp6ffp6S3m9IXr0WgG3xLb2v9NKORlypTLiI1dSElnEX/6+HG+Mvc1vjP/j3y008GlZ/3PoP+LZz+tJdFq4G83ZdBe/VO8gRge3X8331pxGlfNO1x9cMXcNH65oYQ1n9aqIEBRFOVkFOjy4q/rJfqiHDQGLVELknFsaRp1FMC+4YL1KYMb05lnJeDe04avengpgqeqG0OmDY3x8I25uroaCN8gi4uL+4MAv78bp7OCKcmXDTu2zVqAzVowaFlZWRnr169HSsn111/PzJkzRz1XXyjEU40dLI+PZqrFSDDopqT0Xlyug7iCfnRuD3/VBIl2NSGEgeTkz5GedgNRUdPwelvwepvxeJqQBDEakjEYk/D77AQCPaSmXj3GVQ7TaHSkp99AdHQRu/esZvuO65l72t+JiQk/zW+qbKcoI3bYk/dAfn8XO3feyPyoWLJjvs7vNpbx5OpFg7Y50NyDxx9ibmYsra1v0tj0AgBtbRuZMuXSQdu2tLyG0ZjaP9bCpqoOSjtP4+zFd/L463dSpHmU3btLKCz8PUZjEk3dbt490MLdy1Lwt30bk87P2Yue5YoV04fl1WrUsXJuGut3NfCjywuJNk1sVshjTQUBiqIoo+irCjDPDhdBR52RimNTI87tLUSflzlse39zuO3A0OmATTPiESYtvZsaBwUBIU8Af0MvtnMHp1VdXY3NZiMjI4P9+/fzuc99Do1GQ3f3ToD+RoF9fD4fZWVl1NTU0NPTQ09PD729vTidTlJSUrjuuusIhXazd9+fmD7tR8OK2j3BEF/eX83bHT38VtfEQwVZpLb+jNbW14mOP5c9XR6kVsPs+FgSYopITbkag+Fw1YbBkIDNVjgoTSklW7ddhtNZSWLiBej1wycBGonNVsjCBWvZtXsVO3fdQtGch9BHncXuui7uHmc0wKbm9YRCXgj0cO8Zj/Ddd+9iy8E8FucmIKXk8U3V/OaNUgIhydfPTWCB5YfYbLMIBBzU1j1GcvIl/VUvfn8XnZ0fkZm5uv9J/6OKdhZkxxETFYvT/COeKX2eW2e9yKdbL8ZqLaC6U7CqMMjiGCcu10HmnvY4VuvwAKDPjYuyWLO1jpd3NXDLmTkTuj7HmgoCFEVRRuEubg/3949MYKNPtmDMjcG5tQnbsoxhRfv+FhfaeBMaw+Dido1Ri/Xs9HCbggYHhnQrAN7qHggxKDCQUlJdXU1ubi4FBQWUlpb2v+/u3oEQWmKiTyMYDFJeXk5xcTHl5eX4/X5MJhMxMTFER0eTlpZGYmIi8+YVcOjQb2hqXhfOo7+b+fOe7q8DdwVDrN53iA/svdw7NYXX27p5dt+fuYVXyJn6bX7SezEf0Msr86YxL3ri3QXt9s04HAcA6Oh4j5SUlRPe12zOYsGCtezZfTt79t5BMO7/EQzJMdsDSClpaFhDdPRc8vK+y+7dq/n2wsf4/cZE/r7qHL77rz28XdLChYVTiDXr8HX+HI+2l/S8X2AMFVNW/uNw18vYcNfL1raNSBlgypRwqUtbr5fSph6+97nwUMWXFKVx9ceLWbloBbmm5/F62/C4m5g3xYMMapg58wHi488e8zznpMcwKy2a57bWcfPi7EFtP44XFQQoiqKMINjrw1fTQ/TywVPnRi1OpfO5A3jK7cMa+vlbnCNOBQxgOycdx6ZGet6pIXHVLAC8lV2gFRizD0/z29ceICcnh+nTp2MwGCguLiY3N5eu7p1YrYVotRbWrl3L/v37sVgszJ07l9mzZ5OZmTmoz39Hx0fs2Hk5Pl8bOdl3YzKlcaDsh9TU/I2cnLtxBILcsu8gW7qcPFiQyY2pCdxoO8S+Pf9gG4v4cfO5VHl6uH9a+hEFAAC1dY+j1ycghJbWto1HFAQAGA2JzJv3DFu2rKC37QEs+u8wL2v0qYK7urbhclUxs+AB4uPOpLDwd8j932Sh68+c979eer0hfnRZIbefnUNL62vs37+HVw+u5N2Pm/n5FYuJ18VRU/tofxDQ0vIaZnMONmv4/2pTZbhUaMm0cCAyLzOWtBgTr5WY+Puqh3inpIUffLydh2+ez5LZExtgSQjBjYuy+OFLxeyt7+a0zOM/FbIKAhRFUUbg3t8B8nBVQB9zYQIaqx7nlqZBQYAMhAi0uzHPGvlpVWPWYVuSTs/bNfjqezFk2PAe7MKYHT1oJMK+9gA5OTno9XoKCgooKSnh4otX0NOzh/S0GygtLWX//v0sXbqUZcuWjdjQr77+GcrKf4LFks/CBX8lOroIKSWd9k84eOiP6KMX85VDVnb1uvhLYTZXTYnD42mivOQbWC05pKT9mpqDXVyVHMvq9LFb5A/ldFbR0fEeU6d+A5+vg6amdQSDbrTaic1CGAr5aWndQE3N3/D527Bq27i5aDtG3SWj7tPQuAadztZfr58y5XI8nlbgfpKtf2B65hKmpWvpdTgpK/sp0dFz+daVP+XQP/fxzRcOsLrobM4ObKCrtwqzIRq7fQs5OXf3P51/VNFOnEXf39BQCMHFc1J5enMNPR4/a7bWkmQzsnzmlCO6VivnpvGrDaWs2Vp7QoIANU6AoijKCNzF7eiSzOiGTOojdBqiTk/BU9YZbgMQ4W9zQ2h4o8CBrGenIcw6et6pJeTy429yYswd3Hq9rz1AfHw4wJg9ezYej4fi/e8TCnkwmU9jw4YNpKSkjBoAdHR8RFn5z0hMXM6i018mOroonHchKJjxS3SGZDbv+TplPZ08MiuHK5NjsXdtY+++rxAKeSia81duy8ph11mz+HPhkRdT19U/iUZjICP9JpKTVhAKuens/Gjc/UIhH3X1T7F5y3JKSr4DSGITrwdgUcIzOJ3VI+7n83XS2vomKSlXDgo0crK/SPbU+5iZYsTb9Qz7iu9m27aVhEJuCmf+luzEaF686yz+fNM8irsuIBDS8NCrv2LD1meAUH9VgJSSjyvbOCs/cdDkRJfMScUXDPH05hreK2vl+oWZ6LVHdlu1mfTcc37+mKUck0mVBCiKogwRdPrxHuzCtixzxBug9Zx0nFub6VxXQfJdpyE0gkDfnAGjVAcAaEw6bEvT6dlYQ++H9SAZNj5AX/1/33Fzc3Mxm83s27uX9AzYtdOD0+nkpptuGjEAcDqrKN7/NazW6cwqfBCt1jRofVvQzMPi66yWP+Dh2KfIc85hc+Va3O4atNooZhX+ob9rXpLhyFus+3ydNDW9SMqUKzEYEomNjUGni6W1bSNJSStG3a+nZy8lpffidJYTEzOfGdN/SkLCufxrRwNvl3m4fsbLbNu+ktMXricqKnfQvk3NLyKlj/S0G4elmz/1y+RP/TLBoBeH8wC9Pfswm7OJigo3MtRqBJcVpXHpnFTe3/pvFrKRps4KLNG5/XMvVLQ6aOnxsmRIm4R5mbGkxph48O1yJOERCz+Lr553dBM0HQ1VEqAoijKEu7gdQsOrAvpoo/TEXpGLv64Xx6ZGAPzNLtAIdIljF3lbz0pDY9HR+349Qq/BkDlye4A+Op2OmTNnUlPjwOEoYteuEs4880zS0tKGpe3329mz90sIYaBoziPodIMDkkMuL1fsqmBbYAbGlC9B10aqDv4vRmMKhTN/x5JztpCUdMFEL9OIGhrXEAp5yMxcDYBGoycp8Xza298lFPIP2z4Y9FBR+Ru2bb+GQKCHoqJHWLhgLYmJ5yOEhk2V7ezsuJikxBUEgw62bb+KltbX+0fak1LS2Pg8MTHzsVpnjJovrdZITPRpZGTcTELCkmHrhRCcPutudBofmbZGXq2YxSeRdgB9cxacM23w50GjEVw0O4VASLJ0WlL/1Mb/SVRJgKIoSoSUEsfHjXS/cQh9ahT6tNGf6s1FSZh2tdHzVjXmwnj8LU50SWaEbuxnK41Rh3VpBj1vVmPIiR60/cD2AAPl5dnYuVPD3j2nERcXx7nnnjss3VDIz959X8XjaWbB/GcxmwfPcVDj9rJyVwUBKfnXvHzmRH2HlvgZxETPxWLJGZYeQGPTv3C7qpEAMjz1bULCMuLizhhx+1DIS33908THL8Fqnc4jH1bx/NY6bltwGunyRexdn5IQf07/9g5nBXv33onbXU1a2vVMy/8+Ot3hoChcDB8eKrig4Fd0bv4EkBQXf434+CXMmP4TPN5mXK5DFM68e8Q8HQmrdToJCcvo6PiAVv/Z3PXsTl7+6tl8XNFGbmIUGXHDb/JXzUvnH59Uc9vZOUd9/BNBBQGKoihAyOWnc205ntJOTIUJxF87bcy6cCEEsVfl0/KHHdjXV/5/9s47Tqrq/P/ve6e3na2zve+yLMtSliIgIgIWEMGCQLCXJCZGTU++MYmJmmoSNYnd2DUSsYCCIihN6bsLbGN7bzPbZmZ3+tz7+2NgYV2Qxajxl8z79eL1gnvPOffMHV5znvOc5/k8BHrdI3b1n4ZxdhKuEiv6SXEjrn8yHuA4geC/UKsj8Pl0LF26dJTmv9vdQmXVTxkY2MeE/D8Ni9scxy/J3FbRjFeS2VCUS54hdESQmHD5aefodrdSVfUTQEQQFAiCgCxLNLc8QUrydWRn/2iUp6Gj83V8PhtpqQ8AsPZAK10OD/dtMfDQfDVv732Fc6ZOIj8xAp+vl8OHb0WSPEyd8sKodDpfQOJvH9bSM+hlbk4sanU02Vnfo6b2PpKT1tDVvYG9+5ag1SahVJqxWE4fNHg25I37FQP2Ev48+SKWP/IRtzx/gI4BD1dPP3WxoEkpkZT84kIi9Z9PIaYvm7ARECZMmP95fB2D9L5QSdDpw7w0KxTAN4ZgOKVZg3lxBgNv1QOgmj62OvaiRkHC90cK/pwqHgDAOXiUnp73mTHjm2i1s8nOzj6pj0Rb24vU1T+AICjIH/8HEhOvGPW8PzZ2Uup08XRBxrABcCas1ncBmDP7Q3S60Fl3MOihvuHPtLY+S2/vDvLz/4DROI6u7g10dq7D6azAZCwgOnourX0u6m1D/GLpBM7NiaHk0HQihD0seXgHl+LN+W0AACAASURBVBTEsibnzwR8NqYVvTocuHicyg4HP3jtMFWdDi6fksRlk0NHH8nJa6irfwBRoWH2rC3U1f2eru71pKXeMir24bOi06Wh04XSQh+7dhrXPr2PgCQz91M0Cv5/NQAgbASECRMmDPaNDcgBCcttk8e8mz+OYWYirkM2fE2OT80MOBmn08n7779PUlISM2fORKFQnDIeAKCp8e8oFEbmnfdNVKoTmQQuVzNVR3/KwMB+YqLnER0zD6ttE/Hxl46IkP+o38nfW6xcmxjDUsvYI9CttvcwmSYOGwAACoWWcbl3Exd3EVWVP6akdA2CoEKWfZiMBYwbdw8J8ZcjCAI7amwAzM+LIzvOSOSUq6mo3M3/LQrSY/07Pncp+wa+S+RAKppBB25/ALdPYn9jL49urydSr+bJ66ZxUcEJw0oU1URETMJuL0GjsVBQ8BcyM+8YpYD4eTErK4bfXlnIEzvqmXOGwkX/DnJAQvIEUBi/fGMibASECRPmfxpZkvG1OtFPiz9rAwBAEAWiV4zD/n7TaQsLnUxjYyPr1q3D5XJRVlbG4cOHueyyy+joCAUYZmRkIMsytXW/xevtxmp7l4yM20cYAF1dGzha/QsEQQjtxg3jOVC8AmQ/e6of4tz8nyIIAr2+AN+pbCFHr+HXuWNfKN3udhyOw2Rn//iU96MiZ3DOORtpanqMoOQmMeHKUbLB26ttpETpyIoNHRnExl6AIKiZaPgr7oRmOoNrePlQLk/u3z1q/OVTkvjVZQVEGUYvimbzNFpanhrWHdDrM8f8uT4LK6ensnL6Z4v6PxlZkpFcfqQhP0Gnn4DVha9jEH/7IH6rC11BDDFrTl/b4YsibASECRPmfxp/twvZJ6FJG5u2PYQW8nfeeYebbroJo9GIMlZ3xh9wSZLYvXs3H3zwAdHR0Vx//fX09PTw7rvv8tRTT2EymYbjARobH6a19RlkQAAUog5JCiDLPqprfk1n5zrM5mlMLHgIpdLEnv3LGZAjqCWbqV3PscIxg8Upk9nZ56TPH+DFSbkYzqJyoM32HgCWuItP20ah0JOd/YNT3vMFJHbX93BlUfLw0YZSaSI6eja9vTuwxC1mwcRfs2ROgI/relApRPRqBTq1gii9mhyL8bTPjTQX0SwHcDjKiIqaedp2XxUCAx56n68MaUrII++JBiWqJCOmccmj9CK+LMJGQJgwYf6n8bU6AM7KC1BeXk5vby/FxcWcf/75Z2wfCAR47bXXqK6upqCggGXLlqHRaIiPjyc7O5sPP/yQ/fv3M2XKFLq619PY9Dc+FhawWV7E7zSPUd/wJ7q730aS/bhcjWRkfIfMjDsQBAVlFXfh8bTyuHgv9xXMwVmxjCXex7i75ucgCPw6J4lC09mlrnVb38VonHDarIEzcbCpD5cvyPnjLCOuZ6R/G7XaQt64exAEkWiDevi8f6xEREwBwG4v+cobAcFBHz1PlxN0+jDNT0VhVCEa1YgGFco4HYoI9X+kXsDJhI2AMGHC/E/ja3Ei6pUoYsYeWNbY2AjAwYMHmTt37ilFe05m8+bNVFdXc/HFFzNr1qwRP/xarZYlS5Ywe/ZsfP5KKipuBcN0nhj6BkFBRXnis6ww1VBb+xskyc/UqS8SHTUbgLb2V7BZN/Iaa7hp3EXMiouhNeeHiDW/4u2sRhq181kRf+pa9ZLkpbfvI2Ki5yKKmuHrHk8HDkcp2Vmn3uWPhR01NtQKkTnZMSOuR0ZOH9bm/6yo1dHo9VnYHSX/1jhfNJI7QM8/ygnavcTeMhFNxn9mp38mwkZAmDBh/uuR/RKIAoJi9K7L1+JEnRYx5h2Z3W6nr6+PrKwsGhoaqKqqYuLEiadtf+TIEQ4cOMDs2bOZPXv2adtpNHbKyu9Cp0vmdc1tKIcCTNC4eKpLxa0ZFzI7ZgGyLKFQhBZsp7OK6pr7OMJk1PE387XEUFphSvIaOjtfw9v2J66cdRHiKT5XX9/HVNfcg8vVSFLiSvLzfzd8z2rbDIDFsnhM7+NUbK+2MSMzCoPmi1lizOYieno+QJbl//hOGsA96EMUBVRaJaIoIPmC9DxXgd/qIvaGghEGgCzL1NTU4HA40Ol06PV6JLcStUpL2ic8J18GYSMgTJgw/9XIkkz3X0vQ5EQStXykPKvkDhCwutBPjjtN79EcF/RZtGgRr732Gvv27TutEWC1Wnn77bdJS0tj0aLTK/HJskxZ+XcAKCh4hJsPdlGkqOE7uUu5pryV17v7+VriyF11Vd0DOGUdm/U/4vW8tOHFUBAU5I27l4PFK6hv+DPZWd9HoTAgCCJer43aut/S3b0BnS6NhPjldHT+C7O5iKSkq4/N+V2MxvFjCriTpNAht3iSnn6n3U11t5Orpo0/Y//PitlcRGfnOtzupi88MPB09HcNUV9ipa7ERm/b4PB1pUoEOYhKAl20Ds2GBlQaJWaLjqhEHVWNpVQ2lKII6NF4YtF4Y1AGjKhMdr7xwOj0zi+aL9QIEAThEuBhQAE8Lcvy7z9x/zbgdiAIDALfkGW58ti9/wNuOXbvTlmWN49lzDBhwoQ5GW/DAAGbm+Cgn8ilWQgnFXjxtTkBUKeNPR6gsbERnU5HQkICM2fOZPPmzXR0dIyS8fV6vaxduxa1Ws2KFSuwWjcQEzMPtTpm1Jh2ezGDg1Xkj/8dH7bupJ8ZXJ4yngWx0Uw09vBIi5VVCdHDu/reoXbs/bvYKVzBgxOnYFCOPI4wm6eQlLSKtrYXaGt7ARBQKk1Ikg9ZlsjMuJP09NsQRSVen43qmnswmQpQqaOx24vJyvzumN7Fzc8fwOuXePamGWiPVULcUX08NfCL29VGmkMaCwMDxV+qERD0Sxzd28mRbW30dYRqRSRmm5l9RTaiQqCvoYeq6hrcUhBRViAoYlHLKlwOLx21/QR8EmAkjhOyxdGGDqJ1H5Capwf+i4wAQRAUwCPAhUAbcEAQhA3HF/ljvCLL8uPH2i8D/gJcIgjCBGA1UAAkAVsFQRh3rM+ZxgwTJkyYYVzFVgBkdwBvgx1t7okzcl+LE4SzCwpsamoiPT0dURSZOnXqcFDf5ZefUN+TJIkNGzbQ19fH9ddfj1LZR2XVD4mJnsfkyc+McmF3dr6OQqHHYBjHxur1KJC4PG0agiDwnTQLt1U2816PnSVxkbiCEo8efoY5SFwy7jryjaeuVTAu95dERs7A7+vFH3AQCDhAlklNvWHEwjmx4EH2H1hOWdntJCZeCTAm9T2XL8BHtT0EJJm7Xi3l0WumoRAFtlfbSDRryf2UCP9/F70+C6XSjN1eTFLSirPq6+8eQg7IqJPHPj+/L0jlRx2Uvt/C0ICXuDQT563KJWuKBWOUBsnlZ+/LH7KnfT+iKcBFbKVVTOewPA6VX83Uoqk0HjqMENAwe8oFaOQITO5KMup+gl4YgCV/gsmrz/Y1fC58kZ6AmUCdLMsNAIIgvAosB4YXbFmWHSe1N3AigWI58Kosy16gURCEumPjcaYxw4QJE+Y4kjeAu7wHfZEFd3kP7rKekUZAqxNlnB5RO7afwv7+fgYGBobP9rVaLZMnT6a0tJQLL7wQg8GA0+nkrbfeor6+noULF5KZmTl8zt7bt5OurjdITLxqeMxg0EW3dSOWuMVU19zPQb7OnEg9ZlVoTkvjIknXdvK3ZisLYyK4payBpZ73COiLuDi58LRzVSg0nyoLfBy1OpbCiX+juORrNDQ+hMGQO1xh79MoaR4gIMksnpjAu+Vd/GJ9Ob9eVsDHdT0snZz4hZ7VC4KI2TwVu6P0rPoF+jzYnjiCqFeR8MPRAYo+T4Dm8l66Gx143QF87gBeV4C+jkHcTj9JuZEsvD6f5PGRBPu82Ks6qa1upqLlKHVyJ0mmOK7mWaKMOqZ5ypnjKufDpNvZt28f8fHxrFq1imhxCD64F6r+BSkz4Mq3ITrrFLP9cvgijYBkoPWkf7cBo6pOCIJwO/B9QA0sOKnv3k/0PV4N44xjHhv3G8A3ANLS0s5+9mHChPn/HndZD7JfwnBOInJAwl3RS+TyHASFgCzL+FocaCeMds+fjuNZAZmZJ3bSM2fO5ODBgxQXFxMfH8/69evx+XwsWbKEGTNmADA0WAOE0ttqau8nOvo8NJqQu9xqfZdgcAilykyVs4dOIZ67LCfU6ZSiwLfTLPykpo3LSmrxOopJoIsJ6WcXvS/LMvW2QbLjjKMWaLO5iNyc/6Om9j4scWMLCNzf2IsowANXTyYj1sBj2+uxOrw4vYFRqYFfBGZzEb292/H77SOElAA8Q3562gbpaXXS2z6I2aKncG4iAy9WIrkCSK4AQacPhUmNzxOgqayH+mIbzRW9BP0SCqWAWq9AqRFRaRVEJqnITlCC30r5u3W0vqLmoFBLnyJ0JCAgMHfqbC5IsaJ4uxaWvQZxeVieu5TV3b+jZ/U/MSdmotrzABx4GkkA5v0I8fyfgELFJtsAKVo1k84ylfPz4D8eGCjL8iPAI4IgrAF+DtzwOY37JPAkwPTp0+UzNA8TJsx/IUPF3ShjdfRrXNjNbgxDfio/KMEXJ5JiSkByBU55FLB//346OjpYtmwZojiyyp/BYCAu7kQgocViISsri507dxIIBIiPj+eqq67CYjmxEA4O1aDTplEw4U/s238pR6t/waTCxxEEgY7OdahUUbS2Pk+F7k7wwCWxIxe1VQnR/KmpiyNON49H7EUxZMRiueSs3sVbh9r53trDXFwQzx+umjRK7z4l5Qa02hSiomaNabx9jX1MTDZj1Cj58cV52Jxe1hW3oRQFzs0Zu2F1NkiSTNm2NpLzIoeLJNkdpcTGzAfA2uxg20tH6Wk9EainM6lwO7uQtreSJIBxfgqD29voP2zjaIeLqj2d+NwB9GY16VPMNPQeomuoOaTSBOAH7Mf+ALnBBAoDBfiiZJgUQWpuBonJSeg1anhkJiQUQu6FIAhwwwZ49lJi138Ngn7wu+ievoAqQw2iYgPJTTqc5sv5duUgs8xGXp1yZg/M580XaQS0AydrLaYcu3Y6XgUeG0PfsxkzTJgw/wPI/iCCamRwXKDXja/RgX5hCk88+yxBj59rmUfbjmr2qGoYL6QwlzzUn1AKPHz4MJs2bQJCXsSiotBiI8syjY2NZGRkjNpJz5kzh8bGRmbNmsXChQsRBB/V1b8iMWkFEaaJDA7WYDCOQ6/PJCvre9TV/R6rdSNabSoDA/sBiIu7mFLPAooilCRoVCPG1ypEHpuQjtVtx1zzIfEJy1Aozm7X+OzHTcQY1Hx41Mrih3fx0KopnJN1YrEWBIG4uNNnMJyMNxCktHWA62elD/f93ZWFBIISKoWISas6wwifjSMftvLxujoEAfLPi4YERUg0yDyPg5uaKH6vGX2EmtlXZBObaiQ2xYQ+Qk3H2/VIH3dw1B3Etrebc4GK12up9MpkT7OQf24CDd3l7NjxNnq9nsuWXYZer8d1sBtPVR+6rChiJicTnRWPXGbH8V4zeUIKCRdP5+2uRt7aewuTiGFBXx2KFc+FDAAIuflveBv+uQrJMp7avFja+t4hwjgFtTqWpubHkXic74vTWZr4TeC/ywg4AOQKgpBJaKFeDaw5uYEgCLmyLNce++elwPG/bwBeEQThL4QCA3OB/YRss08dM0yYMP9buA5b6XutBsO0+JCr/1i62lCJFQRoUHbj9XpZtXoV6t1eCjo0FN4yn5qn9+AniC04QDIhffv6+nrWr19PRkYGgUCArVu3kp+fj06no6+vD6fTOarAD0BOTg4/+9nPUKlCi19n59u0tb9IR+c6Jkz4I253I5a4iwBITbkJa/cmNlS/SKLUhA7Iyvw+yoRbKdtbxd1Zp95Fz40y0eF+lyrJTVLi1Wf1jg61DnCkzc69ywuYkhrJnf8s5WtP7eWOBbl8+4JsNMqxSwoDHG614wtIzMw8UfJYpRB5aPXUT+3nbbDjOmwd8T2NFbvNzb71DaQVxBAZr6NsezsZi1Jprf+YA6/MpbdtkPGzEpi7MheN/oQR4m12IO3pRJMXRebkOLrXNzIgQ2qMlul3TGXQM8CGDW/Q3t5OQUEBl156KTqtjv43anFVKGCuksGcD0nJ/TkKhYaBwV4Agn0ePtrXyjb3IyxlHwAfzYojVd9JWsCJUhnyMMkxWbhvWUd5xXdx9u0lLfUWsrN/iISKW0t2E+Vcz2XiNoZsr0P8/LN6J58HX5gRIMtyQBCE7wCbCaXzPSPLcoUgCPcCB2VZ3gB8RxCERYQcLv0cOwo41u5fhAL+AsDtsiwHAU415hf1GcKECfPVRZZlBne1Y9/UiCJSw9C+LmS/RNSKUCKRq9SKOtvM7rLtJCcnk5+fj8tnpe+f1cT4DIyLSKfL382Wl1/ihhtCp5Br164lNjaW1atX09fXx5NPPsn27dtZvHjxKeMBTua4AQBg69mKWm1Bq0mgvPxOQEZvyAVAFJVIab/lnopBHuJ2bMqpEHEdDT2hOOklcadXluvo+Bd6fc6wdO5YeWF3E0aNkiuLUjBqlLxz53n88q1yHv6glpf3NXPtrHSunZVOrFGDLMtUdTpZf6idLVXd3Lkgl8unJo8Yb39jaCE82QgYC4N7OnCX9aDJNKOfcuq4ASkoIZ6Uxgmh73r7y0cRFAIXXJuHMUpLwdxk9n+Uj1/+AJfTzZJvFZL5Cb0Hd3kPfa/VoIjUELMqjzi9iuyieOzvN+Hc1srGd96isrYKrahmSc75FGTkI3b66NvXjPtID8KCIWo1PyfYMYTekEVa6k2hWIJIDe6gRP+uZi6c/j4x2iLS923jvfEFBBr/THPzoyiVRoLBIYJBFwBKZQSTCh8nLu5CAH5d2857TgMPjf8J8+Pvwx9wntW7/Lz4QmMCZFneBGz6xLVfnvT3uz6l72+A34xlzDBhwvxvIUsy9ncaGNzdga4wluiVeTh3tOLY2oIclDHMSCDY58E1UU3f/j6uvDKU+qYdHw1KAVeJFcnqIWlGFqrGal544QUUCgUajYZrrrkGrVZLUlIS06ZNY//+/RQVFdHY2IjJZCIm5tPPu4NBD729O0lMvIrcnJ9SUrIGh/MIPT1biItdgEJh4HftSmYpKokJ9vI2t7DlSEPIzanXkK0/tXzx0FAddkcpOTk/PavI+95BL+8c6WT1zFSMxxT8jBolf1k1haumpfD0rgYe2lrLo9vrubgggZouJ9XdTpSigEGj5K8f1LJsctIIQaB9jX2MTzCNiiv4NGRJxls/AIBjawu6wjgQwW5101E7MPxnaMBL0eJ0ZizJGDYGju7pou1oP+d/bRzGqND7iU4yMGXexVRUvsuyH5iJtZwwAOSghP3dJgY/akeRqMM9P4La1gb8fj9+v5/OhgYmyRaG6nspkrIoIA1NpZL+8trhMVSLJY4KP0OFHqNXoqnpUZISVxJ0+HAaFDxjhO9UQ5Mzhqy2biJIZHDCKzxUv5+Vyh2ka0UCgg4/OnyCjkHjQmo8yUR09tHl9fNEm42bk2NZfUwESqM+Id38ZfIfDwwMEyZMmLMhOOSn/41aPBW9GOcmY16SiSAKRCxKB6WI470mPEf7ENQK9trKMBqNTJgQKnMrapRoc6MYOtgNkox5nIUb5t3As88+i8/n4+abb8ZsPrETX7hwIRUVFbz77rvYbDaysrIQBIFg0EV//15iYxeMml9//24kyU1c7CIUCh2RUbNxOMuxWjdhs20moB1PtjuLBbp2lP5InppzPe/1eni1s4/L409firit/SUEQUFCwtkJyrx6oBVfUOL62emj7p2bE8u5ObHUWQd5bncj60s7yI03ct/yAi6dlMTOGhvfXXuIj+p6mDcutMj6gxLFzf2smJZyVvPwdw4huQLoCmNxl/XQsbmR/VWhhR9CAXxJOZGQbuLgxiZaK/tYdNME1FolH6+rJTHHTMF5Iz0SkZEh0aD2rsfQGX6EwZBD0O6l95Wj+JodDKRKbOjbjO9N/4h+arWBQuJYyCSUaiXxdxUh6lUE7V4CvW48QhtlXbeiQEtWFegdnRycGsl9+/7MpbZFVBkFasYZkOqcxLevJML6f7D4Ab6enkyC7gLurMrG7ZSA0Bm2WhTw2mVODmGbZTbw65yRn+c/QdgICBMmzP8XyP4gzo87cG5rRfYFMS/NwjR35I9oxPxUBIWIfWMD4kQztXV1XHDBBSiVJ37qdIWxeKr6gJBSoM6k5rbbbsPv9xMVFdIQ6On5kIGBA+Tk/IQFCxYMBwoePwro7HyD6pp7mDH9TSIiJo2Yg822BYXCSFRUKHvZNVSLwZBDXt69WHt2srNtBxfxHkq3n8SUG9EqdVwer+Py0xT6gVChoLa2F0lKWoVGHXvadp8kEJR4eW8zc7JjyLGcXhApx2Lk/ssLuf/ykboDiwsTuH+jmhf2NDFvXBy9L1Zii1Lj8gXP+ijguBcgONXC0NE+hO1tDCAw56ocMgpjiIzXD3s4ag92s+OVatb+5gDRCXoCPokLrh0/Ko5Ao0kkPf02WlufZW/PVizKpUTtuArZK7DP3EC5rZGJEydSVFREjS/Ig229NPiDuNRaVu/0oHZJRN+ah8IU8mgoo7UE9H2UF38bbzDATtcq7m3/NQCOQAbnCK8T47mAuLQI/phegz2xnKi2+QRVZhQ5CwG4zBLJhTERBGUZtSiiFEKBkwFJxhkMYg8EcQaCjDfoUJ1lXMQXQdgICBMmzFcaWZZxlVhxvN9E0O5Dmx+N+ZIMVPGGU7Y3nZeMJiOCrcU7UCgUTJ8+UhRGlx9Dv0JAEaEe/vE3Gkeqx3V1b6C7+x0yM+9g+vTpFBcX093dPRwUODgUyvu32baMMAJkOYit5wNiY+YjiurhtuaIKURFzuCFgTR+Jy/ktckpTFZ1YDgWJ/BpdHWtp7r6l8TGLCBv3K/H9tKO8cFRKx12D7+8rOCs+h1Ho1TwtZlp/H1bHa0tdoSKXkRdKIhwLEbAYL+X5vIe+rtdRJfbUADr/3qYZKOS6UqBKy/Lwnzu6N1w7vR4ErPNbH2uivbqfs5ZnkVUwujvWxAEcrJ/RFrqzbRXvI7wVhIB2cH+lDfpkaZxw+IbiEpJ5b76Dl7udJBmiODxcSlU725F7XUhiaDJHBmDsbfil7i9/fyKe3mk9u+49Ra0nj4WiRM54H8fTQDmpkZR1f4MivHR0LaQIfkyIqIyhsfQfiKmAUJ6D1GikijVV2vZ/WrNJkyYMGE+gbdugP7XalClGIlelYcm6/Qu8+MEY5WUVhymsLAQg2Hk4iHqlBjnJCHqTv/z5/F0AjKDg9WYzVO56qqrqK2tHfYUDA3VAWDr2UJ29gnRHrvjEH5/L5qoC3iuvYdxWhmXp4OkpJV0ef083NLN4lgz58XEAmfe0dtsW6is+hFRkecwceLfEMWzS717YU8TSWYti/I/u3jPmnPSeHR7PTu3NXI+oHcHudBswGI6fenloF/i0ActHNzURMAnoVKJXGxQMBChYfaCNCbMTcLxfCVDO9qImJkwIr1TluWQfoM7wEUXpTIwPpKozAgCfR4UkZpTZhWIDj3qjYV4/G6O5j9KTHIDV857DA8KFhfX0OD2cnuahR9kJKDq9ZC3f4CuCAUJjiA7K7s5vzCRFreXR6p3cJF9Gx8q1vArcwTT+4rhovuh9CVMNhvxGSEFRqdUzuBQNRMKHkC5t4lB9xIUB20E+jwE+j1ILj8RC9O+suWDTyZsBIQJE+YrjbfeDqJA3DcmIarHlspWUlKC3+9n1qxTC99EXvrpMq1ebxcAzsEqzOapWCyWEeI/Q0N1iKKWoaFaXK7GYS3+lq7NSChZXmuhT24DwMTTXNCvwWlvISDJ3JOTNPqBp6Cv72PKyu/EZJrIpElPoFCcftE9FXVWJx/X9fKji/NQnmJnOlYSzTouLojHUdkPKjV+f5Dl2lPXKwBoruhl19oa7FY3WVPiOGdZFnqXn56nyxi3PBtdwbHAyovS6XmqjMF9XWjHR+Ot7sNV3Y+70Y7CL40Ys3dH6F2iFHCrA0jRSmLyEzHlxiFqlXQ/eQjvkIf3DWXMnXIpVtv92B0HubsziXqXl7WTs5kbZcRVbMW2qQFRLZJ7TT7Ox8rYWNzKRnWAtV193BX8BwHRxM9n/QDzG98GbSRMuwla90N3BclTfs4gvbT2PY0mKYH4+KX4lGvoCd5F/xu1IAooIjXIviC9L1RiuX0KypjTv6uvAmEjIEyYMF9pfC0OVImGMxoAfr+f5uZm6urqOHz4MOnp6SQkJJz182RZwuvtBsDpHJ2B7PcP4Pf3olbH4fN5sPVsJSHlFn5f30FO+yZsFLDAksw3U+Mo7tjG2+117HDORxFo5Btp48nQfXoUuCxLtLQ8RX3DXzDos5ky+RmUyrMrxiPLMvdvrEKvVrBqRuqZO5yB62dn4Ckro80o0mD3MsuuRJZkBFHA7wvSVWenvaaftup+uhsdmC06LrtjMmnHFnz7+00ggCb7xM5Ymx2JJsuMfWMD9ncaAHBFqtmYoKBFr6JbK9CtFVEbVaT7IdMlk1fbhMUZJLYtAk9bB54tHQB48LMrppYVN64hOtpI70cP8lHjOt5yXM/PshKZFVBge/IIvkYHQlaAiMXJmFIjGYzScI5D5vaOXr4e1cXkvoNkZ/wQ80AHVG+E838KGiPEjYej76D2RAK9BNS9pKbeiOjzoPVswTJ3AeK5N6OI0CAoBAK9bqyPHKLn+Qos354y5toU/wm+ujMLEybM/zxyUMbX5kQ/LX7E9WAwSG9vL93d3XR1ddHZ2UlLSwuBQACFQkF6ejoXXXTRZ3qmz9eLLIeiyQcHq0bdP34U4PPZEAQV3d2beJflrG89xAN0MiHjFr6bFYrE1wglpItrKZp6KQcPriRDcSeh6umnf3Zl5Q/p7duJJW4x48f/FpUq4rTtT8eGwx1sr7bxi6UTiDX++6lnM+JNtCPyD/sgbUjM86gYqulj90ed1JfakIIhKuQZfgAAIABJREFUg8CSbmLOlTlMuiAFheqE98FbN4A6xTRqMYxclo1jWyua9Ai0eVGsbmmn0+vnwfGpNHt8NLt9tHp82AMBmspLcXvLODppCs44E/ltHeS19RPnFik2eWk5fy5XREahUChRmudD3wdcbP4611e76d5Ri6BWEHlFFuXyzXgaOphsfBpdZiTnVPezY0YerrqHcKqiSUm5DtZ/D1QGOOeblLXZebJ6IvdKepRdIaPDkrmE5KQ10FnJ7uAEbj+QzvWaFu5YkIMSAWWMjuhr8un5Rzm9r1RRLuzB1tKI3+vB5/EQ8HmJTkohZ8ZscmbMwhB5+qDQL5qwERAmTJivLP7uIWSfhCb9xEJYV1fHunXr8Hg8AIiiiMViYdq0aeTk5JCeno5aPfb89U/i9XYCoNOlMzh4FEkKIIonfiqHXPUAaDVJeH09OJxHeMVXyxXaQ+CB/KQTmv6DQzUYDbl0db4McoDWlidJS7kGlWp0XEN//34qKr6LP9BP3rh7SU5e85kq8fUP+bj37Uomp5i5cU7G8PXuJgclm5vRGlVExumJjNcREatDEAVkSUYKhkqsxCQbRon1+JqdiAgcIojTrIYhkaqXjlLX56NwfjJpBTEkZptRn2LHK3kC+NqcmM4f7ZFQJRiI+dp4AGw+P7sHBrkrPZ6ZkcbhsrEAFRUVvFZdxpQpU7hn+fLh9yLLMgMDA/QP+niuvouLDtbw4PhUnhycxg1s5GelHzFYNx79VAvmSzOxDb7HUGUdKlU0hw7fzIS4x6EE4qxllPbtIif7JygdNih/HWZ9C/TR/OalPextVmIVvssjVhuIJnIn/hhBFGhtquZ2/10ENCIPf1DLnvpeHlw9heRIHdrsSCKXZzPwZh2SfZBAtA+tKQJTbBxKlZrO2mq2Pv0IW//xKEm54ymYv5BJC8+uHsTnQdgICBMmzFcWX0tIRe+4vn95eTlvvPEGcXFxXHLJJSQkJBAbGzsiBfDfxXPMCIiNXUhr6zO43I0YT4ridzqPAhAffxk6XTqV1XdzrffXZGqVmEwT0WoTh9sODdUQFXUunZ2vYzZPw24vobn5SXJyfjzimS5XI4cO34xWm8DkyU9jMk34zPO/f2MVdrefl249B8WxILr6Uitbn6lEqVYgiOB2+k/bPz4zgkU3TiAy/kRtAm+THRQC7SqRSywRdNW4iUZm6bcKSSv89ABHb4MdJNDkfHpA50abHQlYZhnZrrOzkzfffJOUlBSWLl06wjASBIGoqChuioJJEUa+XtHEypI6vt6Yg5hqwGHaRdoNV6LLj0GWgzSW/x2DYRxTp77IoUM3UGv9JRncS1fp+6gsMaSkXAtb7gdBhNm3U9LSz96GPublRLOzbgL3N/v4sVGJIAq4fUG+uUNFAJENt8/lcLuDu98sY/FDO/nDVZNYXJhIIEOgdrCUPPMMSqYsQJoWz5xII9PMBnSiQE9rM3X791B7YA+dtdVhIyBMmDBhTsbX4kQ0qlBEaSguLubtt98mLS2NNWvWoNWeXaDcWPF6jhkBMRfQ2voMg86qkUaA4xAAkZHTiYm5gHtqalkpP4/okYhL/N6Juft68fl6CAZdBINDjMv9Ba2tz9Ha9jypqTcOlxKWpAAVlT9CFFVMnfoSWs3ZxzEcZ1etjddL2rj9gmzyEyOQZZlDW1rZ/WYd8RkRLPnWJPQRajxDfuxWN45eN8ggKgQEUcBl97J3fQNr79/PnKtymHh+MoIg4G10oEwy8mB2MhUbm7GZVCRIErHaMwdqeusHEFQimvSIkMfBHUBhGJ3lsME6QK5ew3jDie/Vbrfz6quvotfrWbVq1acae9PMBjZPyqHuiUOk2iR6EucyEL8L9biQMdPd/Q4uVz0TJ/4djTqWoqkvUVp6A0GVE7ldJGPGt1CghrLXYNzFEJHE428dxKxT8dh1M3j8gf/jb4PzSTf7+a4s89M3jlA1aOCZ+HVkWq4m02Jialokd/yzlG+9XMIT102jYe1D2AfqcKZNZWWJkx9JAR60KFEKEK9WYVAoMGZOw5gzg3NMWi7+DN/5v0vYCAgTJsxXFl+LE3VaBB9//DFbt24lJyeHlStX/lvu/jPh8XYhimoiI2cgimqcgxUksGz4vsvdBITq2Rc7XLzDUiZyiOmabuLjlw63O64l4HAcxmwuIiKikMzMO+m2vkNT06Pk5f0KgOaWJ3A4SimY8OC/ZQC4fUF+9mYZWbEGbj8/G7vNTen7zVTs6iC7yMKiG/NRHguu1BpUaDNVxGeOjjfImBTHther2PlqDQ2HbJijtWS3OqnxBDla1kditpnzbymg/+ESXIdtaHM//TzbUzeAOiMCRIGqF8oxVg+gK4zFPD+Vdq+NQ4cOMXHWHPYMDPL9jPjhnb7NZuPFF1/E6/Vyww03YDKdXuwIQrLE4voGUnt8RK/OQ592Lb2HNtPS+SFDzOZw+VpgHlHumSgHvcQYo5g69SWa976BueM8eBTa2AM8hUoCR7eT9yu7uXNhLgaNku9ltVNRFuCvdgclD25kl1VguXcX9tZB1v3mF0y+cDE5M2az7rY5nPuHD/njO/tYUl1Ow4VXcePKGQjPV/GXchfNq1J4rquPgFqJaFAxFJAYDAYZlP8zwkFhIyBMmDBfSYJDfgI9btyZSrZu3crEiRO5/PLLP1fX/6nwejrRaBIQRRUGwzgGnaHgQFmWkSQ3gYADlSoalSqSJ1qbiFDI5AaqGJf7Z/T6jOFxhgZDRoDPZ2Vc7t0A6PXpJCWtpL3jVdLSbiUQsNPY+FcslktJSFg2Yh7/OtiKUaNkSWEiY+Fva8s4tzlIll7Fc9/bhRw64qfoknRmLcsac9U+Y5SGpXdMpmJXBx+vqyXY4iRHLRB/TgIFsxKxpEcgigKeCTG4y3uRL5cQlKdOQQw6fQS6XRiKLNg2NRBxdICdcQpmV/VyqOIQu1U1yMgcqahgQsYEls4IFX9qa2vj5ZdfRhRFbrrppjFleTg+aMFd1oN5SSb6KRZ0cgw+0lj1rAvr0B7gmlDD7XsxaZU8sGISl0xMJG3VClxHuhEFJXLFBvy2IJ7+aTy+tRatShyOqxAt4/i5rKBFlNhlFclxNZLfW4LDHIOvu5MNf/4tGZOLKLr2FpRRClqaJFxpOfz1xuvQKpUEbyzA+thhMt5opNZjJzEjkn9+49QprF8mYSMgTJgwX0l8raGqajX2JnQ63ZdiAEDIE6DRhBZek3ECtp6tPNbczd9bbdydHCAeMBrH0+L2stE2wG2pcRg7tNhsW7BYRgYFCoISlSqGuLgTjt6MjNvp7Hyd+oY/MTh4FJUqmvF5946ax8NbazHrVGMyAg5V9yDu7iVRoyKrIAZTjBZTtJaYZCPxGWefXSAIAhPnJZM/OxHnhy0M7mhlwpU5iJqT5Jcnx+EqteKpG0A3PqQe6HA46O7uHm6jqHOjBvyDXnwfdfKvVBUfzDCzqXQ/OZ2NpBHHDG82G/QNnFd3hANvDOKbPJl33nkHo9HIddddh1ltRJblTw2SdB224fygBf20eIzD9QVEXjh6K70uNd+Y8h5mrcz4vJ8DAn/9oJbbXirhxjkZ/GxJPpEXZoPHAXt/g2f8nTSXS6wv7+La2elEG0JeJzl6PGrMfL1vL3tzkrl3+TRML98NX1uLlHMhhza/w461L1H/kzvJjSmg03guRcu+jvbY/1mFSU3sTQV0/P0Qv5d03NbQR2ufi9Ro/ak/1JdE2AgIEybMVxJfswMEKG2vpLBo8pdiAEAoOyDSPAMAo2kCHZ3/4onGcjxiHH9pbOEPgCZiFv9o70EU4NYUCwO+Bdh6thIMeoZFfRyOw8hygJSUa0Yo/Wk1CaSkXEdLy9MATJn8DCpVJLvfqCMmyUDerESGvAHaB9xYnR58AQn1aXbaAAF/kI1PlmEALv/uVNL/DZW64JAfUa8cXnAVKhFfkx1VknGEAQCgzYlE0CkZ/KgddXYEJYdK2bJlCz6fDwCVrOBSXxEGtDy77xU0BjMDcelcUVlNW2cjvTkTuPuqy7Guq+X6Cj070vppbi2noaGB+Ph41ly5isB73XQeqUAZp8M4O4mhcWaufmY/v1w6gUUTQmmjvlYnfa/VoM6IIOqKnOG5/+OjRva0RLI673XOsexgUuFjxMWFPArn5cbx201VPLe7idKWfv72tSLSWjZAwI1q+kLWljsAmVvPO1E22q/NAryYlG7+cPvlqCv/FbphGY8XgTdzp/HKymiWHtxKQdUh9kbMYb9NZokcpLX1eWJjF6KPS+fDggjmlfRxExreKGnnrkVnlo7+IgkbAWHChPlK4mtx4I8U8bh9TJo06cwdPgeOCwVptKHFwmjIByBLaOLvM89jfekL4IY7O3JplntZZokiSatGE7+Uzq43+OjjOcTHX0Zi4pXH9AREkpNWj3pOeto36ep6i3jLUmJizsfnCXBoSwuiUiQ+00yrPxS97w/K1FqdFCSdfmF/4ekjRA7JRMxP+LcMgECPm66HitEVxBK9Ki+UOuiX8LU6Mc4erXIoKEXMF6cz8FY9pX98n02+AyQkpZAfnU+8So22yovolbAq7CSrUzmiHSCq6jAdgkDUeRfwuGhmoWOInvPjcDicrGyJxl9wCa2pgxTqsxh6ohrJG8Q4Jwlfq5OBDfU8IfpokTz8cV0Zk9NsSAM+/D1uFCYVMdfmDx9LHGod4A/vHeWiCfFcltOISllAbOyFw3NXK0V+tayAczKj+fG6I8x7YBsFmgBzld+iKJDGBkq4JDaClKgTu/Ty/U1YSCR/vAG1Tg/Wo6DSc0CI4YfFNVQPebh1XCZ3X3IPktNO3YZ6tlZZ+dr4N2hvf54B+0EmFT7Kxl4HqRqBGWj4aUkbdy7M+UypoJ8XYSMgTJgwXzlkScbXOkiXoZ/o6GhSUs6ubO1nxefrQZYDaI8dB2xxxROFwLVRvSRp1RRKe3GhIqBOZdDl5RspofK6MTHnM3XKC3R0vkZn52u0t78EQEREEWp1zKjnqNXRzJm9E4UiJOTT3eBAlkEKSHzwfBUsOCFRXNnhOK0RUFHSjetwH13RSr696rOnFQIMHeyCgIz7sI1+USDq6nH42pwQkEcV2YGQYFM5LXRpGpjuzGKl5QKUTaBrDALu4XaRZgt/npTEXQUpXB8XQTAYRKvXs6m4hl/UtZOoVuGfbubWfAOO95vJadUy5GhCnWoiakXucKGovvp+3nxmLzEI1Li87OxycH6iGU22GePsJBTGkNve7vJz+8slWExaHlgxGY34MoKoPuVCu7gwkcIUM2/uqeKjXZU84zuXJ14qAeBa7QkDoL+zndqP9mOJXU6yKXTc4euupNOYyWWl9SRpVPxzUhYXxBw7eomM4sL8eLZUdrP36BYspiy6rdvoH+zmcNsAR0wmrrDLtHtdHGjqP+uKjJ8nYSMgTJgwXzn83S5kX5B6uY1J50z60nZKx2sGaDQJ9PoC/KpxgHvFJMYJTUBIJVCnjmbz9DxaPD7GnZTOFh19LgqFAZ/XRv/AXkRRQ072j077rOMGAEBH/QCCAPNWj2PHP2vw6mWUooBKIVLR4eDqU/QfsnvZ+mwldoXMNd+afNbvSJZlrFYrMTExKAQFQ8XdaPOjUaeYcGxpBlFAGR36fJpPxBXU19fz3nvvYbPZyMnNQamOwlTSj1MJVekG8uuH+Md4LXkXZPBwu5VohchNyXEjSuc+kJfKJQdrsPkC/CQzgYiMBBRGNfatzZiXZmGckzQimHFdex+DQYnnb5vNna8e4uUImSuvnzDic8uyzI/WHabb4eG122Zj1quAT6/VkBKl5w7TDu7Q3E/nis08/spWYgZTiG1RsOOlZ8gqmsHe1/+JQR16B6KjjCdarVzRUcb+qJnclR7PnekWDIqR6ZKT4qoQkKh0XsmfSsZzcdpb2LWb8QdjKItSsHIgSK5SybriVopSVQQCTrTasdWV+DwJGwFhwoT5j+K3unAVd2NamDZcH+C4SFC3YGdxYeGndf9cOS4UpNUm8ov6DhyBIImRExl0VuF2tyPLAQz6bLQKcYQB4Pfbqaz8IT29H6JSRZOT83+kJF+DQjG24jGddXZiU00UzEumuaKPhvIeJqTqUJrVVHY6httJQYnWqn6q93VRV2pFDkjoF8aTn3rmyoo2n5/fNXRyb04yRqWCnTt3sm3bNvR6PeelTCPVqcYwIwHdhBjcQy5cu7sJCjJuXZCd+z8mMjISg8HAwYMHqa6uJioqitWrV5MVmULHE0dwK8AUgPz6IbyzEziYAo81tAOwdnL2CAMAYJJJz60pcTzVZhsWCDLMTMAwc3QmgDcQ5B8fNTI7K4ZpGdHcdn4Wv1hfwb7GPmZlnfC0PL2rkfcru/n5pflMTRujFK8sw5G1VClns/VPf6ZPl0FJ3GQu8+k5/O67HHz7DQAuW/A9aJShv5S/VlbyTV8fC8bP5OqskYGb/qDEr9/aRaHuPnKjb+JA12QGvW4O9cwhWF2PIMRQFa+GRjdZJg0bDrWwKPpW4mOnMnnSk2Ob8+dI2AgIEybMf5TBj9sZ2teFt9lB7I0FiFolvmYHXjGAOTWGmJjR7vQviuNCQXuGDLza1ccdaRaSFYXU922ms+tNACIjZ4zq19zyJD2928nO+gEpKTegVBpGtTkdwaBEd6OdCecmIQgC89fkUfOzHub2iTjHR7CppIO6Yitt1f00HLLhdvjQ6JX0xKr4WPbw1vKxHQNstNl5pbOP+dERxNVXsW3bNvLz80Opj0fsuIjg/d1v4XjfyUD/ANMV2UwJZtAUsLF3e+XwOGq1mkWLFoUqNNr9dD9+GLsk8bsFUTyuNCN4gyRfmM564NWuPgb8Qc6PPnWO/y+zk1idGE22PmRQDbh8vFXazqoZaehOKhi1vrSDboeXP66YDMDV01N5+IM6HtlWN2wE7G/s4/fvHeWSggRumXsioM/W3Iijx0ZsajoRsXEI4okgS0kK4qzcye7DEpV2JcnjM6nNuZKyil62E+CW+x6jo6eGwb5eYodS8XR0oJTcXDd0EICY5EJahga4oqSKe8zbSZcbKO1Q89KBJZybfBmXFU3nz1tbAajvjyUQcKGNFNBYZCRFkByVgk0BkarBK5g1/YTGxJdJ2AgIEybMfxRnbQ8+VQBaHNieLiPu5om4Gvvpop9Jk7+cgMDj2IbaCaLi+sp+cgxavpeRgGsgFBzY1fk6ANEx80b08fsdtLW9hMVyCRkZ3x5xTwpK+DxBfO4AwYBEpEU/Kl+/p3WQgE8i8Zisrsqo4gOdj8VONaY9A9zoULL5qXKUGgVp+dHknZNAyoRopv9uK0smJY5YLD+Nw04XAMXFxQj7dpGfn8+KFStgKEDn4f30Z8m4fT4GjGYa9cnM7zAjB2WiFInk3TCPiyJU2O12LBYLRqMRyRvA+mwFQ74gt8/Q8fjMLCJNJ87RBWBN4kgDLijJuP1BjMcyDZSiwARjyFsSCEp8++USdtf3UtHh4IGrQwu+JMk8sbOeCYkRzMsNSRRrVQpumZvJH947SlmbnXizhu+8UkJqlI4/Xn3i+MjndvGv++7G4wx5U1RaHbEpaSg1Ghy2bpy9PUjBIAIWZi+/glmrbmTtE3sBWIePVQ6J3JlzQt/T8xX49QpwwzX9u0Jzjk5nXdlDtAcu51/9Ju7QdXG0Zy4A+zoLWFG0H0hEJfrwS2panCkEM3XkeDbhNaVxvpTMQzoF61vP49vHglC/bE5rBAiC8H3ALsvyPz5x/RbAJMvyQ1/05MKECfPfTcDtR+jzU6looV/jYkHHRKxPHIF+PzaVgwsLCr6UeTgCQR5rsRLsrCGDGL6XkcB30izoFSIKY2in7fa0AGAy5o3o297+EsHgIBnptw1fs9tcvP7H4lEa/fNWj6Nw/sggx866AQASj5XZbeodolwZ5Ko8M8qhAO95XaxYksOyhZkoTop+n+KBlQ7GzGGHixxrG1QdJCcnh6uuugqFQoGjuANkyFw+je81xDH/iIP7G30oojQYFyYhbGzk4PstqG+ZRtZJXpmB9fX4e93cNV3HFQXJTDSdOd/96V0NPLajnl0/vgCTdqR08O/ePcru+l7O/X/snXd4VGXev+8zvWYyk947CYGEGrqi9KKIDfu+lrWua6/r6rr6uqvrurZVsSD2sioWFCnSOwkkEFJI73WSyfQ+5/fHZIGIIr4r+5Zf7uvKBXlOe86ckzmf863ZUXyyv42idBPLilL4rqqb+l4nz186doj//8opqby8pY4XNtXi8ASwuv28fe0kIo7bb+nar/HYbSz8zV0E/D7Mrc2YW5oJ+H0k5OSRNymCiNK/kzC6iJjLr0MURRp6nUSoZFR4AhyoMzNjbDhIM2j30aaUk+aG5PadiAotZU0PU+cOp/jtFc7ktfE38WxZMfERNrptfr4rP4hAPEatGn9QgsXlJ2BSsyRjNsYBA5oyO3GZQeqrbdyy7lFeX/TEqV/QX4iTWQKuAH6onNG7QAkwLAKGGWaYf4m6nYfRIZA6KYe+/iOsbShlXu9YpAjIU/RotaduVv85VDnc7BxwUGZzcdDuos7lRQSekw2Qqk7l8uP8vEplLApFND6fGalUh1R67GEXDLppaV1JlOlM9PpjgqV0fQted4CiczJQqmUo1FIObmylYkfHiSKg3kpEtAptZDhQsLbbAQIULcsmO1bHo39Yx3ghcFQAAOysM3MJCmKPWPG12VEkn2huF0URq9VKe3s7zW1tnHGwlcUDsXxnSOO8iy5GJpMhhkScJV0oMgwUh3w8sKmfPHsI7aR4DIszkChldHc7Oa+khw92NXLjmdkAOEt7cB3o4a1sJcFUPbelxZ1w/B9iQ2U3Ay4/35Z3sazoWFfBVQfaWLGjkaunpfPwOfn8x5v7ePjLw+Qn6lm+tZ5ko5rF3yuapFfJuXpaOi9uCrd2fvqiQkYmHAtg9LpclKxeReb4IvJnzATJD1hMtv4F6ltg8UcA9Dl9WN1+7po7guXf1fJ+XS/eiqf4pHYVD/Q9TqNJQr46FqO7hwGdBqvtAN3yJUgDAexBGU9tvp6SpvOYlbKdHlUC2zrnIyLQY/chUfYA8Qh6GCltwRFdiMwXJMLzBr0sY3fHiW6mfwcnEwEy8Z9NtY9DFEWf8N+Z1DjMMMP8nyAUCtFSXEs+CYyePYEC9WS2bdvGms37yQrGkz7llw0I7PH6WdVt4ZPufioc4TbEsQoZY/UalsYamRUVgeuwBYM6+4RtdbqR9PdvR6NOGzLe0fkJfn8/aWk3Hx1z2XxU7+4ib0oCk8455psO+EJs+6iG3hY7Manhh7YoinTWDZA66tgbdl2PA0GArBgdKrmU7BgdFR1DX/n3HunhnMGvb8euDkzLcvF4PFRVVdHV1UV3dzfd3d243eFUPYVEwQXeIqJCKq6wGGnd3MrI+Vl4G60E+zxEzEnD+10L+fYQusvziCyMOXqsrCXZVBzpZ9zmLuoKE0gPSDCvqqXcKGXLaD0fFGaeEPT3Q9g9fkpbw1aPT/a3HhUB5W1WHlxVzpRMEw8tHolUIvDcpWNZ/MJ2rlqxD4vLzx+XjEL2vfbGbl+QPke4MNG41Egunji0VfGBb7/E43SQGbWJyjWr0Yy6BrU2E40mA406HWkwBHuXQ848iAsLuIZeJwCFyQaWGDR8OmCnZEsJA5alPOBWkCdbx8FxIfQOAwMGGSDS7DeSae3EZopmu+dyAiEfZ+UXkhAzhWveqRucjRQl0bgRkPQ1cf32pzE5E3mRB7hEFmRFlJUY8aeDO08HJxMBEkEQ4kRR7D5+UBCEU5N8wwwzzDAnobq6Go1dRlAvQaYLvwWfffbZpKenU11dTW5+3i92rIdr23iz3UxQhLF6DU/kJLEg2kCiUn5cb/oQm73dKFUnlunV60fT37+diIixR8dCIT8tza9jMIwfEixYvqWNYDDE2DlDH0o5RXHs+LSW6t2dR0WAtceN2+4/6goAqOt1kGxUH/X15ydGsLu+7+hyly9AsMWBFDWyOA2ug70wPYoPPv8Is9mMTCYjLi6OkSNHEh8fT1JSEi0bzJiqbQQjleyTBpi6tRNzt5dWi4s4lRSZSUV+hY1dWRouPU4AAEgUUmKXjcC7opLiT6rx2UMghvhkWgyfTcgmUn5qoWX7GvsJhkTOyIlme62Zxl4HTl+QG98tIVqn5KXLxyOXSvB6e4nWxTB/VDzv7G4mVq9kydhjqXM+t4viVhu/+7KK5j4XCqlAnH5oR0mP08H+r78gYWQ05swq5P4Q/sa/HX9WqEQNkSle6nXQ8PlDLB5tpLQ5F5CgDW3jLG01Hw+Mo7f1SkxIkSHlo5YzsHpgdux2CvRKIsc9Qde6ALJyKzGjm6hxJyEXfCyedDlahYBMWkkgKCXFpKK1H0QgxSYl3uQlKaaPUGOAacqFPB0qJ1mZxH8HJ7t6TwPfCIJwN3BgcGzC4PhfT/fEhhlmmP+7hEIhtm7Zylxy0WUPDR7LyMggIyPjR7b8+fR4/bzRZmZRjIH7MxKGpPYdz7FCQSemqMXFLqK5+RX0EcdM/t3dq/F4O8jN/eNRIeH3Binf2kZGYTTG+KGuDJVWTuaYGGr2dTPtwmykMgkd/4wHyD72FljbbSc7Rnf091GJEXxe2k6fw0uUTklxk4XCkARRImBalkvPi6XsWbEeu9zOmRdezFmjRiI5LgLeUdxFSnXYkiC1+RghF9lYqGdWeT+xIjSnaeHLOvoVApaZP9ynIC4nim1jjEw+aAHgnRlGXpk2Ao30x8sZf5+ddX0oZRJuODOTHbVmzn9lFwMuP1qFlI9vnEqUTklL60pqa/+TvdYneGevnvwEPZWddsY9toGkSDVJ6iCW+mpqNZlEBh1cr6yjWJbGwUY/bW3VeLwdeL1ddOwz4HU50eeXk9DlYWSrnGDQgf2yF3mtZSNCYIDZ1l30GRW8friIcvMotjeWYVBuRy6ZykDHA1hk5zAVGXt7EfE0AAAgAElEQVQRuXrBCFjbjUXdwtbeKWzsnsby+R7u3bUCSeNFAPQ12BFUXqJMynD74bJXCIjRgIL5+cm8saMRAehu1XJ1fCq5Ud0QI7CpQcTvnsGokSkn/fxOFz96BUVRfAd4GHgMaAIagT8Cj4ii+Pa/ZXbDDDPM/3r8fj8ej2fIWE1NDc4uK6qQHGXaz29w83PY0GdDBO5Oj/9RAQBDCwWduCxsENVqsoCw1aCp+VV02lyios4+ul7Vrg68zgDj5qWdsA+AvKkJeJx+msrNQDgeQKWVY4wPxxkEQyINZifZscdEQP6gn/uf9QJ21PZShAx5qp42bw8dUgvZnjhcZy/iP/oC9AdCR7d1lHQx8FktIeDrsRHE/nYc2pBARpOL7eON7MLPygEbYoeTZ/OUTI3/cZP05AtyaYiSUzw6gnsXjTplAdBj9/BlWTufHWhDEOCqFfsQAZc3yONLR7H9/lmMTjJgt1dRW/sXVjeex2t79czJcfDkrK+5c/zLXFFQzogIB40tnbSqU5gf6+XhpBoSvAdQ9x6h0ynli2ff4kjZO3S1beHwxt0YMmykJWaTV+NAuOANpFI10i/u4ZXg1dSbJzPhkI0piX+l0V5IukmgtHcMuzqmYlIN0OmJ5uO2GVyMgiACn1WFr3/BGBuqrD8hlQS4Y189Tb0JSBwBshP0hFxJSC1eejU+VpS/yUslH0BIg1ou4c2djQgSAVmqjmBI5Ml9v6VD8RZ7hFo+dhuJN8h5YMG/VvHxv8pJ7TiiKH4LfPtvmsswwwzzf4xQKMT7779Pa2sr+fn5TJw4kdTUVLZu3UqGJhF8oEg5vSJgrdlKikrByJMIAACP51ihoPDcA9jth+jr205Pb/hrUKvNRhRFmppexuWqY1T+s0etAKFgiLLvWknIMgwx7x9PykgjGoOC6t1dZI2LpbNugPgsw9F9tFlc+AIhcmKPBfrlJ0YAIgcOVxPqqKS7rJEcMmn0dbDhvWJGGTNINBvpbg7gj5Wy3mzl8sQobNvbsH3TCALcPVbFpEmxKBK0VC5KofCrFlZU97AVN1jh3Ngo9iYrKdAfK24kiiIvbKxjVl4sBckGlEo5Z9576q1vQyGR331ezkfFrUfHsmO0XD45DYVMwu+/OExGlA6TVkEw6KGi8k42ts3ji9rZzEyt4JL01+jtEVgSO4k6+5dUrt/CBIWEkRcNINcE8Pv7MI1VMc97Frs3C3TYsvB9osKQYCDkGyB+gpmUHiMSiYxg6kSa8tPI2l/GLc0fc6l1N7XqVF52FeDw1vLE+WOJ0Su58o299Lhj+eO+u9CHJExESqRSRn+3CxE1N067mUMHqtluLsFlmUy0RINDHeClK8az4JmtiKKAP9rI04dfI45JOIBzChP5ZH8ber2foqJENrXUoJWJPPdtNUmItAO/HZlEcZOFmSNifvTzPF2cui1nmGGGGeZnUlpaSlNTE5mZmdTU1LBy5Uqef/55Ojs7KYgZgSCXII8/PRkAAM5gkO0WO/OjI36yrK53sFqgUhlPe/uHbN9RRMn+i2lsehGpVENOzu8RBBmHK26jofFZYmMWEhu76Oj29Qd6sfd5GDs39UePIZFKyJsST/PhPsxtDqw9bhKyjwmG2m4HAFmxOpylPdgPdlNfVc5F6kosBzeyefNmxrhdCAjUe9vJy8tj4c0X4omQc26jF5VE4JteK65yc1gAAJa5yWyPlTNmMIUvc3QMf8pXUeP0kCOE4w7+FBlkhkmP9LjPqLjJwrPf1XDHx6X4jrMunAy3ux2nsw5RFHnoi7AAuHpaOnfPHQHA3y4Zy7UzMrhoQjIRKhmf7A8LhLr6p9jVpODDyrkUxR/hytzXUCpMmCxeYr9bR8MX0YBA5qIGkHfj91sAgVDIg9r/LgDSKU6iRvUx0GUhJk8gJfcsgm078UYYKa+6kyZtO98lzOK+5pWkDlRTVnAd/xh8w5+SGYVTFyAkiogyN0GfAl9+M1a5wES1ErsnwNv4UEVqeO7s5/jtzLGAFHOfF022gdxoHemm8H2sMCnJSLme8YaL0Cqk3DY5AgU+JkqqmJ8cRVqElJDfR49XywFvIouQoz2wk9XrNp7SZ/xLM1wsaJhhhjkt2O121q9fT3p6Opdffjl+v5/Dhw9TUlKCWq3G4FYiJEsRpKcv2Whbvx1PSGRB9E931/N4O5FIFDidDRyp+QMGwwSSk67AZJqOXG7E6WyguORCXK4GsrPuJzX1+uOCCkUOrG8mMk5DRmH0SY+TOyWBA+ta2PbhEQASB+MBNm3aRPHhembJndRvcxJTGY+fIGsVO1AotVRL8rh03jSa/1GLKJNwxZ3XHu2atzZDxdKDdu5U6jlU0Uf/oXC5Xv3sVNZkq6DeelQE5GnVfJcgI1QhcrMow6+R0dDr4hbj0DTDt3c1oZBKqO918s7uJn59RuZJzysY9HKg9Aq8XjPf9b3MhyV2fnN2FvfOz+PeTw5iUMuJFNdSUvIp0TFzWTR6DJ+XddHUsZk9VRt4rfweUvVt3DLxO8aOep+IiEK6X5nAqtYMPL4A434VR8HUxxFFP3rdSARBhs12EMtAKeq9Idzq81lwo5qvWlwkJU2lMD6OwLdfYNbb6OvfhizjGW7wm3jbVUmbXII9SUdkZQtehYJrP7+aRm8/cDu6uHUszk/libMepPmlQ5zjdNOmUfCGy8vIQ51cOCGZ26ZczBtr12HzBhg5Itz8Rz54H09CwUExFbHdwrhUIyn+JjYq7qVVFo9Jci2R7naaiQUEdAoJv/GpOOTTYJQGf/IePR0Mi4BhhhnmtPDtt98SCAQ499xzEQQBhULB+PHjGT9+PKI/RPuju9DP+GUioo84PWSplci+l6q21mzDIJMy2aD7kS2P4fV0oVDEUlF5BypVEmMKX0MmG4zitx6gtOwaJBIF48a+jck0bci2nXVWzK0Ozroi94SKgN/HlKAlLiOCznorUrmEmBQ9ra2tbNu2jZBCS6RUxNgqIBEFlMi4ctx5fKZR8uHmOmKO9HGZIEOVaTgqAJrdXp6PEjlHJnDe1l4usPgQBYi6ciSaUdEcrGwmQSknThkuoiOTCGT5JdQCk5eMoKKzj8biDkYrFEfn2DHgZm1FF9fNyKC2285z39WyZGwisfofd6m0tr6J293KqvplrGmwc/XUWG6ZocRuP8LOOjPjkjzU1j6EQhFLff1fyJam4g3cw9/XrmZz602opE7+OK+JGeM+QSbT0lFezOrdSbiDcs5LriQj/2GcunGcV1rH77MknGXSYTJNx2SazsiEnbTaJXSpCvjPzrfQdL3HX3PyKfR7UKfMQ5d6Nk83VCI1b+R6U/g8xdIXcPY/jEpfjeDpJ1WziGrg7XP/zITUKBAEOvVS0ntF7oo38lxbH/d/doh4gwqdUobNEwAgwh7E4w/S1OdEKZMgtLuwJsqo7rKTP1ZDSUMpEyW9RLvt/GPN1yTLLBz0h+NOxqWZUPVAstnF4abOn7xHTwc/KQIEQVACFwLpx68viuJjp29awwwzzP9mqqurqaysZNasWT9Y+9/X4YCgiCL1h2vK/xw6vT5mFVdzXVIMj+UcExVBUWRDn5XZURGnlMfu8XYSCNgJhdxMmPDJUQEA0NT8KlKpmqKJq36w01tDaS9SmYScolPLoM6bmkB3o4249AikcglbtmxBo9GwWzMJvVzBqF4BRa4OMSjir3BRcG40ogh7D3Vxv6hDdVw2wUed/TjlArIxMbC/hxDw4cxo7h8VtkgctLso1A9tZGRyhc37IwpicQUdCEBFvYXxMeH4jPf3NiOKItNiPmZR7hyW1YV46tsjPLNszPdOfCsodHhjkmlqfplNXbewpiGPWam7mGn4ij17XfS4k+mw3sesxFWYjDMoLHwNn6+bzK6vWVlh5tOa2cglPl65yMvMcX8GoHTtara8/Rp6aYjLfvtr4rbfAfteo2xOAYcdbv6zvpOZRv1RS0xufATflLfzmw03EuE4BMADfUBKEjJLNYGdFYgImPRjuLfwNiYnTKa9T+DC6hLusU5jgfUsPs3TUk0nIzZcB9YauG4dFUqRxT4RnTPElRE6lsv9fPTuq1yvWEeR6jL2BdPorLVwMH0AX1BkVl4MO+rMXJKazpdAjTLE4cYyxvkFJNYAttbdKIMiFw70sD2pkH1VPordVs6LehGVzAT84ZTun1+SU7EEfAlYgf2A9/ROZ5hhhvnfjsfjYc2aNcTGxjJt2rQfXMfXYgd+maDAvQNOgiKsaO/lsgQTIwdr0ZdYnfT7g8yPPrVjOJ21BAI2cnMfJ0I/+ui432+lr28rKcm/+kEBIIoijeVmknKNKFQ//JUa8gbpXX4Qw4J0VLkmcibGsntVHSkjjbS2tlJfX8+cOXN4Z4OTB5N0hBwudGeEBY35jcOM7AvXbRsrhn34yqxIfO0O3HUWois6+cgtIjjdiMC2KSZe1fi5LRgiIIrUu7xcEDe0o17A6iWkllLr91MW8qM3KPm2vJOrpqTh8Qf5cF8rU9NcBO3vEpTWcN0Zj/DKlnrOyInmjJxoonRK6K2B9y8GmZLm2QvZ2VbAB+V5TE8q47LcjwmFRDTqDCrbwpkSk9PkFBa+gFSqRK1OJS3tOsb6H6WdGczp2kLrez7W7enE63JRV7ybzOggC0e4UU07Hxz7Ye9ymkbfyQ1t/2BV7Bw29MUzb9DNE5K3YnOLBAY6mJB7ByNjp9G65wXm9nxJ0/Rb6JbE8K5tBC+Mn8CsqPD98G1ZOGZiQoQGuTxIXW0LMTjQWarxWTyIb13OzsTnWAyo+ry44wSeSvqWqZXLCfoE3pXWcK3pAXY35rB2+V+Id4/ihrH5bK7qYv/edkYMtPH7A4eJ2VpKjz4CV6+CObYdR69BtNvCq4VLOdP5KOoYCwk9Jxap+ndwKiIgWRTFBad9JsMMM8z/egYGBli7di02m42LLw6Xpg15Aoi+ENKIY+ZmX6sNaaRyyNh/lX1WJ2qJBLVU4MGaNj4fl40gCKwz25ALArNMPy0C+vt3EQjY0GhySEq8bMiynt61iKKfNs8MskXxhABDS5cLW6+bcXN+PM/b12TF3+nEtrEFVa4JpUbOFY9NRamV8cEH76PRaEjNK8Dx9Q4m9vqQJ2hRZg02FErREyruwaiSM9kjRZRJ6P/0CIHOcEOgIoWAIkaNOk2PMsNAcroK16FGtlvs6KRSRDgaD/BPOntciBEKXm/rxRESmZ0Xw4Z9bfQ5vGyq7qHf6WPayHeQyQwMDOzl2ikKPtuv4O5Pypg3MpJXrpgCX90KcjViyE/7pkOstD5IrrGWu2a0kZ72Fi5nPY0Vj3Kk+yxMqn7G58w/2lpZFEX+8dltZFS3c05yJdlj01A5jDSW7cdttzHj3EVMqn0QYeLjiEDXqCVUHnyTg/vuweVqJDO4nYe2ZbPGaMDRX8fOHgG4CZvmPh6fMItEpZwN2+xM9chQJS3kvg4v8VoDM0163tjegMcf5FB9PwkIZEfsQew6TFPwYnL1HlqrpuHctQfo417p1TjkOmSGSBaeaSHRWk0/Ol4NnMN18vW83f8Y25tHkVBqZhlfwYY/8zUCPqkMVTAs3HRZLhKKrISCsM2RwH7Tteia8gEfSyQ7SUy3YOkehzR+9k/ep6eDUxEBuwRBKBBFsfzn7lwQhAXA84AUeEMUxSe/t/wu4NdAAOgFrhVFsVkQhLOBZ49bNQ+4VBTFLwRBeAuYSdg6AXC1KIplP3duwwwzzC9Hd3c3O3fupLy8HEEQmDVrFikpKYR8QXpeOUjQ4sF40Qg0g9XofC32X8QVAFBsdTIhQsPSOCP3HGllVbeFC+NNrDNbmR6pQy87eZe9UMhHVfUDACQmXnzCQ7676yvcoSRufd/Gb2fVcNfcEUPWaToUzvlPP0lAoKchXBTI12I/WutfE6GgpaWF+vp65s6dS7PFxxRkaO0BdAszEQQBURTRjI3BurqBV5RqkhARAiEEBCLPy+JBuYuNHjdl00ahGCwQNC0UwiCT8k2vlbzBtMjj3QEWp4+OATemUSa+67MhANdMSGHd3jbWVXTz/t5mUiIsjI7tYvy4d9lXvBRL70csydXyRkk26yvNlH96KQWte/Et/hM7qt/lnorbiVdYWH5VERmJdwAQ5dERW+bntwM5TImto6HxKyJMM/m6+Ts+LX2bsd+CXxfCkdXEm9oGMAhML5rGvJTzqa5exbcxJhote2j8+FMsXgvERSMVO8mQSVEH+nF4eqhrrUTqtXKjW+Q5YGlvPem+ArBamNu/h2DIjfrNWTwtUbB3zK0cbvkNf1pThUwiQSWGmI4ErfkZglPuomezk7s3foizq47oW29lT3cD+6wyrm1uImnEJuT42Nc4grKISTRGnMljNdE8oVvBrNxDbNCPoy4wgujYbLrae7H3W/Fm5DB5SjKL6m7CG5IhkwQ5I6KToNLEEaWWZHq5Tf4GFYF0DIZH0YpbfvpmPw2cigiYAVwtCEIjYXeAAIiiKJ60x6cgCFLgJWAu0AYUC4LwlSiKlcetVgpMFEXRJQjCzcBfgEtEUdwMjB3cjwmoA9Yft929oih+ekpnOMwww5xW1qxZw759+5DL5UyePJmpU6diMBgQRZGBVbUEelzI4zT0f1CNv8OBdmoiwQEvil8gKNARCFLhcHN7WhyXJ5h4r6OPP9Z3kKlRUe/2cl3yySP1AdrbP8DjCUfTazTpQ5Z5vd1YBvZS3rcUmUTCi5vqkAgCdw6mvEFYBESn6NAZfzxorvdgG27BiV5U0/pNBVk3hvPtt2zZglarpaioiPeL27kUBejkqEdHY13XhLO4i5Aj/EaZ5AMBAd3MZCIXZtDp7OGLYgfXJsUcFQAAComEuVERrDdbcQSDJCnlxCiOddY73BF+fxqdZKAbHwV6NZNTjKRHafj7plo6rB6uGrmO3NxH0Ony0elyaW1dicw3FsgmKMq44MAVLFZnkN+6mpVN1xOQyHha9gTvFN+E2W/nQpPIhF2/oVE+Cis6Fg7sQt/eyd2WK9nd18Gishg0PhUXZbeSlrKIjoPvsGrCRXxuqWVHx04AjHoD6VIZZ6WcxciokYxw2Bn1zX0oRREB2GOKZ0p/NZxxN1tlyZjW2ZB1tcOz4aqOCqBfm8Tvkq5gdv9e5h94niUlKWhk8Tj8IXzAZGk9rmVvUR3I5KGdNxJr7SDp2WeIWLCA93YfoeJgE/dEPopMkPN5wzkklx1kmn8ziYYjZFnb2ZE0jiJDNXMTS0mWuEm/5En6rR6u2VjNA3NTkLx1BURDk3EyvbZDTAvZOcPxAKqIRxgh+TsBUcJv/HfyntCDUz6CoU6bfw+nIgIW/hf3PQmoE0WxAUAQhI+A84CjImDwYf9P9gBX/sB+LgK+FUXR9V+cxzDDDHOacLvdFBcXM2rUKBYvXoxGc8zs7Nzbhausl4i5aehnJjPwVT32LW24Bt+cfwlLwAGbixAwyaBFIgj8eUQyi/bXcE152N87/ydSA/1+G41Nf0erzcXpPHJCyeDu7m8AkW9qR3PtjAwsTh/Pb6xFIgjcPicHt8NHV4OVCYvSf/QY1YerUA+I9MWK2L02khsFVv/jC/LGjaKhoYF58+ahUCjob7QyFxn6aYkMfFGH60APqvwo1CNNhDwBrIN5/9qJ4eDD5RWf4RenMlNcjyhePcQ6sSjGwKedPXzXUMXsjIlD5lPeHhYBs9Kj2Nh8LMBuYUECr2ypRyNzsWAk+H39lB28BoejCgC77FJkEgFB9BMn6eEb7zS+2DcTgSA5+Wu5PiTBWWxEDARZDUh4HpNWAQSYliBhX2uA3TEdXGqNRdWp5oyEdtJu+Ahi80mwNHJzyRe0nvkmDX2VvH74z0Re8AaMvvDovCutNuTiffhURpReG1P6S3g840Zmj7+L3x1pxRvbRVUwBoqiIOiHrU+inv0QWz1jac+/hNaaaqoOCCxXPMuD3IwFJV2jJnDe2y3cvfkJ0h1mnpt8DZIOE96V+9h7pJcLJNswKCqx+G/Flj2TqxZfxfJN35JzeBfLL7qc+txMFtbdglNUkhesZtOz95Ouv5g3JEo2vvE3zjOF20+vyUlGbKphhtmO0y9luuphAF6ynE+TOoZ26adIZLkM7S/57+EniwWJotgMRALnDv5EDo79FElA63G/tw2O/RjX8cPVCS8FPvze2BOCIBwSBOHZweyFExAE4QZBEEoEQSjp7e09hekOM8wwP5eGhgZEUWTy5MlDBICvzc7A6npUuUb0Z6cgyCQYL8gh8vxsglYvSAUUiT+dtvdT7LU6kAATDeFCLeMiNFyZGEWXz0+hTk2S6uQxB83Ny/H7B4iKOhMApXJo7fyu7q+QKkfS5ohhYpqRpy4s5KIJyTz7XQ0vbqyl+XAfogjpBVG0tbURDA7N9e7p6WHXqk1IkTB6/kQmXnM2UiSEDll5//330Wq1TJw4kWBIJLPBjlcAf5sd14EeIuamEXXVSLRF8eimJSKNVCKJUCCLVhMIONjp1JFKG2Lbf1JVdR+hkO/occ8yRaCr3YOwS4mzdd2QOZW3WUk1aZiuKuMx/sAM828o2X8JGbK/AzAjaQ8exy5qah/D6awjK/NupFIDxa1WULQR0tbSLlGhSv8zU/t3srhrHQXdZi6IvBoxEElSzMfEpb7JtdNjGRFv4ILxSYiXPMufoqKZ1iWg3yMnSWNj4u0vEogdzfK2Phal3UuPVM8te+7nmvatqGVayF08ZN7trQeRIqL0WEAMIsq1fJZxObdUNlPv9jIlxUh9nw/ftLsgOgcAdWIh6yaO4JGEWJ47JGV+XhRzJk9EHpIxubOCmNee4YWvHiPZY+GRqddhiR9NVZuVik4bunR4SP0WFtJwBucxQnDjjDOx54G7iNm6lQ9nn0tB2y4kAoSEKAQBxhlXs75vBXvFdei8hzAp3IQECW+bd5GaEz6fnb2jaXNFsKMnDZs9HDi7Ryqj6N77fup2Py2cSorg7cD1wKrBofcEQXhNFMUXf6lJCIJwJTCRsK//+PEEoAA4/i5+EOgibO15DbifcH+DIYii+NrgciZOnCj+UnMdZphhjlFfX49SqSQp6Zi+D7n89L1XhVSvwLhsaN68bnICimQ9QbvvaJ77v0Kx1clInWqI3//BzAQ2mG1cGH9y46rb3U5r20ri45cCIhKJArn82DYuVyN2ezlmyQ0AjE8zIpEIPHVhISFR5JkNNeijYtEaFBQf3kFJSTEGg4GpU6cyfvx4gsEgH330ETliDAigyTIhUclQ5kQyviOHrmg3ibmF/GV9HRR3c7VXhk0lwVPZj2FRBvozj70XClIJUVflI/qDCIJAZ+8masUcLo6Vk6G9ncbG53F72ikseAm53Ijf7yHUFgPI2F9q4d24P3DFuN8jkcg51NZHur6J9uqnGK1ORa1MIxCwESPbwp2jWpiQYyAr/RkiDUWo1eHrerjvCLV9eiJ1h1iqtrHSMZJlASMa6yGMyclYSlwcVo5ELw/wen4yV/dtoFb2Mq9e8hzNB/bzyl+fYHFrMiqfBInEz/wbbkaSMYO32808Wt/BZEMctYte4YwvLyXN3caWjAs5Sz7UvRJoDEfWh5InI0megLDnZR6T1nKDK4sEjYLFmUY2FrdTv3YjKfUb0IRkSKJHEBWScPvnFcgFeCA+xLtvuvhbzRNEeWy4dQaUV13EM5p4Dvek8JkRFEG4adxBbm0qwxj00uu9G7c8wF3JfyJP9xYHbE721IQbKU30ht+HP83L4ZrqDkxKNzOSOllf42BZZichUU6LVMqYuAmcO+UBgrvfYiDWxO9II0YRQ0YokxFCHdtl07hd8t9TwPdU3AHXAZNFUXQCCILwFLAb+CkR0A4cHy6bPDg2BEEQ5gAPATNFUfx+CuIy4HNRFP3/HBBF8Z8VFbyCIKwE7jmFcxhmmGF+YURRpL6+noyMDKTS8ENYDIn0/6OGoN1H7E1jkGrlJ2ynSPrXLQAAgZDIfpuLi+NNQ8ZNchn7p+UPKYH7fTo7v6Ch8XlCoQBudytm8yaUyvghJvWu7q8BgV3tY0mPUhA92O5YKhF48oJCajtsDByxEZUuUFJSTGFh4dHsiC2bt6DxyxkQnYw2TkEuyJEMpg/qpifhfauCdvko/rzewmWCk9+IKvxKCRGeEJHnZaGbemIq4vGf267O/XiF85kZk0pm3AQ06nQqq+6nZP/FTBj/EX9cu41QQE98ZDNdAwU8VfIcnv6ZjImZR/tAEdNiD5Gd/QDJSb+iu3s1R478gfQ2D2fVb0NwjIb4aIgPC4BqcyWPl5YjhuZxrbybRUt+xcrXrXT1z2KEYi9XPP4MH//1Kba3eVmYrSd/4Z94qGwcX3z0Aq++fzWCP4hMEcSYl8XZ05eQlhmPJjUcUrZvwEGiUs6X43OAHHD9keCGR3k5egFniiKS465HVMceOjWJJPx6PQS8UPY+k1q3oa7QMbEoiVHJCu488DF8URw2QUsTkO/+FdXGEWR5B7ir7SCeT3qZKEjYH5vLB1MvpXXEWIJpT3Ok8mxEeTefyg5yU9/FJA54uapzNc7AEt6JPsLGtA9xOl0UKHxstnjR7lwD0xZxdqYOR6eRXUdGc7lkJ7JQkNHSg/RnjSNF0UdA1KMN5jBHtZg7P3uEQ6kpWKXVg2dkJWvgRSaYk/jUvQinN4BW+e+v33cqRxSA421cwcGxn6IYyBEEIYPww/9S4PIhOxaEccCrwAJRFHt+YB+XEX7zP36bBFEUO4XwX+tS4PApzGWYYYb5henr68NqtTJjxoyjY/atbXiq+4lckoUi5ZeJ/v8xqpxunMEQkwwn9h44mQBwuRqprLqHcHd3CcGgE5NpBrGxxzKhRVGku/srIiOL2LlLwpkjhloVFDIJD07MpLS6hlbLYQqKCli6dCkSiYSWlha2fr6Bhv5WZgRGInT7UE49FqC4XxJEIYSYYROZPSqFrAorCCAPgXHZCLTjT15wKIaKLM8AACAASURBVBBwsMfqBmDKYKnf+PglKFUJlJVdTfH+G1i9/2JUmg4+vnoGi17pQmo9h1e7VrKotxgoYkxKDF5vNxUVt9PXvZ4xTUpM7WbImQ89lfDWYshfSu3EK7lh+30IjnAgZExBAKttOWkRMzloiWPO6EKUGi2S2b8isPoI2j2f8K3/II27tzMqYCAk7UEldWOZMYIbr38eqWRopsYBm4txEcelL077LV8mnsO2RivVTg/5gzUfxFCQEeYD1CTMJMZiQWowIIw8l5X7BUR/CGdJNbI3HmZeSw3rR8wlOSqHsb0VBPpqyGo9RAYCgZwCXtDOZF/uBPq8cm4+K4s1W+rRat3EykZTmBbN7xdfSu/TxTzSsgqr1MQhxUw+i38dp9MJgLvjGxyqRdRnjUIlCBj6K+lTjGds4xw6ozajlncjx89MRSlmmQJjwM6bBiXvtTxOhKhlgkPNWW4nasfDrNOWsyNuDQ1S8LcJvPrmAe66edJJr/3p4FREwEpgryAInw/+vhRY8VMbiaIYEAThVsKmfCnwpiiKFYIgPAaUiKL4FfA0oAM+GVTgLaIoLgEQBCGdsCVh6/d2/b4gCDGEhUgZcNMpnMMwwwzzC1NfXw9AVla4va6nfgDb+ibUY2LQTv3hvvS/JPus4S/moh8QAT9GMOjlUPnNhAWAFIlEjtvdTHz8ecREzz26nsNRicvVgNZ0JWaHjwlpJ7oWzIc7EAnSJAsyOn4c1i/rMcxPJyUxmdm2fOakTgSLn6DZjUQb/qp9Z3cTf1xdyU1aLZc5pFARDtJTFURjPCcTacQPhjgNPa55E1XiCDJU4pCof2NkEaNHPc+jX72D3x/BgtFbSYu9hWumqfn75iDxphi+sGcAEC3dSkeHGYXby7RaJYq+Tpj9B5hxJ/jdsOtFtpS8xCOOYuSiyBnqeXwsEYmU7cRiCTA9ZSEfWiOIyg+Lmy8O9ZAZpSbHE+LIrm2MmjmHXG8Qx8vLEUTgQDmNqxZhOOdc9PPmochIx4KEZo+PqxKHVpQsMhjJbyimvnIfxq5WPDU1+Lq7wKxBH9hP7V+mIdFqkabEI/fF8B+a71hSvRmnXM5/Tv01++LyABgzMZXp46/jsw+qCKXsx+JegA8BiU6OaPWRkO4GQmRKL6fKJpI9To9KOoDK+CIpzlrWxz/Kw6pXcQXc3DL2Fl47sJyD3R+iMsmoj53LuIAFYaCZalcRktjDtAlapooWugQTIWC9NJnqyAE+17ez0DKDpS1LkUs+YaL2M+Zmvsxo5Rm8XB3Ju7FNrBb8fGrdxl38DxQBoij+TRCELYRTBQGuEUWx9FR2LoriGmDN98YeOe7/c06ybRM/EEgoiuKsUzn2MMMMc3qpr6/HaDRiMpkI2rz0f1iNLFqN8YKcn+zY90tQbHWSoJSTrDzR5fBj1NY+jtNZC0Bi4jLS026kpuYx6uqepL7+aQBEMQSICIKMettEoIkJaUasVitmsxmz2Uxvr5nmcgmSCD+WhAnUr2lifFCOIJeiSNUTcgaInpGCp9GKY0sbts2tvNbex4rDHdwbZ+JcvxQRL4JCgunKfNQjTj05rLNnLTXClVxgOrEcc6RpFptaepCpW7grUIb4l3SWTLmMN6STiHMuocbjR660Mm7yh8RZO+CDS8Bng8s+hNxwIphLgL8qvXwSYyBXqueZwlv5fXEWI+LcKKQS1OosCmUaPhAktOjTaTQ7KWm28MDCPK4seo6Az4vj9TfoX/Em2jlno7z3ZlQltVhXr8b88suYX3oJBIFAXDx/NUQxOj2ZFoedQG8v3p4eGBjgpcHzsUdGIovPQIyORa8foH/i+SSmZeBvaaFu9wFmtRxAHfRRZUzjT0VX4dAZEaUCygSBgy1Q1tULEVGEJOci8XiZOimCvXttCFl6nmkuRa33UN+cgTZk47ye5fDCB5jEEM+nXEHhrHm4tr2JVqblktQL6Xn5G/Zk99ImvIvb14rGNsArkRHsMbVgEXppcgWJCUjp6EgkKsbMjggH23U6ZndFcY5tLK4MDf66DAQhRHSgG09CN4WSaq7vnMk+fSc6hfqE6/nv4EdFgCAIEaIo2gbz9JsGf/65zCSKYv/pn94wwwzzP5FAIEBTUxOFhYWIwRB9H1QjeoNEXV+ARHny4jy/FMVWJ0UG7QmCIxCwU7J/Gakp15CYuOzoeFfXV7R3fDgYOGehK3Q5ek8UBQWv0d+/hQHr/rCfU5AAAnrdSJ7fGUKvlNF1pJSPNh/LaFYLkeiChUydn8vi/Bhcz5cSBOy7O1C06JBGKlHmGOne2IJVJSHgCbDgsI0LpAYU3QFkSSq0F6SgHR/3swIkAwEHZX0NuNAwNfLE2Iq3dx/G7TUwK/ETMmqrCMhlZG9dzrJkLe80T0CrFJCoKrjhmytYWV+FSWWCX38JsSMBKO8t58EdD9Jia+Ga0ddw69hbkUvklH+xgQWj4ikseBmVOpnW9W+hD45l884jNOwpR4KehWoHUo8H85NPYvtqNcbLL8NygYum5l8x+qznSbtwJf6uLlz79uFrbqGs8giaxkbU5aUEo+MQEhPZIY2jIV6DO38EnuwsHu40INr9KAjbboxu8DRK6ZPlcO2Y8SSOCaF3DVChjkQrlzMtx8ON9X9mfE8th+MK2GLOpJZk9plHIqTUUlKaRbIpFl2ehzLfKK4fa0az60t+o/wSfYOHYOGlnG+4CJc+Ga09HIi4MGEeX//hMbR2gaK+KXQlB1A7t1AthWpjJPJgL3K5ksYIF2tIQJ1gRe1Lw6IK8TtzPwucVt6sW42yvZQk3RkA5Hn9WHqqUAlu2p2FxMRv5cycHy6xfbo5mSXgA+Acwj0Djo+uFwZ/P3lfyWGGGeb/LG1tbfh8PrKysrB+24SvyYbp0lzkcadumv+Xju/x0e71c/MPuAIaGl/A6ayhs+uLoyLA6Wyg+sjv0esLsNvLcfr13PZOI9CIWi4lK1bLReMv5OrpGUP2tb95G5PiJWzdsoW8vDymTJmCXhfB58/sxyOE8Cn7iW7XMIDAY7i5P6hCaLHzmSbE1pd38mRbiG0SP+7CKC5p9aFNjUA3LRFFqv4nrSVV1Q9ht5VjNE7BZJpOZGQRZvMmKsURIMBkgwZRDCEIYRERCIZ4YVMVEtUAj1i3Yc4toCKqnUm1Wu7qfpXP5cuxeyVckR7JOmcXT7ui+HVJJhrnZ9TOzOId5w52t5WSYNCyYv4KiuKLAGjtdzHg8pPj7MLz1mFspSvIP3CA6WMkbA2N5aA/yARbFa5f3UPt4Nxj7rgD9VXzqNg7D4lEQdnB68jOvp+U5GvRLliAQaFgbcmnFDkO0xZqJSZmAk/vPZ/dDTamRHnY1avkjRolnjg37gVmmtd8SrF0Cr6o6Xxjt+Po8xAE2hG5OOswhd5Umgfs/K35RRBE7IKeKHstt8sOIhFE/Ao5paF53OdPwhv1Hu1tNubK5nJ700tEy9vZEByPbPFV1CWcy766dj7MTOCFHV8jiKB9r4pepwd3chbWCJEcXxHbk5bx5e47SfN6CJz3Hf3rGun0d+DS3cUeRSpH5JHc1ufiXJebrfYxgA+vu412SRdulOT5fPRZ2hBFgXbfaEaaz0D0ef/rVXn+BX5UBIiieM7gvxk/ts4wwwzz/yf19fUIgkBcixLHjna0UxPQjI39wXXt9kpstkMYjZNRq9N/EVdB8WA8wPeDAh2OI7S1vY1UqsVqPUAg4EQm01JZdR8SiRK9bhR2ezllPXlcMTmV/MQI6nocFDf188evKynKMDEq0UBvby+tHV00dFuYbmpCpdGwZMkS3G43Hz+zDdESASltrN2wg0jpmRhi9Nx+aQG+D2pQ9nnxxahIcfvRIHDJ+fnEFP28GAmvt5uOjn+gUiXQ2vYuLa0rEAQ5giDjTCScLW7kyG4PdVIdJtMMoqPOYntzBjaXjvExH5NW9CDMuIMiTxvqs2JQf3wl11R/zgtcyML6lVzQo8O7x88t0+fS1xuJ9Ss1fukiYBHnZwXIXFtBd/dm/J2dbOjwQuZiol7+KwPWdvpik3BGRTBjSg5ru1S45Sp+vyiXpCvG4G9pRZmdhW7mTCqrHiAkyPk88lVukH5IXd2faa5ez5G1AYquimGR7Tuc0kSSk6/imY0utjdbuTtpJ/Pax3CJIOdRbQsPFjyJwurFO1FPXW0Oe1t68CplSIAJKSJ3jf87HlcdifVBRjit1Aip3OC7g0W6nbwljCJayGHbNUnYdqxgTNXHbFKuYYtFj6YvxBTXZuo0ydwnv5ytoTOY7yxlc1MRk5Qq2HuIhv56ctp04JfgTM9FIjeyJeEfFNbbUcSNosDfTYNvCltWVAxetUiW+hOZgpvP+h/lzKi76AylcLgnEpXcgU804Xdto10eSa7PQgiB+lAqnVoDH81QkxaUc/+//Jfx8zmVOgEbRVGc/VNjwwwzzP8/1NfXc4amENfmdjTjYok8N+tH162peYwBazEAKlUSJuN04uPPx2g8tSAoURTp8weJkkuPCoh9VicaqYR8rXrIekdqHkUq1ZORcRu1tY8xMLAPnS4Xm62UzIy7aG5ZDkBF30gePCuFsSnhJj1Wl5+Zf93Mn7+p4NosDzt27CAUCnGJQiDoFJlw5pk0Njay9t0SVAMpZEzRs+BXV1Ly9U50u6BYeoSx/lik3iCiVOBquQZVvhHrt42Y8k703f8UXd1fIe0LUTjtBTTxuQwMlNDXt4XWtnfYL5xNgsbE3Jh4vN5u+vq30dv5La/vuRZBlsFNuREIZ95DIGBnYKAEvzYT3bKV3LzqDlJLXya1XILziIXN8y/iiDqdRFML8912Emqb2aJN483DEczY8AxKhRSi1NQXXIQUkaw/PMSFG/tBLuPGzve54YZlPP6nzajkUhbMHodKfswN5Ha309X1OeXyRXxq0XHzxKfJ1OXR0PgcmeeAuV/Op8JlTM+6mbLOIOuby1kQX0r+qI/pyl7LBeZc3qy4kvcqL2R0pJQp+g+5ZvSHLB17gCer/wNzg44lyU+idgQY15GCpqOMrbLR3B66ExUeXrefg4icKeOT6XSpubrxXKSymXxZVMFZpSsQRfhu9G+52riUswdKmdl3hHXWCJyGIPmrNrNC+ymhHJFsaw7utDwifdE4m74llBMiMiqCp7+rR61zoNAXMD4oRbcoHVNyBBEHpqKte49zb83D9Fk7Tl8qoUAPMRFn0k0WQfsKum0wXuNHJor/j733DIyruta/f+dMbxpJo967bMu2ZMuWbdwBGwym2BTTTADTk9BLaAFCQu+hQwDTsU11w+DeLXdZsnrvZXpv57wfRCg3jdwbkv+9r36fpDNn9iztmaXZZ5+1noc3Vel8VK6noKOBx9IBpv3Tn5X/KX+vJkAL6IEEQRDi+L4tMIa/r/w3wggj/B/G6/WS0KGiKJKAviyRuPOKfiQI9EMkKYjLfZSUlLMxx0zAZt/FwOB6evs+44Rpm/+qNe+fcYQjrOq3816PlTpvgLFGHRenWVicFPudaZDyB6/b378ah6OS/LzbaWx8BBDo7vkCg6EMAJ/fRTQ6rD7e5y9gbNr37oJmvYprys3U79vC9u4AM7PKCdl17HHtRBRFtm/fjjpgwewoIbs0jgW/KEMQBAr8SfhUg3TobBxe/jZTQ4VMnjAJ34F+IgM+lIk6FKa/oloYjcAH54MuFsovh5wZ8O0CJ3D8OM5HXyVpv5qh8Y+Q89FHWCwzCYVsdJPCK1zP01mZ5KUOLy7arLX89sulNAVGkRZbz0mnDTdv1Tc8SF/fn5u6RGL8aZTsdeG1hUm+7156VSXE1Q2w87ZrEUUBWZKYuvEgyzYPsP3heyiNf5JwZICjh5QUKLQciMkiqPSADM7CWRj1Wq6dmYhZr/3RAgCgveNVQOD96BkAfDHg4M7s69j8+hfoUx3YWwtYfdoiFrSHuXVNDRUouKuvDCnxRPoLvUi98YhE2dc7mYfivkRXG+bgot+zb/82PO0KLolfQ3mnh5KhNmRBRVXa2XytkXHU6pikayMazmEwouaTQ91srnRiV5pZ0L+DVxv9nJ6SjIiC59pqkWJPocWXw6yWPvx5pzCq8ShxfV+x8UQXyZ4EJLVImqcd92AliTEWkoJxBHRu4iLDUsoxvjw2zjbykNTCon19LBpyc3I0wJFNdxGvi9KplVBqI0i6FLSYGa3uxWOPQafrB+BA8jhm7/qI/I4GOhOhYsHFfzMffi7+3k7ANcBNQBrDdQF/zjYX8MLPHNcII4zw/yg9a2upiBQgFxr+QhHwv+JyHUOSQiQlnkJi4nwyMi7B7+9mz94Tae94jeKiB+gOhPig10pU/r74qCsQYu2gg4AkU2rScXN2Ml9bndzV0MXvmroJSDI353zfTx+JuGlsepgY03ha27rYt/dMCov24PNtw+c9iilGz8oVAUaPzsFk7qdcHWTL5k34fD58Ph8Oh4P+/n50oopa7Wiu9WUQGfTQorZw8Q1LObRzC3XrDCTmmDj1yvEIgkDUE8JXNYihIoUrT7maj59bzh65gajazIS4RKL2IIaKlL8+MU0boXkTKLVQ/QlYCvHHn8bg5i68u/ag0MooJuQSOFSF//ARFCVp1DfcTypeHpFvJm9gLM3+QvbarDxT/Rn400HScdcpl6MQFTgcB+jr+4yMjEsxuwtwPP8O8r4OohZw3Cygm+5h94dWTshPQPzz+ydAWXmQoiN9vHVEzYunF1CcdRltW9yUp+xjZ4OGNJMKt83KMXUO3T0fU6Z5AAUGHI5XiI0d9igIBPvo6VmJLvFsugfj0URlPjrSTe+2JraErsbbrSdVGWXexiGeZQA1MF3RxCf6XgbV17F1kx2HL8z1yft4qX8ir9XHEjWdz8bPkgi45vOh5vdM8LVgDZlZob+QHSGo1pyDMaEJUYgSawjQb1OQpPJyQvI+dg6VMklfw1Q5F4t/BwX6JqIyDMZ7yezcTUvWPORoIQIipQ072DNFIKiOMqi0ER8cRUJGFtljx1M6/3x2rLmZXqGXUXERJEnDEUsiT3CArK7n2RF3BaepDRzKicEQu5N9xAG1jJ0M8CAJkXj0ujS6D3cxJKswOKMUbzuOjBKlbhZ5pxb8T1Pzv8Xfqwl4DnhOEIQbZFl+/oeP/S29/hFGGOH/Nv56G7pDftpUQ0xdOu3vLgAAHI4DAJjN5d8d0+nSSU1ZTE/Px+RkX8cLHWHe6h76zshEEMCkULAkJZ5L0iyMMw2LydyRm0KVx8/7PVa22Nws+IE5UEvr84RCQ/h8F7Nn9xAxMTri4yuAz9Fq3chSFrl5B4mNczDgSMbs62Xv3m70ej1KpRKHY9jqV0OYyb5WIo7hHYoKcSyu7gjKrTu5wLKO4BkPolQNF8x59/dDVMY4LY2gvZc5jmL0qX4qD+1HYRlLiT0ZTf7fMDA6tByPJRHFpRvRte7Bv/oV2l9ZgagE3YJk2k7s5XXTr7n1lt/S/+YLdJ5fRTTqxh/NRC0pCTv20mZdR6IMZwogGi/jTQFmFiYgy1HqGx5EQzIxK0XsHz6KqNGQcOst6M+fT2P7w+w+9ha9zvsoTfMwMPAVQ0Obsdq2EQoNcVbBDJ6oPJ92+XEy1Ql4wlvINHXyacMAU+NlXP4GDtnK2Xf0EXJSJhEI9HD4yFLGjHmK5KTT6Gh/HYjSbrgI5TYbYpcXlwwbRZmJooE81DQKIQ7LQZzC8A7CM9FcBHcuMVUDJCiUXJ6USJJ4JpOlOj6KzAU7GPQSSzL3MmGwhW1DFTw5+V4OZhgx99+LI9lImS6fONMx9jkLcEtqzsn/mgUp1czUbCM2386YokdJfLuZSFiDUghyqktPqkvigSxoySqmqHMNe0ZX4Vf6yfdn0qrtxhRchNcTQ/H0bL58vg5dbC6TbfNQaV9gQMjjpTQrrzQ9T5lqgOMJLxNNkvEGleS3eNEFo3wzUIA6JpsYtUDcKAGX2I2lxMNRwYwYktGn+VDZMgm1TKJv6y5YuPifScd/CT9FLKjsh78IgmAAvgRGagJGGOH/R0RdIWwf1+NQ+OgdE0Kp/sf/PhzOA+j1+ajVP74vnpNzHb19n9De8TpbbIs52RLDe+P/dsORLMsIgkCpSc/4Ih0ebz1Gw/C1SCDQS2fnctyuUo4csZKS0sKFFz6EQhFiX+XniKIMYjsFBZkEAg5222Zy7WXXMz4jFqfTyRtvvIHJZGLJkiV4vV52f1wPIdgsDHFiIIHq1zczz/w2CiGC/+s7oGABstKId18vmnwzqiQ93a8cQsBMSuFKQjYjexsles0GCj3vYtweRvFVL+LWfuIuWELKLy7F3/EN+8rNhPeehr97FoVrgggxGhIXeaiV6/i4N5Yq2518PV7kzE270U/y408WmLP/MB5Erk9OpFWn5QGLj9lZBp6oTiAuQWRZfQdPJOzB4z5O9opJOLZ/SOy555J44w0oE4aFfUrHv8qegfWAhNFzB8eqB1EqY7DEz8KSMJfZCaewoecgL21txvit1HGKeQG+iJKcmI/ImtXLgSOTaAzdzKKyS4hEXBytuobq6l9TH/iUsGYH8YlnctenVpSDPuYmxxIbiPJLh0QUP5qFo3ly/UoGAw6cqknoMpaT44tnQcsSlIKAyaJFYQ3jFwVGiymEoi5StUZ2TDJy3cGVdHpj2Osy0iY/gcR9OBLvQRa1tLU9TXHmJI7UDKso/vL0+1h/721kjyvFZNpLQ80DJMrdfCKcztls4MxeiU1tO8nKNuDUVGLnKApRwanMxqZxoIjTseiGyax/5RibltdijFdRMngCA3qZeE0Lx425PO++na4iLcf0MagCMoUNbhIHoqilCFFZYK6/i1TqEAUJdkFAoeGQTouoi8OaKlKU246Q3U4keQBz7d++NfZz8lMWAV2CILwky/L139YGrAVe/5njGmGEEf4DyLJMTU0Nubm5GAzfV97LkszQR7VE/CE2a45xxtRz/s4ofx5Lwuk8SFLSX/Y96XRZpCSfTVfXB9jl6czNGPs3x2lpeYuW1ucQuAadbjRO5xd4fZWoVTMRhOn4A59hsURpbi5g1Og9lI6fiNmcgyzLKBQGolEveXm3IggKmpsfp8dXQEmaGb/fz3vvvUc4HGbZsmUkJQ13N6iNLuq9Htb69UxVS4wVbfQfNeIOWiiY3Iy08hf48v9I1BEkdmEe3mM9sN+Ob/d9pFXlkjkuk8LEPg50qXA+3kVccxtEZSJp4HhpOeFDO/CcrEFGRBFNI2/FFgS/yKfn5LMhqQenoCc2KrPM4aR6rA65UkQ+oCZuyUnMKZuKxv8+tuAgTxRexJT0iXzTcD813T6EPC1Oew+NzqdIOZhPeFsVibfeQsJVV/3FnB7rTyYlxsrMCTdgNBRgNk9EFL//OvjV3AKufvcgD7y/EwEd29cehPgplKRUE6eTKEkR2daWx52CApUqjrLSdziw9zq8bEGW4I7PSxjy+jjZr2RmV5CTVCp6/B3sdzTCexpypSLWWnzotHXMFSX2px7hvAsfRRdnYOWhbi6fnoNSIXJ3Qxd7uodYnBTLiVUfkhy1szpYQUQKIEhWdPat+C2nIPptKMK1LJ1yBdW1EuXZcYh9vQTcLgoqptNVFUHIreJIVgoHNGm09phpT3CzryhKmNfR+VVcFLuEalUjVf5G/BE/E9QT6HE2kTarmXDoMyIeE+YQ5Jka6AqpcaVasar1uN3pJJuv5dmhzZR5G7hTOgaAQpARlQLb40vx7e8kTpLQJ6oxp+kYNdiOYlDCrxXpTNPRk1qHaOr5hzn1c/BTFAN/KwjC44IgvAKUA4/KsvzJzx/aCCOM8O+mubmZVatWYTQaWbx4MXl5w1fnzi0dhFtc7FE1cNJ5C8jN/cedwx5vA5GIi1jzpL/6eE7OdfT0fcZpfMnc+L8USpFlmZbWZ2lrewFZFgiFX2LPnoVEImZgWOJXpdpPeXkNQVcBk8YlEFW1kZPzBgCCICCKaqRogJzsa2hpeQZJFkm2lCFLww5/drudpUuXfrcAiNgCKPv9ePQqTu63g/1PuBvqQNIDfjqyJpIsR3BUN6MpiEOda2bo6beQml9AoY6iSojFv/EgJo+HuUBUFOkoLGTsPfcgpLfT/ocHYHMLQa+RpDsWYVkh4WrrZuDqCFNLa5HdGtQivKZ7iUOth1BqAzhK38e8S+amqe1YqccgeHnp5JfxasZwVksP9sGbkBG5N/NzohoZdbMX9Xt9GGbMwLJs2V/MqyTJ7GmxMqc4kcyMed/NtdcRxNbjpavBjr1mkISQiyF1DAlhH33GUpJkGW3vg6BPYIJCwXvdQ3z4bg2xPoneZifOHhOq0gJqDUX0+hJYajCwRfCzGT/BTBXu7StIP/UyPHk5PF23F6nVTKnrKItPO50dx5+lSajhm60q3tlpJcbkZsmEUqbHGXmzewhPOMy9HR/QFzSRdcbNvHz4AWQhiKW9m0i0k8TmJoZSknil+ikeO/c1RqdYqPviTdQ6Pbt2HWOs52sGtGGW6zUc9n4FFj0Z4TCFriyM4USSAkl42yOIRpGexOEvY2utlbWuNZSO34QpdhCVUUJSR5FEgVb0dAfi+LpLyUmNv6N7vcQsLsIoDiImDbtO1jgSaRTT+dx9OrfWvEtNuoGnzvgNg3FJPPPq4yiitWyZJINwBalVOlITjf8B0eC/3x3ww5sT+4D7gEpAFgRhsSzLn/71Z44wwgj/W6mvr0epVKLVannnnXeYMWMG0/Im4v6mnVZxgKKzJ1JSUvKTxnJ+Ww+AcQI9gRBp2h9Xyev1ubRo5jI/uIF0xT3A96VGkhShvuF+eno+oq8vH7O5BK32S6adsJbsrBcRxXRc7pUMDb2GIEBv1QJsUpiJZy1Cpxs2Lw2FbITDw5avNTXr6e7ZiMOfQK6zhuef34zbLXHuueeSk5NDqKsb17p1+I+2EajvItnroNDdSjQaQpVVjrpwEf5DrxI6LGOdewtaxTEs6f1EPCbNwwAAIABJREFUX96J2XoUW18SCaU+Ei/MRp73DsHdawmueojoGdfxdZWDw5s2ceaZZ9CROZHYBTvQfKVFvmEtLnsE53kF3JvYwkURLdNjHPj9Bia0NrOrczREo8yZ/A2TD/dRWtlP32Q15098ijs6Y2nwtZCuUTFKyuGouo9M1dconRK6N2LxGrQUPvYown+xp/W7QxyoHcLmDZHilvjmzRoc/T7s/T7CgWGfOFEUUCp3M8ndz1fJp1BenMWWNiszY4wMNIaRpBApgoAowq6qbm5Q6MjWRNgfN56HrfNJGpJ4SzCx3hehHYkEnYoX+5wsVug5Mjofj0mA3jBqdQ8T2+yo29XolXo2tW9iReUYkuQgT+7awUmj0jnZEs+duSl0HvyAIn8H671l2NKsdPb4KWwdyyKHmjXuR7A41Yz1nsbmovc5FljOWZa72bRnNzEx+dRGdrArpYf9ETPaqMx0IK+ygDsSN3NAMYUh6WSCIRc62cDJM0+iofYIqSEfF805nzLvXmrDvRQ1ekh2xHEgdQYV7Z/xhiWLVw0SJ2fNoDQ5lj2fWZGj1UQzPofI8FwPBo3Mjqvj7ZIrWDn/fV5zB0AQyGx9nj+dM4rOUBOSAvI1aXxYPo4crZql/2S+/iv4ezsBZ/yX3w8Dqm+Py8DIImCEEf4PIcsyHcdbuSA4HZ1dS0AO4t8UoH/TUYKE0ZyazsTy8n880Lc4HPvRqJO5pTlKg6+RvVPHoPpBIWFIklgeOZsH2Ux7xyukp11EJOomEnHT3fUeg0Pf0NNditVRQXLyG0QVo1BKdWg0zWRmzkSW76By/3bc7nrcnZNAkMnOHM9wE/gD2JR/3l4V2L//TdIzWvG4itArwghCJ2PHORk7diyyJNF16XkEe+yg1IDGhEZvJG4UxI+GAS5ACMdinHsOrk+eIzpwHNP4rxD3bUeSLXQ354EmQPwpJ8CxFQgn/BrtgbvRxnXC3ru5avG7vL2pjg9WfMp5ulp6F4qYck0YX3fjmShzT3EzUVSMyroMqfdZtFovGdGjHAynkKh38rDtBt7IX86ph+2sPON3PNVvZKxR4I+jszgz0cyJ27cxozCFosLbcf3uDZRDXm6+8VaeUutI7fHQ2+Skt9lBb5MTtzXAAU0EdBA9aKMnVkdcsp5R01KJS9YTm6LH1rmfjW/s4Zz5C0lKyCYvwciGliGWLMzn+CO/JDm/iGW/e5xDr+9jb7OVu9MM1PR08Iw+lXgEnlPqqbYf5k1zEXNGJ3P3KcUsfHYr61NPwxkU0XQdIBpIYJHpXQrGlHB0zWoyyw1scX/Gp+73GGMeZMXAeG7Z2M5rC95iUaIZe9vH9BHL3rFFfLH/aTKtcZzUouDd0m30JgQAyLB/zkmOKXzS+Ak5m5V0a+2sKdlPj76fpIiKafUxjI8NM3qSFY8vnmggkxJXL6E8Ld5ID1LDGIJWgVe8UDLYh7z5Vg4WBlEp1RyuWsIxVxenKmqxCyb6qsNMjJNJ+OY4u3RNiIp4JEnPKaEOag3ZNHeZGOrXUJY6wDVdK7g8thREFeaB1zAG62lXHkYhGvEbp7A3fhzTY3TcW5Dxr0znn8zf6w64/N8ZyAgjjPCfpb+/n2xHLBpJiX5CArqIhGC109fbh6LCwpRZP13IRJZlHM4DaGPK2Wb1IAHrh5ycmRT73Tn7nV6apTRk83w6O9+is/OtH4wg4HQsoKMjldiCKhzBGG7ffg3Pzv+IxqZHiY2djMFQSDDYD8EipPBwB0HlQRglLCd117PYiowoLWrUQZGs1GpQRNnhruCBhXqamzcDEPB1EH35ToI9dpJmGPAnPEOM8m1ilKsA8Ja8iHAwFskYQHAVIxji8LV/gjX5N2j183H7Ewi2/I7Y885FMW0KfPwVvHs2eAfh4lXw1W8wfbmMWfNWcO6qIQ4rzCxyfkHe2HbCT6XwultmyOPi+kQfUu+zDJJIZ9zNbO+LMCqugSvHvcNTR/7AhylT+VXzcq7u7mXOWROp0OnYtr2DJ1pb6Hb4ubQsA+NmDf5dbjj/CnK8OWx4cD9az/DVvS5GTVqBmfFzM9hZ20mWN8gdD81BofrxTkF3fS1b3n6ZrLGlnHTZVcxTKHjq63pEAfKVHo5FIvTUH8dtHWKBSsNmZL6wWHml3YekN/Per2ZiDtn59ZNNKJB4/OyxJJo0nOrZx5eGaUSO2wnbexHFVO4rScU3dhnb3v0Tc8Myp7qOkhMTpdlr4XxDFaOP1fGk6gYSVRO5xl3HU/p8PtXsZaK7hJNacnivdBO9lgDzhhbhtw2yP2c3Paq9GCN6nktbSSRTQhNRc9uQg9GdRnamT+BNy1aeUqdjKa0j2F6BzvkF2pbLiUFG0pgQ97n/LNdAv8aJ22Sit/IXBJNSKJ6ZQnndYxxuzGPJwQAQoTV7FK258eg9zfgMuRglgY9M02GgE3t8gDfTz+Smzo/I9XXRFzUCdno8U1CqD2HRLcFtmsDilg+4M9xLRmAqTP/lP5Wz/wp+imJgInAVkPPD82VZvuLnC2uEEUb4d9NQXc+oaDrqkjjiFhcCEA/kfluZ/88QCHQTDPbRax6DBMQpFbzRNfijRcAWmxulAOWjH8Bnn4FSYUCpjEGpNNHQMMiO7fvIHDeeCv8rpDUYuGpUhHu2nMXjsxs5Vn0DRuNYwmE7Vl8i6dP/yFDTXD75xM19cfdzWM6lN0EgWUgAWzu+rOEvwwulOgY7t6NSxRMNWOHjpdjWtaMwxtKU/SzpXpnA7AuIMZYjYcC+Lht38n7i5oxF3ZyOLv8KBp95Cq+4H9k3E4ftPtQSJFx+JaSngEIDg3Vwzp+gcB4kFhN94xTu/+wQOkUqXZEk/lB5K5NTDpKWtpmDfivL8meiSz6fg52v0KGezlx5OvbgUa4s+IB8r5Wbir08GSrFpo9l8QfvYvWlsbxB5n2Fj3alBALEP/8Ggy2rGUoqpap/AuNtQeqTlcw8OYP55anEJOgQBIFIVOLYjlrOLEtDoRKRpChDHe301NfSXX+c1iMHMCUksvDm3yAqhtv3djUNMT4jFm936/eflV07Gd8ShxaJx6u9CCojK66YQn6yiRUHHHTr0jkhVEVSzBk4+nrJHjjCghlTWd/uJUIuM/SbMJ94B2ZTKhecXkhkw9s4ZYnbk2eib69gctdaTs1q5teVK+nV7KBfZeZjS5grehZT6prGE6VP0acOsNBZgcYtkiAUYN7jozavmZZMJ8iQ5czg9BYdv4htonPqZWzRHKFUKKbcfCoHBx7nuK6LiWIEQRYRkAmLyQTlGLTCAC/FnkdFzldovDKBjjHM7H0Io9JDizKddaYpDDyo4dIt42gjhxj7EbJsu6nOu5Za/zwanGaK6KQ3PkSxfQhZgFt7n+P36b+mz3QnE43tXFsnk+r6iLKm+4lKSt6MXEaMy84l0/9nOfzf4ad0B3wB7AA2AtGfN5wRRhjhP0Xg8ABqUoibm/2j435/O1ptOqL40y17HY5hmeAN/jwK9RouSbNwf1MPR90+Sr/t+99qczMpxoBGNtDYlU8oFCIcDhMOWzlw4BDlaUrG1t9ObsiFLHi4S/4t2omv8NzBi7m5/DX8/jZkGQwaK0pdhJyZf2RMfR7Jgw42l95KkvI5drVUoAyXUMxqpJCCeUNriW4F78SzEOrWI/Yew9OTQnDOWeidUSLxWjLmzQTm4VhRjxztY7DwY/LGXIxmQjJRTxqDr72Ap2050pVhVLf3oZs9GXV2NlS+DtEgCArC2ZNprL2TrMxlrBr3Fke2WLk98w1y8xvYPHgZn9WOY39/KUXZ61lW8TRTKpvwhe7kvsQkXt3QQKGil2tsfQgOF4HQe5ypvJoXxp/DbQfex/zSjWQsuJ5OZRqyDPmefsa2rCZUNgdp4a84bXwyKUWxnHykgX1+HyU6AfO3i7hj3U48wQgn5Fuw9/bw7p03EA4Ob6cb4uLJHjeBGRcsRWccbrNz9Lo52uXk2tl59DcfRmMwICaZ+ap2Bxmh01EofcgRAzICv119jGtmFfGHtbUYVAEmtu7C0ddLV92wtv5vzyhhy7tbCXgt3D3ODDFp8PZCaNtBkyqDq2MyCesHENO+wmvNxGvLY2raXkb5engyaRYXHk7iRMNsLs1+Flndx8yjCcREVBTMKuGMM87g41XrmLDpaeLcoNR6MMoOLIo6ABTRah6r3cPocAThyEZGJek4PspATbGRsDGFoOAmo62PtAEPtuNGZmk34RgnMqbGS77xUVqzDBSHW3km4W5enH4K1ZNz2HTwGIIrwKjUDFJzb8Qa6qXaP5+c7g0EYhU0FQQZvclPU6mZuLwWHrbfSsIxiQrfEFXeBdRELuFgJJ5I2IKACNGB/3bu/k/4KYsAvSzL/wlfgxFGGOHfhNPhJNNmxh8no84wfXd8cPBrqo5dh8Uyh/HjXkYUf1zcJ8sSHZ1/wqAvICFh7nfHHc4DiAoj69wWfuVuJc3ejlGbwhtdg/xxdDaDoTDVHj+/SY/n7bffZnBw8LvnxqiinKXcR0lPJT6FkprR6YyZ/i7C26dzy9D9xFb8kTu2JPHkrAfBsJjOtXMIi0NkT34NYXQT1RnjmFaqpLkFPANmBkwTKOIbjjoKSZw9k8jBAzy/s5jRoo6zXbtBkKgOjGeOWSRm2rDRT6jLje/QAIGSehTxGjSaYXVChdFI3JLzkd96B/en72P0Kki68kY49A6sv5NQ5lTUnXvZvuFWsBymtquGJ3b9kunpUYqLq0jQTKDV8RbavDhMtktpaDuDO14+wuK+ECn2KLVKKw3GEFcpDnJ92+0Y1c3EKAY47orgTh7FTSfdyk3736fl2B4Sy+ZQ4TnOl8aZ1J1+IWc9fs93V+8AZT1h1lZ2cfKAh5nFSVyXlUh10xAAkzNjWHn/LRxXpjMxPsSSux8gJjHpRzs+Eaufr/94gKgkMy3XQtvWJrqKLawWjSisM3HhJ8Yf5ZTYKirjemkYmMaNH/mGpZzHxyE0QN3u7Tj6e9EaTQzqXCjTX2SpTYs46THY9ji07QDg+fBsXPrjRAUfxML2cbE0RUq4e/zbzLPuIXlLFXPE8TyQvQnJ0MrMIxbyrRYkrZcZebGodj7BpUMrELI7CEYVeCQDOprQGUMAJDRuYdBgIlx4LqHtn5Mk2mjr1zKQrEWM2FENQcNoLZ3ZKqqZQMbUdpx+HXLzHE6OfYFUPew0l1GXoOXV2lv4aFsWsutSxutUGNUGes2DZA8l0CuB1m0g5oRx2DQtHE3LIMMzRCJDaOIkdCYfNVWz2WG8Gn24D4/JhqT20ykrGAAu+Vck8z/JT1kErBEE4TRZltf97NGMMMII/xE6ttYRJ+tQzPje7c7jaaDm+G1oNWlYrVupOX4rJWOe+a6fXJKC1By/jYGBdQiCktLxr2OxzAKGlQLdqhLmVR0gZO3jIHBRZg7vSKX8Nj+NrTY3CimKcvvXDA5Z2RIt5vw5E7jGchTlN/cg+2ysUMwjqeIwGXmXImSUwzmvw8dLucL8GDMuO5HOtggFaafR4A+QWJjKbJuevkCI7sxe+lueJRBIQFYm80W3kbm18ylVprIqKYWPvYsIywIHw8UsrNyOK6mMwoxUCEfRj09EjsrYP2tCNKoYyPwIc8yEH82V5RdXYlv+HsaNAkJRAvr2V+HYCo4kTOa8zPv4avA6JnRsZ7c4muWts4hEQ1xS+iWibOLu7nZ6gyJXWs4lvV7Ny7LEVz02Zqh07MtT0O30QRRejy4EDRgUZQhRH1GdQEiSieriuH3GdST67SxXPEahuZudwfE8rC6i44UXOeGEaUyePJm9LVbW7e9CrRRR1zipidVye9cgCw9soDB+BttfepwVUglNSQU4bXupOHKQsvmnfSfKBODa1MFBKYIaKGh28WW/jZXCGciSjhNQUR5q4eQzCiiZfi5t3g6u/PoaXNZCKvIv4HN1LAlFo6nbtY1oJExcfg43b1iGQgzweUKAmvVX8GFvPz5Rydc6A5WWXcjfvu4obzF1sfXEiZm8dewuTnDUEUoQaRB30a4zUmGXuSvGhk7fSJzSi2L1l8iAlFzBhqEK+to66RszDkNHCxcXHSAkJvCicRoTA2G0D2+i/8oQobwkBI2EOqIhJAZIz7wW45EnqMuJIX92FQBfW69lUqCAGGEHJUI9+EJM7XmSh01pnDO0CJexjU9SVnJctPJQ4UzSd85AI5oI6sfRHHecdFs6TakCRkRkCVwBAXeugbaacwkJNnZnv02BfxpWUcRrr6DEUcN/gp+yCLgRuFsQhCAQZthDQJZlOebvP22EEUb434JY5cajgKKpw7oA4bCDqmPXoFDoKZ+0koH+tTQ2PYxC1DF69KNEo16qqq7F7thLXu5NDAxuoOrY9Uyc8B46XRY+XxM93Qnk2PpZsGABkiSxYcMG5nr9LM9MpCUYZkH9IYYGuqlSFqOXQozbeiVKxTH8iWWsLHiGr7v2cbnqEImJ8+nq/gBlnBHNSdeg3fUaTksdBmMRhyrtCLKRiWldxNbtpkX8Bd39MaSVf0x/fxpnn34q0zY3k/L5BqKCSPukC5mVkcwVaHB0HkLpl0kvPwllOMpghp4Miw7X1k7C3R5M5ycTcLSTZf7Fj+ZKlZyENDMRxdYBApMHkI8d4/WCK3khcym/GlThkrPIc3Wxt+5KqtzxLCn+FHVkK6vsOjyRCFcLRYzf0cb0mLc5FQNnyn9gZygR2SYAAtPULVy9ZBETc5Mx61XDW+bWZqxLN1PTaeXQkEjX9rcZpeoC4LZkL3f3pGEciEP76RCV0SPcutVGmkHBqV1f8knqWSQed/FqeDV5vM57jgirvFk0GdPQR31UxYxj3Vtv8OWAjlVNIc6flMmtk7LwH25njO4TTqcX7W4vF2bYuZr9iLIBIfwUGyw2SucO6wwUqAt4Z8FbXPX1VVQO3UN8+sOMnzGbzW++Qkgpsb7wEHYpiEaGS5KnceHBT/AIAkvSk+hXKinzB7hxMJ6Q1o+GZh5ShRgQtjHKZqXWnYBCEHi6UEQlw/1uO1pBh1OZSFe/ifiuAMEeNRFfF7l0YZq4kLGhUlKyT8QibMEZOoPrBi+kq28vH122g6mjtAxGZGp6xnJjxeW0NN5Ed+gVym0yJ1iHWJu8mEaxCk8wSFdsH005c7muq46XEmwc08Zyfu3l6CJGnIl/YltCJwCfD27BmrOdqHUOE7sW0NO2B3uCnVBiP/2WMOaAgY+dKi7wjUMVyaDRspqxtnNRB5JICscQFSIMpv7PLbb/O/wUsSDTPzpnhBFG+N+Lt9mK2aehpyCIqBCRpAjV1TcSCPRRPvF9NOpksrKWEYl6aW19DkFQ4HIfw+ttZMyYp0hNOZu0tAs4eOh8jhxdhsk4rCbosMVjmr+QKVOG2wpVKhWr16yhZd0XuPRGCga6yS+tQHfgC27TfIakUvK4tIw3uk+EXgUPTK9Bp8vC5TpKY9Pvvw+4Ih4YIr+mm1HtvyYQn0RCqx3i8zGU34r73WYO+NRY0pMZlV+A8qqbGdLGMGAyc9eB9zCa1QiGKcS1bMMXk45/ook38+LYqIlyuM+La2M7unEJBNIbwAFm84S/mDPXaX6UpgjuqRIvSr9ibe+Z3LwtgK9nCPepQ9TtX8LaoIV0FZyYsYfukECNR8ktqS7GHRLIj3mbcPFCVntUrOx9kNPl3zNAHDoCvLK0HHPhD9rFpt8E75+DpWcLs8ovomVLNRcpP6ZfyiFe6MQ8sJMc4XyWE+ZE2cBzXzTQK+u5XVqNz97NrXPD/P5IAKN61bBJkGot9+oeotxxiKm6WF7U5PFOxsUEqn1kGSO8sbMV8dB6blS/zFJpCKcmhf6oiqCsp1DsxCj2UKN/lQcrbmVw21quV3VhESJkBdx82WflsKeLGzUvkn/yy7z/xbNsLx3Cr4mikmU+HRTIal8BDLfTPzbgoEtpZGxUiVcXZkCh4j1jiKyQji3GKPcaJzOmUcA2KYcq4zYCfWfxqj4TtaePOXoVcdvfx66Npz7OgHD6OTi02XhVh7Gzl3JbP1mCzA53AV3mQ2w/aSWXpIYJB2R270llX2En2/Y/wge+KM35Cj5KLGal2kan6lt9C+1r1JlBKctsSU9GEnRcVX8hCkcRxfodBA5FuXO8kiqzizVGiNFqKFZ2IyFRMjCD2EAMe9O3kaJzcdCvpMsbQ++xxejiGyl2zEMR1dJjaqIl7Rt8Khfpicl/8Tn7d/BTugNm/bXjsixv/9eHM8III/y7GfimGYkwCTNzAGhufhybfSejRz2CSmVh9+5Z5OffRm7Or4lGvXR0vIFCof/R9r9Gk8iEsuXsqzwHu+NPSJKC5YWLWV/2vRzwpEmTaAxGkL/ZQJJ9kLEFBqYev4t0VRvB4lPRLniGqxQJ9K05TmVLE8maapISr6ar+x1iYiYwZvSjBIJ9BP3dRNo2I8luuqLdmGUZpEGouJrscWmI77dQmDiDGWfmMvDoy0i2Tl6ouIwzSv0o18bh3fgm4pg6BFc3r5Wdxzifj3V6iUBEom9lPRq1AvPCPKrrVxOwFzPUkkSXt4dISEKjU6BQdOE3Wskdp2EwFE9+dCNnVs5EGW9i5mVO9rWmcUP0DKLI3Ja2A4UY5HOrjmuT3MxoUpIQ2IhccT3rwks5FPAgzboFzzdNxEg+rssbwlz4XySZC06C5LGw6zmieeeg3fokSYIDa/hKerWfkCUf4WKNlj94z+RFoYaNci5XiUdQ97ThQ4Wx8gNu0ueRJNjZJpUwW6zhfNUxkuz7OKi/CICwoOTXwVXcqv2UVnUyuVI/zXIqD3AfvV4TndFEXlZsZUC6G73yGsYE1/J0pZdFoV1o5fB3oWqAqcDy+s28mvI8WycMooqI6KQoH/XayAz5QYChsJGPUm7jw7w5NOsFxrvrGN/VTQvbaVS3oEVNxFXIgeRGUpNGsS39MPFSAb3OKRiV1UxOiCP+1VcJKhX0XnQeL2SO42S7ifbIK1SaqhEksGicYIdnS1YgGN3cmBRCG4wja+9S+rraSR/o4/ipMlWDHRhkFU0pg8Rac7iwez7l3hKOa5tRap9ktzGRDXFTmek5E4NdgSz4CXvWoVSl8EyKgrvtKdxpa+JR9TK0boiqHeh8aWSH9cSqRLT5qyj0zIGGyRA2oNA5UdjyaTdXERvIZkb78PudIGl/pgz/+/yU2wG3/+BnLVDBsLXwiT9LRCOMMMLPhtN1lLa2lxhb8gwKhZ5wnxdlW4Dj6n5OLpiNx1NPR+efSE+/hNTUczh06GK6gwGiTU+SlHQqBfm/Qa/LISamDJNp9I/GDgRMVB87kaLiL+lVFpCZlEaO7seGo0tOmMIV/Z0saVnOgqYddMsJrJ+0EJ3pCFOUYeL0ap5eUkZnVzUNDRIabTJ+fwexsZej1eZiMAzbrYaTFvPMrmewGJcQaDNxtXoJdOxBO/Va0vK1WNoddH54H4aVVdgySjg7bTLTB1UozjmVaNuXuFd/RkRtoCm/lNYhPXPaA5gjoOoOEpyVwarnj2LtngRMou2b4z/6GyYXPQJlUNVwHv3qJApmPM2MZccZN+Emnvn8bl4+uoxkBF4wPYy1sB9Dz3RucPtYU1dAifQVlnkPM9gyh/JaK+XAznoPPjQ8Zonj9DEnIEclBMUP+vcFAXnajfhWfUTjoytYpFpDnVxK8TULMDapyNrxCM9aHiFDE2CVLQeLIDA7NI59wT3IAqz0FHCP4XMa5RRuCN3IXu31nB15ky3ieI6oYjgFJRtEmGRqJioL5AgD7IpO5IrwDQRRIyIxT/s+X5oN3NYfj93yGPGuG7ggsBWnYObmKY9xW9UfyPN3EZKKUYqNjAqH+ezg24TMJs52R7h+sJe4qIQgQEhS8m7XRD6dNIE2LSyrcfPb/uvZz3x+md/GdFcZR/T1iNo+FJLAurIaokG4aHseCXH9zFdPR2524B19JvtSA/S2qDgPiS3Gx2kydnL6YBrtVFAur6JVDwVyGqenNiFENYw/kkNbJJf8lEzGhCyUbo2wM6GIcu9q5ir1XNd8HwbFWtzsY6p3DhH/kzxTmMKs41XM61PSKct0KXbhtiWQZPCwbG2AXYWnct3857l+3fugSUMZMiEgoAqbyfAUEvYbsR6aAZJAa/xRHLINf9kzyECXOx2bMoRe5eKClDOAv5TP/rn5KbcDfqQcKAhCJvDszxbRCCOM8LMQiXipqb4Jf6ADm30P5kAFQ29WExDCBEZpUCgU2Gw7AcjJvpbOzrfZ6/TwB+FVpoV2kNvzCZkZF5GefuGPBw668Ufggw8+wO2OJSFvOTe1u/hlUtz359haoHYNYt0a3uqsRBZEDqRdzI09k3jI+ASSFKKx6VFKx78MwMDAOvT6fIYGNyGK8axc0YTZ/EemT59OWVkZVVVV+Hw+ihNTsCl7UAkhaNhAZMBGiduNRjDg/yxIVBDRjz2PKShxTdjH6PNupfVYLvV1ChIrejlvmplHNwa5/riHUbKX3bKEb00vJrNIetkaknNOICdmIfYuF7WeAPPGWempr8EjmXiy5DQKRicwVTzKgHU5D305hjcrZzABBU/PSOOoyo1SlslsOovPIgKrohr2G6fzXk0mQpuNJ0ZpWDQ3n6c/OIzJKzJDq8WxugXPvl5iF+ajLRqev0CDHefWfMKRm9GofksUkdhLX0TIHodGKcCORzB07cJmSgLysMoyVygEii0zGFAnkq8fokRs5774JGYpB9kbLGe6fT+fxYVYvnQSqZu62d/bh0EGFEo6Ao/xKzmZLIWShChMk/y8m1FPYSCFYyl9+JxVnIWAAhktQR6rvA2tHOJTzWLalelUBEqYEf0EnyhyvtvDvS47MhCUFChlkcbaxaw+83SaYkzMr2zAH/XQG5jKV2kWBGBa6yLOi/FyR+az6AJhnEaBhe0pTGlqo2VeIc/ot6EPCmSljiYjWEBSROKP5qexKZycN5TJ9An1yEITAaAFFedzFFHO4lU+AAAgAElEQVQRQ7gpAbW0h0pTGe6wyBJhEllqHWW+k7H1hBgsWoE01U6gYR8BqwGHoQ+z9xxe3S/TFxlFTUjmWJ6C7QVzuXRlNYoukVXn/IaqonFMP1qJoMnCZBtFY8JBjqd8g18VJagIExoQkMY9/qOUMSKiUUQI6roISQoiQoRPvV9zPv9+jb6fshPwX+kCRv/Ds0YYYYT/p2hqegR/oBNBUOGsOU5wk5agEGa16gDzxp0GgM2+B70+l2jUS3XzC7yueA41CnZJs3mh5VMeSQv9uE0wEkJ+eToBb4hIZCFLll7PWoUBm9A7LAwUcMLn10PdmuHzk8chzLmLyOizue6NTq6c+DHyt9vJQ0Nfs69yIRbLbByOStLTLqa75z2cjrkYjWaMRiNr165l27ZtCIJASkoK0pAbs9ADk64gVLmDwRcPo4rA8ZZ9ZPVXoxm3BEGbykuaAOcZF7BrVRONR2pJuKQSv6UZc9U5aImyjr2crX2MUYCshYA0DXfHAkIdhUSlZn6Hl71EWdHkITo9hnbVWLzZRu7JSOaTfcv4cN9cnKEIs419XFP8DS2Go5jkEGtCZXw9NpeNB3vJ16lp9oR4xTNE3qx0VhvDLFGK9DuDzJyURto5ZQRqbTjXtjD0ZjXaUfHIUYlgowNFvJaEijoyqg7xsXEpS/LHDc9nahmyLo4FyhpWe8ahNNYyOtvF0KFcakxjkAQFL8ov4JTUbNAbuD+ngnc3+Jhr2MeYpHp6tfuYPKWfB9fsYpLiKC2hy/iTnIWdEPcLUYbkDUzVlJHWP59moQ+n/DXniKsJqlL4QpHLAv9eIkKIK5KTqNfsB/bzlizzYY+aXzmctCjURIAGfzFjdPVUCxdzywWnUWdJ4bebDmE4/hWBmCS8aVezIfZ3VMgVeHyx6OV4HuI67s56nqgYx+f5GtZk9wEr0UTVBBQSAoc52evjviEbLR4L9sAsTpiwHZ0/THG9BxQCR0OnEDtjLinxo+GbG/gwbimOIROyEGWn4SjFa7+it3A8kYCW2CLY2bAbe8t9w3PrhJAiiEUTIeiHkDrMwnPHsbZuPe+f0kFEMx6fSWRq7VbK+iS61W6OTnwMl8b6XXqMV6hRuHLBnoMsBikYnIo+3IOo7CA61kFiTh/boiezTTiRFm/oZ83/v8VPqQn4I8NeAQAiUAYc+jmDGmGEEf61DFm30t3zIVlZV+GrdqKuLMEuu9igOUpWSR7FxcVIUhiHo5Lk5DOoOX4b7wlXMCDF8PmEfP7YUss7jrOY3LSec4vO+m7cSNVKlI52TCi4Wr2Khztm8yc5k6lmA5nuVuSPLgJ7G9GZN6KccDnED7sPbqruRYy0U2DcAsjk5txIR+fr+HxteDx1gEAk4kQQ1NTWJjB9ejmzZ8+mtbWVHTt20NHSzoJZ86l+r5UUbZQ+xS+Jhk4HpZO+Ua+QscaBaM6C4pO4OuJhblCJessQR0JR0LjQJzaBLDNFfIylitG8GV3AevHXVCfruMA3gXaHm079cRZ41nEwRmCvazYAGxUwRRcmPKgjub+DU1a3Icsy+bFuflHyAeMTjhNVpNAuZ/GNdYixE/4/9t47Oq7q3P/+nOlVMyONeu+yJEuyJXcbdxuw6d1AILQULrn3l95IKAkkkIQSEkLohA4GF7AxNu69yEW911GdGU3v55z3D3G53Pvem8t93xuS31r+rKUlzd579tnraM4zz977eb77Uf708SAa4IGwmtcFeJMoRsIss9l4/tgAALfPz+ePe3soTTOx+v/UEzg0wo4d3agVAivWlWAqC5B45bcMy3bE+dPSsvFYlHg4jKFoGQs6diOLd6A0N9EbGeJq9yBmzMzMaqBB28tudy6+5Bru3jVJQ0jFiGBmjcnDFYfvJ2NsnDXqKOfEIh4S13CSKKu0/TSbn+CtVB1/lj7hFq+fe7w+DLJM2JrHz9PmsSN+jGZvNd+aauaJrGsxr/oec/adRfBu5DfJH/LS2ARvJml4yJ7Fq2NdnNBouS1jD3JoP9c7bmN9vAZK70aUErxl/ZCIIs6yThOBeJBmWccKVRF3uu/m2YwXyYqmsMJ1KaN5Rcy1/xmPWMaagSkKJw4QlwVu8wc5OeskSkHEdkyBXpbRqxKMTK6gz1lO2BcFHgUn/Ktmpc8lc6qqGLWul3AgHb0vA2NuE5v0l6GLSzQ0H8WdUoHaLyEgoImpOffkJyxJP8awNRUxMkyy9zkmlTKbSkPEVGEESYE+bqBemIuyI8Tla/cxlJA57otSMXQxKGBYeZzBtbezPyYhK9QohAQ1nCFPFwL+0xC8vylfZCXg5Of+TgBvyLJ86G80nvOc5zz/y0SmJunb/TJ2960ED9SQHDYSTepjvMZIvXEe+/btw+FwUFeXhCQHSST87PHr2C0s4Vt5acy1mnh65ixWHf6EHzhSmZUdoNhoYnxsDOHDB4AUHsr5J77tfIYf77+dsvpv0pDoQ9y2FVGQaZppxqt4h1y3ngLzN1GrLbx+rI/vzf0TIFNS/CPy8+9Ar8+hte17VJT/ErO5isbTG0BuIB7XUVtbiyAIFGTnY0uWCbQXIWz0sFBvA2wk9o0Sl6dIiTyF+XEQJJFw7a285okwaJIoK7WT0h1gqUXijO3Y9I0RBPL8Z0jLLkYcVHA48xJuHIghyvBiyW85pZhkfd2P+O1bbrKZJFtw0mMPMA84fvZSehNxrrT1stLg5t6xagadVWzqXseymXPY6r2D68qvIx8jiqEgy2oyqDJZ+XmFlcNvNeI67WTZzFweaupEmaqjwW7m9qcOY9IIHPrxGtQLM/n+9rPIEuxOHsb8yo3Eogm+lvgBL9dNp3Hu+vNTDDSd4a47VmBteZ8yRT+94QJMhnMkRUzo9DFWlO4nNqCgzZnND23NlKqHGI0paI6ns8bQzcW+KSYFCZUcZxN1HAUMRNGnPMdbFh1z3RLDZpE/2Sy8bU7nNutCtkZ66Ygf4yvhK/nqWBSBFThNXwV/jAcev4/HLp9gMJHGcDTC16aCLPXrMYoym6Lz8KZeQoHvQ/bYXuKI6yZ+6MjAqbazJ+csi4JhaiODdDjPImZkczKaz2XOStYnPYOy18dunUSt8rcIspNUhZPBPIlRXz59o1dQsfAF0AcoPx1iS2c1y7L6iKjm4RXz0PjcXKB6EZ06xMHJanqK8pESKowxA+PxHNIU2STUfkxjWWSVnsUlebjkQJC4KkJqQEtMEeJE4W6GTCfxGjwgQ5o/m6SYEUkhElVLqEQNckSNQruc7rxLGVRr0BWG6GcOYzkFGFQGmnN09KYpEdV3AGCSQOOZJGgxMT/2DgtUM/8O1uGvHyX8iSzLK4HK84qB5znP/5043m9GPjZFJrchIeHXxPAXBBgvepSs3O/y7jttFBQUoFAo6O3dTEEhfLIvRLNqFZepm6kOWtnWcYaUlBQetsb52mScm043c6k/QMbxN7hVmuBDw6MYTXo+yClnQ8shbjrxGAIQtFgYW3YNGelz0XsbGRx8npGRd7Gk3UW1YTs2rRurdS463SXs37+fRYsuZWj4Jfr6niJVWo8ohujryGNOpoD11TUEiu/HfdyKIiIyFJOwqY/SGZqLPUdDeomd+NlWRj/WI4RHGJ/7zwwm59IfDQGwLvcTVK5eJNe1pM06AgkZUSVwaqaFs9FLmTcCG3ucVNvMbK0aZNzvQYzJ/Kq/hVZpAY8WH0QZDHPUHGA0lM6euI67BC83uuvZPRXHKYdZEbsCQ4mWVw470OcUc235tTy0eQgUAkV1aVhm5CAIAvMX5rB9Zy9btnUTCSeonpvByZ4JJAR8MXhiayNlBVlIQI3QQ8o7dxE3mrgu9iOyy2uxm7T43U7aD+9HEkW6/FbKgeXa/SRJlxByTwdjVhaoUA1t5ojGSERUU+eKscjeyLPhOeh008qCP3O6UQBPW5M4rOlBNZggybaHvRYRhSjQJ+hwKeNc0VVBc6aP3wR2oxd1fNd3GyvHGthEjGJBSfaHPXT87g98MGeciEbg/r+48Sf0ZK31U5cYY688l5cX/ZwbBz/kG4MdfCU1iRz9IMOa6fTLBscGVpv/TLqui/H0DRxZUoD1oJcO0xDLHD8BrZ+rNSJHrTbkwVIyh/2MljlJzAqSWrURj0ZDZbuf093VVPb4aE+7jaHwQgq0J6jseYmC+hEGA3XsmF/OwfLZJFQqtPEYOt8UqvATKKQQJstF/EJo5Mr+Fwhrr0YfXUB/ipttFX9BIfaSUOcgiAkE9Izlb0DrD1PhCeA2ZpOQpujNnUNCqQRBwB4UMYVU9GsaCGkVDGcJmMIykgJyEgKzFWpabQJ9YQXzj73NxqwR6qq+9eUbCP76SkCmIAgLgUsFQXiTaZGgz5Bl+fyWwHnO8w9M8MQY8rEpfBlHCBRC2aI7ybPbkGUJ54F7aWnZiNm8kmuvvRaDwcCRo+/j8RgYCxSSKTpJVilpd44giiLRaBSADYKMV2MgGgkxV32Gifh3qJsqp84P5tt+hXaRHnn3o6AyYFzzC4rV02lP2VnXkZtzK2daH+Roy7sE4+kgqCgv+y3P/Ol1/AEvvadc5CRfj5B7L8Pyc+g9pawZWItKOcykdBsxh5mE7KQrKZ2a9SnE3t6JIz6HyrxklMeGEY9sR/IOkr4yg4rHv4rfG+WVh/aRoQTr4Qfp1F9Bp74dvWGKDOe1jNnfQeO8nB92J9Ou8fF1QeJ3+gEm9PmYXdNxCh/0j1Oa4ueq2x8iHE/g3raGjd2X8m31Ru5Wvo9ccxP7XddQNeRl8NwrrE67iE1akfj4BtoG9OxqHccyw8YZn4en7/wBq+/6J3otKZizjZzscyNrFayrzGDfwU4EWSIvMszLJxPUjgVZrTjJ79RPMyWbuClyLz2ynafXVwJw9uPtSJKEzmjiV4eP8GMpm8ukYZJGs5FV9YQVAzTwAUgyj9mNzDIl6GY2pYtuw9e2m4AJthkquDjUTpdazQe2KibECbSlDxMSwsxy1eBQdDJhi1A4YmAEF5XNOtLLakkWU1jiqmUXcU6GA0wllERGX+TxZZ2MJCtY0l/IkC2I2eWlMWQn0zDJ92Z/H3VC4paedyhQj/L1oSuZ8qyiN7mZ7jQfa9oXMpR0C0vVP0ael84fMxXclawgQ3odUQjS6C0kUu1FkiV6mu6kPWQmZfAVSqqGCeQ7yHMEyZyI0q1N5mzdnRBPJU99lHn6p0mp99FBNnfM+hbd2cXYp05Q0nUSd85qnIrXEaQocU0hAe823vUWUDl+I+q4ng9rOuhPehtlwkOtup7RcBoTqu2403+IqM0HM4xkTu+UCzLICgFjJMHycxGWxzSorY0EYw52Di2kJNCHyzZM5IavsNsfZYsUIymh4PXaIo7+pYPOLJiUh/8OVuKvOwE/A+4FcoDf/Yc6mfMpguc5zz8ska4ppt7vwm9rZahiO6vX7PxM7hcEQsE8jMYerrzySgwGA9HoJKFQE15tFi/NXcfPirP4Zl4aMH0ssM/nw+Fw0Nm2n+5N27HkxcmMX0pIWoppaQ6hxnHC74cw31OO4rI/fjYOKSbifquDyKCPNp3AHydv5pwQR5SVLK2o543n9uIPeFGLJhxTrcyZWIxfM5tgeiOOwVo0iuPky1r8YhlK7R4KFY9ROOMaBGcuzfGZzEtSojszycCpF0mZ7MC+qgpb2h6E6BTm5GTGdRL5YQWe7Is45lqAqWAvRvSYz65ifOlWEjo/A5WvM5I6wsr+YnYMrETMGkZGRkAgrhnhvosXoVAIHPI4SdL6CE0k8TXtVkgph3Ov8RNpJ0fU6xkNh2jc8i5XGST2pVzF3a83kmrWUl+ZzA7XFPP8Pk6cbuRs2WLuWVHMGxvbmMrWsyjZzI/6XCxMNHNf3QSjva8xx9mBXhNjLJbEz4w/5pzfxgWlNnKTDURDIU5/tAWTLRmN3kBjQs9BqZqblbtp1g8xEbqSRTk/wIzMzvFS+rPjzJBlnJNu/uXge9Rj5f0qNypDmExRy6vqeczpr6duSR3vj7+PacBEusfIzD4PXVVJJI8F6ZgX51SpgwSDAOwxHyTNtYixokbOIPD6bC9qSUepdynFbe3oUwWipT/lY+NpdpTXM2RJZeHZ41SYA7RMLWPKuwqb7hwbF1iIGJdQ4PNQPFJBS8Ys9upPkx6ZzWRWK/EBC8+6XmQgL8Tqgh8R6ZuFJiYTUwRxcgu2rmdY6z1DJKGlNdJAj7QOn0Fmse1+Ot0RnnRXEq3I5O3ym0kooajvIfzKNnoyQB9uRKmO4Ev5OoJqNkV9f+KgoZHJktcY0YfwawbRRZRcNFrDjOI0/igcQKtdiqjNR+f/mLtLF3G2yUG3wkpUm0JFb4Q5XSHqF9tJXlxIZ9M3Gffkk9USwBLswi6tY741xDdytDzRcQB9YoR9nSqmCm1cPbGSqYkumPNlW4q/4gTIsvwu8K4gCPfKsvzglzim85znPP8/iI8Fcb3aRtzsYbTu96Sm/vLf9P5jIs07TjLgMFBaFiI1VUKS4pw5ezsgs0d9I/lKDXfmpH7WnyAIWCwWLBYLvvYmemIi8QE9gexlWJenknRhIbpSK87nm/Fs7iHp8mIigThSJEHw3S4SjgAnBRGdX6YLiRSNH1fMzF82F1GgOkOevZzLr1tLz5OHMMsCmZX34TLs5PShcS7VP4aQWoVn/n0UVP8I9huI7tlCT6Iaq2IZo0i85RtgneMUb5Wt5J5v34bwyk5o28Jg/tX4RZkcET6eugn/mIKsBedIz1yP/fpaRt3FjOYPY4z3oGpJYV7UxQEWE3O0gxVEbw3KpCbqCpKRZZm3e/ei6r+AB1UvEVfo2ThYS7j8NlYPPsL1iRdor6jncKqK9GY/MyZf4axhBtWrvsHRwx8TrrkA1cx69vqnT+xbn6JFnfiYaAgqd73BC/EPSTd7YAC0yizeTCyjNZJNmqOP49kmtEKE/Z2TPPSLxzF1HSIeCSMmRHxuNxH1GnpkHSrDDtbfnMzRl7ew0NjD7mgG56YyyHROUpJRwWRPDzN7khAFme/WfYfNB/t5b2oYjTaTZlMV6f1+5vfNImCKEY05kNUaJq0Rjub1oxAULOyzc9UOBz2ZKWxZaKEne8/0dFAAfczM1Y1XMmQKMFVax7XxmTQKfgLU0NBt5YJ2F3M9Hm7On0VP8SR3tx8hK3MfEdMjzBS78JRMEXGV8kbkfjYb4gSUemoHtBzy305E6WZuymYQVTiab6Anw0h7bpQFZ6A5cTsP5eoJCkMg+4mqpuerrwMUAYwAI5icZxAkCb9CRqm4AEWsg7B6HKWoIjVoxxIGlfA1LLxGh2VaB08hKUgoJVwaAztHx/GmKfEn30g+Cf45T2aVXc1LvadZNjKXaEyFrPHjtLTy4+YUoh2t/HrJFMoxI2nhGOkzrqEp4ucnh37MmOTgdreAWm1la5KSkRw3r3X/kjZt95dkIf49X0Qn4EFBELKB/M+3P68YeJ7z/OMRnwzhfKkFVCKDNQ8wNF7I/CXT+u4+n4/xF8+RPCpTkbMCkWO4XPsIBDoIBFqQETgSquLZKYgbnKgqUxDU/yZaEw2FOLnlPdRqE+F4gCnjHvIuvA8AXYkN9ZwMQsfHOHJ0jJFQggVGFUlKaIm4GZOm+IM+DaU2wHcanmTLie/QEjPxXXER6enZJN4bIjNhZa+6heJQLZrEEi4Q/w8agpxLFRAbX6Nvbz9a53xIzMOAzPtEccaiLPQeBmBPTh3pg0l8I6UEWt6jsUsEMllWnGCy1YQ57xgoImRmXIHBlkpSWxWTYx/hky3ojFGqKx9g8du72ZfhRBB1xLwN6CxnOTV+iklVNQpvMykjEnNVHTwauh4GRnhZsnEg5X6+O3E/lZaTVE4Cn6q/buAM7k82kRbMZ39xBbF5S2kZGuNy91F0T/2Jbyv6UblkEl4TJ6RqMBay/u77eHTTIFubJ0iW3BRl5RJW6rnJtZnt5iW86MvnTt0x5tvcLLj0Un76ToCooMEjGZGVGoQDj7DU2sRAdBanhnJRMEXFlJ3ilUvod3RgiKgQgLys5Qx5HuXkjIPU9FRx2j2bTJeGal82dYoEx2ODjOak0205RF4gjyUjq6g84ySab0GyVpHjO8KAfZAUrwalBBPJfhwpEvboMs5lanmzL4IhIFMAeMwiXk2UP5ftYcQ0jFIS2Fq2lbfG2rh4/AjVWz7i2rkCHyrXY5wqYnVjgoKpCRLxHAqU7zCsKcOad4RwTz2JiIUCh0CqU8OIVaAz+WXcyibyp6oxxiwYY2YMcQtqUYsoSMTUEeKKIIPWVsbNAyBAgpMIqhD5Y8m4cr5LX1oukzGRuFJEUt6JJlSHJtJMWnQlcvhpRg1jVExVICVdiqTUcqPnEdLlE5wafI/kqbuJxk1Ya97FLQdpG53HiEJDfcbHAOxLd9O/xoNJ9Txevw15ZDY28Q4e9+k/e64EWeYGQWChoZJr/7bm4T/li6QI/gq4HmgFxE+LZeC8E3Ce8/ydkSIJIm1uIj0eoj0exKkoglrB6KJnCQsiifhFtLW10dzcjLE7wfx4GQFVhKLhUnoqDHR2/RKQ0Goz6Y+ZeOyMkmy3C/dpF4JOgaEggsHaQyyYzNETXUTDQVZk3cjR8TfYOjJCqieMPB7h1I4BhlvdLDKpqNYIVFsNKMIJegsMlPRvwi+t5JeCjlKNH/3xh5kbV6Jm2sGINE4fb4tKoEpfSOdHLej1I1wQn8mw4muknMgDIGoa4axmlFcTSaSnG6hx+TBqRlGclUgoNaDP4C9HBrhr3lUoDzxKY7wEk8LOgvU6NvdM4SvbQ384hX2tH9LteZLZSRZmyT5a/XOYnX+S0oUz+YrqOQ63e0mEc7jDXs9bild4v/8Q74kWLh1I8H3l23Qoy/mjtI5/vkxP4FyMlNZ32Bar4MDi9exzf8xTFzyCPhSjbfsbpIeOsDa5nRXHr+OUZgbXKV3kD44REZRsNy4g3C+xy7iCj1XV/KVOjWRMp6/xXdAW4takMIWNq5X7+fncfhoGI/w8fBEvWa+mVv0OfTsO0Kb7JmpZxjK5i2j+TPTOUzhjBh4zlZAbn76v2f5UunQhnBlJJGsrUETCPPv8FqI5x5EUcLa4lYtb21gda2AImRGnCmtiPftzniLfn8+ikQVEVT4Gc+ciYGbU1M6Rgi1kuMws7CvmWO1K4pqt7C59m6vO5bKiKZ0Rm5LDM9XMMEdY7g3yz8lPoImP8m1HjC1SJW253byZlMZDHY/zmljCltN6ItGPUBuWUzwxA70wwUW2RxDkUcSKBpBUTLVfhDVpgjFNgJRgNmd12xiynmNh3xVUjy1mPKWXca0Dp3EAQVZhitmwxNLI8s5ktmMtcUWUlryzSDUOtHIS+yyX4ErSMrN3kHHVh6zrriPdXUBUVURTeQF7yuxoEr+kvK2Fzow4U0nFXBN6k8qkEwx0XU7w3EoEBAaKjlGb0USldQSVQcFwbwMFSg0JSUl784PoZIki5QgmIYZaEDEpOzBqQ6Tll5JwDhGYSuCUF1NtHPx7mJAvlCJ4BVAuy3L0bz2Y85znPP+eUCiEUqlEq9X+v+rkhMTks03EHQEEvQptkQXzkhwmTFvwOg/R0bSCaDTA1q1bKTblMC9RRjB9mJGqB8g7cS+msVn4s05SWflrmlu/g22snrKpBMk5W1G4zxGMLCLYvoAgM4iJEdrHj5NvVFGb9F1GlLMIDo3wrV9sY3nQhjFJw5xLCimqScH3QjNyTERbYqWgy4lSvoICRPSGUZKSdIimJFp62zmrSAejmm/pdpCYdCPpSlBEa0mNlkO0nAAiykwwzypCX2Xnt5+c5OkTHlZqvORV/ZbgB1/HZMrE7N9KNENLXUzLZm+ET3RrWSP/mkYqqM23M+p+ik1zOpgMJiAIyYH9KAQFm3391KaB36lDSJI5fuIy/tK6BHTdiMEyDgwFsc8rZUf/YfKzLmSN4zRGRZSdI0XIFiXPtImkGDWUWBT4JmWe8x6gWC7knSc34ndOAjD/yofRlqTQvekBaqMdjMfMfOguR3v1vaxdvY6h0yd5+qUTWGUPlTMv4PCZTrThKQRNHjophlmpJyOxlg9S7sDbc5ArRrfwfvZN3BO/masCGjpNUVLoJjksMTJQQpq2jS3DtZyae5pcMkEwkJjyEHgji1LFHUhCCIWsZyq5GXeSj0V9V9KccZBjZe+R01SMCSsBUcanOcKocRBrzMrB9A+xx4qISW4+nrGKAO8hyFaaa35J0ywzCkmicEQmEn+CTdXPEU75BbIcJKSbwt+xnZ26o+jCAr8Z8dLVXs5CMUZPbg6PWUdZHRig1mTkrD8LFEZ0wjHmmfdRrtuPe1LBmQoTn5i7yBhOwRTOYcJ8jCDdfJI3xXByL9q4AZdxhPerHiJmjuL0lbIgGmBCLKBbX4NYm8alp/ehTOhRh/OwhBbQ26fhWLkOnULiygMHSIv7kbyXkB43ENZ4UKUdYkPOe8wfXc3zxg18VDcTQZYpdXqZeaKK9tAiSBiQlGH6U0YocM3nfa+ZmrJjLM7fzyU6Dxm6cQKJLNbJTqzaEQSFgFKZBAGBXE0bU4o0pEiIuoLrUYx3kqfRkF3u/rLNC/DFnIBeQA2cdwLOc54vEZfLxXPPPYcoitTX1zNv3jzMSgOyKKGy6vB+1E/cEcB0RSGWOdkICoFgsIf+448Tj9cxNZWNTidx09UbMGx1Eze4GKl8iJIZ3yd91jri74ziyzpE0N+HgEiJowJb8XEMI89Dw23o0nORrBYiU2k0Nm4jNhhntHwuT4il3H7LTbT/+KcsnGxlv20uxQ0p3LquEDkhEckyEe3xEu33Igj7uUOeRU7efn6e/AnZXUO867uKYclEas1CfnFayyXGPVRfsBJG92Ed+DUJTSZxORd52RXIi7+KPxLnmSN9PH3Cw8VKDStW7uD+/lGWWzqpmKjBHBhCQqJUimNVSPylLcHiC+6lfWcOt2fBxyOnmRQ1XGOLcfQcU60AACAASURBVOuiN8hLmc3m7s389NBPGYkLZKriRMeq2N1lY7dUjbFoF9n+HJq1IprhLDT2T5i1+zUuUR3jVNI8Yu0hKkv1tE6Eubrejr9nisGsCElegap+HUn2NPJn1mHPK6B29cWo1GpuFTOZ8fxPSPcoEBRK7l6yAo1CQeGsOYy+7aAo0IN3fIyzL/yBMd1C0qJOvhqfIKGqQhEVcOx0ICBjEoPcpenjVX0lbwgRQCAtdxTdkJG3fV4GjOUUxwykOaeDOhXaaqTIcbyG46iFLHRekYBGz7Gcd0iO2shVaUlxLWJbxmZ2lf6BS1p/gCAr2FH6EbIgE1FFiOth0HqWxjRAPIVK8rIm0cDs7qdxFW8gR2ejpXo+A1unOJb/InrXvyARQquAcQsI2EkVLkF0vIZf1IIgsOy0mX21Dn5iS+ex2AAmo8hAMJ+RgJ+kwlZ6CpUMLNHylEvNYEAJSj/6+p8RVgc/DcUHY0LFjB4DaYYUakJWXh1dSLbdw/W5lQzqdfzyiIOaXgetmQX02TMZtaSQUKpAlknxiSTibeQNHEVnvBZlQovL3EfUOIQ6GKXtzQKEVS7u132dTRPfpEkzg6vaOolIWiIaH2idTOonOCNm8z5RNGI+sR47c0M5zCnbCMDEeDU27TBFuWVcfs16JroiHHlhFzdr7+NQ6Q/Z2TXBkH+UGr0VdZoeYeX3/mtj8DfkizgBIeCMIAif8DlHQJbl/zapURCEC4EnACXwnCzLv/oP9d8G7mBahGgSuE2W5YFP60Sg6dOmg7IsX/ppeSHwJpDC9EFGN8uy/PfRWzzPef5GhEIhXnvtNQBKS0s5evQoJ44c53ppMdqYkoA+jjmsoUUxxJHtn5B83I42KYO05FcxaVVMHJtHGmo23HoLse2DRH0Rhuc9QUXNA2RmXgFA9orLGBn5I91NL6A0KQkUlmJqvhrmfxMufAiYlghVBAKcfmoPxXPmc69/DpfUZSEailBpi5hkiGO62Rw/NczXlhVj3uMg2uMlaW0+/QNP0zzSRLuvnrtmZpBbv4vJpy5m4kwfsqjiUuVb/Eb4PS9Zf8HPDTNQNWjhggC/3fYLNo5fiHeXHmnnjs/uyTrUPHJ9He8px6B/Dy6DA1MgDYUkodGlYdG3UxsrZF+Xk/err0GUm0lT7+UVp5pchUx9TI9FzAJgYdb0QS1nI0ZWp4m0vKokSfIw/8IpmoBaRTFlaiOiL4/1OLlM9SwOnYXDZ6Fkznys87N5cGsXh3t/ysVhFdkKE/lH9UAUx1gLjvYWADqOHGD9t75PuH836R4FAxlx8sZk3nnwJ1SXZRC3ZxARUikQx9j06P0kJAXjBelU+ZoYV+nQSF4MkS7EWAuyNAGAS3cCS3Ejo60rQNTzoGM5e4p28lbhThIqGYVCT4HXQEIRoezqFfS+epyEPIBem4NW18d+azN+Q5DLe/S8VfgGVVOVLByqYH9hK7tLniaoEXElhbBELVwwdgFJwRgLNBt5KnU+I/pxLjPX8P3296B8Hb5Z81BpNBw9MYaon0fAGqauawtKdTm17W5aC9ZwesZKVrW/xTlPJt6cNHROHzljIWbbUzic6+RifQb3eJysUjkYzNLTk6ImIep4ckLLsKigLJJFUf9aWjMOMGTpQQb0Yh5fsRgYzVagcOqQEKhRjtBveItj3WsYTE4nUVVJkz2FsE6HNeSjYnQApecM3RVL8ehC6Ds7CVCDOZ6Ez9LOiCZIuixjHOqlt6SG1EEdO7ttrE79M+tzgoyOZBEwVbHXMAulLFKtjLNU6KZBqUGnjFOYls2YI4+wuJzC4sP4XEUke2dxw4/Xo9YoURZrKdZNx6/4StKha5ARVz8L1UVocsx/Y4vyX/NFnIAtn/78jxAEQQn8AVjN9HkDJwRB2CLL8ueP5DoNNMiyHBIE4RvAI8B1n9aFZVmu+0+6/jXwmCzLbwqC8CfgduDp/+n4znOef1QSiQRvvvkmXq+XW265hby8PLxeL71vNqLrU9GlGKUknAFAsTYHrT6d1DEBTWCAwdwm7F1XMyO0AIDA49NfRpMV71C66Dukpa797DpJFSV4d5XSd0CFQgultt/RrCsmb+YdGGIxlCoVgkLBqW2biIVDJC++hOCmYa50Spx64jRaUx1HBR8wHSS067kzrPXKJK3KI6leTcn+5/mZ/jvYdD7Wz/sacTS81lGEJHqREXD4V7JKr+cDR5Q7HD2ogEeJsIMrmKUJMVOhxYyAXpIRo3D17DSMM1M5vWsfAG7DKAWGbABMa1aT1tZFVVIth2xhfrW9HYCB4NtMiQLX2CO4T2fwxs7vceWP7ietoAiNkE5L0MOiWAcJKR+1LGIMnkGlV5O1tA5/236+O/wHjIEg21JNJEyZxE5r6D5xhECok7zUIdZ2WIEoOUYdyy4sR5ixDkFnRRAEnMOD7HnpGV7+/j1kZU2HU50rnqAYDRO9sHfQR689B/Rwl3UHez3ZDGYYUaTtZKTgOL2GMMiQ6zRxY+AqDlnCZDVO4fAMEQoqaEg+zPXu5Wy07uB9+y7sUxokBRwvG+Hy/VkoJSXn9m3EoFQRi4+jj/TiCnQyUNtNzqSSj3KcqGVoTmmlQWpghiOLtuxuFNK0JMzikXlo0BDVqZmVnEckZT2ru7qoT53+n/cM+9n0T7eh0euJV91Dc76OysF0rmgqpDe/FOvkaR746jL2vekmOt6BURfGEVdjjUxnSOT0qDmVAx61wCcFZhQWHSYRDH0i31ZZCQki8306SgavxuQvRidYkfTZtGW24dTX84DSjNkYJDcpghCJo1e5MSlv4Hi2jfaMPBI6I8k+N/XNJ6kaa0Mwp9JkOEZh/z5GvPOJu5aSrteQkNzETS7SE3E0XhdtKTPJUcBETENRTx9x22oURRsYOv4eqYPHyTKpGUyvQmfMJT/mZyDhBBkGx4dRyRJCpwb/qVpUEQe5VaDWTAszGa1ayo1HGJBy2dN5hExTBeHYBEqxkHCahGuqmxJbyd/CpPxVvkh2wMuCIOiBPFmWO/4Hfc8FumVZ7gX4VHDoMqYDDP+17z2fa38UuOmvdSgIgsC0PsGGT4teBu7jS3QCHv7RDagEAbuoxmLJpKRmGXmzZmHJSmN6eOc5z/93JEli8+bNDA4OctVVV5GXNx0UZ0xoSB1So622URlKIjEUQLs8h/YTI1hDChy5enSl21EKFtwlFex3HKM7ZyYmtYZa9VFmr76etNQlMHQC9j7M1AU/5OVhSBxSY8oMoE9KZrjbT4eYCd/+t0U+QaFElkQ0hnLOveflkZiBjB4fGUBhXiVbpqZYrHFgjeey1ivjK0lCyDMz+eajBDONNPeXc3WdDmkwwaanfo0Y8FGYtwjHWCOj2VXctqaGD95s5L0FKRzsdtI2GeOarBOsqXqNgti3SBXX88mBXsZCCjYfnqBG205T9Aww7QRkxnpJAIb6BvK7R+iWBWr145wKZpCinORAWCRXo2a2LZvyW55l48P389Z9P0S59nYC7jIS1gNoksNUX3kjgZZGPortIU+bxXfDL8PoH/DK6fwwPY9zSRLr91qYf9UNjLmG6N17gEvRoVGGMRtlNtg/Rmj9CLnvFYSlP2S8ch1Pn94G68yk7wtR3xMkISh40zVBujXAa6FvMO5rpUOOYJJgr+9utix+mUmzA43cjdVtwTKhIrm0kLNpA/wq9WWQoXRGEhafkoY2ExeY63gj8w1ajD2UDNuY252BK03HxzPOcKzSQ91AJgqTBQQBmzNGRDpOd7GbiFYirlOASsnykVV0Jjdxyn6KhWMLqe8SacqfICWWSY4UxakwIwsCD3iWc6KmiobmOMeGvfSrr6HE1YmgTCEeDpMyNIYyDZYf2sykLGPqOkdqVSXZFTNAfJiYKLG6PICrxcHu+Rey/MxH2Otd/EtahA98ag4E1RwMqgEZQSEgCSJ5vnyynA3oQhnEND52zMpk0J7O/I4kLhk6yhulHiLaC+hNsxHRKoCMzz63aa5xlh3bSTZgGOxEGQoQKEtmtqMU3akB/MpBEhlOFGIuW3QyPYE6UhUBSixuinHiF9Xk9p9iUm/iVf8iPO8MkG5dwA12K5WNH1PKGHpvPrp4nGxthJBBSXTMgTYuUp4/j7yrb+WjPz7JcPMLNO81Ur1sFbh6iEXH2TE6j/SOUcJ2iNmz+LD/Jbo2jiK1pvC7u/7ypdmaf+WLZAdcAvwG0ACFgiDUAQ/86/L8XyEbGPrc62Fg3l9pfzuw/XOvdYIgnGR6q+BXsixvYnoLwCPLcuJzfWb/F+O+C7gL+MyQ/m9Q1NZCTXscvx6cNoGWxo84vjUVTUYOGdEBLGfCRAM2DEsXMvPrt6DNzf1fu/Z5/u9C9EXx73egn2lHm5/037aP9HkYffkctliCFWtWMHPmv2mJe7b2IigUaFIN+PcMY72yhPuSErw2V887M9Mp8r7KwMApBJT09n2IW1nJgrqj/D5+Ec/HLoJWKOxs5P2jXyUjOIS66yCxocWg01GwuoOG7iF0JjtTMQPOiREmVTPp9M0mEY+DLCOoa7EEEsw1qxiXZMyzUhFbXPwZI/0egVyDnhMkeGHcxfrfu7Ap8uhsmEtCUrMklMmhx97D4TwN9iwue/gHbHvyEYa6mrmoNoPagxb+fKQfs07Ft+e+TW1qO/G4jMPwLElFFzP2wbRzLYkCJ/f24m6Icr03xhGTC7F3ek7R0tVCxNmLIWOYuqjMKSAtez/DooLLbSEKC36KPauQDQ/+hpce+iXjTR9wg6mPjTbolwRuXzeHXaMCear3eHhimK7xo5zJnou3aQ6K+o2M+NSoCyuYd/k13Ljrm8iLhimWEliP5zHL5CSe/1W8nYUkqd+Dbfdz9B0PlcH16OxHqc95nu5QBuGEGiEq82LgGsLKNdj0ChwaM1nRCfaVHGbSFMQ0vJ6Qp5iLx3fw1qIuXNIIcwevZpftE0y6MXozA4jZEjDFx/wBQRaY05ZBhSOFUEk5Jlmg3BOmPbudTGyYJD8T2SJFAwomLRFOl4Ywh9SMm+MsGV1AeiwZ7UQN7vQYx9KPUWQsIKYZp9RVilNI+ezzN56eR7Ivjn0qDxmRsZQIQ7oc3BUTGF0enMY2Lv+oEbVWgd9egGlqAkd7K898/RYkMcEFaX2MT6qI5WspqumhurIDtVrCOabnsUW/ZdtbUY4Yd3DadBBZKZHtzqbeO4eQMoM00chA2iDDyTVku0ZYek7N3vwm6sZTyBtI4BNGEExjJHnykYQY0fA+Yok+grnFyDoNpzJnUKmM48SMxarkuJzMTJ+TjGAmoUQnVo2PcqUNqyJIqeBhMq7DNtRKQlawLWM5iyvMXFZTysoZ6aiVq3nx+wlcA7tJBDw4FTrUooE0azrl199M1mQu8kiM8WgGGvMGUjIOsOPpx5no7yHUfYyO/joEQeBUeZiciA2DIJAwW8l0ucjzf/mrAPDFtgPuY3pWvxdAluUzgiAU/W8OQhCEm4AGYOnnivNlWXZ8eq3dgiA0Ad4v2qcsy38G/gzQ0NAg/zfNvzCjZaWEkx1YPH6MXpHinijm5mHcNgdNM+czMTeLHOUo1Yfep3fja0ST00i/bB1p3/wGSvPfb9/nPF8uoj/G5LNNJCbDBA460JZaSVqV/++cAUmWeax/nCvSrBgPDxH9ZJQ4McrIQtNpQZqXQKFXEW51EWl3Y5iTjn/PIHrbAIfzK3m1dZybxTMMvfo03R4VUW8eiYCVSFQmNSfMxYXf48oUO0c9QVoCYUoOPURGcIh/qX6Qufs+RhWKUmnPZPDD3zLH9iP8skiOuhGNqZga9W4Mld/EHbIx2uPhugfm0frQcWIK6PBP0n/Ew6sGJY9npVDhKCagjvGTeIQ5kxKJuBGXMo8T47NJN6txnxxgwrUNUatn+VduR6lSUlBXT+exQ7iGB/nu2nKeO9DH91ZqGe85RCKhIi31IpyuA+x44QiynIXOMEU0JBGw9PHU+AQLIhEkDwTLp3AJJrYf/ITKrAzswy0E1Su5YtZWTulPkaNW0WBNJiNj+uRDc4qdQP2F/Lj9Brb0lbEpE9ojSibfvZPMURPP6sboE7TcmZuFWznKhvqdFKunnZBnMg8gtbyAZ+QQ40lK2gQFM8q95ITmkdyzkuOWVko836bLqyIsqcjVnGbIOZ+huJOBWCs5pSXck5/K4uNXYVeCMb2KgGDCaPiY7tTTpI6uZsw7n4JQF7F4kKBWJCg6SUnxc5GrjKREPTIyeEc4I5kpiZ/FEFWTFEkiWjqTGAGsI73MHoCRuXpOpzexangVGlMVBxa10Jc0hkpS4jfEqXEXszhWxbtpe6hx1rG2bwM7Kl+hM6kba8SCPWJHp9RC0EtEryekNTKrNQyyhEIZx+Sp5mzuG5zIPEu23siKUwH8Zitxs46EyYL9ulk4pxyMHjiBHPcyXBFAaTAyx34GOENHQI2wO4+gz8rg8Dn0fXVYc1bgLdmAxCSu7FwSo/2U9yeDWcnW+mLUYgJrfID3a1/GGEqjsGclClGJnHIWOeJgMNqOTXcBFv2FCIKM0R8hHhQpR4FPFUWZo0PtO4HbVE5AWoKYEEjEjzFvwklEWUDCkoLaM0nh6CCSICCXXodc/Csumf9rLizK/Oy51RoXkV05l8hYlNUWDbZryjDWT4tD+PcN423tY/ick+TsFK79yYPseflZTm/fikohMycvwTnfP1FQdAZrRxGC3Is2w0bDzZ2ohH882eB/JS7Lsvc/LHVLX+B9DuDz0+CcT8v+HYIgrAJ+Aiz9fBqiLMuOT3/3CoKwF5gFbASsgiCoPl0N+E/7/Fsyb8GvOb2rlz3zBujQ28gOjbO041mqjkVZuv8I/iw7J2pmsXPhWsrsw2T2+lC/+DJTm7dS8MTvMMz5O+hCnudLRQzGcT7fhOiJYv9qFfGxEP79Q0w+fRZtiRXdjGQ02SZ2qRL8vttB9bstVLk0OFRu9s9PYlVSLukfDTPxp7Ok3FyJ54NelCk6wmdHUQmD2ELfo2/7SaoyLybnrTcYCaai1CawZKSRUVlJe9M5wj1tPHvP7RTWzmbGBSu4RhfG2v4K0qyvsHIgmc4JyDRnMShdTlzW0y5fxiLNU4SX/wZNxhIUby1iUeY2XjxwGa2pKg5ubKdOUKDI+ZgLx7ZwXeghJFlkbsGHHE/YaD91GGP+BvqVelbre5gIF9HiruL6SjvO1mdAFlGXLGB2QwMDg8/iFT4CoP/MKWp1Zn6+6SkSXXpUFZDITZCVdQ3+gQvxjxoQBCibm04k8SQlPWfJj0TYKVyHX97GpakBCnIi3KLUYrr6p5y69WH68lfRqD3ElCSxQh+msPCHvNbVgyE4zByjjZK2PzAYsiAlVPzIk6BiwkVOeJx8ncTrZhMvCRn4hSiZosh2TZA7HItQq0+zOFDHO41/xKlWsSwg4valc67AyZI+I5tM+3gjdTvKVDUznA3c7FlGvaQDwgx616NUmMizWVjXvZ6gpCYt2cUD+gMoErPpzT9BpTeXpb6LeUQRJSfmRC5NB2F6IbUv2I0dO2dTJ7nW2EBHv0B5UEV1J3gMAuHCMuLE0Y50YdUmEYkHWXzWwrb5Y7xf2o4pMURUipDvyWLQMka6P4m1A3mkX5HM9++fZP9SFTG1l3sTq/i18CbZU1nEhQQROYhBjCGLClLGD1HmWINb08+5vAMs7bmTytFLcJfVETAn0+RvQlAnKPFrGDQPsbF9G1HDfNRLb0an1FDHwxCf4LBHz7EwaL05rPTokXU6NCodJ0pj7KwtRB2JMqdliqkcaM4uos8uc06UmDIoWXfuEL0KM6re66j2jJKmTSdCN6ImBBobtop8/I5GfFI61kASCllFXDSgEnUUxvUougTiygYuVgdISqgQqic5LDmZ46tDSigxmeIkeSrYP9tLh13Dmgk3SoWCXm/vZ8+2LMv4nWHsDSpCvikgHVXK9PkYkhSDtOlFatHZQX79LJQqFatu/wal5Xkkb78V47r7aX9bYFWKi+i8LQRPfZXWxDC53i4sFpG/B1/ECWgRBGEDoBQEoRT4FnD4C7zvBFD6aTS/g2nBoQ2fbyAIwizgGeBCWZYnPlduA0KyLEcFQbADi4BHZFmWBUHYA1zNdIbALcDmLzCW/zUWXFFCeqEFzV90LExINFdN8OiMx1ljf4r0kVauOjjJ8l27aLxoPi1lRbhtwxgnFjCjaysDX7mFlDtuJ/WeexA0mi9z2Of5kpDCCZwvNBN3hrHfWoWuxIauPBnjgkyCR0fx7hsk2u0BoAaZnYKITlbTlebhzJpqHpsM8CfZy9brSrC918v4Y6dAlFHaNBAPk5L1LgfMF3J77yvIx9uIxHTM/ooWlWWEvNynOHu2lbA3wi03XMfI2Uaa93xM35OPAiCwAE3vBPHYG6SZtSSSLkMlqkhW9NPjmcnCG+5Hv+RO9AC1N+A6tpuw5yLI0lHTGeDQ/8Pee8bXcZYJ+9fM6b3pSDrqVi+2JPca24kd23FCOqSShGxCEpaXzmZZlhZCWchCCBASEhJIIaSaNNtxdyJ3y5Isq/cunaPTe5v5fxDLCyzs8uGFLPvn+nTOzDO/ee45M/e557mb4OYGzyN0Lv0iA6dhfVxDz1EvTfrn6JNqKfePctpSTbp+P0Nn7iIjCeQNtJPKTKHUb6e6cgWQYnT0MTJyAFPeCkbaWzGfbENyzyONRNAIIhmXhO/7R7gQ3oxK7yUdM5NX/i4F7x5Ai8QX7EWUdN+ATzpN/TED8WUGqsqnCO37FxxagUlrBz4WGgC9HtCgPNfGx87+E3YWrnuJAjBBlcmHHBToUSvpMRexP7OYpx0XkIUU24ZqWVY3zr+lYpyND5OfKOew9TSCLHOXP43xbDVRg5ExW5TXik4SUIQo9S1Gp9HS4zzN/XknWBlp4J7pfAYjbjRsZvTdM0Ry1FSps7wtPcuMuh5d/nNo0iLLWtWk81IgQm50Ak9yYdFTlEQmtb205cTRDl3HqXA/eUk35BUzX9NIVlQTNyjIH+wllk5grF5EIBDCIdkw6KuIxt/Drq1m85s+2uvn0VgkPi3cRO/MXhq+MYt+2kfeYIiRigy/jL2Hx6xkVaqcsOjDkXJANoKYVFKcNqPL6Dla9R5+TT/R7EEGFi/npG0rOjnKhc3LELJhRqb6Ka6pwh9TkxW0FMnjBGULX8t+k8W9hzAV9FCX7+RDy67l9KnHIRpir91Je2kheb55Np2docpfwsRUBOeiKMOFGgZyVKxtPUz9mYPU/+Y5U5o+iCRkGKnSYo0qEBQKpJkJpnIL2Ve/kjV979I860OpyFLXcBCtIkt8cgvTA0sxJZyYcjSs3rqU2VcukJYkAkUnuGr7g7z4aCsd+R1o0bE/pxeXvuC3RoAkpZmZPIZz6U8x5J2noG4TDN7Imf5ryIzNk81GEdN6qniUkorjBB0PMTxyB678qynJdIEqhbcol+otX8DlnyUqliBl8rmgmMJs/XfWrLr8r6Slfp8/xwj4Pyy8qSdZKMn8DvDf9hKQZTkjCMLHfzNeATwly3KXIAgPAGdlWX4D+C5gBF7+zUrDf6QC1gGPC4IgsZCl9O3fySq4H/iVIAgPspBd8LM/W9r/R5Q3O8ktNbHvZ13UnqvGsTXOQc9dlOe00HPHa3ztSZmanimKVo5zNGcder2HmP52Fo0dhSeeJHLsGCVPPIHS4fjvT/Z3/scjyzJSNE16LkbonVHSs1EcH65HW2n77RhRraCNYQ5lDqHXqHFIJkyCnSqc/NyVYnp9A+94QuzIMdMVSXBTZJ63P1KH8Ms+UjKo/Umcqm/z3LJb2Bf3M3N+kKhXQ+VmG5LuGD3dqzl44DkUZClyFlNQXMmimjrWXncjnl0P4Dv2PO3xi8jqBklqBJRchDaqZaVhGFmuQVYLTO0vRtFyCkGtAPkW4sltXGxSsmUuy6ReYLHp2wy48vjymA6DKskVBX7OdV8P5hk09gpqAmc4ZanhXHoLfeosFiWkel9HVFWgMpTSM9ZJ15FvslQIMC8ZUOeNM9YZoXZklGd2iuy4JIlCNKDz62ntsyM508hZiRLbEYoP/xhNGu7PL+NcxkVRapCKOQm3QeTUoutYKnwHo78NYflGenIPALDTnMIXreCl+bfZV2KgObIEXdJLkT+KMSky5tRg9t7G04se44MaFd3hBDJQ6rNSGfWSn+elYcrMYZuH5qnFBIxDfMrvI9u7hQlnFMV0mM3py3ld9wqCJHKt7sPsk5/gucFv8HLuPn5tOcxLOXu5dL6K/oyML2clZhHCcy+xpLSIdwx9CKoA2rASZSLD26l+dKoi9IV59BYkESSBcreOEWcUTVLk0uF+7KkACAKiqCLkXAiE08aSrOnsZTLXSu/IEKKURV9cxWjOzSjSl+GYS2BM/oDughTX+6upna6mn30MZ2dovOlmDmsGyU+5sESquHEuj7RKi3XaTaJAybgrQdK4lMrZOaRskE2no0ABs/le9lSU0Zw+z83RXzJrNvNscgsDRUsZjAlY4mf4mHoPJdFZavsS3NT8A07XX81nQlfw6a2rONfewZG6jQzX1ROwOFCMRVB3pSgPFxAUZYqSRkp6k6zrnmFWeYB0SuSkdSVKlUCp3k5xqJhWUwh91sec2Y5ktlAyPkhlfi6XVxdy5Fw/Mg60Oh92U5iZiQasJXsJzYuQ1SLkJHnhVyJGfZi6+qPo9SF8A7ew8RKBhqwKp7KO1uhJjMoY2uQcZ85cQzjSjSxnsJQtPNOGtBVJTJJUjCFIKgAkVYyUzo0mWEVW2s3IyMOMjDyMIiNjarRQ+OZ9bJxPIcqQZZB5JjDo9Ow6dZS3Usf5xoZv/BU11wJ/jhFwuSzLX2TBEABAEIQPAi//dwfKsrwb2P0H2778O5+3/onjjgNL/sS+YRZiFN5XjDYtV396KafeGOHq/ud4vHEnI8dWU+uOc7BpD9vax5laVc/t4ks8r7+WuKOLXs2teG3lkMm+ZwAAIABJREFUNA38mtmvfpXCRx75e0bB/2AiJ2dIjYewbC9DYfn9in2yLBNv9xA5PUNmLoYU+02sqijguLkWXa3998YfPXqUw4cPs6RxCZs3b+b2YTc728KsG05yg0/Jh2YCFJq1/LCulOlkmg+c6+eGmWnujfWyJVNBOvsibzZoKIz8kGv7DIxPOchbOo+xpodM2ky9vIhLxDMUZdoQ5mSO/KsHuXwLS4p6cHX9GL+jgZKm90ipNJjbvoTFX4DWIJDVldKTE0YzaCIvT0t+sQk5lQVJZs4TRpYjZJ0BEiVPE7f6ODfXTNtcObcuaSPH+SrRqU/R5r4HKaPCrnmcktQMB8ZzSCmz1Ad6QVRhLKhGZepH4SkhVx7AIxs4JjWzqbgT73kBt9NKwwfqIXuYLFHORrajcDTQNPcMRVXjlGlaSUoKzm/5P7wz8Bpl0wHSkTeonM5wvkxAJ/cR1CvQJyWSOacYsy34Z5cISjZ0bidqeZD7XdUcNc8iCUnIBciiymQpUZ5AIwl0C3G6lYOIEqzpEyi7bJpIXIE/oAFThkHnGW5s/xxGSxSVMsj5yDvkoMETHwAzyILES6ZH+GL/7WizSuwnJihakcu+nJMUR2fQpIwsyrub3PF9JKbOMbnzFhS8R970Usaj25jKaWFCU4JTEUXMqgiJcxgzRuxCHYOK06ybbmKRmCXhKCIenUdIRDBiJpXyktCq2L1zB+uPncBmKyHoHmQ2b8ETW+4Zp69wLSdXJFBlBGazGT5R/xBCvg8pI7Bk9D20+hRotNjVLnS+LOk8EDILKylGsRG3xg7iDHH6kBVKUkoVb112A3a8XH4mSHjuHhq2PcBD6j5eGLQxpQ7xxVwfZJVoLpRRm+nnKfUr/EPkZr5rNfD0rjN49ArkNReR7wlyxdELjIXtbI6rUeuVXHZPAz95sp2lYRG16CBfuoZ5jZJKZZhchYAyrCOljDK81M6m/nZyG9ZQLsqcGh8k3zvH9fl2uqMONOo40agdp/krBFO5tLYeAETUuigen4bikgQN9dNEYyEkw3Iy4VkEYYoCdQpoYY0JIAxAKHweQVCjFpdg7+4lErBjzxYQEzMkPTcyZMxne72J6XNW5sMWCjXFVG74MH39XyHdt4uqoSimWJaMUoGvdBstHavZZvo5Ts1Xacq7jycDoxSn358g8j/HCPgC//kP/49t+/8dokJkzdXlRJ/czpuSl/lKIz2DF6NdtY+tHWmKWlTM35Hmmv53eMn8AcqyR5nP3cJAwkPV/gOE9+zBvHPn+y3G3/kjZENJgm8PI6cl4l1eLDsXYViZjyAKpD0xAq8PkRwMoMzTo1ucgzJXjypPj8plQGH8fVfPfxgAjY2NXH311RwPRintDnPlcBJtcRLzlMxDbRLHPuAgGXgXp6jhsZoqun92nC2ZCsYjFzjhGUM5L1Cf90WK0lrm7Luorl1G4S+eBr+PwmU/IinrSdiaMKRH2C5+B9nzXbwzxbye/QwhrR7phJZlcg02SUHYpERae5YR4VFkAc6FHyXHk+C2Ty1DEAUS0TQtx2epc7yO3LgX+3wKTul5znsjBZkpbGO9nB69jsKKENkLRdhcSibStdRMdDGu3goC1IR6UOm3YCqYoqruRk7ucqOLm2hefDs3Lvo4Iyd+wIT0DuGGEpY7dHi9RrJ+AVePClfBp1ifN0ZSNtBZeD2+Ldfz6ZaF95BFMzrUWRlzXKa/SGS7/TRnm2w4fCnOTcjIApiQiR/PQS18F0tawZj569z8zk+RYkHGqpJo01uZtPQxYTlPUpTpSihAhBp1OSs3DiLosky+WcZlszqG8swcXjHDu6X7UQ7eRKk4i8OvZqAgQp8piTFpI6YKMZWZ4qtFj3FVVy1CxSYWpQcYF+YYyAmwelhgsUFNUmNEF4nx6+AhJIORdfFGVooj7DdfTEpWsjrchaCSCOpSpMQUF+ydIINPG2RqUROKbBZj0I2cDrM+WI87FaUn/CuyxXXs37KWaGaWYje0GPNZPRvho7/u5KN3uTifn6RpwMK8bgbSISwJNQ19dZi0N5DvPkk200ekMpdQXiFCOklbrYLaGHg0JeT5Fu5nOdPHVGMp54ouIqI28/ngCzyn2MLlggZ1y6co3fJNrsxNoFY6kLQhlnYnsWXOICHwRHs5zV4PrYvVuJ0qaqbSrO1LUOhNg5zPYkFGKYhc+/FmjAUGqtIKYtlpMolTzFovR6MBrdKPVV1EIBOhz+yhUutBAC4q03Fofxu5ublMT0/zzjvvIEgCefmDTIw3ojTW09Bso3P3ESQxw8WXX4lJNOFyBWjvuJ2s/k6iqtt4dOo+Egkl32n+NIMDLST7CjjY8DLerI/vbvo+jYWX0vrsz0m63exhG1en1Fh0cPDkxbyqTdLlyaXxbJg1i3TI80laf/YYS7PtaOdDJDVK5tdfh2PTI6RmI/R2v0599uuUa76Kc/ZxevOdGPz2P1RDfxX+pBEgCMJlwE6gUBCER35nl5mFtL2/w0Kb1U23r+TOH3yOry+/DeeYh8n0GvY3H+Oycx3sP3cHtxU8zIpQO2dtzdRHx5gtuZbCUB+zD3wd/erVf3cL/A8kdHAcWZLJuXMx4SMTBHYNEmv3oCkzE35vEkEpot6mIFC4h6rqL7BQG+v3kWWZd999l8OHD9PU1MRVV12FKGUYevst/rmnAI2iDYf7a+gV62kO3M+iV9+kc9m/I8qg6vknrg4uZijZhWPltyhL2xF712OhAFRw3bJPcXBuFnPna8jxDLmNcTTKGJrgiYWT6x0IMS+Hsx/FE65En52hVluMI63EW2qm/q7FPOOu4vv9tXxL/ixy3hEio5u58muHCBlFLjUYscmQqhjCmMiyuDvEleF/IaJQ8y+dv8JTW0fMFqMiN5+lX1tPRAjxL2/8nLI5JWopiUpKUyA7UKhqKClKUlyRz0ncxDy1jE88hcmxFd2hCI5onIwzSM6x96gIpdFHk2D8MXFZ4FCmgbG5T/Cq8RuMv3eaGq+DPoeXKtdydCE3MMKgS6CiJE15XMtHu/4FZ8G/05hIovcVsSjZSIGtnT1T1Vwz/DTqRIR8axbD3OcwaVWUDp5nxmYiWKniZM5CSFI9wyjzE+waMVLi0aLX6HBqK6kKGuh3nmXWNEhTv4lFShPB/AK8+pNs934Yk9LO66Yf41b7eLrpNJVBH7mxPKxJKx3VcaonMoxnPUSsSkKVNuYtY+jcl5Ari7yarsYr6/nHrpfJVLvw2GViythCxztFBhGRGe0UFx/zMaypwWcPUeDVcSqaAtGCRjKwXXiVj7v0zGoSNMkW+osXcf+zjyO4j2OfawUZ6saNLLWE2Bj08tpsAwGhBlG0otJvZ4Wpi3PJNH69gkw6gddZT3oiyfAiHSEpF0N6LdbiJhAdDBaauVV6iqdGNxAMwPOaJLcnC9Cc+giF654APISCV9DbcA8db+2GTBH1s04EBOqOhkmoBdKZBBFpnIq7mrnwkwvoVeUoVKDSKHjnvXGMCZlU7DhHLKX0r4BwsYOVc9Ps6vZhM6b50Bo/R2byKRBhaODzBAI7KS2NoFZbOX36NCBjUicRBYGOjrcpK8kFUUJERIyLVC91cer03ej1Ffxb60baJ84jqD7Iel2ag/vPk8noMEYcbOA+Hst8m8d6f81PirZjGP05XXIpCODHQLHQSb+4EKmwt89NRq2mIXWWSuV5Vs++ggBEs1Wc13yYouLLeHPvIdra2lDoBLTJWtqs/8xXNQ/gzGZpuKCAa/8q6u33+K9WAqaBs8CVLJTn/Q/CwKf/kpP6W0OlVnD9jlt5fmCCiSWFKDs38Ou1J9jenmF9ex/DSy1cFjrCZDCPPqPEFjGX/kU30NzxY2a//iBFD3///Rbhfz1yRiK0fwxVgRF9k/O/HJv2xIiemcWw2oW22oamykrszByB3cOkRoLoGnNQbs7SNnAz2akoNsdanDlbAMhms4yOjtLb28uFnh7ikQhSWQWr6m2Iuz9LvOM0W8NfQhQnyS6b5IOKh1kj9XPlwC4s/mvITF6POpaPybeYnsBxdMufZK5YRWt8PdcPXUZMmSFdncTSBTviL+KJZQGBs7H1BOpWYvU0YZUtlN/YSGTkHdwvOCiq2MX2RbXMt2rRNTlpvLGGmWSabw3PkI2oeTerZUvBa/SLG2lWhpnINTPbGUKnkVEWD1I0muBZ80Z6EiXkVAaI11mZH3OypOM0Oa/s4kjz68yqw9zd7aa/ein3Kl6iUuWmKK8AjfgoBe8cgz2P4DJ9Aim6k0BqiEPv3UP9QR9blmcpNEyRdgvMq/PpCG/h9ZJu9pvdqNMCmoIf4TUu/C5BOYJe1uBPGymLjZEVBMbyYERUMjxnxUeEuFrBnZ4AK9Kd5NguMJ2qpVVzE6bwIQr0KdziJ1AJSRKBV5D0cQ4vC3DFiXyETTIyAstyYpyed5D0LyFUm0cMNUImzfLhfKwuI332Yd5rnKC9ykJSNUJFqAp3+TxHUxluGt3JMUs3YTlEr7WXXlsv1fPF9OcEGC2QSE09hSzBa9ssSJksy+YKGZTKGVGruLvnbRKNRYR0GU7mHwMBNsxfSkvOfpSCAp8xydDmFVil6ynoacPLUU6UvMZQ3gBXjNTzYFEWjzpFVcxJR5UHY+BJZhf18cQlSiCBUrOYSsUEnrCDV4a1eI068hwuBGGKSNbG+fC9yOJRUKeZsOajzVg5W2Zj1FBI9WQKv1nNYKGduEbFRfJhgmNqgm49uYviTOrzsff9FIenjtm2G9CYo8y2foApZpFZil+dpE+TYblORB9QkMlkMWTV5FHN0JNRdKpFZLLjyEk7L37rXWJqUMox4iYfXc6dmEbmSU+m6Qw7qLJN8N0bt3FBNJLf+zyyUmBsrAmQyXftRqvLp693I0ajD4t9Ansgl9FRJ/PzfSiVTpyOaY4fP4pG8wTpdACl81HaJ6ax5vQQCzppCbmIiHFuN7fTJalZnFwI1muZauGdzufYmu3kLWHDwv0oplAn2hjRLEJhGMUWz8Wr9VMXeQizOkQ0u5lg+g4mVTLfs/6cxrcmMEZzWbVqFauKm4g/N8RD8suMq5R8dSbNitjh/6yM/gr8SSNAluUOoEMQhF/KspyG30btF8uy7P9rTfBvhbwly/nMgYf5eOOnUWdsZNQWTjZ6Wdfeyun2W6mx/5hLDPvYlfwgx1Xt7ChYz3xmHezdS2jvdsw7drzfIvyvRc5IeF/oJdHlBSDR68N6VQWi9vdv/9GxxxEAY8tGBKWI+ZKFIlOCIGBYlY+2zk7Gn0DOjXDm7PVIkppMBo4f/yZjo11IkkQsFiOVSqFSqZBzHZRrznPxzAsU/HKWEOvxZ+4noVKhuncHV40sQUp6aPQcoL1xlvp+J47RhRpcbd6DBCv24qqQcOXfR9kuE7myhYTiJeoHn2Fe/ByhuUrgJCmFkoExBw3q9eQgECCL+ycdzNlsiGKa5Y0l+M4sR5mjxHZtJYIg8MWBKeKZLObAt+nR2rhEGSbjmsTosdFW9BluTX4X0TWCgMxpMZ9v+z5MuWWUnZZ2RrsaUTiDaB64gwO/PMCaPWfJR0a3toLLXfvJkRYyfTNyJylZi6bchBBzc63iK3jdhZzxriEvrKbmoldAkDgTWEeHdBOprIOMOsU+0wnSokhKE8KQyGHHKT3vNSbxWjMUCsWIogJNdJyAzYxJE2YipGbTu3mU1B/CK0FUFCiVFtqJeCQ9jnQ9VruRQNaFJEdJeF/F7DCgb24mpR4mrUpSqFQSkdNk53IIDm+mUNIxo51G43NTMpZltCTLnDLMpeMb8Zh9TJgmmRRn+AfpWv4t8RjxtIl95lzWTzcREyT26H0UiUeYME2iyai5UJtmoGsLkdw4UcsrZNyXwlSIX5equGbkBNbFxQzrPLTkHSGrWIgTqs5aaQFSchoEWLZ5A65dBpQaF17Aq+1CQualmpMgq/j41K2kus8SW2ZgKucEb1RAjqgllknyoZiRPF2EVq8VjHqsRc0Eo9WUa3Zzsekgu/zfQhY2EIq9i17RQDY9z4GKClaPerjmjJ9gzmmmzRYamvchxLJ8a/hTfGbZo9Q5BuiON7NBNcRRm5HZYAHqgIuYMYhRNUmbYGAkm8Pt6TSKoJVZVwf5M00Lz6HZj58s6ZiNxsW78ZwVUHIdukwOqdgRDmzZhkvhZ6bLhl6KEVhSSLXxBJMXHuVJVrMpEqSkpAPvfCkWyxxGowWjMY3PO4bVMk/EXc+0IYZ6Xo/Pp8eRN0hlzQkymVN4fWmqqv6Vh08IqJUyGfuv2Bm4hoRqli8pnqQw4aZRKObMbAG24hzmIyJHTn6H9WiJsuAeCQlx5tUqIlEdRkMXn1Q9w82xcdxYOSYvZa14grecJr5nHyAhJOjVj7BFu5q7Kj8Csyk6NRN0GwdIB5vY31PGijrtX1AL/mn+nJiA/YIgXPmbsa2AWxCE47Is/3014A/YvPF6aoZGGM21EPSt4+cb9rDufIbFrSP03ljG8uQgK3re470l2xmQRqktvA5lZHrBLbBqFUr7++MT+t/M7xoAlivKkRMZQofGSY4Gsd9Y+9viPbIsMTb2U9SBfIo76zFtKUFh+n3fvsKkRtYlOXX6IyQSftratlFe7sdqPU5RkRbIQSlAdV09xeYss8/dRFl0iojjowxmNqOL6pG087ibvkFHfz752W30n8xFLEvh0AzzQ9cMiwNVmKY68EpnaFw2jyQLTI3/jG2pTyHixZHZz6HsPah33Ijhga+i09lIltawarAT4yotjhvr+OJbneycSrLRp2GTPYpy6FKyySiOu5cgapTs8QTYMx9E73sdAzGevPwlZscfJ1q8j7mpu6gb+BjKtAK1o422+SW8OXUpsqTn6uIWGhynOVR7JU84byU7r4Bt1eg3xbh75hU+O/EMCjKkNn6ezkCIk/t2oM8ZZMml+5genMB6zEWZfYAdvAomGEqs4lj4dsLZAmQ5C4KI295KWpFGlBTIZHH4UhTOO1k6GqSlNoAYFMlYk7jGYsw1a3GpZCbCSvypBH7HJKqUirdMRdzs7mc2aKFV1BLRtZCNbwDZjxR8DeQoofko0oE5NFtFfBYvO8I6Ug6RCz1bCasDZNJTjGdsTNUPsSXmpHRCR67biE4ziaCooiJUxWXZJYQ1c3yl7BpeHR4lP5lDVKPnoFDG9S2HWBXIcv9HBKwxJbNGD5GcXPSO3QhZLUn/evaValk3105uUYZW2wAXHJ2IGVg6X8oZ5xCD9lGMGT26iIzHEud07yk+kyjlZX0EgKaAkrA+TYsaEGCPeR8XZTSYwwE8djVpIcm8lOCmMzK3F+yj1VIFXmi0bUItLuXVAjXfXHcLXxiN0NTxE86nPkGRsI5JtJxwudCkM2xoUyKqpygQp1CZpikUp3m0/052Jk9jG4tz2n810oyaV+QGFGKKtCAgSD5eVpawSZOmORViU9SFUlCQt/ERKnN7cftLUc/UERpfgza8UITnsut/yq/EbxB571eolBXMW8J0lzRz8fgP2GYsoLrmBE/mfIL98qWs5kskvJcgAErlSgpi/Xhca7how2MkY1FaH7sFj1CMdsV29pm+zhXUgQDvJBMYDn8Wx4pXiScUiLrFvN4+iWg5QbNlMXZEbta8RkHWyyPpq7lH8Ta5sS9y0n8lv564gvHcH3EuUw0q0Ko0hKQYp/O2cMnoOb4Q3U1VJsHJbAUfy3yOenEcQ2Mej8gjGBVGfnHx0zz8+P0cKT7Jl4/dyk2KJZxuOsKVQpaMLLK1/A3OWxsp/eupxt/y5xgBFlmWQ4Ig3AU8I8vyVwRBOP+XntjfIjlLr+DDB+7ky0X3EOtegSJ/L6MNGco6WznbfSd1tm+TUzuOa2qarjyJJcpFZMuuQxp9CM/DP8D1wNfebxH+V/G7BoD1A+UY1y9UmNZU2fC92IfnsQ4Mq10YVuWTNE2QyQTI770bdBKmi/5zNepsNsWxY7eRSg/R37edS7feQW1tHidObmbJEj9TJwTa33mbtR+9HsUr38aQ2siI+EG000okwzRTDc/RYhlG1Kqpkjv4Z/EUmTUqlGKat4MaLHmXMzIxSmGwjYrLp5jp2Ulz4j3kAivKZD0zRbs4GN6JoHbxy0ODPOHpQ1nUjFNfTSJ5kqPNSW60anhwXQWPvLYPfbiYRrOGzHiYf2/W4pmbozyg4qVZH8rkDPrwbh7b8TPyDflYF93N3PgOWlVpejLFnLQmYOQDAAjIrFJNMDmxGKUzzObcN9lWWM3npl0UBIP8aPD7FEdGOGBZh5h/JYnB1cwMdwAgJcvpfreGrKqYDrOLlsQlFEccTDpbMEUuh6wOrfUw9po2pk9+EstsMRSDI6jCGNcw7pLYkf4ohdEoCN9EAm44bYNMGn19nJyYlW5dgr56AxmlTEaU0M4WM/hGkAwiycZiHi9dQXOyk+WhFpZaVmHXuFCKAoGkj97wiyRzKvHPVhLzhPCbJpnSD7IhOcWM2YgMvNc4z7Wdy0Gfgz1joCJWw3lDD4ekNiLpBPE2yJdzUCcdVHh1fDr4LYL9cfY3CyyZsHO+1AeyiDbvDUTjAEnPFr4i+KjyC7RY5zhc0ce0YZqq6CI+NXkHzxW8Sk7ayrvqMywLLmfJsMAvlp2lJXqCVeJKXir9JTun9UzlJDhvyLBp8gockSLaLM8BGryOUh4f38q7Td/j3WwJO+q95MxP8GLTNaxQz3HYESTulXhtnRFByPBgxX18QvUcH+r5J9SCke8bP82M1calXe28pnbiVlTwTY5TVtKL2+9kWURNsTdCzF1OtsxImTDOYmMb3iUpLuyvJWhcjEvpp8p1DEv7RzGKXrblPYRizI0wliCtC3As5eOSxTtI9KiIpiTir/VzNNFJbNkilndP8u6aD1EmT3NRPIs7o2bk/HKWBd6h59p7+Wb4K9QFphFFEcNwJ9ezm/TMm7B/miGWk01ngHEWVetIupNoLVrSijTTlhEyow1oA2vxZFt5+NDbZKWVXFIvsHHuCnKVv6Ay0wsKDSekBk5L9fxI9UMe8vyKSxUCj3k30pVNYLL5qSmKkZ2dZcn8BDeoR/BJCv4xL4c1gpevGR4mlZOgXxHnLklFrXMN+F7kpjVprpUTKBSDhBlkiQSSrETUn0aRm8bl1P91FOMf8OcYAUpBEFzAh/idNMG/80cQFTSVlCPZNMhZA+Z4Ds+smuXL52UKRoKccl7KJnk30+5uZgoL2Bcf43LDIjK1lxB45RVst9yCtqb6/ZbifwVyVv6jBgCAptRM3ieWEtw9QvTsLNGTM8i5CXL0H8TgayDSfAJR+38rWEciEc6fP8/E5A/JyTlPMHAVt9z8Jaz9L8Mzz7FMUHPq0Ct09edToK/E/XqEhPpHCCgYUQYRFj9DMu8crZ5KqkeSKHVRxLwsshGUYppkXKSo34FmeJB0XI9xkQ5fdDmN/nM0Mkx370MkFDHmK/bTpEwzM13FB0N9GFJRPDsWESzNpewc9B3cy6khP7lTeipjBjzWHp6tm6JqSsFRwY5vro4DCicgY/E9zn31X2SFawmZTBittoDuxDW8akiiyyrZLAaprt2FNgPzI0uZyXGSWX8pL4bKuJPnKR76AT8YyGetv42Y6OSl6L/imV0OfZDUTCBLVrTIJMIiifBCvIQdkJEJIaCdu4aEMoZlxeMUuvpQ6yLE3LtIjS/4YK1+F6vD25BnXERSepS6eXLDJUSUcYK9+1EVikRqVaSG6pFzzzGYO4suoyOujCN6KhguKcMSHCKoKCQjKLBnu1HXVOFGyYw8jSzL5GcKqAjtJIWEVzFMxByjzTJAUbKQFywhLvE3cVGgga8t+iUZZwGSpKIgXcWSrA3iDjq1XvIlG6aAnng6TDhnHm+4mVbvVmJlb/HKxTqaL4gIJZCJF6E0DoCkIhOu4/uVP6LM4WTaGiAtpFjsW8K6vo/QJcXpLRkipkggpGwcnbkSk85IedzNsG6cJwpfIKYOsm9tjKA+w+WWFBtDSUYm6lg/WYhMgsXxRfhXPsHrqe/QZ3fxnUw7D4YeZp9jFQrBjWlaz2sXW8hLzrO3/W7+rewfeKTkVvwKEx8ffYG9TXZcAQ9mj5v8nAg5jhT9ZhvrNDGaLjhx4STkjOEOjyDLSi6WT9Ia+jBnxocZK8inMgS3KU8jt/8DetFHrf1p2jUhRFFFk1CH09fG5tQMiXAK+6p8BJMS38FhvsU/ce+aBC8u0+MXrdwdeorInIvNig7OUMX2rTtwW3Tsx0H5hTM4pHmu5ADnpCrGcHHNsR9Qjp6mnArOz1vReCfRKXQkYgkSmgR1ObUU1diYHPDRvrmTueHVmDRTrBgrRPQc4VJaQFSAycXNiwv5P6esHE83USMk2Kl6njU2FWNFOvy236wQ5sKoBH2BaiR/AdvzxzAYwshykIG4QDatR592MpLpIaA5jlKhIzaWy2zMwcvmOcLhAjzjH+GJ7mcpE7OU//qnfy31+Hv8OUbAAywU/Dkmy/KZ39TyH/jLTutvl5qVO8jr8BLTScTnV3CheA+SKUWu/wTHPfex0nwEc904OR4PbqvI6WAxq0t2kB48zty3v03JUz/7e+2A/wcE94z81gXwuwbAfyBqldiurcKyo4zoOTfe987hcF+ObEwynfMUZcnb8LjTtLS00N/fj0KRYHnTEOngNVx39TcR9t4PZ58inVvPwJgSv3sDVxavQ6vMJ5YJ84bpAOPFLVya5yGrTCBoaqnyuJk6/n87nSl1GbS2JNE5HXJWBfZLUemrSUaXUj73HCvo5KS0k6JsLRNNUb7nN7PT7KG+sIe6nl5AyVzB03SgIFtopvFCJ8EV48zp08gn78He+AqakWZC7lrukI/zs/kjGAxjoNAhzV3MTVddxuTkc/T1f42g7iF+dHIFuaoQ1wbycRbMophcRnCmnsK0iUIP0BOhWnTgUm1ihWkAs7KN89HLOJu5khm7kqmqWezGl/iV6QovnKqnAAAgAElEQVQKQ8V84JQfoyhQefkXSEWdhCfWM919CaKsYlIhcL7qTQoMndw1lka334DFepB2RwoEyItvRh+rI6bxc7D6Z8iqGIpMArfNzf51n6Wu9ASeYSXl/hinHAoCmgCL/LUsmdpGQayCkbKFazzJPKZsio6mc5wwLCQ1CbJAdbCaen+SjJjitPMsoiyyLrCcEe08YSHIQx03UTWRQjA5WKfIIaiIYZIsdKnaGFPs4jWLmaX9OYSCWkRZJlZcBYIFKX2Y8eIrCLsuYAjMc3j5PNY0zPjWo9OPk/KtY6k8TyLsYtQ+jSVhwBkrYt3ARwjqpzEmnPi1UURZpGnwDlSJJHs0KnSz2xEWPYHbOIkoi6RUGXaed/ChDQX4at9C0bcMZTqFLlfBpoozPJj8Mn2WPFZNzXHCVcdO66No+6PsQ0F2owmrFGbX+Y/zZHIHr3Y2UZga49myq9jt3EhIaeAfB15C7/KwWi7jJXEnDdpdpNw2qqNtFHGOOdVyJtW3oXMX8iYrOKsWOJtoJC3GuEPxEqO+W1AJUVLNe3hr6iJs4haui24iFZc4GPshm6wHSGvuhRW/pOPsMX5etodrc7UMmB9EJ6dwpBNsOyuyVHwWYzbGcvkcL55Lcme/ndY6EXsqxId4k5RCz32JTzKHnerLPor17Y+x1dnJBoeGqc5BPlVZgDftw5vWk06l+JntQUY0w8R7qpEzFu4vKuOiUTeFmu8iICNbywhduQvr2TR3RsYYyX4Sb8lpBmtjKC1uSCowDRpxzCi4YHUQ0rqw5A6gL+8iNl/BTPc1tMZlDix6lY9Mfw60E7wlyZzwNAICTc4LrMi0Ygg0MRS+gsZ4N0VTo7i33ol2wE9Ble0PVdVfnD+nlfDL/E5NgN8U67nuLzmpv2XMZUtZseeH7M9fhnd0HXZhLwPlMjWd00hRAwdUd7HD8EOCF7qZdzoZU85iTCqoqbqc2IkXiRw9imnz5vdbjL9pomdmibRMYVxXgGnDH20y+VtEvQrj+nzOZb9MvnADBeXXIfenOd/2OPHdLVSkQlSXr0W71MCZ3TeRmG9CCnwIxdhhBouWMz5owJG8hQ15hSTVs7SYp7EMjtCkrufygXUou03MuzrwlDzDXGsOxsIohWsDBMdNRIaqsUeKIDeEQltDMlBFTD+JPlaAOljNkNONMn0rglpk1ZVb2KXeyM/OP0fL+ARbzxwk4UqRV97ARYETmJvjGHYPMq1NMXPuSyi0ASbO3YEyrUDUBVAMb+dmexVH8woZD6RIxJV8/Jk3uDj3WYLuK2jvU3OznCU/7WTGNIx2uhGVJoRgN9Ma8nFnTj8VsRZyFG2oxCihbAHtintxbzpCueIhyjM6kvpZnhw3kcxrYkAvEjWOkasPIiiymGUtyrpduAfW04lIq34es3sjV2X7sD/tJapSo5tMY2w+gSArqI7WYvZ2cMHWwYitE0tcw+d2pfjSrTBQdAh73x0AaBQJ9OlhxJTIJf13klBFmDZMUeBvRZKLcGmWcls0TcRfxcbQCZKSna70ZURlLSZTgD7dPuY1ai6bvAwkDZtnNqMSlUwEJ8lEQpR2vcY/npZ47ToTiqSfiNbGuzkNLO9JoVSVIWryCFhiiAY9AhDTZ8lGL3DUpmHSGqdi0kDEqEAKLcE0qmI6UY3P+hOuOKYkbazmCvscRyL3MK+fZm/to9R5mljpWUlRqIzcYAkCIs1pPy+IOYTSZkRViKZINRuDXoJTeo6P5XLtlnsYF3eRUJZjEyp4XrLSZ8/ngwMzrIx/ku9M6dhR82MS9VZU6Sxakvyq/TM8FrqSV9kAhXqmCmxc4d/DW7bLuHViLxXTuQwNX4WAksuQmOFrGJUzvKvqxJ2uwptZhCykmNfN4rCWsWw6yfKkQLlpkPHQTUiCTDjwJsUztzAnXEAX1KCtsGLeUsKbD6pIqdaxVW5BeO56NEvM3FKlpE+qJy4YUGUlXu39HksU7+BTFHIueC8Npp/zYfl5WhV67m13cjEHyJH9nJa/Qa2uAF0kxfGXRsgENrC+ppgyYzeFwfPcPNUKtDJLDj8YKmDM4OCS+GrO+zYTQ2LHxF6sml+iIEQ8u47+8Gc4/f1RJJKU1p3AVrIbg8GLOmIg3PMBzsybGEnW8lnZTpv/FO+mS1k2MMRH9iiJfGUp/2Y9jMmuRpvRIgeDMLaGtYJErlLmgiFCv6+S9uwSEJIoBIn703n4lC7agzXMPt/H1V9d8xfXj3/In9NKuAj4IQv1+wHeAz4py/L70/LofzpKNavc3exesRHNSAxH2MkbdbN8vkMmT/E6U+HriKp/DZXjWAIBQoYxBudXUNa4CnHkKHMPfhvj+vUIKtX7LcnfJMnRIP5fD6KpsmK5/E83u5SkLC37PoNS76Ch6Woy2RCW+jpM+VWoehdhO/Q0bUNVRDJOGBlEPCQhCw4EsY8X341BzgcoO19JtX4LCVUQk+IRjJlcNszfiGxxEUx4CBV30C40smmuAevMN0nrTpFdbiXeK1Diq6fErCAjyZyIZgklJIqaX0StG8LW1UBr6Cq03s2UqjSYtpegMKjQo+KmsmqiVgWRuSCTDVVsrHmc3s7HcJe+TtakJdhSRDy0kNUgq2KEXYPM2RaxPHoWxlbQEMoSsStwyVmMPWYC5/8JvSywngRWSz9e0xSvV+3jY3NOrooFyRUjKCyzkIaMyojX3MjpqeUMS/U0leVha6shWPcs2ZSejsHFLFOKvCcu3LtD+Ubq1a2QVZHbfRsTax8gp+wE+pGLqIsM4tHbqH5hnrhex+3//BD3jj7Ea5ZRNGkdQUsnW089w6pOCXeHQEgXo2xOwOJzMZh3jqv0cUoGZB4oCRLR+KidW8OemicwSSINgcV4TFakpJ9ReYy6iInciXvpVt9IWD+BRjPODZoT1IXbmav9GPcNDJAvxem1vUeYFTSPu5h2FTGTr2a08hY0gW4QwixrH2WgWmRDeDWCohp9xkHakMSW7iOWSmGITTFtkTle/SwRXZa1PeVUjKV5ZoPAsqSKIamBXDHOJUM20kYFFZWX8M68gGzpQqub4tNT5XhRM5FxIEbKAYGIYRhdrJhbAlamOj/OmC7IqrIUVufTBNFT1GXk2cF9qH02FLZt/Hh1DoM5aj5x/gDN0Z+yIhWlK5vPlrN7URVVcLKkjC93Ps/pqbuYzCtjudGEOZGgtvUstoyGSrkb48wqxoU4Wms3j65eyb8mH8DYv4jkfAV9yU1o9XNsFH+CXdvJ/ek7uPu2fLq/+3002mp6otsQ1QrmTG2cWHIx52pdXDTgpmluAs11Bk6duhuVbRpqPZxTW1jeFWTVuQBplUiToouLFHdRkJzHng5ylNXU3fUU3r1BXu5YwhWur7E29Ch2KqhliP7IZqyqxXwDERRqMDUhm5ZwMjrDtFxJqfJa9snnqGCKNbTxrch5epUuJur62KI4SPG0hHXCTTZdhjd9H6fjDUxHg+RVt2CpOoykChMOlONqu5W5hidpkdyoZSsflpyY0YAMduUsH37bjZgVUO5+Dd1WFbMZBcWRUgTnGAWbV/PGHj8NKQVFQTOFVj9P5RxhJLqIK1wdKA6XcL7hLgxKmfXL/+vU5b8Uf4474GkWegZ88Dffb/3Ntkv/UpP6W6daJyKblKiFFFF/M+dK9iErM+TM9jNXHGdf+D6WOb6KcLyXU2utpLVBjs/NcOnam4ju/z7eXzxPzl13vN9i/M2RCSTwPteD0qbFcVMtguKPu1XSCT9dT1/KxrkFr9bEmcexliuwWldz7O0XKDo5zL7hKqKCiv2rrGxJDeIYryYQdiDJMSLaElwxJyWmLYzEu/jMpgrWZm/h861WFIbj9JY+T9vbJVi1NRgL9tK/uA3TiTtotG0k0ZlGiwpJK5OsNvJ6+zB6ycpKo4K84Q/B5C/IYMBsydIVEymo1pLxxkkl/PQPPcDc3BuIXQZkxwrcxU089fkjIDUCjbAMCAHI5OuidJrb2JCqoXbaxKgxlx+ZgqwLmylzAygRFEkMhi6uNX0fk7zQsObnZhNgw6sdQRvSE4lbSY5EmZIW0X9xHO/sbdhXPkmR+jDTSQNps5b6oSH86SJimZWcKG9AlLLkxn0MFZrRSUNkA6WcSkkovRVYKw8zxCizpmH+/dkMQhq++NlP47dYeSdjRRYFao1JfrFxHbaxFgrmA2jiMSpmYzyzoo7VqSh7JQFBPEu3qYhRewBk6M0/CcDK+VVICMTJgFpLGeMkNRCOFaCPFmEJLCGqr2VckcBUkc/3cNIUjHM7v0IMJngodiVmXxVG4//H3nvHyXGV+d7fquocprune3pmenKe0SRJI1lWjrYsyzmQbGNkwJjgNZgFDJcLZpcleVkwGLNgwAY55yArWrIk25KVNTnn2DMdp3OoqvuHuLy7n88uu/d9L7C7737/6jp1qus8n+56PqfOeZ7nZ0LOaFH1CRbtHqCf4cq7QZExxUwomgjl9scZkuuQYitwBHWkNSW873mMtCiz/UwFBSEXWquKyV/FiFYhKKlcE7OCu5WkJklnahLBqoIYo1IzyAfT7zAr6bglv4ybZ7YR1wZIWKeoUuYIJ6ooTuWzWp1m77gZY30pKgo95jxKYgoL1qt4dp2TkUIda84FsA0tJ6b9AknLM+TLLj6Q1jHZnkvzRZXZ3+u4rZoElRSSNomodbCgKyCYsaD1XOA66yN4IkFy4vWUmGdoU99nML+UMctN5KyJcOpNK3eoPn4k/ASez3KFO8W0GGbJl7/Ez4b9qIdOkLTacfnnmHS4aZwZ5eCh2zFp5qm4UkbNasGwlh9XjlI8O8kqnZsRnKiKBp2tiDd95eCpxu77CZnCI7g9cd7PqJScraGRQUa1pRyMxemSj7PDsI6sLoGUPYB5eS/zJx9gPuwiteHHjAysYkot4ILUwPKqQxgKA5jjMuZIFm+pHl+hB8e4ncG5FJqGX1HluYggqigqZBUB5+mvMYTK5W2PcvziHlJSihoMiAhkVD11kRAaVYeuqQ6hY4TmNY28pb9AfjyfxbiZ7x2bwmY3c3WZk6EzPhZCNjIlHVyVOcfOsjl6LP8TRdWw7JY68jb9xy0bnKeq6uP/5PgJQRA+/6ca0H8FlmzYgNvrQ7aqLMRaMEiHCBdnyZ1YwH31i8ydvxNdogWNbhxTvJW4eRTtfDHaTy1Dat+P75GfYb/5BjQO+1/alP8QqKpK9PgUsdNz6KvtmFcUoC22/CF2QkllSQ2GWHxrHDWr4PzoEkSTlmg6iklrQhTES/2SWZJzHQSfvR5POMsrug0gmdgSO0JJe5qhzhspjXt5Y6KarEZg/roy+nLv4FPpe5ie/iDDDRY8PoU88yzLskXEpT6O2L3smNNwd7wF2ehjcMVu0lkDOYUOorMCFk+W8XPVRIP7ybOlqJnwM+e0klpSha8jjTFjobbg1ywJvY/3jIOCxgnCY0bq+09xpu0rnLvQTdPCFOfEo4TmK4hO309ioRa1QUJIRRh2n2bUOoxe1XDru3o84RnCW01MUopeMJJzWTEv9nXweqqWGX2MRPHjeALVlBT2c112GQ0Lj6LKJmaVqxhwDLJXMgKTHDK7cPi+z6bB7yJOL2K1zrHMa2av+xAdhmmaVD1mc4x3UnH+vsCGUw7x4NyzvGx/BIIZtvou8ELtRvTKOP6BLbwWk9k0tBlfy28Yc8YBGHTJDFxfSXtRC+ZYgDF3HEmFZkucG9p/iDeaoCLooz0/h5/ttLOmJ0VRoYZjgsohVUN7aRxRFTAqBmJSAlEVOO08TXWkhqWoKMiIAmgVlTW6F5gx5XPOUYd9biVDMzdzNuRltnAfu9Q+LCTRKCp3zL3IUeO9yFkbRk+K2KwGvZqP3a8FOYtWsWLUD/Nh298gCgl2Cq+zaLSwR9nGQvAWdvR9iin98+T7U6QFH8dMO1mIebAIKlvVbmqzS5lQtAzYOjjX9EkU0YJe9rMsWsf7qdXsmt3LnVONZBC4xvoIT7OZMtsB6s1TDKXWcSKyix1cZKzXRSpfR8YRZNT0Afa2NjLm1nB333Pct7gbv20pxxbv5o3ggwBopAhRo4bBPIHmcZWDDRq2W35NXdl7SJoKLh6v4LctH8JntLFisgDD/JV8Wn2ODaFhLGMKWYOJoerPEx2Yxzd3GbOc4UfyLdyveQ4hBm8FKomv0vKb4VlOpUQ+odNR5T3ESNOdLCKiAq/P3MrOJU8id8D2D77M4MQci/2v0Slk0TWv4iumQnJjIa7tPIGqirTansTrXSSymE8qWUAsUMMpcrjIGGphjPpVF3F0JJibW4W59CncVacJDW8HMYvNMo634zpK8trJ16rYK97HYA4TjdUR8a8l2tdDiXEdser9yNVdOKp/DWkL2kgRgZiflM+OtewrVKDhFRIEjsmQMDNjHaanbIGmHjeLqp5iVca87h6IqaTjXRgWs+CCQtUDQIkmwFeNhTgHFvmRJcV1cYnre/4KJfACY6HrSIt5VM69xPuvmiipz8VRYP5zu9d/1yTALwjC7cAzvz/+MOD/0w3pPz/uxvW0nX6FY0WtKL06clSR3iqR1WMZnLoTeLU30RG/Gl3jI9R193KhbTlZo5GezrMs//xfM/e1TzD79R9Q8rPv/KVN+YujJLIEnu8n2RtAW2whfn6e2Km5SzX7G5ykpyOkRsIgq2CQ0V9nQJOn58L8Be4+eDcOycCVuU1skOrJP9yIpOqJZ/+RxUwAeziAJGgY1d1AjjYXg2ginPYS07+KvDPNDiVGy0wP4uJ6hKyRpppfY8tsZHWihox5mHOlr1Jt0lI3K4Cvjp6Sg4y++QPU7KWiH1q9jG6gl3SqEpftBOVvPYc1tEDC1Up3rAGDGOFyiwNjt42pIQ3lm8fRWzNo3QqnhqwUx/Yyab2OxWkdicAaACyiQrnvXfJCk7xylZlDeW9zjW8FrcIc66rGcZsnEX5f1DuDgO/0brTyGqazBVgKX8Sf20NZ5hyRLoEC/VEwJhg9UsDbbTaGxY0Ml+0BICilUDRDiHNTiBqFTETDHmUVR5ynmQrruJhJkxYE5iU9tyxGecdk4EuFOoJaL7mzCiPCIaopRBQVot5SmmffJZu4hVeLDbhjKlkZDm8Hv+dmjL4oeZEJIppLO4ympB7d8i5Gg7WsGZbwm500jafobjWw3DXCysUsx00GUNNYsgY2RVayJ/c4iqAiAMPlT2EJtJJVJETK+Vk4iEN7GkUVCEenebT2edrGl9CycCeXT1xDie00b6sbqUiexpe7jHS8iILqML3Dr5J1VWPLlqIN5iGgw2V7kVsNz9Ap1HJwqgrJI7BGmOIm8QB+2yCvBr6FOXULYfENXiy5gUXRzNKUhE1I0JpoJK5dpDTYzMElfcgaBzfGO0llFpmT7Bx2bWCP+wo+fMLHGl0nCU0WQVE4kFrGEv0Q+dohTKazTMVXUAHMW7oYT2rY09bKTK6GR3q/zbULx3jH1kZ7fjOWdyVsbg3RQJZFwcqT63K44nyQlCix3XeOmsYTBIMeVPXj1OfPs77/PC9ftg1HIsZYuozfZK/kEwsHUBAQbnsRy6xIqnOSvvO9aFWJGU0vu4eWI6sCSq6IsSDJ+2mJHTOvYTNNoUnmUeGVWD4xgc9iw5AR+DI/YadwkoUXXiEQCKBT9CiChu72dm4TOlC1WlRVRBBUiovvZe+b/fRkCmkwZCAbxKg3UVSznua6PN7pzlKwtBNV/jyClEKOSZg9Q9TV3Ysg/fPK9umUmYX26/FPOckGdOh0d9IV0mAOVDJh6qDfmeXBhUZSET+zud0EsjKLoz5ajHZOy1F6T82xyiwjG2Sezn2NROZKJI0eW46FogfuIt0XYLLzcfrMY+SmcplKmzArEqvzUiz/3Cr2/ug8qegFnhXLuCssorPeRjosUT38Mvr6U0xZK3n9t0nu/MqOP4db/Wf8eyYBd3EpJuBHgAqcAD72JxzTf3oEexnLfH3sa96IqSeKNu3gWH2a1YdBc9aMsfQMUyNb2Go3k5geprepmbh1lIFzGbY8cjuh57YRPfIayd47MTTU/aXN+ZOQ6PKRno6Ss7UUQSP+i33S01H8T/Uih1LYrq3EssaDmpKJty8QP+slcnQSjduItFxmSvsYi6ZTEFKQ3nFwIZDg1SkfRckkqtrJaPwHKILAaOxtNIYinLYinEo5aTKk1QlG4yNk4mEa7JeztnIXDMcpDdqpBlS1ljJ7gmwoF2eqjIQCI427ybXOYI3Wkj+7ibGcDsb6tiJpEqR1aYrrX6ds4CLLLcNEMzbej32UnsYvUChNMS40YIuO09zxjwgopIUonu1htGYVLx/HqT5Bc2WQhGUTiWk/mWicgtHXKC1tojLvl5jcA6gq1MdFvjChxSG/hgaZjFmHv8+MYFUYq4KGdIYz1jhHck5xcPYw+0JXkXPIybKhGfKXh8itjdPdU4EalnEPnaNzXStpTYqyuIlxU5yw9BbIYGgpId4xzbh8inmymFQDk1oozGTZPeulUlT4VCjM7UXlJOYfQtVVE0z52ZI4BkZIBxrJEcN0FLyDX4Gvv65wegMcKhJZMFQhTWbxZ8wY7AkEFV5LK3xZVDGtHOfQQhnEBU4tCbItUYvJfIFr55Ic1+UiKRrcPpU9hcdBhZZAAcXD0+ytX8HJeDP6vINsVt7DFl0gkCpjUfJyl3CeyXAZQX0VAceblAa38Xzgu7hn9jMqbGcg/4MUFA7yPfNviLdpsNHP1qkrKLAdYZPuHPXSJPuDZbxsvJHDribUtMBPAAMpfqZ9mC05P+XI4ufpyL+JiGjggzEFvaKn0zZHKOnlZO05ru66D4N4FUZB4W80p8g7s5vAklVkunrY0PIrnlxTSG7H+xw2LyM9ZeWThkPoSPMT6+dIbj1HvDtIV2QFHpzsbahmLkfLP/T8kBmTmx9qP443m0d49nLaxDRh1yBn2lpZfjTCXYcXEWSBoHmBJWseJ5k0E41+kLm5UW69cgvlDz/E7VoJtzKDbEizf6aVTfZOXpI38KvHI7jMUbYDNjXKhCZFrytMXW8xAM6IkVem7kYqy3Kt51UmUqWooSKuvOAjJ5HLycY4VYERCqILvNSyhbuGLuKK5bJoHmI0lUPf8gaKQwu0TI8AoCJyYP8YCdWCEC1FFPtRREik4rzTHSIz8TSyroqERo/BcalCpWBUUJJZfL21TMRUMoYGzGKYMn8dQe0s/nQeObGVoFfJ10J+joxj75d5aMv/JOYz8m4yxjZrJcmpd/GWl1AviPTJSfLSo0Qtl/RdgtMllPSe5ZzBQGtyDo0FPnXfN1iaGqE4B4ZMERoDjUwn82nU+4kE5nn3jW6O+I8TLz5GYuKTDKfeYan7KmRvOyVTh1m4Kcvb8wVcVFLc+ad2vP8Cf0xAqERV1UlVVce5pB/wT89dA0z+qQf3nxZBoC4+DxoRmxglHi+ny+FDn5vA1GHEfeUBxkY2shDdRqhpH0s62zm/YgVxCvCODOH+0v1M7DrBzNe+RcXLT/2XSxlUFZXQnhHkUIrUaBjn7Q3/THlPlRUW3x0lcnAajArSLTHiRRdI+nrQ6wswLi/GfFkr6ViA4YnvMTv3MiZTNcvrdhOIjXOg6ztc7/PjSSbxNV3O3PAN2FMNnIkexnjbZWy77Eo642k+dvYAu6RnqJHPkZHciL40iSE7JcElELfgrXsSv5pE6thFiUmHaeRmVFQSgHLxrwlo5mgxNpOwZugOm1EVDUt1fjzmEoxjzbgsLxGcMWIwxNmW+1PCFjcnIh+jRjhFUb4dk3or89Ov0LxaxqDP8iK3EBaaqKONDcJpXgndSLnkxmTXkR3vokR+AaMYw9dj4e0GMxlzlmtyV9M/oRBbtHCZ9Xki0zlkVYnH8j/GfuqwO76HrEnyRK6Wb/hexGd1kmowk1sbYzF7A7bKTxCJPkXN6HH2rL8kwfvFuQn+qtKFUe5CMYicbUpQ0QdNkzL1m1L8widgzki8OjXBGxYLr4Ru50vmX/HDSIgPuJejS/ezrFeh0jOAL11ExDBPsFLD+eK9rOoXaMjIZFtlDvqMGGPv4RopJ5jfeem3F+CzM0Gsko7VeUkeXTGNdcqC1nQtRfreS30CbuwuLVEhy7hbpnXEjj5P5vO/muK5dW7U0e3IOju1UYW/N36PXp2OT5VIZEUXv5vz82B4kkdM57has4Aj9xi/Cz9I0nMjoipi1g2wVf06P/TfQyq2nDz7L8glxs3mfZhI84tIHVFvEd3FboyaDPWSF1WbRchKfCHzWV41fpN6+SUe1lxNdUahJGPiSUuKQtMUL9S+jhUTJnMcn6Oc/HgvzrNPsmi3YAiFmVdTfPB4iP0rrTzcegNLerq4QneSTnctd3u+w4zZATT+E5H1VjRZlc/07eP71Xcwr3PzFIMcneyhODxFe1kxexuXAgK5bi3Lp/3IooGGNY8gSCn8k7u4fP0WnnvuOQSbE72apXHxReYNaxFCGpYv9rNt8yNkogaM4TTZ0P/zdh3Ry0RNMlj1FBZWMDM5yfnCYlpGu+lJbGA6qpAP6JUoYKAsICKocF9W5kEBThYt5Yr+N0FRKAl0cdC5mZjOyNLZfpzOKeaTuZAw4IkUUJI0Icp1WEvexVDcQU7eEKIkY1MmSAYteC9YiHtzOCveQ0s4F6P5AM8am7gzHiJGlJmFZcQsBuJmP0VijKVmG1ZRJX7gQaYdVmJaI5UuM7/xiWxDYKakBEFR6NeNEvKH+Nzp53hr7ZVkLFq6lcvpsl6KkQ/n9EG6mJ685Wwqa+DtyHngKPmJfMad73Iip4sdUzv48dg3GagdJE9Thk9JMFrUyI//diPn7v4dAO9YdjI5kcsnt1X9yXzuH+OPrQQcEgThKlVVx/5poyAIu4CvA3v+lAP7z05lZTm2yCJaG0QSFRgd58gWKRg6E5hII1rG6I1tobR0L8VnRuhrWkbcHqHr6LtsvetjmC7/APF3Hmdx/wFsO/5r6ZH5i3QAACAASURBVAqkRsLIoRSm5W7iHT7mH23HdecStPnm30f3D5KdSxB1tTPX9GvkUARC//w7JMkMCChKgvLyz1JR/lkS0TTfvPhTAj6Be2ZlwqW1dClpKgL1zCSHWdL1Eq7fHUQx+zkafp9vqwcQZRVB0OBZWIX9wnYE2UiGPnRqA9bzxYyF7VS4FEyKFkmYQlZVEkoRS9ImdJkasokEb8eHyKbLKbE8iXXPScQVLdhrj5GI6fGedhFafQsTDHCtdIYdjh8AoKh6suUWijwhNDqFQOYb+A0yXmWCoNrKKrpZLz3BR4QaVL2OB9bVsEx/lvkOK95+G0+vqaI+uIlW71I6Yl5ucX6BuGphyFNMcec8w8FcGqrfYEqTZHm0gZesvVwTUGir8wN+vLh4TCpBFQ8y2VDCfaOgzYxilxWWSklcWZlBs8CHSiPcrEwx6nKyfkLhF4tOIMaXFjIogsC59EpMGiMTujwaw3NY8q+kcCHEW8u9nA0HaDKUscx0jjPubiRZ5o4jCgsfMeDWxtHhQBfYw1JnBUXai7yIxNJkGU7fGpSkhMa5n3WFGd5ULLR5jbjrxiGm8KJN4Yaol/NWO60X7iEnUYY8+DM0SpB16+a56vgP+IblM/za9jCiRqWfNpyRFBWpYgjeTNj4APfGTyEJKu8L21Bqf4Pa92kUJN6reJZdoQy3J8b4gbqaksAq7jQ+gVFReVZbR2Iij6jGwKwmn0rRR7M0i6AoeMr6ORhexsf8X+RGwwnSMqxOGhk3TGHWprhHPUDjpBeDKnO86Cnihq9y04UJ4qqAORQlEprk18odlEfc5J2foOiyJCcblzGerSSqseAJJLhi8TQWZQFPb5QFSwGiasMQyuWXazaQ0RgojilEh1wIBj1J0ySyLkm5ppX6/nlaxrWclCZoXnUKp2OG3q5NGBdcVLz/ACJLOf/232MuChCdcJAsMaCLe3lv41aSNgcFqYc5FHgTp7uR73g3Mme001vZBrF9GD+ykda8TfgzZtLhCKvG+slKDnJEBVUVSOuCyFKS/Ll8fPnDTPcP82FpiseXriJlTmOK+riw5lJa3IaRo7S2HsRiDVD/++c8E7eTSVox2KcRRYV00orXW4XPV0o04iQrG9DPT7Ckppr6AQFFXsC880NsPrhARj9NseJDjgyiChniFoW697+JruByUnKWiUKJSIsRZHCmvXRpc+jVREipsMTRyLx/irncANWmHJxiAuNCkL8xt/OIa5SAlIemIAAjxeQbFR6a9ZDJPYIpa8CRsvOND17F0f0ZkkqYylAdndkicsf12LLD9DuaGRwZR5fMMmFz8nT/Fuocg6z1jMAfLP/z8ccmAfcDBwVB2Kmq6iCAIAhfBT4CbPwj1/03QOkVO2k+0Ed3YRnK6KVa30M1Fio6s+i7BQRPJ5mBKnLTS8kUtNPUfpHTq9ro7EqyFXB9+g6m2g/h/bvvYd20EdFo/Msa9G8QeWcaXan1D7X4/xjxc14Eg4Tjxmosqz34ftfN/KPtGGodJDp9KOYks0t/SfH6D1CWuwdVzXDw4H6GhnqoqXGydGkJs+FuuhdOM0ILxokoGw++ScVYHp/WXU9ZfgUov+TFhStZ3buUDCl4/zGUaJpxj4/I5DdpMUJg0kNLeh7L1C7U9FpQZZT4PKm3/gH9umsxOa9juSmLqEJceI1QUQocPvpOfpxIOkZl/Biu4QVS9XdgKTyPvWuaybJiyu2HEdJZZo7kMd1wPcP5ZixDOoa6rUwsl2mzrsBk1jLNSTxuD7NdbgwaM1c7ytideZszllq+xS6+o3uENbrDzCiFbNQ9x+HMUvxeE9NFbnJGVnCnsY72eIaNtocRBIEHUt/hSImJ3T3f5huTe/jiSi9tiw20TVTTUz/K1606fnlIxN0WwS35uFI6wqOWLRxNL+XDpUcYsnlZGk/z9vyHWWJ8i/5CHffacsjVL+OB/AHEC7Doj2AyGLgpNcTDOfm8ZwpwxWSKvlQNDcos9wT2UftyGq9VYfc18G7OBGPFo0zpJD7ytkx/XQmz4WUYLqRYovFx0XWRz6pHmUsrvEgeX/afotmYBhkip/TU5McpXmxhMrtAdXIK43CKX8cCACx60wy2/5b2ivtImz7LQO1BDIsXkW8Z5+Wur2GNZtnnbWXUq2EDGrTqIrJyhouWXXganiEk2XjatwKXN0rUeRYBicr+CrpNs9xueYuXlXV8SfcsJjXBbm7AFzei5iXpsDQDKiOKC5cSZ6n/DBVqD7f1wheq7+QX8rWsEzq5znIevW6Ih6RhFFkgINkwKUnaXRVoZAXDWD2fq60kHWvGML+DmoyWRb2fHkxcMf0wH05eS0RjpnjKh262gp9e1YZGVbjn4gvkaoMI6SyuxVI2DwkcWCYxMx3mfiXB3aEyorYByqKL/F39VXzzVIysEMXW2sfSkpNMjDdj8ecS85UzVenFaZ5nNKRnmT3IxYlcVEGkoNjE+bJmTJFjqKmL/KxxPbtGkuTO9THubsDnLCEvu4Lu4wuEE+/y1LolVEdjIOnodHQyWPwJPnCuF9UUwuI6g9z9IbKChYVMgtuefIJ2Ww6CINDiGubHJZ+ghHGuqXsJjSZNe8d6RLSIgp5iawDBPsbARBOvzm2lKZbFIaTIhOpRci+i1Qik3cX0TYWxKHampVEOvzfD36LjJSFJmzBJwbm9TNYW48tfS7DRwWy+h003bKZi4hG+3e1ES5aGVC8JtYSjGQW9JFAz78Qq2wlZz/Pe+k2oUhZZbOEhyUVu3kUM2jMsq7gZRuCWRjs/6FCw2IcpD+fhWFzkqtJtaC2FnOn5Nak8HZvVNdT4X+CM2UiR6uPp3U9gzXdzxrKUdBbuXz+PqvxlAsH/mIrgXkEQUsA+QRBuAD4BXAZs+G8VwX8bfcVlLJ/bw7uNKzD0JUAVeL9CotqQwnhOi+XGPuJjU4zEt6NrvkD9wSE6m9uImGG6v5ei1gZMa+8guu+7+B/7FXl/de9f2qR/lfRUhPCbI4hmDfn3tSHl6P7VvkoyS6LLh2m5G0EroSux4v7cMvy/7SbR7Ye2KEO2L1JSeQdFRZeyUmdmZrh40Yvb3cCFC/NEMfBI7CQ6ScfmRCHXD68gJ2Nin+Nd1meXweR2xlnFglUgY7QTPv8YJcWTnP54HXbDCJoJEU23g50GkVDm+8jkgqqgpuOI5kK813+OBwpfYkfCTlmqkPMLBzAsxGAEjM4k5rzjiN4NeLwi52tuQjJEWOV+HtfyWeZVEVM6w/ipAoLZQvqtGzEOz7L07OM8scPCvqVmdgSduDO5jKk6fNoPIBd1sZjSMK9RCGo3gAKyUsywcJivSU+BBGG5kP70ffxgvQ4UFUSR02qGh0wv49H18j/SH+cAuXxaZ8JSvp7ny46SFAVyF4uJiTLXzufwgmee18oLWattwegY5LJAN9GQhoiQS37jEHOOHK7uqeNqy1t0T4ocbxOQdU5qR6s5sWaQZe0q3SaB62N+ZjQSzxuKiBh9zDHKtHw513Ocywb60AVAZ/Hw3V9Mc6JO5bktAiVhlQ9MJmBDB/drigioOexKL9ClqrxktnPUIiCoAn8b/zI1jnHWjp2jNsdH5cw8H1H3oQDiAPgkI8+athAQ3eyKPk/DhhFMR7/P+eJPM+W5jqKBctZ6f4hRlNk/U8dU3IArV0TKuvFGFzjlkTjrXMNLK69AUBTuencPqqrBGPJisBmIWOw8E1nPt60vsE/3P0ih4RH5Q6TCKTLOXJRclYF0MUYlRUI0cCZbjCs3RF3fAF0FPYhilKRioUUeY7nxIENqET/P3sBWy3mcUR9HHG286NqOJ+hDSttY2fXQpecCGb9ljlOlx5A9H+di9ht8zv8kfr2VSKCSsDWBqKpkRA0LOgt2FFRthHF3hJVDkBNX0M+/TFRZjUFxE7IOA1me/vwnqci9E0PLYa6rPoh3ppyJwXq2xs/Tru6gXanB4p5iYbSNltueZHjmYWLA20uuBiVO/dQpjKlSXlKHSA4WUKJoKPNOYk3EKIzeypI5AwoqQtbCyrEzZIUsw44U5QsOtOkckvpJKuun6R5dwBa1ETNH6GpqZOnMCFOOPL7t+hs+032SZUt+jiAItF/cTnooStZThM3XwhlBZNg2w0DWjcMgUWAZwBqxomatiIuVzNuHyXO5UCdDoBWoycnj+piFeWkOgByvFlGjcllTLydYS6zKxtavPoBFr4H9b9Kh5tEqDFMrDjNvLCMZX6BUsZEn63lbl8SyZAvhC4cAyLcX8qsbW/nq2++Q0Q4wMVdIU04ck5rgqc/WcNveCLmZJiKChu++9h59Pi2pthvQJkYwBYeJ67SsvLyVxfFOFlUTmFQMRokV3rO05u+ioKrmT+mm/1X+aGCgqqqHf7/8f5RLAYFbVFVN/jkG9p8eQw4tgWHQiBjVLNpsDgPGRSyFKTIDJizGAAb5HF75eipyS1nMCdHS2cmpVc0c2XeQj9YvwXHrNpKdh/E/9itsN92Irrj4L23Vv0j03WkEnYSaVgi80I9rVxOC+C/HMSQ6fagZBVNb/h/aNDY97s8sJeS9yIWBT+Kwr6Sq8kvApfTAQ4cOYTQa2bVrF7tf283ghUGaPY180/hZ1L4o2gIzqXUq2p5ZNONPYVGLOKq7m4eXVXFmYp5HkwfpvcKIXRzF2Xszmed7sCg6fGv/ClVKIMkiWW8nUbmf3a0J9jlPosuKdE/PcNayiMnVQKPJiRAtIp3VEZkzIAgi7xZfDSjcZHqAjH+EYY2GVakUo2EDyVGRYEUVS2aP0V20lSO3bGV/9VFsssoB+zv8dmae1nQKgZcZ17o5I9Uzm6lHYjXLyGUgtMBp7cepdP01AG8F7qVH1IBR4DrtMN1yAds1h7lG+yIvyhs4oS7h+9IFypQ23l9SwIF6WDZuYYfaz2Xx86hela6siyfb0hTk+nDYUhw+v5NPRvezRd/OCw4XALl9c/x2xc3UXngN2qB+0kaOQ6KwNk1PuY6kJOAKWHk9kMfKTDnvl8TpKh7F77gV76gN06ksfqubkQ/qybMIbHxKZe3PFWJaCz/efAMPKk/wdPoVprQSdekMb8WL2GM1kpHSWNI2TmuaOO2vJ76Y4OGqYT6cdzmlgVH0fh0xd5aO4CrEfLhj9AXO00iLpp+ybbP425+g2qphpamDYNrIKzOrCYpXI9hKkE3j+CwBhIwHZbSD99dc0jJQJA2CxgjpGOs1FxjJ2UhIMHIiVcXezCjbNBe4O/1F5uRcdsy/ijboZ6BkJXF0aElTHh8joMvlKPVQN8Hx6hNo+nSkgdNSExtSDzOFk13SPszBMI+PreBAxXb8yx2EJsKcdURI2KxMuuNENY+hqIOktcsxyklMiTjP5d2OGBJZkxlF0gVxx0LM5rjoamhk3XAnGgGOtBjwLOi54mIKsqsQJCvzYowLmQJW6qeRDWaqljyNq66d+elKBobXUEyQ07NacgoSJLzrWHG9hdHRQfpOHcaW9DJHKRdkDebwCzT2p3D6ZKY2SpxYGmHz3OUIgsg1fe0UjTUQlxYQyeXG0xEEXZQB2zC1htUs6UqiVU1IZj8DPitVayL0npYRgYGGBkDB5IzzhcxPsDecJhEu4mLvKhI4+dhXbmb37t1ktHE8W9r49JorefzEKC+fGiZBgmahiHmtQCpZxOqUnhO+HpzOEqxRWC/YGZKidNkvIkY16E52Yr96E96rr0Q4dBGtoGARs4CG7MRputXP8ZHiBW5feJ3K+AgHxSsgcym9T9OUz3N9Pm4KN5I2zOEuLGDbknyi/dfx/fFJjvS7cJinEX0B3uw5CAjsX/Ih0st+rwbrBDD/7w8Ia67GHQlSRjPxKROu6DD1Jh96nZfuY4f/400CBEGIcCkbQAD0wFYuyQgLgKqq6r+97vv/cyq0CoZUEo1eRU56mDYEMRTaEUfTOObDjMqLiGIUNb6RWPnrlHX00NHcxqgcJJVMYlqRj3HFB4i82cH0F+6n9PHHkSx//jzSP4a8mCLe4cOyuhBNnonQq0NE35v5F1X4AGLnvGjyjOhKrP+sPZEep3vsXvR6N01NDyOKl/6ag4ODjI6OctXGjZzZ/RBPZ1+hxX4ViuZWbrIrPLosQ5X/a+TvOclHZQj0W+ga1/LEByaBKk6UunnT00xZKkB4tolF5yD5dxqx9N4N2QwiFhbH32J/5STPV3QS0yRpHHdzxfx1VOjmsC/OIkpRNJooNnMKRYwikUQjpLHpYuiEGJKgQBZkNOyjlKLDGeIVGTZdto9heSP5vM395UE8Wfj2rMi9RSLfcLn46OQyphQDO9UhrpXeQ288jqo+RiRbCpbLGUjE2TNdR1CyMm3LMpHRYVBlPp5qIak+yyrDc+zLXsZXsp/gOl0PF0WFi5zhXNE5FEHg42+GqFw7x4QjH8OJGHeOy3ztYyn2yVlGEt9k1O+kXWPiJsshHtKuQZTbWT4YozPzGrUzKoIqEHYbuSxnGFGrcqLeiCSnebTUgFiaYeeEB0/Uz5BjFFF5hpNeMw1BeGlngPe0i9yXMHPl8kEebVnBE5FPMJfnpKNwiodn36QiK/ADTSn9BoGMlAZgc7SZi5Uaekbh9YJrkeS3eGRkDdcqfSCoiD6Vu1JPMnfWyJFkFQNSBSdMtXzc/CbrWnsA6AgWsDe5ilcKd9CkpmhKKMhZJypBVI1ApGIJs04LnpF5Qp4cxGwCa2SO9k0PcX5qAU+kkylTMT9fvIrRsIFgiZMxxY3Xncdk4SxzsXwkWSYj6rDIUSoDoxzL28B5ZR25s1Ym0AEqZ9UKCsQIKAIbxXaeDi5HJIu5IAuqilxnY7Lax0zSRsBciBj/Es2jTzLoa2VVtoc6zQKZgBdDJINgKUdnzOKy5KBkF/GEfcR0evQZH9N2F9MOgbzAKMsm3Aho0BtPUj43h+CxULQpgKtkmOmpehYWNuN06pG1hSTRo8S86CcryPj1GLPd9BzvxT2vAw9kVT9u73t4grUgFrF+WOFA4zTT6lmWeK+mJFFOWFbZt8yEiJHrzqZYtHqoSudzpqCevEWFostfwVx8AVFUgXO0btETChWSzehx5k2g1yXIZIycTm7FfPQq0o52nAUebAY3giIxp4/wkeZ8Sp0mVpbncvDkRQA8Lhfv1lrIP7lIf8ZFgWBkzjiJX+Pmu6qMpvK7fNa/AX0yhkZRMd73Df7qzQlqhQ4C2FBn2lHzmxiY8ZNUtbSuvZo4TlKv/CMA+xULsySx2NxMhRMM1XjoyC3CZdETDaYYOxakqsBFqbGffr2JvZ461JkfoddXUuMLsannHOuO7qPj6z/lH05P8sUlIt1Tfcza3Uy4PJyuqIIK0MoFnFEy6NJJXopHuHVomq9U//Ey538K/th2gPVfO/ff/PtwXLaWhtEhRu121EQpirWXUHEF0IdpQGWxwIgtdoKJyBbyKt8gt89AQ/cQ51eWsufll7n5Ix8hZ1sT2dm7SJz9BVOf+Qwlv/wFosHwlzbtD0RPzoKqYlnjQco1kOwPEN4/ir7Khs5j+UO/rKKS8SdIjy2Sc1U5qdQcgcAJQqFTBEOnSCanAB0r2l5Aq70kopHNZDl06BAOhx35H/8OW7eXbRu28uQ1OwkZLYiqygv+t/n82V7OeuuwzEYIqnrO1Hjor26iPjHAuKGYZxb/mhsOSwjKpdUJUafiNmgQ1QR7sg/z1JYxrGKMG+cVtgdzqdSPk5P3DQBkRFJoCUlZ9IiYopAStAgWlUwqTdhvoE/RM6mpIJm9ldqBw8hqL1/dYeTzMT3Xp/byNaebaY2BXf3XgTRKXVDlnKuLB3RLWeErQkrcjCDPURL/MX2XJ9juT7M65zlW50A4a2A0YkfvOM3+oIPiTC4Z4Xessr5Md9jDuXkbarHAqB/WRHvpqchlzDJOQbiGvMVeHvXewNuZpfwm9j1ytoi0WbScjspYukYRsfFeeQ8ntTmQmkaTKWQxZ55lI0km3fkYZZV5wwITVCLN1dBZ4aN+UmHGmWBzbDuCqsUgi4iqCOk+rBcFtOYMy2sE3hEk9L45Eoi8qr2NT20s49jiaS4I57it8mOo5qt57en32Rlbyp01XyclpVETGq4IiJy/zE3usTns3nVs0p5D1WlY2nqYixe283jiOozzIxhchcjBCGIwynPSEjbmjzIYzyfcdAv9iXy8gRy0Uog7bsrlwtkRRF8cMewlm1/B1p4zDI+JrEwIqAi0rlzJPaeiZBU9V0hm0mgpL7HReM1dDL03QK9cwFvF+WRcvcQGXZiyCeIaM+ZWE2snekkELJzMWYkYXk+OkCCi6pFQ2KQ9y7OpzYzq7Fi9cZZPerGqZ0C1kChM05m3Cnt2EVc4gM9iZ8a/DSWpwyOeZ19dGze9/isktChyOzgbWblnNyfrllMcWmDE6eFo3RUgSABYFk7RnqtSHC1DsGSonplA74LCkmGmhmsYnWpDFaLoyvMp14poS/I5vnCMlTN3Evj6L/GUCoyVlzPmLkYngBp/moZYIRpFIS17KZzKp7osQlellyZ/JclFA0HdIJ1Vq9BlUmzvmCEnVkXYoaVsEvKWPYm19DyBYAEjQ5dhtfrJN05iL5hHo00S8JUwPrCZ97bcwFsZmbty30aHijKo4eiT/UiyhYwuRkvxpX3yFWUOmoQEqFAW+BW3pfz80PoAbREtttpNzAcPE5J6seYFyaAnFNdROjuLcP31bBwJMFcg0aCU4Z8L0fP8G8xnupnPXiqv3Vxkw5R3E++9NYE5MkWFcJpnWEPTuB/tChevOPVosir/U5Ng73v92ApO01545A++TQy9ipANUJ1eS/NsJ1WDNgoCs+x56VXWLt/EjhGZQDJAswC3Xb6RhVSWrx7rpdRiZVEnMGhKEJW0TE+Ow3+kScB/8/8d58arafn5C3S0XI1hxIMOOOvWssKWRe0VkHbGWNl7kqOOLWRSN/B+SQ8bRk7RV99KZ/8AbWNjlKwuInJsORr3Z4ns+SnTn/8CxT/9yf91bYFYJoZZ+3+2yqCkZWKnZjE0OJlP7cEabcJxcw3eh88TeLaf/HuXImgl2iNx7u4aRRdL8qgOppX7iJ64pDev0dhxOFYxOdvM2KCeY+2HiS+LIob0DGSyeAvqEdIBDm68k9E78gmY3dQHQ/ygI8D9jaM86dnO5r4DFOvcyOs+zbmFvQTziolbrPzt6V8yI+bzWMN6FkqT9Gv2khutQ/Guxc8o6fznqJVG2TOdII9LwZtJQ4SZzBI6klfRZn0JnZzGn/4xXyh5jiHDKPe+YaB9dS5+/Sj3PS6S0oIlLbIiNcelchpwvqWBjNHL31piTIVcvJFjYIlvKbrgVo7lnGHbuIUu8ywG14ss73aRVgVk0cQz9QV022d50gbFgVo2xDV8kBj1tmmWpl7nVtPrDKv5lAteTivVvONM0JgcpTXZQ4+pjhphgdNVpxAVlbHSGzlfBTu738NaFkVG4HHbtRg6ZhHL2gl73kEbiiNqIzTOrKO78D1i/s2MrvGTuxfmCwrJTy4yaZ7h6MAdnNclWaj4GdvPqqxdqCKdm0c0HeDLibu4PZSlLv4SxXPnsa6IsVHNgt3CVSNRDuotfOvFhwi+Y+DCHQIV8TIe7t1JRslgKFnD29I7lERLGM4ZgayZ8PAL0HoPLXl6AoF5dFoz+ukRZhasZLXTYCtlQFfIcW0LKavCx0ztTIsjzGUvZ7F4ga/eeQ/f+8HbCMj41ByIhAlHo+iD82hDfo62XcmKqUHqFB8pv4v+/FJmsi2I4jy10S56LJdKt25ufonRWQs2sRlBSBGONOPIWIghYpWDxHVmjlWv44w7Qv7km9RMFDIoFVOkBljabOOZTgtvpC7HJSyS7FRYPTKLLGpYOtjP+o7zZGwwV/giF2qXE7Dl8uSKK/E1ebAO+3m9aTOu+Wk0iozWcj1qzRTRZAadJHDVyX0kKpYw7chDlGNIqgFBVXFHF2ke9FM58jZvrGxAFTNU1k0Qnffge0sif7mB9KYd7D/fzdqd29l98osUt5/DFN9Od92VzDgOo9dokHV65EwabWqA+sk1FCSqiFjLkHM9XDF3Ac/aX2C+4YtEF/NpHZollr4RozeBtjKDOdjCep0RY/lLqHk9qAi8O7AFR1pgfsDEmtMXOXDVvSRN06iCgKN3gRtqNChzATRqGAQQ0jq8o4tE3BYc0hz/u4SIO8dAjSaJpBqxad7Dmkzx17a/4cXEt2AghmioIsfeS4U6zEKwljRa7PMBvvyx+5lNZxCMEi/UtnBFeAHR9w7GbIB2QyVWvUS500wikUCOhTmtVPPJkgEuj/2WrxbfT8Ko50OLGsoOzTNzcxHP6ONYK0YwZvPxuu6jaqadxtk58pK5gICiqvQ1ZfCV7OSyiYtU+GsxJgq488YPk99Ugi6RIHj35/hWTw/Hd22jJnAzBYLCK7pTmEQVNq/5v+LP/0+QHnzwwT/7Tf/c/PKXv3zw7rvv/rPfV5OTh/+5n7O/ZSPSRAad8x3seonLx6KkJ0TmN5jIPR4lXrtIILqdYN4CDcN9SNk8vPlahsdGaVu1Aq1RR2pIh2VNDeFXniE9MYF121YE8dITkg2lUJJZRMP/uzndnpE93LHvDjaXbMZldP27r4ud9ZLo9GG51s3FkY/iDxyjqOyD6D25RN+dJj4W4neSl8+MzKNmAiyoBk7mZ6lOH8M7Vc7YaBuZ9PW0Lf8Ub+7pYsRWhjYRZzyR4c1CNxlRwKboEGMxgnYI6ENcNn2cxzpq6YofZCE5zFTxGrqL55AWwowl+1G1afp2LOVzY8+zY/Egjdl27px9g3rhJLnSBFeoI2w07ma1aS8rlGmK0hK+VCM9yU2061dzQbeGLu/tNOhVHOEjJHwanLlHSaVXcsY6x3tLkoxZIuw6qP4v9t4z2pKzvPf8VdXO8ex4wj45hz7dp3POauWIJCQkECBAJGOwwTYYuAYc7sUm2IxB5CCCEAqN1ELdklpqdQ6nr0nUsgAAIABJREFUu0/q7pNz2jnnvatqPsjL41lzZ+6dO9ieD/y+VH1417tqveutev7rff71PNQGBL78+McZbu9GFRtImozEDSXCNjs+2wqL5hKnzXqq4wq1uTYsBTeGVD2JzBj2xAqTjXF0qgFnGo5u8zNfGaNz3kZdpIagM0a/q8CvK+DHdis/sLr4jtPKM04Nv7LZedZZZtkBSauViapaEokGxrpC6MUhBBX0+XNkdDkOjaRojyww0qLhV+tzLNgSyIoRyRDEV5BJm+I0LVaw7A1QCu8jURcnIUQY6rHiqwoxoRbYnbNRNE0SMK/wrpMirqSH2ToXVQmZoK6T4wp87Np5bIU40X15mgoFzKJAZbzIF90ufrPJzZXmPKKq0hjYSG0ki0HU81rqKAG7AY8fSmIcZ8GN1ugmJeoJ1kjsC4wRVCz0u40kPFZON17Al+jhstpCvKxHlQS82WXcGjslEYwFMy+cyjMtw/sw0I8C0+cxaFQymXHMeYkrHetpXJ4FqwNUldebNjI5FOWgJstnVDvPaSRMlKmSihTSZkRK5H1TBCO95IpVCKqCotOSd1hRqrUokon7hCUePHYaxWVg1+pxnij/mFfVrYRw0Bef4KErp1ElDR/7i7/hR/e8k4bZEapsUZzjGdqnpumanMSQyXFlYx8FnxVfMcB9Z36LkC2gNR3k3ne38cbsVQRRQlcE2WLncrUVReNAUAWalqaoimTYe+USkqrgjaXIHjDjbAiw2v8+8tF5MsUi9A/xiWef4pXFGd6yXOTPX1DRaAvEKnZzqeEqnoILg1zGEY+xosrcrXuIjhNfx5e5QXmXinfzTxALdqKLG7CUl5B8eVrN12myTeKpnMbeeA5N3SkwRimmqgiwnkrHIM2NI/gOJ7BZLVjvu4/oNJR0MSyqjcycA6M+jkAARdEypDi4x3GWZ8pe6qUYHo+H06dP47W7uXrlAlVqlpVcgp/793KXsZ8Fo4litpVpg5Ga5jSWkBF3UUKPnuGmLl6vb8a9kOVvexp4K5PhmreO7ZnL9Br8PJnbTXV1HZt6vTx3Y5IzuRKBtm5+blrDsaa9eMoxvtfTytaoxOqNGB1ZgfWTaQZtv8KgbuadszqaQ0ksZRN1vgZSyTQ5Vc+KYiCr1ZKudDBJiDntKgZfBV5RZOXxxyksLPDV+1SWNzop1t5MZCFLB1p6JA2+fVv+l77h/z2+/OUvr37pS1/6/v9o3B9EwL8ngkj6ue/x6y23oZ3KY3SdxqzNcWi1m/xiELEzT3ylknbrOcqaFkqlDUhiFN/yAMuuzSR1SVKpFGsPbaEwGUNOOrHubST2y59TmJrCtHUr5ZhM8NtD5AZCWLZVIUj//ep7/3eU5BJ/8tafkCgkiOQj3Np0K6VwjtQbC+Sn4hQXU5RW05SjeSS7HkH79vyqqhL7zTiSXU+2d5TT354mcE0kEj2JrdXKwOog33D6+KlGw6ZIglsvn6M2meGcr47Bwnr+aOO9NNX3cOHCBSZnZ8lmsyx2rnCuqpLxqk3sC5Z519XLfHzBwh1+hTOaf8QXPc135h4gUy4wHhFpSe5lqFkkY/Kgc/6ONrGMo92JvqTlCf9vWChs5Yp0Pz+staHReLg1sYC9JLJU8nA942QmtZb+3AautXmYWZNiT+EVpmbfi2yYY5PxnwkeN5GcM6HoRTa7rhIsbcIlyHxzeJGqCwbO9d3OjaYWzq7fTkWxkd6pK0y1dVDKrdKQEnCVXCyh40NvaVEsTmQ5jBp9E0rLLIvdFBwJFirjXGtOU9QpdCUfYvvsexBMjXwr8SyBqSaSJglD2Ugx3UQ5087+YgUhW4CcKmBJCdQs7CfiXUPe/hsM+tMA1IoqMdnEoqaDnfNhKrIyr22rZckpUFCMSIZVNCU9KUsYjWwkZ+olp5vGGmrH7z3PSDMk7XHk8G7Cxlk0io+wfhlZLNAV76FhYZaJtib2ldbwTVHEWVjlg5df5sgW2Lagx+NMYkvJUBQwGxt4xZwmY1D58+fK2JIlVvOLjJWnSNT4kEpFspve4JKhwI5JhZLkoDYTw5bJYilmOV/qQF9opFVsZcJ5Eb/pNgIRG15zlnxRIipV0GET2CR1MlVIcbTsoVMvsSs9yQmtA6tOpSY9xytrx+meqyCnl7nZs4NEZAI5k+SS1IUmXeQbcgVW0cpPkakT4xSTBpScjqxg4HSsDbVswZuN8Q7lTdyLGfYEL7Nj9AUWfLvY4z1D9fYZuotThBct3EhU4rc0IqXLfOnMj0CAz3zws0w3NSNkS2wcPU1he5nEXivihA5bIknnyiRV6gp95UGemPshlqs5quMqBrOCxvMtgikTQqkajbGMUhRYu3KW8x2HkDVa9imvc9vJs1ijRaZqWqmNBjG05khbawlfux+T6TreRJY9Fy8Rs9pYPz6JR7+DykCUjZ9/golVM8aEE79bxVrIoysWsYer6Lg8gKUQRJSzWALDZLf3MnTuFkJJF0uJRkhs5ZWF3RT8VcwM1WFYqKMteReumbspuq9xLNDHsrGVn2vex3t/d5g3W3fy2Oc/wGx8ilgkRM4gsW1NDzfURTT5OAbZRXuinqBS4LJkpUUT4caNGwSDQWYnpkmU0lgiEaaMbey4fh31YpGG1SlOeJ3cYhoiqlwmJ3swYiJgtvPC5v10KBIn71jPhioblnMLnNOVOeLbSVoq8mr9TpZrDPxwNcLJosqyw4ugl+gc7WfrtQt8ffkbbKwQsG0+RDFbojwRRDFdR5810xuuQF/I0ys24ieGTpokmzPQ63LiDE9jnhtCGw+jlyEvF5heWeXG6ZNoV5cYenAjZy0BiEf4sw13Mz3yPea0JcL6Ilt2//7+vv+fFQF/SAf8O+N0ebBl0wgaGbHoIaBfpOy8DRimbjLKW7V9rBu9Qd3O7xIMfpXr9XdTN/tl6gM5lg05hoaG6OjooO2BdgLfuopg34PnMxpC//QtMhcvou9+J9rGbciJAqmzK9j+X3aiOjx1mOX0MluqtnBq7iQzL19FdyELKgiigFpS/nWsoJew7KzBustHcSlNOZjD8WA7p05+nWJSh85WZOxonEsXf80Ldz5GxKDlnUNjvH/VwovGEu74AreeW+WVnbfxgelJ7rAPsmn7Zs70D2I315As7ydms/PumRz3TixybeplTlR2cZPtVj4bfgJL2Y9KFYPZFIKugwatwMa5Iic6G6le/DxzpQlaAzo+o/1rhjTdjGru4Gs1P8NStvBM69dwelTuPz1PgxrjgPVvqLRPU1JEPs1ePjt0iqHEE+QUG2rtKYQzKeS8laHWTtZdHSNoruGLvmMoSYEb/XXkLFrKlkPcdGWCiKvIkS1GXl7/EHK+kntPPw3LU0z7O1ks7+XvWzPcG3kVa3qSktHCy47bMQl5do9c48UdZXSyDkFTZtR5mpltIzwcO4c7XqQtXKQy4kRG5EcN76IzPUWP/ih39ea4XpA4Iul4o+cYcAytqEFVwSd7eJ+1xN/Ov4N8vhbxwcvEj1ZjUh+maPwn6sPdZIPbiDefBRVEtYysmcaesVHwHUNR9NxsMnIqU6A+YWeyQqJoWyAgruBKNbPY1IqiMeAKxwmaXDhCIzy88BZpg8RL22DXm26aWUGrKMQb7+eW5cP8jdlHRiMQdNRRQIta1UyuogJUBW3Mz/WQng2KBTEsUNF4g0V5FzXJKJcaOwmgRRmD9Vk9ZtvX8M8lsQk5bi7fYEVj581SG89o3RwoJhigBi0ykQ6Bz1btxP7GAgHVxri5BPo78XvD1K2MsWBSeeLTf8Z8sshPfnwdR62Ic0lDP2XKqob67AJVNgFJUBnIVdOTmOLDQ0/RHAr967sgCyIIKned/wzD6zvZVpvCbIzQUpnglble3tV/mLpYGkUj8ZUPfYLRzk4QBKzhGOaqLKHrXjrfOUvhiyVCqwq2wxK3v3TuX+d3E0URRITg82R6CjQ3+Bkb66AourGZ5lGvFdg4fpar7dvZqZzDNxNj2dvHpDtJjSDgfKXACY+FtWsvUgrP0HYqzVxVNV96t42vPGVm/aVBTtx0gFBBomwP4Jmv44bBQE0yTspqoTbXSFXwFSKbdYjrMji+ryXxVYXsrhTO5TDuQpLltWupLURZLVVyROzgU3Yd1uDbVjJ7dh/daj9fs/0FOcnA4f23oip5Ls1GKfgbkUpzyNoM0dgpyskCggCOej0LDGIQ89wsREFVqXYYaWps59zgMAALHjeqqnJ8dzf3aHciBONc3NhFvyyz+YYFXyzEYksjr63ZSr1BxytbOzFpJKIrGTJnk9xbc5lza3p4qup2dLE8vZMhNumKFEITWFApFt82qaLX8UvehfZ4iuor36eUkAhWhJFR0JVFtMUUxkQRnSpiwU/Gn8OSWGZ5XMbu9NJZt41yRkuxUSV8Y4BgKkrS18SVtmZ0Fxe4i2oAnjvzOXK1rchaETl6438hwvx/5w8nAf/O5AIBTkeLxGUjgrJCVr/M3cW9MHcKQ65M/5qNNJ2fIdaboE9aYC5/iKLeSFXgCotGKxa3m+vTY/Rt34jBZCRzbgXbLbuw33UbqePnKY4fJ6+dQ6ippjyWx7y9DlEn/T8+k1pWKC4kySez/MO5r9Jhb+e/tnyJ7WeacMzqMK5x43m8F/ttTVj311Ho0HFs6lmqbI2oI0kS55eIji8jabWoewOc/eVRNIZ17Hp8P4GGVb675qPkBQPvPPYUNztUpjxjJNJajMYENrWELXSNwfqdjGXqOCxZGWjs5GKNj4hez8cHl/jIoo7Lq4dJl5Pk82FO1U/zSOkU9ZqnKavzXMu1st3ioEZTYE1R4plGPfpikX2rEu+wfZkJcwOPV6ucsF/CntLwl6t2YundDLQauTX+FI/pv4Mg6fiBspl6dZX7ctNcSzzCbx3v4KWdAl+a/DrxswZGOzexsvUeDPHrVIykCNpclPwSyhwc3lZNybILi1JFy0qOgXoFdUqDdizJjKYJjV5lbXQEs7PMjuWzGPMprjZt4flND5CO69kZOstd5gmU9BfYvHgzG5b2clAjc3fTSe6dyxIotDKde5hieYZVYx3XrJ3sUIIYVldQyi3Y0hvweD1UG1OsNaRIpxykxDKFmQ9SCjVwPd/JzVXn6eweZbL8LobdV7CXLHSFGihWraUiPkrMUkCWFPLaKHpFT9qYpLD8LiqK3TTF7VTIBibtEySkKKqgkEtuxRx2Irl15CxmsukRtkXGcKXjPHvgIJNVk4xVb+D29Apkyoz8usCHmh4l4p3AktXSNleB4G0g43CCIKArFihUuKlJNUDGiyUZp+PANNWuacIlHy+37qFk1SJkBW5kCmSzCkKixMcds5ilHHUWlWVDmnDIyjGzQChtpMMcZnNymtkKL7VLK6zKNqb37Cau6cSeStC5MEtOXWZo5ALfGlRJCSay66rYfulvGI7MksTCbQ0qqWIBWzLJgYHDPDw4glEu0L+vl3/c9Ci/8u1jTc802zsmuWzsoWNwhuSkiXCpmdiAhs5ACHc6w3hTK1/5wB/jr60mJ+lxzYR4WPMM1bYVklNmEtOPEZ18hGJkDWlrIwumSoLu7cxUdzLqybLsqaAilcNyBZJpPX5nMwDnS9XUxZdp8Y8he7R0PBOmOhzmSp0O2SjiORTEdEEimkny9Poh7ns9jy4MRw908eepab617b0cPH+OumyWk6KAYpIppTxoFA0W/QTNzkm607/DNFEm+qjKaHk3+UQH3XMXkUWRF/Y8QUO8HvuGbfx6SWZM9uCz2bldsFKmgEEbJh+rYcik4Zy3i7qon/7OdXx8dZTxsyLFAMxoKjBrl1ktFNELMgDZdBKDnELWCiCooEIhGiN69jhau4+SCAlxmSG5lUZR4eSaAj/b+hgxkx6TPsOJrm2cWbuZa74WRBFeiP2S6qmXUaff4rXn4hTzGkTDONv9Q3TOL7AuNE9NdhVSQaRiETGdQJdO0Fxy065tg1yETD5OopgjK+bRZ5Jol6ewrQbQxCKo2Tjh3CJCLolQyFO22NnnvJs+8z7cUiOtlqP0Gn/Huv3b6Gvswa91EBM0XGkZRbRHsXfmMDhbSEteevLT9GgVag8+8HuLPX9IB/wb/jNFQNnk4eq5s4x6m1FSSSTbDboEK/aVJOJqFnmjimcghktfoto7x5jkJabdhzc8QNLeRnW5jN8oM3JthJoNTZgjItmBILn5AopvE6/XX6f60gTC4CmKY0eJ/Pwp0sdfp+z3Y9q8+f/Sd0ApyER+ep3k6wvk+0McCm1l99JayoMxNHodf131XRp6m3jru7+kXIpR0p9ndObPqfBdIOI8yknLAKmMhYZUDSe8zxNc+S7xqXcjSts4Hank+217Mck5Dg9+goc0F1DrpxiO1JDWJQl5RjBE29ngG2Hr4lo0gpH20BJ7liJ0zJfYP1zkkawJf6nMrFyPwdyHwbSZd0sv4tQMk5D3YdOcY635NKhFdNqv4ypbmDCaaNNc4v3Fb1LSiHy66TO8d6EVa9ZFW8BHKr2VPelx+hudLLh99A5fY/HCGrovT5BbMGCrkjHYonx+2y18cPkXrHl9klxax8XNfaQ1aVaq66kMBTFNpMkFtVxsr+Mbj/8tXfMhbAUDydwQ11MmlISC3GyhsMHNalMjrQvjNK7OkLLaebH1biZKTQjREqpZw9SB9YRrfBSkIllrib4N38XdeI4Xhu5nJu1jxdhMyexF1VQwbu5jSTKwu/UMixk3kVWR0zXbiaUrqZmtoNU3yavFAt5cI8uxvSwrDvTIfHzLd1gM+ViMu6koVuDJe9FotHhzSaLmPGFD+O1NIUBBU+BAdAvmYA+ZopZ2tcSQa5CkMUwZARUou97NUtDN42dfwJLPEnc6WPH5mG9qwqDRkNLBpEfitOURTslr2TA6zo7Fcd60PUwyejdVFhAdVhAEmp0D7PvleWYcCmgs6A02lhxehjSVbKwYpdYxhpAoMGrZQK8QJZoVIC4jCjLWmhHkeCP5XBRPfor7Lp3nT08+Tc6go2vvDaRVCz2LE5QEPbOqm43ZJcJTKkVVQ2/0OpZOLT9Jv5OAUkGjOc/e1XPsPnaWntUFbpu7SN3AAJ3jY7RNTmHOFTmytZG/fvwL/G7DLUQjGlTga8YfktBXMCy08rlHP0PT6hKV4/Ms2is52r2Dr3zyT5lrbeZz3/9HXth3JwdXL7BzfpRtXa9SnZVZmvEiqDnWWWeIxj1E1S7ylrWUtDaWlasomjJrPnSdiNuA5Rq4/CUWfU2U9BpqFkcxmdN03j3LLs152p6PseJysurdic87gmFnlnK4g86BEHUZHzXXkow1OdFo6lgofJKEUeBiZz37zrxFU+csI517iHpW2ON+lqbOU1icfhw/1ZCzOjjO+xlyNvLUTbvZODNK99gYQjmCPTGGf3SYQkZFkFWstfDesJl45VkkMYUx0cgXu5swFnPsnhpmsL6NRdFBe3wUyXINvXGZtKpHeHv7ISJTlQuQMFSQsVRRMnmJqAUkScKZzJI2SMh6HRrJyfl8M/WmKMdq95FRVT61/G3k7FFyqSN8Pr9Kw9QU7/e/wc7URYTwOBMTGgaj+9nZepmAVmKlZEVWIJIVWJO4SikYRh9Yxq5f5qDtJtp1jdgcf0Xj2koqYxHsgQJyMExNlZdT9utQp+EvamZp6/CT9XrxWzaT81RjqXByi/Z3aDWvclrjZ1LKYSKPbeE45WWJKvkNhuVa6gQ3dayjNH8vMW2BBlbYXXcMw5qtONt/f10E/5AO+P8J9qYG2sKLlLr3Ia28fQQ0Zpmi3bkdeeYwa6PjzDVX0TRZ4kabwjuM3+fJQgcjPR/CHR7Cnx7hTuFRzuqm+NXTv6K3vYfeZQfkFT5X/y3sTTXUP/oopaFrmE75aQ4ZmMtco+o7T3Jx6i1eusPFTHIWvaTni+s/T/MxM8XFJKY76vjr0f9Kk76Bx9vfB6KApduA/6klLj55AZ1+H2efuYDG9Cb29RJh+qiqiNBbPQs13+ZK0Uc1EcaPfIqsrZmhdSFO1rfhSZT5zvBXed0R47/UuckqEgHnecpiGVm0sdOWonv6Vm4q6tg6NUKNsY1gSeZ8toDbuYxGbuBGcgKEAmI5x62+H1Iphnk1uY0xnOx0fox1xd9RbfjVv6zwP/PLqbfvgpKXx9f8FbcvNNESm6fjrWcorzfS6XkTl3aZ5NVb+fT2z/Fmfhu3xC+wXLuLKn8/EyeshO9apWrljxkoFLhlyciNrg5yZjPGxUlSHg9v3Wqh92UTdakgTzY8hu3UAtHoKDF9K6852pGRcDdlCQsm1KUsW69fI1q0QZ0ZNZYis8ZLOaxDM5OmVZ5hTljLtL6eeJ0dV26RmywRfnzqv3Cu8C/GzMzbF7HCiFIyAyrfn38HWAALNEwtUG8IkDLo+UkcBFQeMqn8g6qQQ8Mt3hvopRIviassNL7IWrOJvcZqBifSWCYlFqpCWAWQFZGsoOABNjqcTEuwIbLErNZJrGIGCwIxBcSyk1vmZ1jSWvjYtk/iRiEqCGhKCvVCjC2aBbYEu6hKL3G6s4XBql7ieiMPHT5CWOllrbSI3aRluuxErilwvvNu4jtPc8fpizy/tYCg7cWptZFI3cqL0wfZX/tt7ne/yLryDX7sfoL661EWqKTJPs9r0/tx5mJ8dGKGbQuDiIpMyGzhXaNH6T/lYanWiz5roqoYBZq5Gnp7TcOKk5DWxfDMGhI2I4Iqs/fSWzw08QZTFTV8r+ce9ucC9JkvYg5kCWsdfPdmkcttX0ZUQREEpFiBNsMqerXEg33/wJjl7aYvn/7kFxAUhZbAIkvOStzRELcceYqX9hwkr9Vxz6tnMbf6kSSZuYGPIunClAsDiINJNvlf5VRHHVlTJdWROAVrmQw2Vkp/Sncsz7U+Heuv/oy9p09ycs/dWG02qu+8BqqI9scmBLWE8OE0zpCMo1OLtCwQnwmh1ZnourLEjTVNpLrjFKaWcegTtK1Yee6eZjLjYDqc4Sbv31HqlSnl7ISHe9Fe6sCXfBFlZxdDBzu4YHfTHfUzuGE9mnKZ9RPXcSYTbFLV/6Oz3FuQ19uwVRUIVW2k1LGDsM3Mo2fewJlLcevYBc429nLbipsd2V7eUC4xUq5mk3aJuMWKsVhgSazhVHsfiy4fWa0GWAuqSmtHAFM2Slt0Gk9GZrNuiaNrdpLXWWjxf5+vjT6MSYmzWzlKJDiLyVrHeF7hZ84d5Dr38GTQiMtZ5uCBO4kcfh5BUbBNX8OuyMQtUNaacVWL7LXtxJhsJ1r9T2QkAznz7zD2drC+8Jesd8FZxymGHHE+5J8EEdzhPPfKpzCqGzkPeEsm/GKAi+4WtjvtBOfmeUXZiLv8bnaW16FLnONe3bM8m72TIiV0jn4MCNwuv8poswlP5f+5/fF/FH8QAf/OSFqR+mQE1aJFKXgQVIFlfQCH491kOIxjKc3zW9bh+3WIfFagwpQn3fx32Ic/Q8iznnJBQzkc5OFNtzLUPc+p06cYMJSweMzcabiH0kSOqdQ8dp2Thgd2obtoJWq+wRXXP3PHa6P0UYnrwe3M+KfI/GyaXKEe+8NtPC8e5bj+HD+/7aNYvG9XyArNz3JTfxda/U5EbQYN28gWA+TfmEb1FsmsbWV2ZiNq+5vkDG2cjX6J5dusJMwS4KA+sco7z2a5mP8YR9zfplxewqYaaEj5WMMCr1gzLFjO0xe4mWBhhYuZLE1qmbVGiS3ONO5yNW/ZL/OK8TkOTpi4v20Io1Diadca/G4btsA6qtMbGdKU2Sw+SQkNadWEWchyX98/MWDpQhIEvh15GmvyOSz7EujMMsGSh7+zf4g7f3CMjuopvvfgo9irdRQid3O+ZwcB7bc41eLEWpYZsOsYbBWY6ukhrlM5v34X1+v70PTHqN+zyhf0v6BKmGYh3cqrrj4ARItCsc9D34VjvFHagBa4qKkD77/4M9wq0nABvBqKayoI6iTc2SQtgRU8qVGSOiPfmfoEEwU3gphFVUUQC2jtA1CoQil58Ngmub/xDOHFdmbjPq4ZqpkX67FqLkJZYLtFxWVbRBM5jpzs4s6unzGf2UBZs55m6Sh3Gpw4ikvM3XDgSmpZP2HjzLoIZX0jrkyOfe4KYgtxNsVmSEtWNjcM4JZMvFZ82x/SlaxCWy4T7qxhw4iGAcqoegmNo0hhKcrz8lru0w/SkK2jefAk5qQftcHPc7sPskWYo0sTJKtouaQ6KSw4qJmHM9Uututh3yT0W2tRXSE2zi2iLXgJXvtLik1naVz3PA/EnuJZ5Z3sqrlAGznuGTzNjmsTGMtFTtb18Vqfj3xRyzdfPYx/oYOjuvXcpx/GpsawCAqSKpJRyyhIDDr6yEl6DJoinx36NVsnh3m1fgvfXncfJUlLQK4l5T5Eg26Ze72fxpRfwwdzKlmjiCUQpYyGR0pvcFzcjv6yHbchQLUrxkhbJ9p4nqnqBiRF5n2nX6XSuolv7zhAw9IUfjlDiyoSHHyAWLmXysivWbbAskbLSq2HjEHH1e2bOO4ycfClF9k8P8PiT7ZwybmenKVIbkMl5v5ZDr3xLOU1eRJndZTKVTiHVpno6kNjCFG77jcABMbvoS57iYqOAEnZSOg9UKukMbiL+HS/pM50g/VCgeSjoA1pcH9f5NRj69H124hJq2yfPU1ep+eRBz9AwWjiU8dfomV5lhu+GibsGnJt3Xz3zg/huLJA8+IybqnAndkMHavLFOIX8QYu8+0DT9AcXMIqpxA1JRqDAeqDQeZNXlqzMZxyC5XGHKtmF650AkUQCVs9fCAgEvztl6mocVE2W1gNprAlIgAUdHrSVfU0m8HZfxxrNEi8KLMz9yyOcgxBVQnVrUNnMQAqM6t+7K89xQMaA2VB5LffM1OqakCbiLDNfQeiycNF+wXEksL9hhTZ2C4s0q+pi70BQCJkJy0/hqwNUHCeY0IWkFRo1apc7rHTxZ1YZxKYFteAdA2nUouh/nGqWr7tHfhOAAAgAElEQVRF6NgIGq+JNV1hGs/eg4pCUdlKQHyZtfIow0IXZUHLHi7wct0WuhMFMtN5WPcfGZ3e5g/pgP8Aws+9yHObt6ObSWGpuIxWn+TWyAPEl45iVMsk2xx4rgdx5mWEKoUqNc/XWyfZPlFF2bKOhBDCMBdGdqe4vPg6FtWBnFZJhKNkUklK5TJxWWVu5AqadIoN4mZ07c3UVFdSc/QqB6pv45b0g9iTJr7i+y6/kF/g/Mp5tlRt4QO9HwAgsrzIM1/5IhrdXUiGArqbvkXA34xFWU/BlEKMBQn742SMbmK5O/h5/b1ktVqqAwt0JWZpWj1LKv8UY87L9IQ284n0IQ6ubqMYbqY9tpYNkVp6VvdxIHo3dRozV3JGCoKTM65jvFH5OndEtyKJen6jPs3l5gCPm6LUKRk+WlmNNXozL1QM8fHQ3Yhiki7tX6HIAp8SP8KPGw7RsXQ7UWeIgYo2boqc4/2hv0cSi/Q7e5iaqUF4PYcYkqlIJ/n57feTsNg5XbeGoOUSF+pfYNGT5tCAyGd+U+bEOoHpOjuNboHYqgZ7LIZ/tQJBVfhU15O05kd5NH0VYSFEjSWEs0Zisa+FraFBzgY6sNjjGNr0CNU6HnUe4VDDq6S1NlZyVUjRAlKgQCmokpCMTNU3MtzYxkLATCRqAkFl56YTNBtOMh/biF6u4AGtwkihgo+s+Rl1mgSrAR9jta9CxQlqCiHSleOgyTIx+mdcD67DKqo0ec+z07NI+vS7qbleizBSif6NKAsLKWJqFy9W3c5m/xLtmnYmrDewyG68c+sp50w4nUvIWT3ZaAVStIlZ6yz2oh1PzsuFnttZsbi47cTrDDjrKGxxY41N8I7REwxbe4gYFFySH62sp6izUsxV45YUbGKBkioyZzxPtOFVusJ9LGBgQWnkekMV+8cuc7z3IlWmTvJChg3iAj/q+Q5BrYHnJu8l729iu3aRptU4u1/tZ83sPDGbxI93tXGi+hDj2rWEtfU0J1bYuzxEuSqPfWUGp62XSXsNoYLKxuIKNinHpK6WnKrn7y//gO6FaTIbGvh860MUNQZEtUxG1FFbTtO/ycFEhZcPrbyAy7mZ10yVdF4cIKJU8EXtUzwf/xybkkZ6Sn4qi5PM1baSNulAEFAFkUhFBQWHm6u+Gh6cLVNpShIIvo98tBVzeoW0ow+ZDAl9gtXqFsqUeP7AQ9wzewTdcpraQ4+RrMhR0fgmFZ3LGHwBch4ZjTaDfkrAfrVMxejbtS1utH+YC6U7cIUk9KE8KwvvIerahPWuUwT3i+SECuxCBpMrheLxg0kFUeUX2scYMD5Kd+wM7W+tEDXkAOhYCfDDux8ibrPxZG+GQzUOzo2voAsuoshFpGyGNWP99G/bwz2Zk7zZt42HlLWk21VO2UbpHM/x9I6N7J67jmou8bzvCO/c1MFUWoc5GmdZGyMhxrCoGQRAliS2XL3Mhx57mOkXXyCvxtEYFdILYbSKTLzaCiYPRRXUsowkCRh0RgzFHLZoEKucoaTX4tx7G9ligWD57ZLkGquBhNlLXpxG1osInk5cipmMSUe3boyUaGeSPPvKLizZvYjiLBPat5iQd7CktuKQ1yPL2/GYnsSSPcGTTqgsGXk8ukD9UgaNf5QF5VGMhSqWbOO0G0Qsy30UA/2k96coVJWoe+uP0ClO3Nq/JaccIJTbwhp8LAqLdCglzJrbqeg8gfcbRjRTGrzvecfvLe78wRPwb/jPFgEr/bOcspuRoyV0umnyuhDvSO5iPjmMKZilpdlPv64bz3iMWHeRPjXPi1YzQ64h1s/Wk9F1sFCUCMxoceXWYy004rN42H/TGm664w4O3XUPqVSKpUSaih4fUtAKMQ82sRU1tULm5GHARtUn76BmXQsrx8tsu34/uxp20txaTSoa4jdf+iyKsA0EH75dT/KDwhKTFVN0+behEepZ1V2mIm3AUVzPhdYNRKwSH3nhJ9Srk2jyfi47XkevaNger2F72k6dzodZMlGpVBLKmYlIVUTNTvaIeqY0QZ72vMaq/rdcaRykd1gkUZoiGJxEG4hi94p8JD3Ddyrs/LbqLlo4xJdmDmIWjPh0f4pGTPFN437O28d4YLaPK2IXLn0dF9xaPjgexfSbEX7a+QgndrYxm36E5vmr1AWXWPb50BtyBHSjSNlfkecUgqDDF69hXWY7tcsBcgYt/S1pxvR3cmnjPYy3rUUpwfb5U7zpCvO0A5aCDXhTAjVVVnRFDeZCgemlSrKqgrvhH1AEA6GazexXX+aH1x5jMVHD2q55/rL5G/R4rxNKukiGTIiLOXTLKdTk28YoucPKVPV2io5m9qSeYT7dx9W8B5OU4z3dzzO8vJ3nayBXDKHq8mQdS5jlAg3TrejKIoJJQyTdyEJ4M7XOQbbf2IBh7GUWtBK3LVxmrMbF65V3EtM4KDm81Aoy3YkuGlPV5MUkcbGElPFQVVrEZQsTSHYzVzFGWh/HFa+ga2U7w80GZtIORIsOwWfhtktfw5nRooglrkvrSXjP0piL4ZDLvCk3crbYhj+v43q5ik2xIqtuP4phAJ94nqhJIFjYyLC7lQf7/dTMztI6P4lheph9l6H+eoEtq3Osi83gWBllx6VrCCpc3rwRYaMF0TjD3uEZTnVoUAo+FqyV3DN9Bn0xyWR9B9/fZ0SOJijm3XzIcISbjRc5UtzGnw/8mrUrk3zxI5/mx2tvIhfWgEfD/tRZrOkkp7U1LPgcTBoXuTsd4H9zbiSDFfvIIrJWS7esomY3gSojoEFVtFxsrKakFWkVSmybW+FcfSOjrgoqc0UODqioih65aAexTFlrwKydZrJBjzkSQJeLgrOFB33nsY0bECUrRYdKzbYfYnAuYjRPoDgjyE05Yo11HHf9BVHrHjyhKyxXriPq3cWr6808EnmaLZnr1BauMC/2oN9ymleFOwice4zXBjrxTs0THq3A3RujdUbPf7N+gsHaSqb7KtncP0hDIIUzk0dSFEbXePnE2A/I1RxhIX2W+dlGNLEgAGWzDUMuw/rxflabaglUb+b9czK/sJ9kl+UK1gEdkqRStFgYMfSRNA6yvOqn70IEwgGmXdXYlqaxL09jD69iTMUoiDmGzr1FshBFVUHQZpA2pfGb16HXVaIYzfi0QSR/FMFwM5JeQ9EEogDmvIzGUkkIlTorPJLezAa5inkpADqFk+3j2AxNOEp29pZ8TGniGJRaBjQBHKrIhtJGZCQOM0rlTJ69X/su3tptJAeqKEiDeIWfkpcKfN0lcDCxh5rXRZI13Uy2unHNP4KqH2Jnu46g4QiW6C5s+TZE23EabuxDyt9C6vqzpK8OkGjYT61kRckJdMRu4BxYxdzkQJQ0aN+aIGcUqXnvo7+3uPMHEfBv+M8WAdGIyLXlCVa1DtRihKJ5li2yDzUJ9rkl6hpDHPFtonNkEbmiTKWtSGXIxbP1MmnxCtUBPUabjmqxAupFaurr8M+oKIqTrp3NaHUSbW1txGIxrk1MsJKXiOZsLBeCND5wAG3cT/7qK5Qiy6zGNsC4G5vbQHCowMxQiKmLvyMZURE123F2vo6uN8eRUIgaayXuuAlzphZ7uRmdYSs5g48jW0ysmRumYWWcnK2S87VvIsha/m7ZiBjewnb9Dn5bI3HGVmRvVoNWWuGP72riYCpNT0bHc8ILnGk4i9+Zxl66lVaTkXPRVg67NnHv5Gkedq+S0yl8weXmn6ce4WDYwVmPgd96rrEzdYxoQU/0QpHHj6fwTV6F8hRRocxnZ3W0vv4bppybyepvxjMYw52rxRI9S8qQ4vDWDCdappDVcVTRSV57K76rreyeDKCvvokT3fVc6byJHP0UdAK6lTrKZQ3lRhui9CZJ0zi2vJ2J6igWQwdltY45dyUGf5prRS/rq1/ns23D9BgnQDVy+NJ+CnkTJinLn7V/HamspTi5hZvXvMSYbpiCmKFUMINiwGic4x87v0JN3s9p3V4SVc08qPZzPVZDr2uMTuckXzXuRJc5gihlEZApiy7KUiutwVV2z0fwJSLcv+MIJ4M7mc/a0C79nF/WPobf3U2k1UjE0cEI9ZgoElSttLNKpiTix4lJyFOhGDBpB/kkR9GU/Px9yzVKikTHishU1Sp5V4REtpLSikih3cbWfILKqYtoFRmzNMmCtg9d1Msfv/oSLeOLvOLegaMUYsFYT1HU4Uit4ikt8Lh+hj8urHDeEuCR/us8MfAmnlwCWZZAFMiZzIyZ6nCqeXyZEJ5AgMpIhjfXG5hrXIvHl+W62IlGrWO4AabkDkyynrDeQVdqmm5/gJd31hJvvhPzxAIZpZJ9wnX26AbJjWi4c+Y8373vEd5hXuClRDtiSSG/rQpdeZT941cYrNyA5E+Rq6/jqPcA16zt3Db6BmMZHxs0M0iJQ+QMZYrmSYw5H2LJTJN/imiDHzXo5k+uCJh1IoMuLVtmrnFr0zFWp7YAAqgSjfce5rClhpp4DFWvQZuMoSnoSI2sko3HEXQFqreeoJDoIP3zKrTx23jmcgf6iyVi42Ze3rCdzlUbN1p2MNuwFWNB5cgWM3WLC2wKD5NfNVCqGUBozfFC4iN8+Oc/ojs5ikkXJZS2Uy1spG/bAwRmL0NCQ93IDPlSGnuuiDObZ9FpI6eU0R1IoFdl5sY3Io/7QYBYTzOeBw4yHw5gi6axrYRoWponFL1Kyb9EeNlDXSSDXpFx2NdwKavBFNSwaziCXjUyseld/G7zVnrTeW4utyArUMyvoHVm0JedFEoFdr77A+x7/AH+2+rz2DMujCUrWl2GU5Y+qv0L6PMR1OgSCAXKrkq0Zi9xmwGvYqMh00CN6qDUWKahrGdUCVKXrqeiWEG94KCrXMewtExYLKFIIlv27eN0/AajqSTeWZnSFh/ToTD6Uxk0BYXjqX5umJu4ahK5ZCnynsAhnOYeZm4+SuXU+yDv5Hi4msHZOvKLDgx9J7GGD+AWOimF95KSlni1GVzddyLmvFgkkeLSEcqjl1GiS8Q2DeBZfJzyjWPo5ALuD3/49xZ3/iAC/g3/2SKgiJ7J068z0NAF8Rxa+wA+0UxbchOGmQtoHTK1kp8TukaEiA6dR6FTG2Jurprza4pohBRK9DrbqjbQZ6hk/R/1YXEZGDmxxOxwmIYeF6gCM28VicWi5CzLuBp0RLJFRpeW0d61k0JTI1cXLCxHTfRWp7jnCzfhqbczcWmJVKwKjb4VkyuGb9tPeSZZgV7n4c88uwlGJ9GEg4jSWkQpyZWOKaaqm7nl+LMYtBqGWkbwa1I8Fqjlnvw1KuQniBt0fHq9ifM1FmqWJtiqNtC7EmRfzMhSdoxkKsubG++jZOgi4r2Zy56tRPwmCqKBvsoVDpgGSOU/yoHEe5EyTkZL1/i+L0OX4QaHkpcYudFC41SWqfptnO3twRdeYdvVU+jH32C+PsGo3UVW18IpazXG4iWGW87zg1slAg7YcUPCGXUwaf0AufrthF0NDPVs41yrh9H6FuIWF87kCmrpIoW5dRhXwKGbI6d9AX25m87za8l6/Ey6FhGkXo737Cc0q6KnyGc3/ohIwUsRK6E5O5ORDm5rfpmJaAfTkVbU6W6M/t1kow1s7jjGmbgbOdeCqkrcsvYXrLWGmZnejNef4FplO/NON+9WXuFgx4t8M11POX2WVm0ndwuPollwkNMXyOuWWKlyUZk7gCs6RXZCj6G6zEhyK7PtKxxM99BimkBrUDhbbkRBxFv1PNF0L4Kq0mRIUyHm0CkaljVRPqccIa5aaCGJdd7NvcfMvONCjKqEl9c6F9CV30DQJijUdlC3+CM6phQaQwk2rmSYqZR5/PIVqrMJSqKWfYuDDFe2EDR4qcr7mba08KhjhXdlr2Moq6y7pKdlLI3Oq/DWlo8x4eplpOUgwQ4D8coKVlsbON9bwXcOLnOux8CJtSUeiqxwr2kASz7KrKYZFQ/D+W6osWKSC0wYarlj5gJZ7RLj1UHK/g3ISOjUDlYjLu7rf4XjdRt5cecB7pj9DUcKOyk1W1EdAilbC9sHT7FF66JfdFI7W0YwGsiZJfa+cZjztq1sKgm4ik6ythEM2Tlygg0EHc6cm93qJXqH69hs1NA3dJ6K8EtUZAWyMztQyyY6+2yE/UXO0EltaAytJY2sWtEkwgjlBIpoR29NUsoohEacRBabCFsloqsTePIBqhvyGFsj9BXPYKqZwFM5h40kAVsbOZ+MfXyahVkNutvfQ2zdANNiC+OxQzRcOcPawARubycBu5n5mQArES2lWByvP0jlzDUQBJbW1lBTHSZWoSFaNBGdrMA2J7G6IJH739l7zyg5qnPf+1fVOafJeUaTZ6TRSKMsIQkkJCEEQiIHgzHY2MbGPuY4cGxsY2xj7OuADbaJwhhElECABAjlHGakyTlPT+ie7umezqnqfhD2y3uWz1n3rmvOe9617v9T1VO7au9dtfd+ntpP0hl5+dovcqJqFUdS6bSWLKKjoJbcaSeaeIiUzowmM0QkPR2rN0mae5pmlZs5sx3M8bsJGrRsS7+b00GZ2979LdsGujAYo+TlXk1xRjXG8g7cA0ZUKiO9ooKLkSGOBZpYqJoPAQW98Wz6qGBZqYPE8DkgSsqwklqVgxG1DzEeZV5IQY1iHpDEFtiJJlrAXzIPkxbOIKAK4hb8xNLaCUd0JAUBkxDD8Pb75Le3YnUrmchZQ8iWoOhEB2nqcpriTVQffpsLRXUctkUJqvx8/mQmxuwVpFQB7M7LmdVNYc8OYB06SshYylRCQ4bJB+5akjI0h/yQrCM0Y6JKp0BOJYgqJOTuE8QsoFi5FsNQLomho5g3bcK8fv0/je/8t/AOEARhI/A7QAE8K8vyY//u+r8A9wBJwA3cLcvysCAI84E/AmYgBfxUluXXPrlnB7Aa8H/ymLtkWb74Wfbj/xS2HBNF01NIZjXS4KW0kpO6CTL15bh1kPCZqCmZ5Kwxnx7RQcyl4PqCNhYpIghNaj5aMM7yYBos0pA6FiVw3En1mnzMDi0fPN3Gm784j1KlIDQb4+obrqHbfYa2tjb4JAXUyQuXtvEoBjjDsXiSjodOc80X7iYRfAmldgk9c2rxlA8yoXmcNkmDpDdwLPFrarMv0nu2CEEcIyX7aC65nxpvL5nxJEOGUXq1bu70Bvhm7BgXg98lTWvjwTod93b7OZFt4NHLakjfe5al1CAJKfqmjvH0rV/AHAuRHemizajF3OokhgKzOslWzQniUglCIky++QGmU2ko7KVsVtn4wuguTujmoxwO8ehd93O+dikhDVz/3vMM2EBUBYglLHQYzRyzpxAz3mLYehqFJGIJaPjcIZFFvSEe3Pw5pCkrzJGR7WoSoSTq0RDzZgdJG+zjjGEF6rIzZGfuJnN8I6PR15GUelypu/h4qQ6VegUW4Te0WN+hsCWNqWQeWyv/SlIS6W9ehjNu58NEKTVpzTSknyPgs3PcN5/0mAazdhA85YSGrsHqqSKYspOVuYcttjGOcxl/KVwIggdd4CJ+lY6d+VVYp88wkxyj0HcNZdNr6bRp6CirYzRdifyJC+jLufD7k8cZ9hWT6ZdRKlKYpzYhWrqQ4zDjCTNpsFJsbGLa2kKR83q6hTwWDZ9GrzLj1i1mk3wRoxa+F7ibL3TtYeFEBEkZJajTsqJ9ir6canaVpqO2nMbuOs+EUonLaueFG3/M6sFGtnz8V2o9Ek9cZaDPnsajr09x//k9/HllEZlyD2/pVuOJpOOc0TPSZMLqVqAuNXBy3s9JzUjYNCoyZ08wnD6OihzcWjfHM08giRJOexRk6CgOUNiXxmF3NkuzDvJX6zWAgvsizaQ3HePhyi/SllvI+ovDFDi6+G1qDRadE9+sgbUn9tJjL+B3i27EOBrg99I1qKQ4SsN7BMVbicoKXJZMan093JmdzcuillhPDEVvjPfMGwBQRgso0sD7mXm0Vi1D3R1g+7QKlcHDbNeVLDJJxBUCfWkf03B5L5MXCvC5rECKAWUbHmM+RcMxQo4kCyvfY+J0Br6EGV1mDGN2P9kN00xOFuL5uIFksAMVMgmznWS6DfNl+1GpY0gpAVlyAUocZQeZ6p5m445hUpKMobKKto7XKS2ZIXSxlKGyJO9du4VFz/6KrKs2c9e113P0u0/R0nuMqCAiazQA9M2rp2POQvambsSS8KL1BCkf66EtmkVUI7Jzw22YozP8S+R3aFQ+WqLz8XlzUGXlk0wlmb200gEwkiORP+ZkrWMzHssEBvMYCscXEAeSKN1v4zemCN7/VV7y/pStESeFzd9BMbiaQPwIS1duQhl6l69MBEDK4PBwBWvUg2SnWfnuSj22RAYnxnNJJKKsUlegl45TLb3N3pEC1KYRBG0DMjqCqTvxqM7Saeqj1OqiKaDFlDSyoH8USVyJoNWT5vVR2tuHKisL/TIHrqgGQ7gUv22QX6b/iY1yGumbNrLx0GH2f0VL5ZBEV56BBkWErN5bEI0qar+zHY/Py6j3CInIy8yNu+jMKKMoZmNQcKGJxCkpmUOeUyQ5O00i0oLRtoqRrAJil/mZ07+Z5PilZETGtdd91qzoH+IzEwIEQVAATwLrgTHgnCAIe2RZ/nRYpAtAgyzLYUEQvgw8DtwEhIHPybLcKwhCDtAoCMKHsiz7PrnvX2VZfvOzavs/G0arhozZJJJRhZywgAw+jQeVoGQ0W0++O4yEiLXOTN2L3bhL1Exlm1itmSboXMSgs5f2OQEmRzooqN5A4MAI+voM8irtbP/2Qt77QzOSJLPtwYVkFpmZSz7btm0jlUrRfOAMJ3ZPICh1VK+zY85VMtnURNvwMC++9FfUsSjRL67k5dkkKtZgT4YoTp0jKRbxZ/lr3NuzAx2jFJl6OJG9FJchnfq+brwFuZzJbcfhV6NqruLjEgcVmhW8lSvij09w24SVhmCUuxwa3lxYg/noKWKpAKeqavGYrdy+dyfGRADlnPN0TudQoVXyaOJDslXTnAwVstz4HJ6oCdESYHnsGJtHZklKCr43/xvEHrRgDumIKwWWnPNxpqqDgFZD0UQW+wqvYhwHuoLnUeoHWdcoEZi5kqGMtRTod6BJdmJ1+1CvmIsyLpPjD9KfYUaKqrjqzQOUukZxLS4lNlPDtLUDb+YpVFo34ZG7UYRSKAgimTVM13wHS+DnhG1/wGSDA8ABlwh5H1z65sAI8NtZIHMPpsw9tAAtskCW82oGnWvRKsNsUHVTGDYipKCxV49Z/8gnXvl8kpQWPKKJ2Yyv4M6vIebsJy3gI9+rpbbPReZ4N2oBhLR02qkFg4wCgYqEm7ZUNnUzrWRPD9FUsBW1nMAZM/ON1/IwR19AmUhRMTOCNpUA9gPQRxYP8AYhpRZDTYREmZbb4j/gyUO/5vqjY+xR34qmZAMWxX582hPsXT6JwfcLgrMpFgxJ7K8XOFyaj0I/yCMblvLwB+e45/wfOV5byXd7d1DlHmM2YsUsCNhqwqTVuDjtGUMgj6T2EKfm76ZPaWT1TIxbkgeo8JmQen9FXN1HV9kf+YvNzJt1Suo7g+DMRKnzISCxs6iG5UkweWd5oXYTv5j8E7UfzfIsj/99Hk5rzTx6y9VE1RaSgwI+dRX58gU84bMoRjaRKrDx9sbbUX20k5slAycq/bQai1hyuoMepRGdJJMpJ6nQ6CgazeZ4ZxSfTo3WEicRUVNWpCLHBxdKTqAt6gMRLEUnmRm4jLjOy8GZEOWJ45hnkijoYvjDXMIuHdaaEAXLJxDFBLFZG0NNX8Zi1KFdPIddw1p+eOIZxu9zoVTF2R34LsPCHIoPv0PRRC/l1w8zN3cfg/Nu4LeVV/C7ZfX4mr5IPDGJ8nyAL539Fc6sQv6yfj3XnDnHbG4hQYdANKJFEw4ipRS8f+VNTJSUkuMdY2V3B6J8afxhSSdmueTHf0vjQayaWVZv+gr9J17C502SL48ha4NIMzLhdC2tWeWMkkOuVMCKs2fQpwbQC2sR/Qk0YYkDCS8FQScS8N7Tf2bh1TMk0qZR2X7LRHcNClHBBdsu/hxZBOr3sc9sJ0MdxSF7+KL3JXLevRTX4nqtwKT4S1JyhHZVI0PUE1AlOB9cQKlVj3plDrFEN20DvwWsZA59Gbt2P8PWFiYmcphRxygRg3jjM2R/uA97bh4Ay85M0v7YDj5aPcxBWwsHgdL8fFaOB3EJYRYEqlAtbMIfDGMf3oSfCG889Qf0ra2sPH6CAiBqi+NYKDJxxV8QLX0sbQvA7JNEE3b8F5/FPFeBIF5OW/XNLDI2o/CaGPVdxAEMNEWo/+eFCfhfxme5E7AY6JNleQBAEIRXgWuBvwsBsiwf+lT508Dtn9B7PlVmXBAEF5AO+Pj/IQRRQCNkoiGBQgBlSk9IvGTZm8zMxTTQy4VINVcLh2kpNlHcq+FiWTkbdI3MN+XBuV6e2Brj4IUPWf3g54j2ePG+3InjtipsWQZu/eFSZGSUqv8nUqAoioiiSMPGlcQCb3Jm1xsMHlByxd33sfi++yh58g981NfP9JwaXvGFmS+08IMMLd9re5pvZswyHrfzK+GnvFZ7Lbf1/pluaz1H5m7AFPSzsOkUZ1a5SCgTfFOoZFrpJ8d3PS5Dij8Wq3hqTw9Y6sl77Tts1z3Ia/UV3Fq4gOREO3tWr+IydycOnQq7uoSlEzkMEcVfp2Je+6ucSNXwlHoD/RnZ/FvFA1T29fPNnc9hDI3z3jIHpa1R9i4rxuH2YzrupDGphfg3cBakqDV7KB0ZQ135NB5dmDsOw+auJB9d6eFgTOah3O38uflXaKtUhExqdrR+D6VXwZ9913N6Ti1PfukeHnr+SVaMnucFxzqMthZU1iZqhm2cCZVSF5PJT6n5SI4SPy0QMt2DoqqHgkQ/hVIzM+4sQrE8RuV07JohgpZBRClBg3Md6pSSI4YwGIaYyH2ftKSNNak4aVo3wbiV021rGbOexBQxke9ZiyY2wVbjWQALO6gAACAASURBVKIqEZ1CT7e/De/MEIbUv/MlTs/+5ED+22hDRGYuXrrIpEVTiZCtZVS2sWn8IsuGz7FoapCEoGDAksNHBYtBk6Q01k8yKSDIEFFZ2THnOnIze6mOePCpNfys4RYeP/YkX2h/DzG2hhhLwDvEQHEGbtMgX3tnGo/NwK3l/Rzs/TxBdSEdquX8ZJ2JHx3az/bjJ0gKAuczK9m5sIqWhS2gW8xPJ4+whl9xeKCUnQv6caqgnBrGrXEmZmW+7h/nw6zXmXUt50HXJI+lLOxVZnGizoM7LcqEuxqFA8YystlnMlNy7DxdqlJ+fLsNTe8VmKUw8yNW2uUI5zMr8RbakeVZGLz0zmK5h5GG7qCwIEakcxpfsYUd2+5B0+mjM6+Y5e4UK8beYZl+DhrNZsxxN4OWKJWCg3mFeg6E4kSnVYCKGZdM0iajyduJKMq4xpeQkXMGU3YrTs8Uy8+3ISOQElSo/SESgoK6K69iUmOmqXGUilolOuscbBEL04YpXvcXEdKl0KwoICP7NF5/A5a2SSi088bmO3ly5DyhwXPY6w+hW+UjHrfz/c52fqpqZky5madv2sIXX3+GTI8LVSLCgYJyUkcPooj4iSk1HF25hvr0Zr6f8SPCIRPNnZvQaKNkamBsIIJyxoV6voXgmAFBkolbDezZ8z6ibGFYsLCp4V3KR1YyPqSn4+IpDuRWEVbHcafMRJUqFDMd2GybAREhAX5/IwgyBxa6WNeYQfhiNorCILt9JhKhTgoM1ZT5tKTN+yt7RtTkGUpZ5/kta1TtnLNv4S/TBnriaZRKFXyObIR6H6WrnmKuTse5Pbto3fsOiVScxh4fCk0ub6jrsETCJMfSUdtCJNKTNKYVk6WuwhI3MON9n12/fJQ7fvZrNHo95YsyiSVGeU7vpEEzl4bdzXxwZYAd6y7lS7GZ5mPIfY5Udzl9JCkJKrCnZzMveBpUSqwlEaLTApqPm9B8DKk8HUPlAibxHMK5Js7kT+C4mE3tvFFWZuZhcmWS8LQyaQih1xrZW51O/WfGhf5jfJZCQC4w+qnzMWDJf1L+C8C+f08UBGExl36K+j9F/qkgCA9z6Qfsu7Isx/7Pm/vZQs4tpmjCyaRWiRy3EJACBJVBTLb5QC+DnjQW6CTUNQmkTh15HVPE5isw6w5SFliANXiRjhwPPe2nqLhpCTNv9DD1xAXsN1egLbP9p3WvuOF6Cmoq+PjZp9j9ix9Ttng5vslxKrq6ObX5ZqKimuLOCV6ftaJKeXBFYvxpOsX13t/xUt23+XDVWiRxD1OGabYPaxjVT9GinuJaU4L0vCYKErfwE+2LdBm8ZA7F2TEvG4XUhP+2fOb3/Y703Bv5aWkG4hwldveT9Ecu0lF2KUb3huCrnPbMYO2QkAUYIpMTUi29qhq+9eIzpESR57dspyPrA8TkALL0OKa+dXhKrsdcn0ZKVpEb8fCNnX+hYrSbX9wg4rUJ3HcgRfUNcbTtUb4a24tWZ+OX8XU8sfYWPl64iobgBYSKIfxBO1d0nOKrZ5/nvjn/ysPzPw9RiWUjrWSZ4vRpFbgnb8Rgklgd0+IIT5Ifd/B89hCx2SIU7YsY1ixjNrwIP0pSkUJU1vModYMYk3UsnVhJ2Vgh5dojWLzLeMcQRlPwPJGCVwhPrCbLmGRa2cmr6mEUspZr2x/AEIVolpVtobf4U9YD+GMekl4lBpJIqRSTSi2jBXOwhmewz/YiC1G8Gi8JMYIyIjB3/DZ0SSvzMntoihQSVBhRSRLXzXaTP9WNoyrA4ZWL2SFcRYcrmy91vc01i9o4HKpgr+9q8oLnuCLQzTNZazknhVgmttPsKOFY6Tyu6juNl+M8sdTBkikHtx2cxBpJIEhKTKui+NV5rHL30KrLoc9hwFXazmPZSVaOqHijGlyz1SR8i7GqNCTFc9yfnok5mEvSoUShlKmPr8TqMnEgbz+z6nnYlBE2JN/Gm3kQr2BlnyGD+pZMRjIjdGd7Cc1mYtIkiCdSBHQGpDmZ0JciEbiRpowytNlvIrun6UlciRWBIWMOev8eCpMwbQsg6yN8wZPHyWwzSzt9RLsmeX9RnCfnXQoCtKGzmVlS+NT1OIQk6zJz+KYqxjK1zE3+BJ9HYDBbTZ87wpR/mAP6MIWqEDN9q3G13ojpykGstbuZeCeDlFpLuKSG8uwJMspaSLf8D+oarsXpdPLMM8/wSt8FCjwxillO/opMZrQWRJVMQDGJ0gdvd6+mVHKhjIfZGJ1l2+e/CHyRZ87+gJLgK2zRLSMQGUBFkqdHFxPOMLG6vYvwqvXsLcpFF/ASSSbRGS1M5JfhKivinrN2PGcmOOcoQ5HQMyusRhHRMl91is74GKERPTqPkzzVNNekt+FNZPBBsp7nU3fwZVsB1jNatFm9dPskvhx8lZ70KgIKIwmbGtXYJEKJAknhI57Qogh2oLGUcXlBjBzRxcTZTH4d2ESJVkWefJgskwPb2BIqtDOUCZOMDV7kSnUjXPEIK1Y8QF0wznd/spMbhXRmFGOIKzdRk2MFoHTePFr37qYr6kSzdxeT1hwGN4+R71rFUOw9ylyzdFTCoqVpLP3zLqyGAqKVWzk48Sq7fvs4N3/3YWJ9fYg6A6PqSRwTC1gomFjzxBnOPPB1zo+NsKD6LGLcwKGxlbxIhDcwIvUaUVxsBmS83WperlzPofoFLJ9oY4O7k7yj/cjJt5GB+SElOmmYVOQUluiNoNQS7txDljKMrbyS719X+1mxn/8U/y2CBQmCcDvQwCVd/6fp2cBLwJ2yLP8tk833gEkuCQZPA98BHvkHz7w0Q4CCgoLPrO3/qzBUlFHivMiopQZFPANv0smgwUmatJCw+g2Ufhf75q5ive8kg1UhxE4DPquB0mInkwWfY92FJt5aGeXo0d3Mf3QzqkwDnr92Mv18G+Z1hZjW5iOIwn9Yf371XD73+BOcf3c3p996lWQijvJ2I+fSa5jf30mmK4Uz0M2SOTLOSRmUcEHRy9Kmw7QX9aENTWF2P0Fdlol367xo4iLZR8ppmzFyfnEnHfoBlEINGmWYMAkmlR7CJh+9WRJEn/tbADw0koa1PoGtcRf7E9nszjNyWmPgpx4XFQmRN7N1MAzCRJiZklzGDSlaMs6gTg4QndqMQjeK1vwBlpFj+Cw3cG3jWUqG2mjJV/K7DWkELX5SiVtw396HpDpM71w77370M369Mh2xycNRQw3mE0622l4hUqjHYp2ktyafb7vvJeoXQJBAhIZkJ5ueE9hVuoJna4u5JqQmv+4Nsi80E039gH+NahioeIuPJy5jMpmDJpFDdTKITvJw9UQamrH78KWySco6KvUfcUC3lkNzTaQnFQjcSyz6a05kniCj436OFb9BRBFhtXM9SVFGEG3o3A6e1v6CRCKEVy2ALJOfcrEr7wYiOj2l5mFOKl8HU4BtfjPf9gzwge47+EZKMEhKJqP7mesK0mHKxiWb+OL4cfK6zjNbaubkhsV8bvJdtssH2ST9iFerruAB3uZp9bUsVy0mrg+iC3dS6llGv0ZDlXKA0kQfv6m8ieUT7WS6kzzaOkWwJ4g2kWLInMUL9Vu5U/MxnYGNkDjIhaxNZEiwKDlBvz3FCxmQN6UnPzbMGWER0cGVaIQN+JOqv4+NckM3+4tXkaN5BlmGyzsdTPm8nC0sYbFmgCcstzJuc3CF/zxiPJ0eiwkZBdOFaTS0nWQkR0d7cT1Fw120JsoQZYkrxr2oLMWsiffSkZkFgsgdH55FEXfiS4rsz0symHWK7bMKVBUudo5sZMtHu3DOW4PJUYd65DQBpZUMsqloyMA36OfbcTU/dPdgdrYxW3cZdUo7qtAHJMLdKLVB4sF0RuM3UHHFj5huuRa18S1UsSjh/DK0mEib8zqzI4v5piWXbylHucpmIamDypkqbL5qIio/v0u8i2z7Olcm30dkiDdjt3CxvBJxXEHV5DDXr13197m9pvpfOXn2KGtCvyEuqZhKljKTV816IUla6Rx6N6xCd/48E2YH79SvYuv5Y+TPuMjp8qAIr+KCfhXxRIDCeC0/jKWAEN/XXsSsjpGanoBkgvS0BAmlBTn2EIKoJ09yUbBvgkRyOQdNBzBbUvj9Ch7J2IFemcCVacLTZkKKhxDVVrqFV0jIcepKE8hmN4qyEJO9tVwevIg+aUFW2WkwPs05v43Cvu0smvcE96p24BLS8RXfQXvTGDvePsBiwYgWJfenLHT9/gSXlaXxs21zMdkLAeiPD3H52CHsHj2QJCIXUhQ+zFnrYuTUh/zV1cum6XGEYJiM+rsJOi5jvPkIL/9mK6bePJRFBciCzNZQAbKxDiF2jOxX21mypg5V2iuIPdvZZzFQb1PxVn+Y6y/sJIlM9/wGdN5R7uj6iKvDHXjufpSKljhu0xRy70MYTyrQqBIkbTJyy1Fkxxak5CABtQfjTBz1kv+9xG//THyWQoAT+HTP8j6h/b8gCMI64N+A1Z/+oxcEwQy8D/ybLMun/0aXZXnik8OYIAgvAA/+o8plWX6aS0ICDQ0N8j8q81+JrHmlFO98l4+WLkbpcuBPiYwbnFT4yzmbL5Dt9PO6ditb5COMrVCxMtdNV1cemXNmKYy+yPzpKnZLPZxRdDLR20VOeRUZ98/Ht7uP2f3DxEcD2G+t/IfJgzyeI0xNvUdp6XdYct2N5M5L4/yx7/Nu7lbisobtb7+DWZOEubVk9y1nj/0sgigwZYlT3LoHbbqHqH4F2uhF/jLrYVqXonYyG39USdsCHa2mVq63JqgMDxMMPM4V0yn88jPo7OO8PvUgMUFgX900Ihpe6HiXGsMFnM02dhV/j4KpZpQ1u7g/K4MC/0K6cu9BEY3inpAYVevRJUdQp5pI+OvRhNYSrjbwy+4v84LWT0zcwZEKOFIhAhJCMoFl6kpC4XyWFu9gUs4iSz/JsS2DKJuVyEpIlhhRt7t4NPQNCsc9qFRJ+mMZyHoBcwrKFWrOGSV+n3cjwagOy2yYr7V/SJ42RlPaMSotEpWnXqFNeQ+lfUlW6c7w/fnb0cWMbN5vQkYkpTCiFBXk68+BeoxQNI+EqGHN2b1sP3qEM4vm0164nsa0/bxR+2skUWLjZCWGhIGkuZWU0UdAaSUpXJqegqTAPFNNNGHjqmkZCJEQjeRor6a+6xQOj4cu00YsdolRR5KJ5AXm0oZ9xR284jVQ2DXGlqb3CBjzead6I4qhCZ4LXMEKWyc/1rzKLYkf8C+Re0mP1aFAZnpJHRmH2nEpJLQiPLX2PgoPXCQmqXh4wW38/NiL0K5EylDyg9K7OJdbTa7k5quJB7AnohTYl+FXatgUUZE7+DAVBQ9iTSWYaiqkpXQQVfp+Yt5lxOxqMOlomGqjazYTz2Au9fp2+hVdJNR1PLHlPrL8XgqGehCUEgfnXU7GZA+myEWG8yZIhRoAGcmmJTB1kETCjVKuJlxsgx6ZbNlHur6esByl1d7KaPpiTLEwD/7oeYTJKY7f/yBO+wQXsvewOT+MRpXkRg0c8GRR1/QRV+Zk8X50lFHzEtKQOTMzxpNJkd/LWh5vfRPl9AhdqSju3DSmwt0YzAqmW43EVVtQD2oY6X2IZEQkETmOIStObmoZity3EYUk0+3XcF9wlhCzvAGkKxfgs7WiiltQInFNx60MRMbZlr+TVup4K3M7tlk/FwrKmOOZ4L2DZ/Ha7DT6Q9ykTNI8sI6ril9EUMr0jVZTKbRxzcqleL/3XU6++y5pNgcrXWl8/WCAVGQeL6eNovP18ab6NEExyqp4JX9MKtBqRF64cwF1r9/Pe+YKZqfjSIISk34rpsj/YDZRQgFhXla+RiL5AMfNIziLTHzg2sTNvjd5IfR1ynIXUG37PhAj7u1DnTmX3kknpvQwyYUfIKRUpDf+gB6DlmLfTpKRcert81GoP8BsfYlo8ocUuxvQWw9xn+s7nH3iFAAGDDyEkRmTgry8dPq63RztnWblLw5xLSrmqTPweLoRkDFFQizq0iIGhkmJMm2ZZqRIAXr9IADhYiu68DT19lKm7XuYOmvGWn+RATEDgJK8OhwhiVDuAnLGD5OY040ibmIq6yb23VtP4/AMj517ja3O8yAIrJCPYL9pAYFuDcL7o9h/8Q3k+dcSDx/F0nhJnSAIwBfmkb3uK+j2vY+6/xVGC2oxuIKkctI+U/7zn+GzFALOAWWCIBRzifnfDNz66QKCINQDfwY2yrLs+hRdDewG/vLvDQAFQciWZXlCuJQZZyvQ9hn24Z8GR66ZHPcMklGJ5LQhA27zMOpxgVShkYz+ABq3j72OVazwNZJMF4naLUzOmMnJnaQpeheLu7u4MCfI+Y/f55ryKkS1AtuN5agLTPj29DP9bCuOO2tQGFR/r1eWJbp7HiESGcLrPUFZ2Q8YGP8hirIc9ifW05A8y/PFm3h2/2MkM6A3s4ZC70oM0WH6c0dpKfOgiynJDTegjjoYtO0BwFtwF3vTO/Er32a5Rs1yYwTRNEnVSDtTiVLOx4fxj5eilU5ittzGIwMXWSbuw2bwMtlr5QnNdcyqjdx9vpHcCxn8222LGLbsRzfzfZZSzsdcwzlLCRr7W8gJK5qpjWyPdrHtwkuYT4T513ELr9ZX8XHuMsKCHTllRC2mMOo8fLl2BwIyfzz5Rb6x8PdUe87TOD0HQSmTPu6kyjeMXzTRYS9CSoGIwMbZMHPn78KUdJDtvQ7Zf5Ib244QVmrQJeMIyMxrBUkQEeULGMPtBKkix3SUhr4I79TlE9AcZ9Xk6wjWFEdsywlrDSDnkuGZ4vrjD2MOuJEEgcuPHMSweAPq8sUczz5BQbAWa7iYhCBgDobQBaKYk2OIiQS6sJ6YupKJ9ARz0v6AVwyxT59JjTONaw6fQRPxMWMtJXfiJIVjR6hViMyYdAxkF3PhdBM3CwoubzxGVKuled7dOOIyUeMUk+k1vJWqpDLYzFblYd5WrOEaWcWkYQqr30lT9iICSjVXzYocHelnUpGJkSDN9loeX7SdEnmUHXnbKREmeNi6k7tm3+WrPMnZuMBFy3xkrQKNbhzzRD5TYz/k2eL3uU4dR++qRq7dhMHxELnWDXytz4+vT8kRcYD9Geu4MTDOoHaGawIO3OYE56wOhq0LUQ4FyemYQD1wyZZm0hxCFaxGNKrQJ0eYNvdRFhFZP/wXflL8JfLHeqgOO5kqLqC9tBaH5zc4jZnUjA/z+vudmOdewUPLvsr2qTfwpU1z5kINJlFLZc0+bJULSZyP0G7+xOlIU0ly9gSmc+dpUBrxWMsxTI8gpGVBuJ1xvxXVfIk5C7sYeKOOWNcZHPPP4+28m2TkEFJcIG/lGHm+k3iLG1FPriQaz0Cphg+rdYjKZvTKcyxp3oKAgC7fhN0TZqX4PFopwcyB7dyQE2BfqRm/WkZQGvFODfDYx0cpG+tnR2AGAwIjirlkZ/fS6SujPtBD8ys9NAOZmVkUjhmpTOWRoo+oag73zxRwQkzSpRmiKJFHhZSLQZhlS10Oy2iFhJfLt9zGiy+8Rlg/h6hjDb7AGQDKiaJM3kFIOw7z/orSa8evSCemKUGYaGEguoB+HmO18C28031MGjUkoxJrHMM8e+oONsytAlUR31fFOZKxFq/7GLkWkVdVN3Cb9FeORZspmlzESEkO32rdRWf2GWoVwyjj80jjLuIt7/Cb5RtR3bqB3U1OnjsxyPoZgZAuD73rOABhDVzbpKbTMcRAboh7Vs6jJZTk/OxOJosLyfj2V5F+3858cx29y72kRhz0t9rpWtSHSbChXj+X3bohqmbXYS07iyG9B2voHtZsXQjAgnQNDzS+jAwo0iqZbu5EsbgG5YLL0AXcxJpfInLqRSzAJdNKGTEsULLgEXSZVXDbMnj6OJrBEQQEfOoU/1/tV39mQoAsy0lBEO4HPuSSi+Dzsiy3C4LwCHBeluU9wC+5ZEj9xifZ7kZkWb4GuBG4DHAIgnDXJ4/8myvgy4IgpHPpzV4E7vus+vDPhDVDT/qsgGxSIScu6fBD2ksbIzlZ5UAj6eOtvFKznqs8xzhlKmPubBevatdzj+5dCjWnWN6Tz6lqJx/27eXK0H1oDUYEQcC4LAeFSY3n1S7cf24m7e65KK2XXH+mpw8QiQxRXPQ1Jibfpq39fkRRw4eabyHFJFZeSOMdg5ZwXiaLTrbSf2uCtEgdGIsYTxzBbxjhiot6Pn9iB8moh3seUJJUgm1yJ5N2J+WymW3pkxxpW8iy8h4C5W/QGPpX3M5MvHlJOmvX8bDzSdZEDoMM/bE8vqb/Mh2OYq4STlNSOIXmXIwV09BXehWumb2csZ4iMyUxq4wgC1GSztspZZZIzMkfO66kraSE4fmXDOL0SVgmx9m88jHGwxk82Xwvnf5SDFEzuqDM2eHFdIcLUCBRGI8RiRtodMxFGw/y+LEnSShUoM1AkXMRe+kMotPEtQd6yO0Y5WhtA2+svorLXR08EP0TEz4HswMiOqfM4sanaFmwlfesi6jpOszyo2Ms7mj5+/fewnsE9XoEUcYQjBAwGjm5dDlTWemsPnKUJWc/RJVayKNRJ5P9QRpTQSyRHkq6/9HoOc6YA/Y1iBytFVjfM8INhyQUInjy7ZzVZGAv03CsagnlA4NUDvVTNDlBQ3cHCkkiqlbz4AMPsaE9gT6UzhXKfdjT9JyMlNBlrseakMhIwD59nM3iMEV6Oz2afKzxGeaE3NgbC3lZJzEzL5fMwREO5S7jEMtQ2ER+xEusCLQyIRVQPQWlgVc4WrUByWrB6hsipAuSFa7mS72rCCuOUyRCpduMR1FBMHGSWtdP2Bt/mopUgJ7kCnYM52MoNXKb/TvUrV/M+60TfO3wRdSihNcpsMUqwjh4DQJhbzqJPC1Xj11gs8/DikiE004NWRke3A2Z5L7+GtZ7f8/uETe/bvgDp7pHubOmjN533mJibA82czap3AUscwUIqGZRhHU0N25iSdVRvBNKhjrO4NRkUxoXSMVbianUmBJBjroaKZxTAnl1DPlayE0mSFvURyLu4DLL7eyb3MH4OQG1zkcy3sZIcTVzjbN4HO8iSfArlpFVFKK2x4Ber2BQW8XNfZmIEROmNDVN12WjnfwlJi5wpn07ukAalR1JKjpmkEQXeatLOdvbzsrO88xqjZwoqaV6YojxvivxNn2JN69Np8bZT0UqhlaWyRqUmZcqRLIO8+ZaN0/56th5pJ1lqWKqolnISS09qTjbkhoSF3oYcV3ALq4l3ljGioyt2DXZiJ4EybxvwYiMiI0UEMgewqwZ5MTg9XwuosWkaiARe52FyoeQy39IsLmAlLuPbkuYpMKI0WDiJ2VONNf8CHmzxMAz51k9NB+5oJ4fEKDRF+Yq/ess1T3HVPwpZGE1hub9XNbtZnrxCmT7PRBOEO3ej3fHFIVr13LLkgJuqs9l/JHTuGrnMtH5EbJKya7lErcfmmVCZ6Z2bJYbB4dYvLqB82d28nK+g3VCORV5naQnDWSO3UDmbCuHtNCm7sKOyLYnP2JpzkWKrv0YUZlC3a/A3unE43oebW0t/l1vkR7yXsqAaLAjucHzXge6JRsxpjnJ+1oxH50cp2j/3wx5L6lqJf8lZ0pUWtj2Z2ynt5DAgN83+U/kNv97+ExtAmRZ3gvs/Xe0hz91vO4/uO+vwF//g2uX/zPb+F8FrVGFqEzDHvKTlC458KeULpLIZGkXEtE0Ync7CetFnsrezFcm3gcBRK2acExFiaWJLuk7FLieoifbS/uRgyy86u85vNDVppF+dy3TL3bg/uNF7LdVocoyMDzyLFptLoWFX2HW30o0Okay9RvsrjaybSzBdm86NwguxuudRPYq+ViXQG1pZfFULWGHB2SYKavErr6T11JPkFR2M288h5acIexJPXfkTzEyUoiuERTiNURrXubiwnb05QupD3bx4NjPKIyMgwDPJDfxc+kWjMYY3+EVitRTZFf4CA+JrMt8h8syZYSkjheHq2nKP4MSMIwsIxDI5qJKx0VTPhpdHJUsoTepmakyo9XGuTX+PdRaPyOn76PONMi7AxtZtOwxfjn3J5yeXsbr7rlclXGMjFktSCJ6n5L1h3ahSEVIKmR0iV7cUjnj769B19dDeU8v/SVFvH71zbQX5uIM5TI6aOUxw6P0ZudReTiE329i3rm3KekwYAyFCBiMvHD19ZgUSTJmvRR4R7FEpjDEQnTUldGWuwBZUIAgc3TlRjYc3sui82cRVGCPh6hr60YSBHoWJFipCfGScTszBpmszH4yOn3kNgW490OJew6AkISYWUdb1hwcEx7Wh06SUiqZ0znEc9fezIdLLuNrr71AQiswMG8+rdmFtJdUUD5yitpwDj/Q3UmlRuamoV7mtp5kSpmNpno1z5siNPvSWXB6P54ld7I2dIJIfJis2Dy2SymMs4f405JNGE84iacZyM5S8FH7FURlI8OBa5DinQgI3DXdhT+lx9/bzpU1MZqdbrzx1dhpIeSf5FdOHxfNK3k07xlei7+CMhVAABbMHGF3+kZyxq8lvSfBC+eP8JgcodChR69W0D0R4EzQTI5CS+XMTUwhINk0uDq0bJFDnJMqmGQbV+x/i5e33sszt3+P4ulLi+4TvRNYFSI31dXySOsg2QNNZKe8aKMSxpImdkkjLBi/gpqQkfaOyyme20gyEqVwdBYy3CTlGAfWbWf74WM4nP0M2o0IvhaSVoE58UFmRdg3cj3fUjqwZy3CM3qaeGIngkLk3vE+ZpzjJEpAFOHezMcZVlVhE6pZc2ERKyN2JFGHN/0cbkWMssZ2KnMbaXQv4/ysgTlVh2CkCINFZibmwduZxGtx4NcY6J80MZ2Zz7g1k/vOSuxbqCOpUDBnchZbxEl1soRFyWJadSECGxO8683Fro/R4Pg5LeO/JilrSVeJpCkVhFUyE5F0+nuvZFxYj1kVJzu9Br8Is4Eo6t4wosYMCARMSjIGi2lLPM/lgIUKpAAAIABJREFUk2HMCpHQsmqmj2Zw1AXG0NvUmJRYxwdQxiVUhjXsdn+RjGN95MptTI/MEB3uwi9lEZX1pEwalszrYIfHwDdnRvCo+7A41zB5v43+XSD3K2gwyyQVA0z+zI/5nZNkj46izs8n1ueDpEThioUE/xLHk67lyPw4Nx9JUOD1UjgdYWbwBYptX0eUZALVFvLfHicx7yK0LcU2nkug6zXqrnqAZwxPUjOq5ds5PyBRFcekr8G2u4jku61EHS2E9h74+5obz8kl7p7B4rmkYkhO9qIu9mHPHMF9cRcTw3nkKCXUSYkLa7ZRf3gXsd5eDEs/sY/PrsNSspbpc2eJDLb/V7Chf4j/GzHwvxDNB3oYMUbxJswoTIcp0sbIGN+ACS2T0QPYJ5O8smIjH2ReTV5sitpQPw7BxwXRSJXeTVN0G1mudo5XR5BaxiisX8B4aIIh/xBGtRFDuhVthY1wk4vQiXECh0bR9dRinbyc4bE/4lF8yMjgd/l+UQOCIPDz5ihTCicPFf+GV7Il9i1SMGsIEdRmoAqNMml2kxtdzIDuAqtGynmu5jSl4xYe3OkklVbA5vIQ6Qk10VPLsdmyaZgtxmkfwe8NM9Sdw8e+Os7GKrhOcZLTUhUPJr/MSmcrd/cf4JHc23kvtZyzihqcC4cpqAwg9WgQCqMs0EywcB/ke1LcfT5BmWeCTL8LR3yWAnU6ZWkxmpbmIyDwI933cGicTDXfgNKfxdJlT3F0dAUTnlzmVp5jx/hGgnEz9zU8g9YdweGLsOTIYVTJKLPpEmKmTMhhxzI+SU5XNw6PF3VpLUfWfoF7nn6YqqF+ztXU0VRQw1uWVRw19KHVLae5eh6aeBxlMkl7bQ0frV7Ly5dvIaSZJWFIw1Iygf7qISIrJaIFIlnSKCMJPwezW9AmUtyRdYbwtBZfj4GwS8NAnsivrlNwtTVKfCaPYnETgcpuSmua0daGUZoFhBErbmsGHusCGud9jn0ZmeyYs4HV3jYOXbGG/spKclxjXDXkRxueJtc5TsHAIHXTSc6UljGSZqZ2MIE6kYOluZGi3gG8tlI651zLjEKFmDhLp7mCEzk1mGJhvn7xNXxGkVa9g3IpDfNUHjX+CKdWZGExJNjQfpx58RxMwlacPgtyZB8lhgDaqJtEWGB9UQZT7oXk+uLI8QQuhYlkYpA8nwfJP8mRXCfKmTAZfjVOQwFZ4VGac3XMBMvxChHel2VkGRyRFJ3BGKtQ0CEqkJQWSqihVUhRPj8Tpd+CczbJE6nr2Kst4VZVBsLoHsxpBuz2AkYjcXxI1I/EydEq+fHBKSKSErUYoT5tD942GxWdVlKJEbpsfrJCGmZCpWjyRXQFMqGkH1mnYamxjYZ9Hby3upSjNYMENTIH502SqJKocAsol/yYxICPyoiZoUQKOTlOuThBatsoyUy40DuPyvemiVttpNImycxtxVZ2CE++j1FVAKISqhInC/JOMOKuZLprLpkpUIZFUCZISCnmVJSwJ7eG5sw5rOpvokp2YQ+GaSkopluXxKOLIIsqFnZrqUkpWCUVMyp4+JfVNt6dzWD50Ra+3ngG4XwUzu9G3fMuif79uBIh9AYrGToTdgVo5ARxGXxRGV0iQbosIar0f1/LlO5DxAtKaOuKEgc2fa0OaXo/TwXnc1eDBcElMBNykjPjZ9xs5syaBm6sy2d60MXggJKU34VGDNKizSQmilSGBFQeiWhtGV1pOZyIzLJsdiEdw4VMGAoxOYrIFQX6HY0UDd2ByrGQ8LFmomfOEzzaz4xOoKPBjfWND2nJTeIpTmNOr0i+55L6iFgMwePjTEYYrUbBUrWGYNkurAOXkxocRQpOMVU3n4+tp6nospP/sUhBbzrq55zIHRMgy4h6PQXPPctLmX0cs7pY2BFClgUU8QAKsx05GiJy7iBTC7dw4/Amvnz2GJP6S7r+++fezrbhU+jSHJjWrv37ewye7iLU0kw0GaD4uutAa/6n8Zv/Gzb4U/jvIgR0tHgIeLtozypHJZzEpopi99dTEMsg7NhD9gWRA/MEfNaFfJi+gusn36Mg5aZXmEOZOElyRiYeXkVTQQttGV5e636Nt3rfYk//HvYN7mNr6db/yd57vsd5luvev2fmmV41GvXerGqr2bLlLrfE6b0DixRCAoEAm0VZwKIsWCuBEFqAhLBSSU+cxMFxd2zLlmTJsq1uWV0aaUYzmt7bsz/kfd+99nG8+xt7HXzg9xc8z5f7PI/7us/rRGs2oG3ORpGrw606QVh5hUTxIovWd/gg9X1+m9lCYSTNv2df4Q3xNV4w7CMliWxxb2DCpATJhSA5cel9VAbLWLtcTUHWNBlNx2gweNgaDhCts1BVY0RtniPjmTSVxi1sMf0CnXiE9xe38sLKTchSSbY5B/hJxkuEUPPT9P1s8YzwpbPv8GzdtQgGI35SuGVx7mo4h+CXGPm4jNCCDnVtFO3aJJP69bwmduDWyShWTVCUmmLznn3kmi/TMeXnkdSH6MyX8biKmbpSSFbrfqyGZbJmJUyXQqx7fZ4NQ5Nsi/SRFfFiEzysObiESkgx90Utwm1BYu1pku0hwluSIEK0KY1rh4YN7grUMSsO7zDb+w/jKFGzmFFLTmQV6lgCZTrFUn4+vowMrMvLlF0e5FBbKSumAu7L+BEleTYUyTQmvwF0XiSLn4qSZdQpiRN6O2m5jImcvSwkMgiv8fC9ayTuSG7B0DZNqDqMbKgL7bY5fM4c9N0S8U0xvBthOLOZBcMatNFiBlRyAoYFbJVdeOSzyFRZiCordpMce14+NoOCZEKByWNDjEc5vHEbWluMhogcjaGapbyNrJjrkOQK9mtj1FTNoI0qsKVNtOPi+hUfc4oQQsqDIr6EoDWg9xtpu+Klad6JaUVEK+ThCSqIxadJxIapM99JpeU2SrRrkaVWo7ZdQbj0FpnuS/jUFoKim2Q4g7LBT3AatSiTWtQRA7PGdgrCl3EWLuCJrGVSSuMTZHwPNY+iJg8Z10lKZvwX6DdUM61MEzUo+daOKoZGXRzz5JFlNuOMwSeo+ELTBe5c5eV6c5zY2Ti7O9NUzMY4dmEJGyF2249SYB/DP6NHCIJSysIUjDORt0x/8SKlkp5kMJNQIoO40khCY8IXyeZyTQ1xjRKZPJMZ6WZK9efpSksIlwVMH16hyLVMbmYzi+liioq60N1sQ27M5ekLj/Dx0nYsU2HWHZhEtvcb/EuojOaghQLzaSpyLpG0hGnK7uM8G3g3+8c8e9MNhIvCPBN6hs+0Pky0K4/ptas4qBP5aVY26Yl5ElKYz2y9igtuDzNWIzGNiscWX+U74mmyQrsI4SApPkW/zcQv9v2Gjs4uTH4firwSBG0N5govkY0+TmTnUXtDFfqxQxhkL6O/YS+Jg7/FMTVKr2ENy57LSEolCoUKJQKRmWFO+U1EZAqGTRIPbBSQjn2fl9N7uG5rB62zuRwy1bJ64ji9BUV8IG7kwTvb2Oz9AevST1OqvcCB1od41RniGw81s6jtRZg2YZ6oRJmoQztTRalSjsnkIK0dojYkJ6XU4XOXkyXpSZJClarClzTw7YpXeS73PXquHOP2zjQXSxXkzyhJy7QUuwNISgVCKk3SG8be2EaPcYgN1ZM4wxq0o+UYtEUgxegqi3BBP8Y1fVoWzSbcgQQZ+YWogiFIJECS8H78Ma+U21Cn5WwYSSJIEjIpTeYDnyc2Pg5yOZHTvVgjbip9dkxGLZb164hv3Ymqr5usRBA27+XDX19kdmgF08hRQi4b+oBEdmYvQtOdfzO9+YcJ+C/8vZiAJUeSWP9hOhtaUYX7EMUwZZEcVocr8ZcdRtudxpZhx5O3Ga/awBldIf/kOE4ZDoJpOYaUl/PKL7D3fB+rZoI0z+i4XriFVjZwTN6JK+JiR/EOZCo5qQw3w+5HkIr8jMsHeVp8gtNCBbfNxfmG63fsc7zIKVaoJsENSy18UrAHh0EgP7DEvY69yCWBL/h2Yan/iDqrg8srZcjtxcTMGYQLwoTUHvou3cVHobVk5JykTGanM93IZ8XD3KE+wto1ndy+cJ4MbYjnovfTvvYgG3rGSAZEXmq6lmVBg4Sc6/NP05I/xNwnecTjrUQjcbyjarSWKDUlU2yqPEeVdQrRGCIZkeNe0lCyZh5z7jBJ8xI+XxYLthqKVg2QbZ0lfKyAxkMzrF0aozungUWDlWrvPIaLUDIkIJgk3F+PIyuOIHyavEOwGZlbCvHrCg3OYigyuQgXnyLYPIF+UxBhQ5h1yjEKB2MULnsJq9TMmbLYNOFnl+kaXmtr5febVyiXRnFod1IrnyVHWmD/gpl6v4N4joLXPAqK4klqMpNs1yUYNSg5prOjN7TyStUiOVKIG+ITkA0RSSDVlEZchqInExgG0hy1WMgsSFJYMMpK1gDKcA4ZviLms84iap1IOh0rOg8+0Y9fEcDvm8DiiuM0qvj57SvUXJHTu3oTdh3slvk4I83RLeoZVi9wxhjHq7HTnNBQ7LhIdmyZkuAIaWuMHHkVwcQ8G8cHaLh8HJ0xSURXjlKWiVww4IlLOHUq3EI3ikSQ6ZJyVM7zTAcnCLiOo7t4GPeqWsIPfJnWG69isPsIYVMb/syNWBI70PhnUIpFlIhrScR6yBcMFAkNjMgVbF45S6brMEZ9CWtlZhL6JLHZt1nMr2MlpkDKV/NwqZU/HJ/iOt8yq+f+Sn5pPmNRLSvJNBXqDwl6jyOc247BOI0tL0qFQ2SV5z2MMRd565cJGA34VTejFTYRTk1Q7tAyUOJnwjTFqtJRrP11yOb72ejuIbNphmF1mHhCRUEkn6qUm3qdjLjSR6c1jcW/RPt5O+rKPUQtl1Ft+xCrtYNXxx+nZ17Ly/ev5+eLavYsnMflk/FK6z0wm0FkyohbbaDaOIzLk8eTiu/wpYpiSt+ZIXdMyz71YYqKc1EFKvltdopye4LKfUvIA2ZyjGUkNeM8PvgYx7I2sqLM4AlNlNTYdmR4KNR8i9P5q9j05iXyllfI/+UvKfz3n6Eo30jSmcNKyWlMaTe7Zf1kznyIVnkJ/3gEecuN5HzhTnKGvoVCjDIl30GlVkO/kKQQWDGUs5CUs+7C0+wILCKbnSDPeIk/xK4m2xamKS5wsCxOweRR8nVyPrK2MGILkjdvIDQRYuquF/nRGTtf0zpoevq7/HpVF6YNKjZIa/FMx8hVJcnSgSFmxHT6TbSVVxOLHCJHWYozmaLTpyTa+gx/zDzDmMLGQ9obuPvdZfQrYXyqbGIKPcXuAOZQBJnJhNxSjORZIlqUx+msOdZovFwe2Ez7wDKKwjYEhZEPszqJSh7+WbMbXUkJ814X7qCfwmU3ANq1a/EGluk4F2XdkgZ5NMHYVbvInpzCf/3tmNUivssTBGUKGlbmERrrYHoWyz33YGlt5tKxLkpmhjk830AinsbnjGDq2UdCp0UXDKK7+ysoyuv/Znrzd9Ed8A/+d4rKMnAvO5D0CiRnBp6UDVF1BdiB3FhKXDlBuS1OJPwGi4YvMmZaS0IGqZQCnZBAZ1lG5QggFl7NRtspxKFZFH2v4c5pYeOODbzP+3QUdbCtcBMjo98BJC6EVTwt/JBUUsbPhrxsjozzge4kp1R6vub0UB8p5rtl1zJcUE7xxB/53twDlMXyKTIcJNHWz5ijlX2XHmIpbvn//aeqbDs3imfp9K7hoKON2sAEua0+ckdBlgNXZCY2Jd8lnkygWhGJtyv5gsnGr3wVFEhzXFtxBP+8DrlsO5FVHj6X6EUVjfHDySas9hXWlgSQGSIUZEeR1XuRUhCMKEgnzajECDq1l4bVJ4i4QfuUSMH0MnNZco60bOUFy172LPfyYbuLKuUcd4aSxIslUjqIuIoxH42TagqQrvUTNBvxu9QYziTp2Z1mqymFJI8CoBUgKUQozBnnSipAfkkmx/gCJ+rXsd0e51tTK6zL7ibPGOCb6Tv4SLiFGUcv3bIURzM28B+pAW6WRcmeSPBO4T8xllmAZBBJGLR8XKCkODTNzXNeVBVxxrwlmDRu1ASRmXQYqgyos9LcrJ7guQkjlhI5G/RBZFt+T3lUz5blJgoWH0LvLqIzcZafNf8/YZpMKHAWYg5L3HmilFFtBcJClGCZHt/oIjuN8GfhFDOBdkjIyRa7yRyYRAIqRSeCJDGjVGERx1DIFPRUFlDo8lI5coz2gcMk5TIWiwvZ37SahcpsNh8fJ6jWoxv6kLMaHQrRzE39fZxsbuPf7n+MtCDwP05PISCDxBX8+g5MnmH8YojBAgdNvk9LamJRkcYvtXBLUkaeroquQwfo7HkTXVrFXJYFKynuKn6BpxYfoypjiieePEGjqp0KoZKwyUzxhZfZmV3LMbbz2IVWVlsE9oblRBq78DrjmEN2dFKUkqsWSOfIyTI/ReW5IPFIikrTHZw49Qe2ne9gtuMD9rnl3BHuR2HVIG+Xs+DN5IRhgmvyR9hoXcPYRDHOmUoKxHKUpiscah0iXh3mUbuEvvwMCdHAPN9l/9AI37q6hvaKTO7tqOWXthtRlGjI9zgpco6Q5Vez7vVhRJlIYdzJn83fpuTRrxOf+fQq+SfJr/Ds/AGiFQ0gGPhpZS7WMhHnrB9f/x+4ZuAlllRlvNzaQHfShPm9NpLyKNYvtTM6sI+Gn/YjRFX8YMP9lAfz+IYvgnY5TBrorlTws97f8PVtBTzWkEBavoyv50Vkv/8D+ger0OSkmG67j7EjKa4XRFJJcAuglMmpyhEo2bse37vv4ppOESgr4d7CC1QkWvCpjeQ1DXDlrJJtox60Gz+ib/Z2AmfPkLU8zwtHLpGpy+T6pYtEnU62npNzn/FWxKUgDU1WDngP4wiYKJFWoVn3MIIgQ7EoIqtUoTr7FNrVD/PmQh4X8k/yzdyHuD60F69BJMobBNRKZOk0RS4fUvVOuHyM1Pb1eK+ex1BzEtwaHEIFd71xmqT60wfGclMBU9YVGos7KHz0xxQC68NhLt1yE2nAadSSMzjIaztT3N6jw+wIMZcnsmRYoA74JG4kL6eOhtj7PN9Rx11TNla1bcJ9aQTFmmbsH8yS0hcgRs9i1UfZ9Y3tCDKY3bKC3dCCmSXGTs7TsvP/nv78n/iHCfhvxJqvJzMgYE4GSCfMhKUkGu00CSR0Ky0ES+apn43RHxrEGpnDoavkg6wN3OToIYIGvRCmRXiDc8lbuXrH2/ynOp8KT4ycxWG++FaC+YeM/Osn3+OHq7IhMshptvE8j2BM+vhBf5CtPgOTWfs5Lmipm5Fwum7i7uvuJaJU0Tp4jM2xZgqkbLpLf8Worpqjp3axlLSSE/WwQT9DdjjCkdp1NI9fwhKKYQjPcavpBGglLrsUVIf6sCWM7I9tYofxPAlTGlu5iEydAMD5vSSEoEh6nkc/2Ul2ZTcyMU0qlEFp+h1aDsUxVoSY36Xg1twxAM65Vbzm1nHrQoicRDOm1BxqSwJldgCVMsrliIKxMSX3vqDEFJbo37SKJzaPsWvKzesHf0PvjipOqpeoX+mgp7wTXzrOqSURnUfNVnUNwqEVoikb6+vt/FiKoN4CSbPE+YCKfV6BCs9qGhPZ5BSNkl80TB4C07EFnuArvCfeyYGcG5nIkXG/lEMwEeB6xfv8SXgUnf8zSPltrBiyGQj9giZzD58p/zIh6y6IJFGFYhhUdiJiNv2Gx7mx/rvEmaVYaUOSwztT27mt/BMW70xRP68lkBIJLKr5RCuw/jL8vuAGbjNPkJnXh63oDKlD2ehHcukwfQNNIp/egj9wqG2BOz7JISwoOZXZjtlmw11azdHiPK66mMXtVDGi9tKtDaLTXaGrHfor78Mo5eNQCzSNv8K8yY7Z5+Pq7lzGCnS8sCdCy7yClpE4pQuLfGl6joUMAwPF2WwdHMWsUqMO2xFCQWJaI01CCftGHfyb0suTa+v46oQBGXOcX/UbGkaUyENKzJFB5jKGyXHUoXP38tPZGQS1gpBHBfXbUVWuZ8fIUerO9eCry+SjktuJluZxg/QcfoUVXUQkpPChS1jpLW2mZvkiesmPzVrItkACy5ogs/Ilygd8yBRpyvYs4YrX0hm8lT3NFpbeWiK/1cr77U1o+qoo9I2wU53i3MJNaGKXOF4/z8G0Dp/WiRQuZnvBEsp4P43F/TiUNVwebyPD1cg6s4cTehslyi6ac3rRKa7max9cobHQxENbygB4cGs5L/W1IK6SuHqoG69WT8VAL87SNbz08L345u089OYbpF8/CmvuQpEXI89Vgi35ALMmI99++Y+UGVUUPv00he4/YNS/yCdSG+seexutzoThtVEiSyEyP1fPwvmn4af9iHE1JS/+J5tdOn5zfIJ3zi/wM7mWcgTen9qNhEBpfg7eTCumwnXE79PyyX++w/yRJD3G3zF5MsLOYiMyO1jjMuKiQK4yRVZSiy4njKEjiXP5NpKL57j79F8QMs6Q+fVfMem/gn+VgY7zKzT7erHF2il2fproLr9wkhuuupvoW6cAuPm8GrnFj2FXOYaOAk49/zXSZ5YoMD+CIq+JpGoRRVE7SedllGkv0dTvuJA/R4NjA/mxAUILLaTCNtIyBWm5loyogDKVIp2aJGWRkbQdIHJDkrxLCqyZMqbPe1HEEhwvTnCVJBGXR7BJDm7LrPv/zmulVkumSotbo8dlUJNjc/HQh//rPLc/eA3S/o+IKDVc7PLxkkrLizI5JcFRct/4gNSTLyA3m+m7BIvjXrLFAgA2blVgsKhJOp3IEjG0e0oIvzVAfPB/pYv+O/nHOOC/EaVazui7/XgMceYVAqJ2hI3qCCvLeyiNZuHRnyR3MMGbzSlM0mrspkLG1QU8uPQRg1SRJznJ1k4zHLsB4cb7MMtj9DtXiJfvRB5T0To0xYHGJK7ZZdzpm3nW8CD5cT8buoJ8LpjJ76UEqsjHHMxPEDZew8cbP0fF/AzXHH+bK+FKLsVq+VNa4JivjQFXA7keL5+b6uGWxTnkFjmYkkRlXm6zhRE9p1mtNrI5q5uuyCqSMwqCOjkT2kyiwRw6I/exlNiItbiL0KVi1G8oiMjVyIsjiMokonwZS7UPjT9NS+8iwiE1qbiM6IyG5TE9/lArg+FaXheWsMYy+bndSWnUT+fKNgLnUxwLKHlVGcc5JefRV9LI0ime27IKyXoT+TKJwwUXiVe18lZhD2uWMwgPruW9VDMDC7uJim5CmgU+t3+O3NgSv22LI02oqcuQE9PKWRm7DtXEVVj9JViiWWgiBfzKtodu+zpSiFSb59EpE6yWBrhW9gFXSQexCis4KCHDW8cJdTXLWdUUx9TcMZeg02qiRj7KAe2j7PENwEAYt0xHyJxNQq4mLaU4xzq2cJoMT4wDIzfx4eIeQkkdNUWDfCBrxNWVpq80gTKl5IPy3zM9mc1SNEhW/4PIskfQrbERy2qlzd5OfVpBpm0dyrSBUCpEr74dt9LKZ9wmbDkSl4s0uBskgjKJzITEHt0EJYtXM2KdIpZ+hzLZFeKeN/Ar50kqSpErb6LUY0QXWCbfbWb/5mqObKtHvns9rlgKuyj/NIqo8RAQ46hTamS5DYQ+8xDxO6tYaYiT9h3DYX+eTGcMeTSNUx0injRgDaa4sXeF42viFAc2kooPUhW7QF18iVbdHJWqYeJLzzKjuEjEdC0ftN+DXEpx0+HX2ZLfSZZSxGffyFslfgriQQqipXS27uez68dYV3iRTOsQ/pkVop1yJKUMTXWEGdc9iKN7OVmYxcGVAOvGIryaCwfkMdarSxCnu+mfbUG/GEeZjnI+qx25zEVCjHLv4B7qe/tQjwpIGsh7JYqtsJmEkMDsKaDat4rM7MtkZs1xrrccZSTNP9++lfzMTxNBKlHO4PIMq4e70YXDvN+8lXR2A2sLt/Ir6xTLxgj9JZVskzejjwaZPPgzvnLrbmwmEz/a/zHXiSGCx44TuHCGnNBfeDe9nQuer7NpdxWRThuh7iU0q0Wcf/4e8ZeOIyRlqMsqCXWeofrMAe5c6mVzTS5ZsSwcJHg1nAEIfDxk548np3j21CQvLck5U7CGK+RRmW/mm9es5rH6AiIXlgkU6LHmaNH6kiSXevB8+BbBBQnrA48gqXagbS4h2ncEoa2WX0feZeeZAKUOSMkErvIlyXK7cRS1Ub9wgYp0HsnZLoTyLQjOCdKhGYhN433vXaJDw2wag3QqjOS3IwXCKDJXEb34EnM1Sp7YMEOtsoLtA9exsrIGm9qHtv8EYU0WyyWfJ25sZ7m0jOyRXlLmEOoZGYbhPPQzmdjwcboywSZnBgfa1tIYrmZaP8lx8zlal3azuqoaUSknYbfjfOopXqneTVoRp8rl4sg1uXR87xnMd9xOVts2ZM9+gCDPR5azlcKEwKr5I5T5ROq+/B2Wn3gCymvpXvp0myFyDSXzR1jILCDZlENsbJzYBwfI+Pzd/NV+COu6Rso37fmb6c0/xgF/h4hKOaGMfNaODNC5/tOlEyFdktnoAuulCsQSCxCmckEipTrLxXQzE7oaBrMLaF0eIYkMuSzFDRk/4pWXWrE3ZWMVZCQKPQgZuazYvsJd55/lL7vvpV/Twt1Lf0U5v8R10dvwyx0YZ49xcGsmEgFseXvQhwLcfPA13s67Bo+YSXNuL1miC/2lKPqwiltyExyzVnJFUYcqLiCmz7N1XoHd14NBq6Yw04coJMlSh9m6YYxJrYUu7zZcsw6yvW8iBCSGX/50Bzs6NVyExFQ56nUBGqo+DcR7JDXj59SkjDB6c4RRp5FbOpNU/7WfTGsmBcW1LObn8yfNNtKyJDK1jIBSpH5Gi1yQ8ZX9CVJyJefLSqhwJRiODtIb3Ul1ZJoDBafJiVv44l8FDK6/0BhqQpe3Fd2Imqf3JvjzHhUTuQaURNkdeJwTly4jkwlIkgyZzE6WpEQd1eCcP4Upey+LQi5vXr6JfbZKWktf5Eu2BPGyBAcx0SWrY0n3VcKxMyOHAAAgAElEQVSZIsZYCr8Kqq7MUeQy8JPFMr6z9YuIJDkq1pNaLwdRhtkdxydISBo5EZWZn6e+xSejX6Yz7ic/4uJoaAd94W00Z13g6hvHsfiTNIYrcNoP8C5tbKu2sxiYI7/z26hbX4WaAwhGNznD97NaSpNwruOyqpEJLWyOiGQGzrPLkcGrGa0MyvUM1ko8WvsiZZzGEyjh1lMPk87YRZf6Da4Rt2BnG4cayggshnl1hwpDfBN3ffhn7ji8RI7kwEuScCoJohxkBmZK7qC75K/YzZeRuECai59u8gBUKRnNVxKUO8ykkPP9t3wcXJ1FflUDqdklvrxviP6WO0hKChrOLtE4P0BUAUuZMhqyrbx4w4/obCtli3SCXV4H2RlWwtEONBWnKO48gqVlD/W+p7EffZyHFUZkKR/2N7dij4SR0iGmNKWMaqtYszTD7cHnGU9/lwcPJlg7/gciKQ3rXDmEa+p4Vd9Eg6qFkkAvEgJRfQO7vW2UDheRtfwxlQsvkxblzG3KROdz4VDkcd3bL+LIy+DQ6g5UMhFT8xDeqArDrIXCDC8HX3mWiEJJaTLBTF0D1uFBVtRGPgnX4ovK6C6z8N1PglgzfktClkSu0JInPsFzRWd5c+9PSSHy1Mlx1qvaCff8HDIziXUPcHmxAOU/fx7zOzKmP5pAf8FJxD9E4Ce/RZJ9mkxXFBQgN5sRVEpS0zPI5uYoe/HXYMgn3d6CIk/FDXUbuKpyLXPuMDZvhNIMNVWvfBHjSRu5j38VU1YdsYVPR2Nb728gPuNjufsUkd4XkZlKSMXsLL/4S7Tt3ySVWI2gNtP/5k9J3ZViw9in37H2ShqZOATrHqQyZzXJ4gmS9o+RZHI0eWuJuYZI+23EljsQM7bT4bWyrP8Ai32YuH0YwZCPaCpCdnUTPzO8gyEi8AN7AynvMfpytpBKxdGH50nI9VQWfxN/9macA7fSteH71I6+hprzsLBMErjNDafq5bx0cz5tPddxJHOInqxPa2vCvVre73qPhnwPdqebAsAkWnGYNKSEUVqWshBqmwh5Y5x7ZoQ6dwSnRce4Ic6qgJqlvLWUzfcw1L4ehS/IrGUzqKGw1kIiaiTSZ2b+4ike++AVtgymeARYknxsHZZIhPv/m5Tof+cfNwH/zXSf97G6923e3rgbtfAJRUqR0BUV61W1pCxB0v2TJEU5w5XzpMQiAqoiwloB90oGhUknOiGKWhagUgqx6pURcj0+9BML9OYtEde1ktEQ5vsLB/jM4tsc9+Tj8l/H7agJat/myatuZi7dhTZh5JZZK40TB5iLW+k3N3Nn7TtcYziDdCqOLhhFLkWwhVcQdNuIyy28s9FClseHKDoQPcvkGVrYYXoJuSChUsSYLNNiK8hDXzuKtcGJqE6hNCeoVrip1bsot/jJtqb4F82XIKmnteg8C/YGgq/HqFyM8/SeWqpdX2FZn8VUTQlJlR7zyiKV0wtUj1+hYMGGzudBudxLsdtJ02yA7YNJknKRnvJ80kISazCCVuYnnVTQo7yRjFSKjpkc7EXFlE9NU+S2k7s4QOnCHJK1gk+qV1AJcm6z3cSUzIVH0tGVLOLU2ga8Ji0+HHzgq6AwtIA6FWNWW4IkCqRimXgz+tj8DiTOa3m+LkXKbaa4O0W+bZaKCz3M1JYyp/eyvDyBtyDC4cwm7pT+whWqSKZFZL44sr4lKkyLGC0h7uZlDstvYESdxx7ZRfob12ErL0OS1IyKdUyJVTxgOMfOwBh3OM+yRTXE2vKvULssUYoFdaSc8xEZxrITzGZeoihtxrTg4I86NY3eJRJGG/t01XzJ8Wd+ufwMgZHd1GnfYafxCF3JTRQpx8kpPEzVwbN0HPIj2vSgqMflShNaCiN6Yny1rILb925jqus4iZQctaqOpHoL+wu2oFyznc9ubWF7dgUb1CfYppXYW3Q31w5ZueWAnHsHimgeDaMOR1g26VksaySR8lE6PE7eg58jIETRGYtZjsbwqsP01NbgFQwoRRNPfvZb+PQZPOB5hmvl+7lqx0us2bKLE29GsZYfJdM2yfWn+6B0Fp0vgrrlAhf3NRL0B5BJIusnZtnuXmbP/ABtoyMIS3KE4mIc6hr0BjmpcIRIPEBOz0nqL58kYigiKAaQSUnilmI6zp2gZnIfghRnou4axis+g+m6STbf8w5ld93MvPp99BM+Ws6PUuMfQtgT5ZhP4GJknDsOzbKSYWFIqWTGucxgMMhCRjZDRhse0yFkOgc+w1quXkpjrNnA6lwDN3kyyXOt5jutJZAU+N7zP+Oj5vM0hVdjKu4gaR+CkAt8YBg+QolnBGOiFinoINz5a2TpFPEsCeM376HsP57HeNUeAkePEb14ETE/n0PZLVQGltGNXWC1Zwy79yiXV46SWyzj9vVNrBv+EPWJ/cS9CsLd3bhff52k3QmKXH4Y+RmDx96g6tgxHFlqZJu/hNFQR2L4MGn/CmJOM1PqBcpHZ1k2Cmwa+3RjuyoJSkGHvuleVGUmUv40scGPSan1SMuXEXMaSC6NoqzcjkwtIKQUKKbPw/9bGRMPIKU9fPS5Is6Eh/jBsQysXZfJ+cxdZLzw7xRc7kaWlpBkUeZuldBVWnlBfpDNqmuZVazB7B1DlgqSkKUxJGTIFGoOFzvI8gQY2TBGRnY2tsAiZbO9dJw+gnygC8PUAJIgIjPWImorsaycA2+ag8NlDJ9eROVfIn/6GE5LAXL9WoIqD5JYTpHtJPLYpwVpM9lbSZjzuPHxZiz5Olwfn0AdWsC+dw3XzlnIuGzn/jXd9FapGW0u5Jam2/9mWvOPdMB/4e/JBIyNB8nu3ceJxq2kxJPo0npqlgPETFtQhyoZTMxSYg/yl7YU/7Rymc7sa5mRl7FB/ITj7qtoT10gnDJjVjnQFENA14RkX6FhPESgbIl21Thl0UUM6Th/qu5goTCf47kGnqxuJ0gQnf89bjmXImPOhNI/w8Hiq8nUuvmccgjVH32Myev546p7mVflUu6fYJIgx/IsuN1p7ggkcas8ZGuC3Gt+Abkg8a58A7Y1MD51N1WT95G3EObH3l1UZtm5LjmMLi3nq3yVVELO77mZiFzF19t/g3u5kOFzAa7v8fLOJoH95i9QIw8hqgIk5Em68yYpCOQS0etRKBQ4NF4KHB40URlhIQu9KgObXmC4KJeyZQ8jpS6i2lIM0QgFURuGZJAhYSf2tJliwYY7r5Dy6WlSchmp3Q+xTnE9MzhpdrWSkgTOpXLpShXiTRvJtIVYtOtxRPJZV3CR9nU9fOTZiz4e4B7VPi6kmjAYg+T5plg3Ged0HWwdktMUt2HOESlWTDMnJvDktNM09Vfea9pMUTzKF8Rfss2Ww6pENQtjw3yt7Y9st36ChMA2ThBxlHModwvvZ+9CKcn4/tTv+cPlH1EdmuEt63WcZCfZlkmGFTnscE9hmduHPJWNY+0Qv5YWeXF2Jx3nB9BXLBEs7UGomeTGlWF2nz7C1ZUVdAVFXtPu5Eq0DUfhGHdWvYm6V8Hw5e38vvJ+NgXPkt4WJmCtoaTrCsWzZ5lW6JjJyCcdT6ObDLBpcglx73sYViVIhOsZ9sRZ70uimRrDqHmfeMbvUMaSKEJJZMo+dHYneeZvoMppx7EyzfHqZiyGGXJyVHjdUWoXlpGd7iG7YS0GU5orASt5rV1kqNx484384obHiSs03NvVyfqi/fiG6zBqdzLZ72JpIIlQMoVylQv9SyF03QLxeyZY6C8lPC9DVLejNPsZy5gnI5aLoaqG0Y4Q/1zxZQ6oC2mJKZlRlTCc28Qftjnor1ukajHOmslxIvoGIsZ6tvd9gjE4S9ajX6TiV09Tdf1OhnuW8c0VkVMzw8TUj4lkuMh68HccVZQQr5ejyl4gT/MobwkXOLNOhaYln9nAHFpZMR6DkWOVLTz3xO/IjUsU56/iorme3IjEY3lVVOTayDht4LAlj0NFRr790h9RyYc4URnkpGmQ9YE1ZOZvR5alJDk3hjygxND0CIJSh+fc06woI/xlp8Bze+TUWLdRZipl/v4HCPf1kfO9fyH2+Lf5z1kt15ftYX9OH6umg2wck2jt91P0QS+uV18hcrCPaECJpraepNOJqq6WSH8X8anjhJyL7O70IBoLidx+H7YGCyvFZiRtGPX5sxzPuMBCTQUVI3OscihRRZOIhXVIfieY8kmnInh8R6D3HaSgB1kshBTzk/LMg0xACo4TvfARyflPVxQL+hyUZZtIrUziTDp5snqcomWJOz8OIMXj6LdtIzo8DIIMEgm6qwVWVzzC4QwVM/E5nnjgXxg4eAUpLZDrvIRMktPZvg214nZm9V04dbPc0i+iH51FrzHy4HtOLpVJ/HlLAxuvuJBkEjmuAfKWOnHqdWT73by9Ncqs+TKu1Gu0jSd5YY+R8yX99BTs59qeKSx+D/Bpubc8doXBe+RsbdzMy/N/RtG9Qol9gd7dP6VpYBzdsgNZNI+85MMovGVctetvVyb8DxPwX/h7MgFuR4jAxX58RhVzphlkqFkbiTAuNbM1omdQtUDj8DDHmlWYcBHRtuFQZVGgnUExp0GVDlEpznDc92VqjKfJMk7Rp20inC2nepWLkugSD9T9K9e5ThGSWfkgr4lFrRK5JFA1/RMiYoiW0TLU2lkmWiq55F3N/zAsUPv8GZK5JvY2LrBdugalZMIBFIUGiUkCU/I8Kj37WK2YZpV2mQLBwfl0FbGyONNDN+JMyZnUD/NXgxmnK5sngy+TVAp0WgvxDWZTOD9Hq6OXVukYC0tJhlfi3HfUx1y2nL/sstAaLEWncmKUtKxwkb6iBW45uUxQDPDDO2IcbxQ4l9nCn8oeJ1Jn587iIcIZVt5usVE+F2H3UJpN1hVU4xFmskwUpJ1UWrycla/h2zMHUG/ZzrmAixmrgVGZh0V9HHnSQHHKykpc5Fi6HEkSAYEocr62WuCZL1zFnRt34JNt5y+XIlybvox5ZppFdR6BSCbO8vNsHZTYMgKmpkzu+bcX2LS+Dkn5NJG4mRHNaiZLW5BEI/cs/YJydYDMVBDXFT03tz9Fji6BsfR7ZHhfY0aq4PODa1DFtKTDR6md+ICqBTWRimwqQuVsmynnaJaRg+IOcvWL1Ez9EwphArP8IElBx7/O3kSRzsEtR05iOSzh9WSjydMRaZghtDNNNDjI3pUpxgNW5otkPNb4LKopMLxfhs50Le9W5XM43EGH342qpo/wqo0wCLtnTlPjnqM0uETlfBfKLW+S1kZQRYLo68+zRt1HbX8XRWvOk1w3hWICLE/LiPZXIWl0JNYu4yvoJKZyktrmoGRdN5m1K6hK5pFLFqqSRSQibmJTE6QvXCC2M8nyhMRkuIqXOh4BSeLO/c+TsTiCa8hC0J5m4txZbGND2EQ9pXShLPSgnJcRbVfgylBgO2NFrqzHGs9nY9d7KBXXM1H+WWzpPOyN+7mlPobclQVhE6a0wEreANnL++iQikjf6cREO/bURuRiPuqomydvlTBYtGQf6se0bRMao4bJ3igO2yVmDGc4Ja3lqUsvI61YaKrrYUKyct22J1g7VoHNb6Mzfo4V7Qo1Tat5M2sLjfMSHYEA1f0jNHaOcqZxLTbJyXznNzl2qZtlQz4vF8fIDAT45mIhurw76HV3EBFcHM57h1XRMvIUG4k2y1CuugmlqpQfFT/PEyXbeT//bq5o1pDSzXA89gnPnR/mXcUuzrddz6go48/HB6iQwUbJxK8bD2OtSvLquiTd5SJ1TdsJq9K8V+fn6evkTO1chSaU5IXiGWrKHyUd8VB1xYVCb0Cz/qvox+dRfPAmmp5+LMOXACi2BWkqWEfYF0LnsiModRBPQCIMES9pxwh+1wIJUUAVTYJCh/nuR0gsTCBFQqRDn3ZKClotUiLOlT1Xk69aQ2LmNGfqBS6USYSUabYPSKgEBWmni5JXXsb24nMoUnCpWskt3/wjzwz9kQpzBZsNOxg5OEb15ddRJEN4LUUs5n+BqFxEUR/FHp7j8+/6qJ6KYXKGqfnC1/lxYRbKVD87huL88maBE2sEip0S2pgcUzRBWrKTuHUPm/adw+KX+MtOJXbDLPd1q9kwuITbUoMm4sJvLMXit+NxjPB16U267T00i5UUj04xGCukcKobly4Tf/bX0CYNTBdkcvPG0r+Z1vzDBPwX/p5MgBBPc6XHQ4Gzj9NlIknSbJGHGJ+2sFFdjEY+hWb8MmMlDZzO8fLLuRPsz97NnFBGq/civoiFNvkgU9F1LEVzKNGOU2mcJ1mqoTIyz4/MD3MguwTJf5mHnBP0paK0yH/LV1RvcyEeJQOJq6rcKOsTPH/5c2wUE1zfdxZ3YoWyDXHG4t+jVNDQF09xRSOyIThFaXqUX2Y9zx7TZWoUc1gFDw7JwhFNM/e6zrBII+6qcVqqT/La+I38SXia2IDIwtkcCk6GWL80QlbUiSEZoH46Rv14ivVjCWQyOU/erqHFvxmLlKYvWcSiM8ltXT2cbErQW2fmYEsCQSZidrUxFr2VDOsoi3kf81qGjNN5IVxKiVv0XvQjKsI2ENMSTpOGsFxJR0M9x5xqtHjxjPZTtLqJCYMfUV1ISCGgdNoQ/Sqe0zZwp3iKf8s8REU4j1MYqbfPsOeaDQiCwJOHZ3G4I/xcqKJlwx70gQWOpUtQZvVyoSLONRclisMWLDfehtpUSDSyQG7qCIf8OSS0q8gMXMRzLpe2si5SBgcbpm9FpknTvOt3WBQinqVXeEu4h5aZWoqK3sKrfo8TSh+NRYsU52/CPRdDefJj7gyUMpaj5IC2nRPZcjjuIC3GqUtdYm1gjD2ucyhtGrBGSdfHCFWGkSuSIEDUrCK+xktbWR9bcnpQBNJoXjNwaNVn+USZxZxSIlFk4u7B1ZhlYaKlx7CbryYaLqd6oZualTm0W1ZIrw3B/kpMp2WshFchNHiIbE+QKJNwjG3nBxNf5GzeZg5UbOGO+G60zkbc5jGS2SMoo2ZMiY1cPhNGrkxhqbVj3nk97nQvwc9GMVeFGV1WMhsr5vWbHkKbSvG4423WrD6JucJPMiojEKwgG4ilHRjDl6g444QNSVL1OvyFUab2l2AwZNJ601eosniYn0swWXEzemOUaNJI6Skbr5htfNe/l2JJiS0hkOGZ5a6jlyga8WKKKphfY8Tl2YOEwNHCBurjPWx+oZvYwCCdZw7zTPIiqIJobBvxz7ax6HezNb+JVpcRY/lZPvRG+c3Au5TEcvjM9F7KlaXoq7P4aPZD5OFe1k2tYudXHqDogTvRtq1jQUrSJb7HuHUet1HJOfMoqWQfiVQnH+RM0hAr4YuJAq5PB9kSPcM/F1xAnzKyOrgLUTLzWuYBjscF7iia4t7at2m1XqEYC56YhqBuDCmzn3g8yORSNn4hzVWmGUqi+fQFDnDra3LW5jdysGyJd81z3JGXZofKw0z9Hs7YuzlZHMSeKedhz72owzFEQ5Tkygr6HfeRVFmIXDmFVgNTuTtwd/wTlslTxMcuIg+ufHrgSWlkGjWIOkiEeeXeMhxfvQllZz+GsITDlGT5R/dQXL+O6MGjAIi5uaQ9HqJFWTy2+yI3X3CT9Lvx6CSsPtgaLeZ0m4bWPh+p5WVAIDhwEUmAxpsfRLO2lV/0/YK9ZXvJGteT+dq/ok748BW2YHGNM2o9R3JTmh/d9XMsP/kzhmCKi+UCjdMSyqtvJtVXy+2Dsyh8dsav287ug8tU2xIM59ZT6LOjC4qoh/3kr6SQSxo6bv8BvgtHue9gCEXH1Rwzb6dqoZODFdtRxYM0zfuRm0wUtt5OeDhN/cRl1s6eI9PvJSPgwxiY40quD1NjDh31q/5mWvMPE/Bf+LsyAYLAua4IrZde4522MpA76dDFcIwpWVOkRyuVE53sJqHIpq/CQTRuJlu0MGioY42yn7Arm5bUBEa1mxOBL0K0hwK9n8yEj1/pbub3zZ8ne/4pzhu8lKT9DGd9hqtVg/Qs1HJBtsLalIIyeZoXZj6LO5zN15J+cs+8wVztVvqlR6hRaVkUJSIZIg+nTJQY82ixvIwsLXDEV0ysJsk53yb+KuzijdBG7lOcoNB4HqnCw+HB3ex0j1DdOUtoVs1STgaHm9W8sCtO144MUmua8Kgfx96whY+zqvmwPotqeSW6tIjoj2KacnA6p5GPS7agM8zg1zlQhsrwzj6CK7KGdnOI5+JPcUPQyXI8C39K4pGZNNeJK1wM5qEJQqytkfU7r2dm+BKzc/PUhcZIJyKsu/t+yjdvZ3J6hZgsjTxkxOBLEAsN4sqq45l71+Af+z1l8ixm49UcTYjcZggSMln57nuD3GLSszEdQlOYomgxh0t5ajxxPaZKF/fe/u8EXn+LUHc3pmuuwZjZzILtZZbcAZySlxKPhEJmoL3oAgIxvMXHUPqzGO85TEB5jFh0hWdlXyI/U8fd0UPUXRolNKmj8UgKy5tjaC9OMW3wEBEjGF2VrC7+C+dVdRxc34EjmIXcm2ShpojjGe28ed1u+vdW0lDShxRpIuq8B404gZjWc6b3OopDE8iVCWT/aeJza/6VXk0GC2KaH/oV9BSp6NdI7B/K5RrTIqry4zjiO7Dn38rRtgpKO85waamZE6GH8Sn34A+30VLTjhAIIRtTMj36KAmZglmdimclHQZJ4NyKHmve3dQ1fhXHe9UULdYy4bVhH4RcbQivoYd0gYrc6QA9oSJWRjM4veFGnBYrnz/kYbWmlpzUIbxxA8HxfG7Lf4g802pKtVXMRyaZy1BjcCthtZPZY4XEg3pu++F/UL2hipAun67/yd57RslRnu26V3d17ume7ukw05NzHk2QNMphlCUkITLYCIMBY2PAGEww3raxsY9NsDFgMhgTjAgCSShHFEY5jTQ559w90zl31/nB93n7rLPPWnvt7X0+//D1q9aqH/XWs9567rvequd9ui0kOVpYtshD97gExGQ2No5hTF6CUioyFAa1L07JshQc1iY0X0vplN+HVKNHoVNjHz3O7cfqGU7VUV8cYf7lafptk7TO9iCzREjx5pE2VoK2PRlD+T4UCjsd7d9iTWg+6wericsh15XKuqU38DHZxJ1HGdKfZGHZbLLTy3ClGHm2+Rki4TaW+zfzg767OFGwAUFZwSNDB2g3aditO4o3LUT56HyM0U0kxBUcTTlMhzDJqGKSL7QneTXrAlbrCEkxgdlRHR/7epmSOnlh2k6/UcGQahiFuQGZsZm1zjnIhDjC8CzyFCqUp04xb1TF2eI4n8pDfKTT0O3pIzshG7XTiEwa46ap1ShS4qT+5lGmt2xBMBUSkVroXbiBxW8+jrSoAsdn20iabMKnSUYe8SEBYlIBb2IShpofEOn9mhaji7s3/grtn7cwpQfbNLznOoBs+yEsLvCpJcicXkRAnptDWvMEaa0TXJqhobItTFQqUnvOyd4iPzvnSFneIGLvbkYbiONVSyj7w6s0utvY3rWdu00bUDz5NELAjfDYc1ydSCF9+BiFLqhyK4lPO1HvrecvK6V8ukTKbd4yvF9sxZFUSlbrlwQtWs4qu1h/PoxEq8Xk8yHGw0wmJpLidGJxTSGP+lHt20NtaxR1dTXWl1/isQEPZ4rLODp/Ll/MXEzRaD+Lz/VRsr+Jyo4W/rOvvQTwaMwk66OUXTlDtTSO6Zp1/zSt+bcJ+Af+lUyAQiVwfl8fGUN72F1VQFzVxQp9hMgVBZqMJGzeUob9reR3d7J7QRGD8knm9pppsxXgVyvIGHQijUCV/Aw9wSX0SlJ4YfaNXJVk8WHRjZjjg4T9e5CLAke1Sm4LXeaLkZs4EVAiS+iisftRjo8sYziYyrdRMOPC23hkanoy70Wj66ZMZuVTMUxDOMJhplmu+jlamZcvJspRzAmQN+3CGPLQIM4gVzZNs5DOomAzx8aX4+ozcOOJI4S8Cj6qK2PHYoERq4Y831yKhpegnCxiTDfARYUfaZKPLIWEkBBCE4yz9tAhZjvbWGBrYE+SFe/0ImLBVHyTa8mR+qiTtfNY+HXyGaZhrBCVu5KiYB4hwxwaYjl0p5bQVFpBlyGJlniceGomHpWGuNWG35rB0Pgozc3NmJJMHDAfQF+USOfIQiz+RuYlS0lZWccTA1/RJo1zq2cRWwXg+BE6k7I42e3gVz0XiB99Ge+RnQhJBWTWFPF5p5z7U1Yyb+0SlIWFTH3wAYGLl9BWzEbssVPSfQZdQ5hpLDxU+y7qmBzdXyIozVI8qUNIkgeIRCbQjldxTrqIYX8X8176CP/lBCp6RaZU4ChS8cJGkf6l5Sz+9kt0nztLlbyeVaZPEYixP3U1uwqXcdg0j15zBh6thlZJBT+QVFK78kfEFTuJeKeJaAaocs3G632ArA4ZqkvNGBKC/NT8BXcmzqXEn4ADH8eydITH/dQOWjAk96IpOMce3QLq8t9BiCiQ1T/IqpwTWEQFadfPxpZZwrOfm3ktOgd1TGRBVMYdCiVGqZTjvihDxHk96mZ/nwNFlo6M8RDT7h484SmK9ztRzSkgoB1l0Gtk6EQK07Zivp5bR0FPM2XNn1Ksz8I6/i2uNA5gUKVReEMdT7Zdwq9IZq22AvvwCQZDGrzDWrwjWuq+cy/5s+biGPay85UrGJI1zKWetv6rRPOCOH21lCoUyLVm2seuYkxIZUTQE174DtFKL1Pu+UzKFlIVPUPtjCjlX7xJkymXFJ9A8vdfw+Qfp7x+kHu++xLXrL2VqnId8i0vEpEE0C0+gOKykTUH45Qb1jLpakMnqpAICvbYXXxuMbOkq5yIuoHPej9j4NNd/KL/IwKM4Tf8AKswnySkfJGlJW1wlN/NqOSWNS8SioXYOraDI4YDpOvzqBtZwCz7EprjMjqSPuDR7HECGimxjmtwDP6C8ZmbefdMMlLzJcYy53Fn5X2UxC7RH/Jijwe517EWb1BDpSGDhKRiBmw1yKcczDs5zGA61PrTeTLvBxT03HzThVAAACAASURBVEjalSKSYp3Mis/DudZKSmkJiHH8Z1tQWYoxrcnGmJqALjYNr/+K3sxZvLb5xyi8A2iDQdShIPq0hcjTZhHu2EeiT8OxYCsFl4dJCAISCXPbRayub0SxKQNGTLB1gYSo30vmSJSGah1Hcn0suypyuEpClTeJpWcDaJUJ9BlCFA3GEQF9STmm2zdzsP8gvY0nufGVq8Q8PobX/5TaH62n4Zwbi7MFlUIk3NuL/9QpYjYzz61NRJtYwEjVPeSfrMc8eQ51JMiuiii3npOhK5+B7Zln8H++Bbtejz7g53LVw+QMnuCLpauZWrWW6nmzSXzsMW4+00d7morJnDR0Zi1xrZxjFVXkjg7SZMvn6+RqZo23EZcISBFRiSFSn/4FLTWFuLOt5FbM/qdpzb9NwD/wr2QCJFIJjV+3o7OfoiEtGY9hgHSVFaFNYEBhYAb5TEi9mPqucqm4jomERoxhFUbRwFlDJTX+SwwFU1jAZWSSCJ+nXcvh/CLikiQGdVZW9P+NAWGEJ4a/S7f2MmeECD3jK7GZjmGM6rl2ahWiRE46UpZFL5N58RhDhRtQGoMoUixkBLWcw8dJ/DyreI5C6SB/yLBQttDNxJSJxROjfGoQ0OcPE7ObUUzLaXPlUjTQy4JzlxEFCe+sr0CeWESmL4NUfyrquIKY3EdYOY0ghEiSBtCIMcY0o/Rr+7n+6ACm6Smyl9p5cO4cgrp9+C0L0HuSWTu2n5qJC+iTlDQIFQxqi7Gue5SRmISJkEhMrkKrS8LU3kFG3yBJLgfyfJEEaxEyjQ5regbj6LnqN/CDm1azZtVKBkKD7LoCPZEcys1KxPYzJHW8zE/cQyyOTWIIL+SwIsg5IYXR7kF+2fg5yc0HUBaWI+g1hNtPkJ0zj/qpMb7u9yJ43WQsmI2iqw3fyVM4P/0U8WgvCY1SKvqmqettRG4xYT1fhOz8FPLjUYrTCog4FiORykjqWYO9p4X95bVc19NG+p13o3jiQe5O3sOR1CQcej+ZMSV7zrvwJ4/QFrVSbW0mIeThkHwtAKvi+3mu/5ckG3uplyxlwdir2J0v4XZfISpMIRMTCRnbye5aSkAsIi6XU55Qil59C4pgAjrhY9RTfezNKKMyOIJ0OpGjWcvIVRxihv4ASpmX54QnES0BsjJeR50wSW73XB6q7+KUEGFBvpknluWR2+smATgedOONyGgWJlGnjePRRuho6uWSqGa5VEZcImOi4AaM584QFYK0n85kSpFE2vee4HAkwubmGInOLjrGzuFOaMfucpCidVF062bWZGro/2IrRdYZmHPK6XWFCLmcyFT5bPjxA0RCcb584SKCVMKmR2pwpxdyvqEQWSRALJRIkSWV2EQjrdEEVBoJ0zEVWncGKuECQ86foVeFyTzwHMFTJ+myVPDEvLtY3ldPsdyNfvlyApcv4/5qJ4LJxMhPHkM20Y/tx5m4FU0o9xVhKrybmLMfz8V3UIS6iCvT+OksK4ZwhP928Bcs2jvNyQIrVzJHkIshZnbUMpG2mB6Dhna9gDzip+ars7gbxslWSVlZdxeLLm/lDAG+kJ9nn2qQAm8JmyLpLPHWoZtYhKNrE3qxlsCIn6c6hilJsfHg0pl81vEZeweOcsUbIihCRJRQ4i2iPJyNUi4FETQFaZwIFTPzwe+wbiyBoh1XkW07QMLVw2THuykfM6BOruaX8peoK1qOsbqWiU92o0yuIHlpKoJeyciPf0xscpKT9/2aWofI7N5B3OUFJIpxlIU347IIiA27MPpC+D1a9H4n8pj497yomjED4b1XeFC/j2MVeoatMc7kRTkwU8q5rBgOvci6C1DVB4mrN6IpLSb5wGXSHCCI3xiIbUtU9BjCdJ8/xPfeG0MjUXCh9AFSV8wms8xEOBhjsMVO0sBZ5OnpxH0+9pXN5PDCnxKjksEwXCmqZPWZI8jiMcK6fNIcLjLffgt1RTntjS1oerrRhsLYtWrS7N1M/+ABfp5dylDZDH49YCc+2sd3v97HpqNbqW05xypHL3OvHKFNPcGwuY97zjchFQVk8RgAjmQTgW3bOeWaoINR6ur+XR3wf4R/JRMA0HuxD3Gih2DcRWfmNKFoNel2N+MeJZWpapTSPCTd9QSVSbRkBvHLJ5kxnsTl9GKazQVIY1JmOB0UKU7zh/zNhIU4g7ok1gx5sDg7GVCOkim5k2/Ht3JUJhDXtxBUTVLaq2RuQMoMnZQlQgTLofcQ1AKNOXdjN7VT5bcRl4h0K0/xlPx9qiUd/MycRHG2hIQwzHSMo/dFeU1tYu3rUWZe7Kagq4vMvkG0Yz7sSUnsXLmEuMqCTJQh86UjCjLcajmnzaX0qASGXUYAYuph6m31zO80sfh8H+1L8vmkbCEXhXPYFBY2N/RS2XERqVrO7iXXES4vZm54mMGgifb2Dnw+H8nJydxw3XXkfroV87kLVOT3om0OYB3sQLexnzXXPMbMmYtIz87lDyft2KxmZueY+eiYhM6BFDYlNvB0/EWapy1M+1UY61ZgnRpAJR4mHC9E3dvPj89+RIprHFX5zaS99Fv0q5fg3PIJ4c6rZA41cs5Wxu5JCeJbr1Jw8ShRhRIhI5Os116le6GAr+oK8l4t6sNuYt3DSBQK5Kk2nPVDyFsdGAO3I2k6QqJtkG15S9DO6iDJdpxp/26mIyE6HYXEA+ncl32VuvRzzLC0UGFtIyoKuIVEGqcrKRjp5kLSTBbq9pLpdvCF+nqKXR3M772I83IyHlcC8vQp4rIgspiKJE8xalMBEqS4vV2MlQ6Tc+1i4i1hgu0N7Jm/mIv5RlxqA3kDWdh0J4m6N+G0LyLL+h7JklGiGjvytpnMCekpyFTxeHka8d0DSBMUfD0ZwOMfRB7eTZL7LPXVC+nJzOXmsx9R6DmJQy6QJc8k6G+lNRpiZDiREFoyzDeyW69ElMArhblIKncQDMQY7Q4AEmYZulBc3Ypi0XrEik/QTM8i7NAhr5pD4dwaxvpyyCgxc+XQACMd02y4EUJMsffdQcSYHMJaKjXNGGXZjJbsY9A5H5v0CGI4halQGmb5eoYnRFbdP5Neuw6naET+8BNsH3KSV5pH+hd/xXv4MKLfTywYwnf4MDGvF6JRJkqakEQgrfdmRI2V3SkxpONtGPs62Vqexv7yEn7aEiZbPYfzEg337T2PKiTn+styrj3dRYpjkgO185lWSnn44/e47eJerKO9BA8coKujj+rgbqY9yzkdKyaYeJazpnqsKedJkevRJ9cy5RJR+qIUygWmxTgVATnXzl/AvXPuwhvxcsXegkauR4zEUYsq5og1nLs5Gwa8GBQCYzGR0dEYtU/ejLD2Rs5elaGTB1ENNSOffQuCLIk3zJ/x9fQUpcpq+k/aSUm0EptsJTLQytT77+P52S+paFGS5YuiMZdhkhcgT12AVKpA1vE5ynQzkeFhkqcdnC+rJt0+gTI3F1VFObYXnufG80/jD49THt5MS/b91FkyGHZ3gejHp19BsdtK+vAons5BglEZgn0YmVrzTXMfIKfdRebnp6g4NUpMqUTzuzdo6VBQtSITo02LMVnD2VNBMkaOEndOc+GBH/P0imup6LzAS+/9iarYXDKcKr4o3Y8pnkJ5ez/7b/wWVRuvwRWNca+oYePhfcjEOHKpB63Px/LfPE3M40bx3uvc97f3uH3/DsKhKUbUchLsU4QcdiYkfrRBObkTMtLtPo6kz6LANQzAdxc+ik3RT0QqsFppI3XNNf80nfm3CfgH/tVMgKPXgavDTf5APYdmgjdcTkXUgWI0SHqFG+vUHDyuLlL729i+bBn++BVSvFbUKiPDWhMDphSaEm2sdtbz+6LbEeJxFLEoK1r2cjLpBOZAKhbDJNmmdjb1T/OVXkVcIjKrxcRbM7o5ZjrGwgteUvp6GS9bwqg2g8+L3+He6XxiyndZI+wgTbSzz5bAUZOWxfoYohTKOrx4pxVkf6VBE4a/1Qk0Fdi4lF1DdoGLHTPLiUoTUMfVSJGSLW9k2jjKVFaMgGI/Hk4itTQTsnTRqm4nLhH5ySeT9BRl05pXCT49Wd4MitrkqKZjLPn2ndzwwKOobalsdUNPQEHK5CgGg4Hy8nLGxsYIvfY6+itXsDz1E5JUp1EmyfBdFBFdfvosXzI1dRL/9Id0O/QcaPNztKWF073wI/nnPBV/j5Gy1WyLDaMZNVG4+kE06UtxfLaf1NNXmD3aRrcxGWv2IjRFazBuLEBmSiI04CJ4+WtS07O4fmYa6z9/kZrJDs7NqOOAsYjqznM8n1CFrXojKQUVaG/6Gb3jXnRdrUiiEeIuNz6pnKspedSnihTfU0ftXb/gs1E7QVkqqxMcqFRpmJXZ7Dy/lqi3jAtjs0lyJlL1qRx1QRlfaQqZKblISfAKqktTmNKnmK28wLDPSrO8mlhU4Pb+g+Qr7eTGp+iWJyLVigQt/Ujzv0XWuhL27H+LqbEr3L3uDkLvbaN09yfoAjomjSZuPriN169dQfaQkvYdAXLH51EUm8aU8RFHXEvJUg2wM1HB3OFCilxSIh1ulLmJjN2az6mj76BwnyKklCMXajg1ewZBuZy5GTryHL3YJ0cYC3QTFv1kaksoNyykOmk5Rn0iLxQruUGhZVGZja6LEuy9sxHFb7q8idolVCq+YnjyMyZ1LjySEWwTc0m/Jo4rT8voRSfqiUYaL0moTR5F6nmD03tMRGMqKhQ7GY5WUZigQCYm0OwHnz+VSt1uHJJ03pqTxRepKpZNRMkMxWkfVpN/33rmrcph55URfCnp3PXrB0i84XoSN25kR9BAZHISFixBFR7CdW0Q7TE5ql4VgfXrmGyPseOaFTSaE9kzey6p01P8pFeBPBSjyFiAI0XHwvKj1Jaa0KWFsWln8H7eDDJ9QW62j+K/4zK/mP8jxBEFFecPE3LK+GvmLQz7ZpEakyFTtnAIL5GLlynr6EVfpuNBfxSzoOF6Uc6RVDmvDPfydudvaBg/jIW5PNj5Q/zyYVrUPRzKXMNbsQDZzig5o0FsG3JpOT6C3qTi7K5+nFIzy165n5Tv343o0eObCNCrTeeQpY4vxlsZk+1jrX8mnguHce/5EHVFBZdqrqeoL8A+fz2WY2/y3DWrcMkFnJExjAffJWHpEoKNjQAI0ShCPI7t/fex3bGZnzR+TMvIDubk/5APrr2PvmCUHW4Tfv1aZKEBaoyVDEfTWHTpNJ8uX8XxrEzs192G8bFH0J46CW43sttu56vsbJboztKxNJ+H0taQ3h9kxcZ8FGoZCpUMx2QE5+g0o2UZPLxsA3emWxh0/YbYopXQmM3p5F3YqlNZfXCUQHoGP7rluxx1+jnr8nFJlHGXXg6NjWh8PgSrle7BZsqee56Kri76LBH6V85jPBilas16IrUm9CdPs6DdhUIiY0SfwK6MOgwFaRS3NxDVaehZfxuSwUb0UhmLl61FU17+T9OZf+8Y+C9MUoaZHm0mBZ1RQIYnEkVr9EJcS0tojBQgmFaCYbgJmyOPMaWMM9YzrB+b5qLlMXJ7O+kQbLyYeQdxiZSQQsavWl6lAxPjigCiVM2NfM5nnsVsDlzkl8MSvgwkcrowCAoXv+z9HgUtf0NqTKdXfy1e68fsGBkhWfkkYQQcZjn7DAm8EFbzkD5INKjEc64cJfs505OH1e+kOzMFu1XFmawRkEyxTVVJpqOPhROpEFHhSTxPr7+CBtllev2XSQolkaPOQadXcWnyMjFZnHXNSoZy82gqn4FX5qUzsYkZ44VETdlEMrVMSJVs+/JLXJOT3ORwIIoivWYb1226jvXpVmqdLhydnbQVFbHf4WH9opfJOXg3ptosHMfdCKUmwgu9qFTpbJ4V4pE9Wq6MRHlB/jpLLYPcpE5mJNxByexiDE41R158lgWX2pDK1OjT/cRL4U+FLl7vriE62UHgSgJCoh7v17uR560g0nWIEJfRhaUIyWls/uTPjA1NMnXNQYpO7+dBlwaZVEE0fo60aC5vAWG5EnkkxJt199CDnAFVMm3N47w7z8M6SxLvDcfJKXkJtSBl5+keopmDLEqMMzIU4/Xx5ewoWUFiOEgvRlaK+4nElezRreJnwot0xAp5Ufk41qFRLqaU8mVNPmM9eTzs3kv6dAaj1m6OizN5SxLh8InH2JT2JXeU/RZRkPLJqvXE3QFSMpP5tvsIpaeO0/GqmtPj/YQDftwxJRXX+YiHBI5eXINxoYtqwyn+aLqR701E8cZEqme08lSTjxXTHTjn1PFO5VLuPTqNS6kE4GRGFf/txe/gd7toOtbJ+T2TJC1/CtXkWmLOKO+lGxEleWh3jvLRJ8OADZ2uidQZR3GfXoXdaabnipHRJ79ZShVNl4hL/Lj3HmRLupIf2T6kvvPnzEgIkhLKIjpxPz5ZiLq8E2jbT9DAjSQIFhy4sdsrADBp7PjMzbSnzwFg53w9i89MsUgnQzg9gt+gYEmBhQ8ah9kSTWdzYSHxQICL0TMo1AYKD+8k+C0zSJ3oRmYSHT1PyTWpjCig/1QXJ7LnETUZWPvRx8QoREywICQHyJDW4XRUE9YpUMY1CHJ4pteBzSIltuRWRPUXLAw38twj97P03YtwCW7eu5WMrBnc2rePaFDkLzcl8eV8N139LTz2ynlei0JDYTmTlT9krnuEfYlvQMhJQPcdVkwsYG4oyqV4OacVV1mWEeAXRTUEYmNoBkfYrYpiydRx9KN24nGRVfeUoTUoASWiM4TCouaKcSYgJaBMZyTNhNvhRiVPIujzkvCzn2Db7qQ7QUr+qb10pivYtK6UMZ+dR9sdfHwqC/nxE/xn685UxyRP3/cIMWeUbw80cqjjDfT6Wbw5724kEgl3pJr4YnwauQSu180m7WQFB5KjhGUyqjpa2Dt/KX/VaHmh184fZCqy8wr43tKN3DD8FUaNn0VaB5PxGH9ZlcjcWJC6uIKzLi8HZig5oruOsDzKMwlS7lBEedxrRH6km5yeEar6rpD0t2niEgkl77zN25ZUvtfcx2WPn4ezkil89BFatmxBiMeZ8LlJ3H6E+jIzH8+oRm7toPZSLzq5nFcVZ2ibmqDm+5u5uVNF0pcfIZoNFJjDPPzd6+jb8VcScvL5RbWK7fvd7LQspy1WwKv/f4sR/zYB/yUYUo34NcnIYyANayHmJJSsJY6EvgEFXrkdqbUMUbqNRVev8MHcG9FFd/Kl/irJ9i/pS1qH4oydvYuWMcPTTlZghFfzbyOpeRcAv3WeZ7RCzuGTKymKSbk5spMrkxVkTkyx8lAOKY4PiQemkVX+kDr9BGZ2IkQTGYtvZlPuLuZLzRh6IqQXTGFWwofh23lYtZ2R8SRMnS4mjEYuzFtMuijhlnY3zYYhepM6qLXXEZCG2Z+3DYVExlp3OTXTNTyj34BlbJjg4CAt3efYKEZIF5O4kp1PS3kOqRlWmnzHSPIEuGPddQiWFOrr6zl79ixGoxGr1UpxYSGJEgm7m7pp+e3vyHKMompuQrt4EdVPPsnQ7t18tP888H3k2WEW99djfHuIvt7lOArywTvFKlkTyyVnmV3cj2zTQUa2rUclU/HcrKfp+fgpzsQiTN+wkZKNG4htb8GkepK3pj1oZMmI4bMMfu97CKakb5b0q64h4m1G2TWKZ3UMdfosPPtPkrp2EZJNG1m6cxclj9/P0XPHya+po+jRXyMVpBR9+jG9N93Mr61TdOb8jQ+mN3F0YD5HTt7C4sLneFMUubGhmx5/EHcsDiUGvgakNiOpkX48Y4n02GxIRwO0KAoxqx1UmNsxKl2IihwCQgJeXTHTSBFlUorLLzF6JhFDoIWm1hQaymuII+VtRTqJab/jTG4lxcODdKSmcfC2hfxc9TQCMRovZzPc14pGnwpSGyFpO/5oK/GIhm/ZTfSMLaU680UGZrXTa17H6Gvt7G8cJ8E+AMBtbe3UdPZxVWpAlNxAanCYy6RxaXAv+ZrFNB6fIm/1G0T1buy6zxGG45xMe4XSqRaWnfoMX2o5+MYRHj2C35FAb80Qxt5CBh8qB3kjlokQk1YlodStaIc38aLvDg4F7kEjSSVbJsNlaEXvLGJeroOU2TfR/+purEuCyKI6/JkXYHoxCpVAwuwVvBurJiXgYfVwO+/nz+LnyQLP5Jjg5FnG/3CGsowEIgvLebxnguat27jzvTf4STRKSCrjy9mbWLm6GdW4Em3uGnwNl3Dv2kW9upwxlQR5sYEsvMy64RDq4Goi5xSYZa9iV2ahDV5DxBkmYZkV0TiE7sjHfNRbwIn4DH5amcyMzkbWmS9RWdBLv3Yl2Wdayb+6l1ChiPcHz/GVIh2tez9Xs7Zw/yM53HWqiIX1+2hYuYc/JhzBFNfwzKw3KB+w4usbIjjLwqrAXHbGP2ZWQh8zExfhkTtxxqPUt46xeX0Gk6+1UDA7mYJZyX/PV9GpANO5OvqSo6y67ONMoQp95n2YnWH8AS+9ExL279nJrVMLuOA4TvGEg/GVMzGHrvLrk4+RGAvx3LrN/P6Nd1Dk5xPu6kKiUHDrwtmc/eBtXs0+gjJByrvZ9yBIJARjcR7vGMIslxGIxfgqNhfvfClxmYSALZWyvi7K+roAmDQkYfC6qZ8xC6UEnoh8s091grOPh0772FYmoeeHP0DT24MqFOKuUJC7/yEX9wDf/4/jmFSCprKShLU3olu+AlVJCauBh71hTp3vYMN92ewaPQTpFgoGxplOUPPlooV8suoO5N0eFl2px+o8x1l9LfaTaczw2clxDqCYuIQQj2H1+JgcbsYvl4JcjiIjg3P7d6HWaHmSMZT99UDN/0np+R/ybxPwX0CiVUNcUOLWKUjwyQkrHGwz3sxM5TF0Yz68Zb0kR2rwWPJZcukcf732aYqudDChHWJAsg2tZpRg5W2MaxK5tX8H6yZOsqbmdcxJ7aREo0hTBDrdWQyGLASjJQjyr/juwCDePjVxzSQy1RS6Ih/H9QauVf8SSVxFR8pSIlEF6SGBQ6pJlif5edwbJGUCfu9+G2twipazGUQFOLNwATqHk5TxdiZthRQrSykaLiEmiXHCdpT1iXO59YSE8Kl97Fu+jKMXrrDy9BnGVWGC6gia5CJO5FQwJQjU1dWxaNEipNL7EUURiUQCQKZMxsQbbxJtP0tkcJDo5CQAtwBhpZKO9GwybrqF7B8/hF+tZd2d36X9aiPqSJBIz0k8YQO6Y0HK9x8gfOIo9jwLsbxyOlUVaA3d5J18iz8tehFzREHg/scxdnaRUjeX832t2JuOM5Pf4c/4ISUDLzNBJ/ZbC1A8pycyPIb+rudwyi+SUPtjDOs1dCneZcK/FemVBFRllRi//W2cn2+lbNeLLFF9hf/sIfp9brRLFqMqLUW3bBnOr74k8kyUdfvOcih9MSf68qgTbyFf8RdcXoG5w0G+tnu515DIho1FbNt7gP1WmMw0kiyO8nTaIJHzRZhmfsXmwh2ogrnUiGu5T/Iyr4kPgwR6NZsxhV4hkB4meyBAnm0WzWIFSGC7YSlLxIOI8hqqEi5SJJ5hh/YmroxVMjP5Esr1k2R+qkMTrabHkI65/BSIcQSFhxLnVjL3a3Dfo2Op5BCPO+ewdIYSp0tJ3bm9qMMRVIFxyjwu3EnfiMm3P9vF83fcx2dbD7NC/jSpCwTk+nEAssz30DIsZ0ySykbjlwzekAtSPeFAEmnCEdQWL3PNn9A9VUBc24YUAbdDj1QZYqpqAvWwnmcsH5DWrGKZQSSYMMap4Xxm57ZjGili7MxVJECW4CEuVWFeKEU/oiLRquGL/G/TOhzi9ebfsMl+kNaELRyqtHHDkS0U7vyU0+XV/Grxj7BMOyi62sP7tQuIybT0X7YzZ2MdO5quMtf3GZbhWxmq3oLpSjITH3/ClvJ7iWTriEjhe8oPydZlY6lYyujFEwQc+XSZZ8OlT7HJW5Dv70Ah+LlOIbJiSstwaBk8O44kGOMx2YsEFsh5dcNcVi+9hNcrobnkZt4P2Pj5u69R23SF0zVpvLV4hA9rXbTokjik30uJLJ+ftX6XNBLwtQ6hnZ2CaVUW4p+cpNtS2Nd0mIWn1ARf+DlSfRrLNHfyTE4CH/6kmvRM/d9zVTwYJe6LsisapFChYXbnFIkGFZ9rQzgCkwQnr6L3iaz/aC/e0GcUx6NEpXAx1svvDv8QmVSGKMboMW+nOy+f/MlJkMmQarUUb76NpgVSxg1SfrI1Bs/fQ1dyMh2VNeRZM/j1ikUca4M3cgSWG3X8UiclMj4GgGC1Ep2YxOKcQgQWXzpD5cu/JSQ/i2hMIuIMMrv3eVZu6ULyHz/h/SOiICMmkeOXR/EpY/jlCXSlefAkdzPbWMLc0WGmtm2n79Ax1owPsgZoOPIxf12toqSmjoKBT0hZs470hjM89tazLO7q4HRhGppwhKevbEHyD9cKKOQosrMp6evDkZDOkQd/QG1VJR77BD2DreRNOEl2tOFav+GfLTX/U/zbBPwXoDUoEKQRQlo9FncMp81Je6CY+HyRa7/+HI+2jRTHbNyp+Vgvt2Eb8zCqlTBnYiF1hs/5K2cJmWaBWItlQkalv41d9U/wYOYIZTENbouLo6dWoQUkk2P4FQJTNWpipc/zF/UQz0t/zkfB73Kd4jnikmm60hYxlncUaVTKs31u2u0S1vkCAIyrDAxhI9oIwlSMU3PmEhcEjJ4Soooalh14ltG0ZAazcphW+Hht8QPIn/uQWG8vEyY9pr4ORosqeO3aMo5mXGRDZD3qMT0qlYpvXXsthYX/fXOM/zQAYjjM0I8eJjI4iKqsDO2iRcjT01BkZKIqLSGYnsGTjd8s0XGp9x8iq8IWVHJD4noezGxHv/IY3lEl9o5kFI3DpLSO4zCb8TVlMFX1N2yHNMTO7CPstGN65Ckqcps5ubWb7oMmrHldqGLr0QrvoJXt4c9+F099/Ffc20YY0LxLTOElcWQRquxKqtLnc+HAtYzNeB/pl2qy196FC3US1QAAIABJREFUIr+c6YMXSFonZfpwI0jUJD/5JADyTbPg4EFs3bWUFZVRNDLE8QvVrPOf59Wd3yFWmcle02Mcd0S45zvzSDWoSdzyHpvqvHRVeVESZtnMLYQ9BhoiO5HK/VhGN6HoyGPRwjfRqn7Ds/yS1yJzeVC4jNbWR+7ABZoiSXikicwPHeOUcgld+kKSRDvrEj7C0WHknHUOmYYBIn4BXYYP4Tt+zB8eYNELWzlz7gWCkxrSDvpRNnwNgOtgDN2KC5gCw+wqsWG1ZzDvnMCBZddyZPEqNnKAC5cEABIS0ykYHKHetJBNLx3DVyxHdq+eaNxLdtVDvK61oxwdZb7QhKx6EokEEJX/MS/AKVlJ2uy/IpHGCLktpHiseE82413XxKhxiFWDaah1MaTSCI0yOeEI6BbPI/pVL9gNIBGw6HT4zFdJMq/lukcrCIgiK1q7qfb1ssl+EAnwYutvuc38J56auYTN+Rm8kllNmauLW5okLAuXEJkc46OKSnISgzy/uJhx+19BlKCI2wiYPsE5R43+43Eys0Zozp6JdmqKdOMhbFnP0Np7AePoxziGwtjGthIPS4gDA+iB/y68guI88iVljBRdIfUzOYMnTKwrfZfxMgMvy/OZnl7Bn978LbndHTBzIasco6R/EOL3N0U5VCVhcWOcJ23zkCfZCLZOIUvRkLg+h4b9A+g9YYrUJRwVTjD+ejtytRV1JMDcT37LdP8SXrr+u7yQNevvY4k6vmkc1KwUebYsE+OyKda2HGL1Zyc4oenh7TVSgitlGH1+SsZ1FHU5qS+V0pnuZmWLnClZiImqDIa8w4zLPOS5Qv9xkwKxR+5hu/pvFCXm4XqonGPnm7Ge6SXv8F4eiwEfvcUmQWC1zUpiKExk0vH3ccUmJkApx66SEo9JSAxGSbrSwDiav+cCA+3EBClfLVlFc14yioiGKvzcpNcj8/tp6DnF0MgAalc2iUEvi5tDqBs8sG8Lo2whJAj0JeWya1YRomaU686M8scPg5wsUSOUlhLumSDD7mbQDBdKsghLRboKZmG5NpfFyWZOHd1P51AfG376NH65iobtW1E0NjColZLbeJVuaxIYtXy65hZOV9WyLC2Z+f+rovK/wb9NwH8BEokEg9YHqhRyJrrpyvRRaG+gvaiWpuEutO6r5BInYCtEvCxhccN5Plq9GaclRGnYhIEuphTZGLx+Yn1ziFneRqZqwCOkUBSJ4A4ncCFQyvp4nFOGLmRJem73juCWf48ndDLORspYJR7EKAxxvCSBmLkJ/3gVMdkIBaKbdb4AfWYVXbZEPmm6l5+efA/PgIpzOWWM5GRRdbGDwZS5xOLnGKgoJa+xGXNQisYxAmc6iISC1C/J4cqaZBo8zZSM68nwZbJhPAVFQEVeYR4bN24kISHhfxgf+1tvE2pvJ/21V9EtW/b/Oq8EPqnM5YMRBzFRRGEPwpkxJAYl+y0Cf06K81bigzwfT6StoJgPvrUA0+gw6+sPM6ejmfTWPmRNUsK8C3IVwZtLGEn/FbFYhNRZaxg4KXK6azvb1WGu061mjnMnl90Wmo8+i85djavoazIt98EVCPU4UWZlUrPsc/6840c8X5RL5elmNqUWY+hqYqRjEZ6BDgyFEeQpabhOd9EpeZvEFAHN/iDGVx7i5n1t/L5rFPXfLCgcboLqQXZWj1CdZsCWqCA8NESos4vUm+/HKfkzMpkelSoN78wOhLMCojJOxi2bUMSt0Po4xvAxPoz6cUVjvMiDRPK0FF9dgFv2zeN+f3opXRNjuAUDFWMe9hxaTsWsWl4pHCE0aaf1WCEUxygxdWO/18749psRsuL0f20i52QET51ItDwfs8eKT3qMF3c/QldfBR22NESJhNIkF19NOzkUn0timheJGOedxUsJoWDCKGfTc29i8Hl4veE+EuYXEkbJjolp6rR25N5J/v4aJQkx4ksnSeXGIL+EaLTj6ptH0FHMLIsFPm/Ds1bChO0IldN3gERGc3IDgy2VSAUJmeWltHQfwHSpFsmCu5FLdIzqO5GP3kbyTBVv9I4xHo7yOt1IgMFQBTlCI8+88xx/umc1zYkT3Ol7n+9rPDRedxM7vnLwfzWkcMOsEH0ZKi56fCxLvYR6upDJjE9J1S2lpbyFXMFHvmySZrmU62XHCUdlTO64hOatX+EKSkGmgpQsVOuWcuKSHoO2GUu+FJMiHYPNhLn7d6BqYSIrQuaiQbpPWkl5C96/91uEbaW8+tzPSZl20lZ1Lxv+8hBypUCWy0XpxWMcfvclFlwcwafZjnbpDASzkeiYn/E/XSLUcIxY116W3byOw9IoPckuqm/6A4zqEM58waqzB5lqPs17hzZQ+tQjzLEaGRv1IAWKzUpyXnuZ6Q8/wieXsOcGAyeyBUrd6RTJljIdbeOq9TKncgWEmMjD22JUj8pQu+KM14/yoztFruZGyB8TsLhiXHr2W7zc/yHhSIT26Tb63X3kGBJ5YCyEIgbjRin7ZqmwTAdIt48RVkHNJPSXJtF323z2RRrojYyxrNFK5qCCmETEaS3n9gNfIUsyEJuaxq1Xc/+Pf4U5K4G3KwrZVP8Z+5Rr+CziZoFilG3WPOi5G61CxW0Ls3mvdYL2rmHSg1PI4yG6kzLYsMhPusvJdNc09jtWcfDF99nYcpyYGEMvaac7fyaaqAOfTASDmYDZwg9yyvlZ03H8w31kbbiJL46ewOdyfTOlcwrR9rawZ34taucEkZQMbrrzdn6nlmOTS//5YvM/wb+rA/6LGDrfRHjSixhu5VKBhMBQLSmJXi4VzMfc3UeRmIxWMCKd7MI21M/BhXMJyjT06DIR/EbchkySJ/azRDjIjGg3n2hNNKgFbk7zsfvC9XRFM7k9dJlPak6T5c9B7Z9Jt0xKoWSIwtAIBuk021SLMZshqAzwedMG1oy1UegdozMlkbGgBvMbAgsuNuALytldPB/HjGyy+/ohXo0rfhKXZoq8O86j77Sh9AYQYzEIh+lLlfPH1U488ghLM+tYVbMK74AXaVhg3bp1rFq1CrlEQjwQQKpQ/D/iEmxrY+TxJ9CvW4f5vvv+P+OnEqTMMSRQOR4m89NuynVqFt9ewW3FNm5MMaKQCrynK2PKVsAKi4EbinMpWbGMh8rnMJKVgctkQDt7CP8NbgIl49h1d/Cs+BQf6GZyqmQGFsc4mR2n2WctY1P0JMPKPMaSr6DNakahMlNR/TKhFicxdxgUUl6/OMZzhtlEY4mcMylJ15ym5HInwaFpkMnJWDiGo3GInvBh/LoWDP3LiF29QGjQSmowAdvlD8gfa0EwmxEHQ7ydcy1rMj4lIfox/pYGvHQhW1sGShkQp7vnj0za9yJVaIiLIUZGP0WtTyO18HrUiTaODZ/FLaRybUoKfxlxY9H6OSNUElRJ0Q2cwysJ0qEo45GMaWqyPmBGfiYe32d4RkV2ejeyJeMuYgoZedFuZFYX4S4lQ63JaEu9hK4LEU2epG/SiCzJyWSRjl1LniW/fh9qbQY/jbzCyug2XM5y2pLMRCUK3GoFPrUAokihNMywMoGy031Ur1jHTn8me+1uviPZgjHWjUZTQCQyBUAgKkcmVhOeBEWCHffgLFw9C8mc6ya6+zRD1eVorZcwDtYxmnqFT33VWF1gTIWyhVl8vd2JWd+GWlJDXBKhTT4I0TJiOVoeaO1nrdnAD0MXiA2exmOO0W1QEVk0znxlPVVcJkfRgUPoRxbaQ3LWUUIhObd15rDVKnDV3chK5TZCY7WIyQ1UHr/Im/HH8I6EGSzJYiwjm5/HfkP+0QCST7qJyGWcuHUt+ZkP4LMt5Sf6TNyhRNSSQtrmf8LT4mUaDEGuX/k8kvPvYRvzIZOIdK6VM9YmZ+3xBtadPY4q7OOF6xOYVXk/hbVpAEhVKow5RQTjc/H2TaO1txAZPIX5e8tJWFLO9N/+irzhY8SwD11HF7tqIiSmZHHLD59GLciITaXQXTzNo6sHiHlaKf3957wwFWLYp6ektYniXS8SqK9nNEPDb2+TcTXFz3UXtTwRfJqZjkzmD5rokGQwou/FICTxyNQMgr09NG8oYWbuYpzZJg6axjheJqclM8ZnXCAcD7M4bTFvr3qbBFctG5/fiTImRSKRoPPFyJtIpvxnfyH5vltI3HcW/H7evDedfaFL5FmKeCD/XuL7WtFbcwl7pzlZVUnL3CoWdfYjSZzm2w/dw6SlnO2zashOMHFTeiHnG15m0fajJFxooiewBI9aj2emiTPyGHMrkvnp4hImekeJTLl459H16B1uOho6kMTjDHd14NWEsJssjApqOm66mwqJk8aMLIwpNuTJ6Uh9bmr62omMDOLKKmJqapoRuYpjhdWcLq6hbLgT9dQEcr8HiSgSMlpJGBmi/d0/M1B/jNK1/7xPAv8uEfwH/hVNgL2lg+FhNTrXGU6US/E7q1njP0OHvpSu9FJmuIYpDtoYj41h6Wsgx5WJGGxlYV83LqmcySQrcteL3O1v4Y+eO9mZGMIqCdA5divHnXO5RhToS/+AKYWfVybbyZG20hk385xFpNX+MN3uGynSJOPJP8oV/yxuHz5FebiDCy1FuI/pMJ2KEo3J8CtVvLL0W2jSlKgjEWafa+bj8sUE9CIrVgeIRcaxznuCyO6DTCtFdtdKmdcaZc14Co/+6BNWlW6k0FxIRXkFtbW15OTkEB0ZoX/zZux/fhWZ2YKyuBiJRIIYifzf7J1ndBzHle9/PTlhAoAZ5JxIRJJgADMYxJwpWYmkMhVWOQfLsqxkWZJl5ZxMiZREScwiwZzBTAIkEpFznAEwmJz6fYBWa6+97+3ZXa933/H/nP7SVben607VrX/dun2L1jvvhECQhPffQ6JW/1916Lncj3VdJfJoLeZbcpGo5QAY5TKmRei5LdHCqthIZkXoydGpSdEomRmu502fjOiBXvqVGWRPHMuPhud40ZaCWq7gqbRY7kmOYWnuRAZKq1G2lOOMiKI42MH9cb8hVXqZqTm/QadNJdDjZuhSH88GHHxkEZjjlfJRdTWL332OWTHnGRRUCB0hysYvJCmpijDfeRoze4iLvYWkmQ8y+MM3KJPU6BI8WA5s46vcBUxZvQzfoYMcic3nsbmp2N37GVBcxJstMuA+R6isHdmAlOjcX5Ce/jgZaU/heXQj/nSBTtdWhhyVtLdvoA8zx0P5rMtL4cKQix+EkbQpoxhvv8DC8I/YJbmaQUGLxHGMXNkZBv1lhEIumvbGkbzsTo5Yg9SpR7JbOQ8FPjwnIsHuRponUrx0HX2dp5GG19J1ykR0ci8TBpW0lzWBbDJZ08dQb2pDdWEMzWkO9Eo9D6ckcbHfht8vIPc4EPDh8WnpHUrkJW+IEd5GloifolFYcHua0XoE/HJQSb0o5Y0odL30tk7AGFVBf+1s7NKjdOWPYKh5IqaMg7jTa3jEPAeNW8eoiM1Ejn6DjpbTtJ4qIFL2LlpxKs6IS/R0x+Nw67lNYccRDPFZTgyOqpe4mBygJ1bAq5GgbFDQVHsHtrLFWOtnYW8qwt5WiExtQ5JyCI3Yz7SWHLwJe8gQ69jcOg6NtJ4Hieds0zziYls4njedMYN13Hbke/r2GnAp1dz46Ctsz5zE1BofyVKBPfIgS4vi2e39kn3Sy4yXjMTZ60Adk47O6MPQVI1LLeXLxFw+SXRzpTMLjVRB9Y238k3EYSIGYVLuFCRK6c9jQhjyo7VFIY/OJNBwGPu2rbhOH8FXdRRndCH6sdcg1h6iJk6gPl7Cku54BIUCe62dp6O/IKCQ0GwWqYv1cfc3J8kr3UOg8RBBqciW0X7eWCASkIg89H2AmZVyNGnzEBC4PFTGuZuuZe6ZVLKbphNaGY5hxzHMsemkv/oG2QmFbKheT0LsRE6bxyAJ9CKTm5iY8zKXTlZQ9OSjSNUqNIjo5i7igmIqcW2HkJ84gCU8Ad/GLcQ/+Uuuv+Z51uavZVn6MnoPnqGt6hLXPvsSlYeOYBho5OsZN5K/Zgav6iupi72FNTFaroqNBkAWgOBXJXgHrPhEJTmOy9x16wruGZ2BUS5jXYeVnXYHMyuPcOPuddTqlJyqrUXjHETd341bZ0ClUJFg0uCWB/C0XOJyVCx6iZS1T/wSk0xC894fCSmUBIyRyE3hRE4ppnDGLK7MTOHXGfGMy8zgQslwALdeoULvCdCkUOKWKxktVxJ/xdz/sjnmHyTgT/A/kQQ42tqpbVST0rybH8dJ0EpcdAxMJaOxgpa0TA7GRRHuk6AMOAmvO4tHEUeDMZ9zI6O5mJHPiPpLZLSeZ6MhkVLnUqSxOwi4RlPTOYdbUZIe6uG7pL3MHJiKwXMLR7T1rAhUk+k0YbNdjRgRgzHxdSI8A0w91Yqy3EVraTiqHh+NcYmczh/FucKx1GePwKT2Iw8EmXr0CD2GdJSBkxgdHfSUD9F70ciZ6jN8O9XNN8UhDFOnMXP2rQhb9mDf+B0yiwVlZiZKpRKlUon74iWab7yJ0KAdZVoa/evX46moQDN+PP3r12Pftp3Yl3+LOjeXkCeAt8mOq7yXoSPt2Pc0M3SkDceRdoYOt+E83YXcosF8ax4SjfzfpXezQk6x2cQHTpH45iZOtxs45oJFaUl8lp/KBKOOOJUCrV6FcFqkz9lM50CIsapaykz5fKJdy7o+JUf6h2iPVPJFlECJUeDuBDOvjU/HNDEPtaOBcOcBJKol7IkawUvLlrPIl41lcC/REXOxTH0FeUQY/s5O7Lu24z59iuAVC3g8agYjEsKxHNiBKJMz6lQFObesx3vTehLCV5Nz9ToCj+9AU6km/b4PUKvjkMhkCL0uQq+WYl69lq7+Lfj9A6SmP8kPNglTTDpWx0bwWbsVtyDn3s4t9OiUbJSvZKRYwUVpAdeLA/hCrQx1qhlq1LNyajrnK7QEqi/zYPTbHGtfyA9jFzC1dT8yTwpFi2/DHDWVzu5vCLNoCQSdDNnq6K/VE/I3UdU6RE+dmoCnhf1p00m121njsZKXlc62fidDCjVjxNOURk/gRFgYme2VzP9uPYFaI9GmenxhAkpvAI9Mjrs7C2vVImQyLb2nr0ISXYdRWUxPbSKu3ixaLAJh8ZcJ1yhok2WxVP0SpuhzuPsykGovYIppwfRVCz1XnsPvPY3QkkudW8+hDJhNCck9T2OVdxImGgk/lk3Yh0OUq+/D7cgkEFJAKAzRH8ms62eSMmIlp89XIk8+ilHSikF3kS5/Kt4qNUobzHG6eVCyjcKwVt7OWM3KPVuxHO5FGhbBL++8k+5wC265Cr3Vz0SfwIrJcXwq+wPnxaM81nkTN7QuZd7gZGLKNPg6khhUzMVjuI7aHoHJ+slMuvoJwm9azYWdAayadk7qSpl6PBPFkARCIqIAnk11+N0BerPjUZWXgCgS7OsloNTTGVVA2NnPh+2PGg6n+xj1yo+Evt/Mhsl+TobXMudMgCmXQhzOEyjNljC6w0h3aiIvzeriWI6EEZYpvCAsJ2HTcRSxMUiNeYiCwE2z01iTHk9wlwO8Ujbrf8AvGSLrQAOa8eMJTxlBn7uPoy27mGMP0SxpJS7xIex7znDD6y8RjIhgxDO/wrFpE81Fa2n1xZCstxJqqMF56BCKrCxifvMsgmTYU+D3evjxrVdJLhjD6HkLCVTtxtrUT21yOj8OVNOpH4caFV8VFqCUSAgFg2z9/Ut01tZwIH4xtsTxjLBX4rx0hinTZzIzxswis5HzvTa+ScqkPTEeb38vKjGAoqWOo1eupTEmmcSedoxpWfzi7gc4U9eEPxhE1lRFx6Uyzu7YRLhcyaST51j82mtcMWsmE5ISyNKpiVcpUEgkaPQG+mpr6O/qQONwMYCPCI0Gp96EPyOLUaNG/ZfNMf8gAX+C/4kkIOCwU1EWIKVtD23hIdpirQwFNcR2ySiu2EdnfBLbk8NpNJsprqzD1HWaD36xjPqYOMaWH6P4+E7MNhXnMtrJ7u7DFtWNu2cuj4Rgnk/Nk7FbkKp6ea7tn9hiOsInkXUkDlkoCrWRqj3GjpFKVrTvQXNARu/xMFz9So6MHMMLt91DZ1QcWnmIDE09hdZyRuyrIPdSNWqvn83zk8nNrcIYE4EmthN98Uy+Saik3yTwbPGL3DvmPoyZ2YTNmon73Dn6v/wS56mzeJrC6P9mLz2vPoFUoyPh00+JvP02BKWOwe+/o3/9NziPH0eZVYQQVox9TzP2Pc24zvXgrRuAkIg8RossUo0sUo3cokGZasS0IgOp9t9HAP4ZZoWcorhoPhv0Ed3XxYjOJsJb6hGCAQYHBzl58iS7Sko456/Do9OhdA3QaA+jWLIddd4MckxJNLp9VHZUkjRwmrWjp3J3cvTPgY1qx1HElpN07HagCB/F+rG5OGXxzI8XkZV9h5C9FLTm4cyB69ejGTeO9LffoKS6jx1NLhZePkh8YjSyC2dwXygn2NhO9AMPQyCE9f0PCA3aCZs7B1lEBACK5BT6132JQZ1L6srfYjHPJTliDG+19JCqUTHfbKTM7qTO7WPEYA22hBWc9Rm4yrmBo8pizJITxAmtNPwYT0S8HadpC2aJjz1t+WQbm5kVt4VDwiyUPgFdRTV5s+ag08eiVETSN7AJATVKowtBFsLvHEnACyGfFFE2xL6CeSTVVeD9YR35kZFUyvrpJYxBSTgeiZqc+hqu2fQ5BYltWAcUSHLdyFRB/EoJEquStvN3IXqSWXjzrZQfasLWPZKpS8ZQd7oPUeLjzSvimRLmROM8SG7gID6/nu6ja+mrWErAY0CftpeARSS1oRPlCT8BbxhN03q4xvAmRZTSIaQy/UItZsdK7B8fxTa1kNbgDERRgnHsRkZMbETZHEJe/R2mnq+IaC4nUnTSndCLWnDzvbCS33e8R5HYgFn00BuM4ePYhVSEj+Su9X9E8AcQb7iSl9Kn8kC8gYvWAF6DghVyOe1V9Xwn7uDNll+R40xmMPYI1cnb2SV2oldGoOxLQBiSUuDIIK03Bnd5H47zPVR0e1h4xXR2DGymWt7A2Y4zbGnYgvzQEMYhLa/GrGeTdBcKk5zkqn4qRkZgsA0R0VtNSCoQ1GnRqtMpGWElJS4XX28X7xY1Udwzgmt+7MOntDAYFkd7xCD78gOUZPYiD0BGu8g5vZppHx0nPCqW9B3b6ero5YJFxncxeh6Q6Gg+2U1YJmxVf0FW/gryK6w4Dh1CN2MG2bGj2VCxjjqFlZnG8TzSoGPah+/hlUspy8yioyOaDnUe7f4ocqbGMfKuhZw6tAel20NzVgppCxYjkQ57PS4d2M3lE8e44vZ70EdaiDz/CufaFBgdAhejphGSmflVy4dMHDUPpHL2f/4h1UcP0l+wmMPBeD69cwajxo+lbPePNJ4/Q9akaURpNczcuQXl4X0Y8GOTyjBVnqFkyiLOxKbxRH4mRTEWTpw4QXl5OW6vj8lHjhKzYD6NZecYu2g5s1dci/vL9WgSE9EUFPyF7RFFEf9Hn1Af9OBVKZhy9WqW3P0AySkpZGZmEhYW9p+bWP4E/yABf4L/iSRAppBxfn834Y5Sklud1BdocWhr8UhMRHVLKawvJV+WzeE4PftyR7D4yF6SujuIbq8gp+Y8R8xTSR9qopWxNMZ5kSqsPCZ3MLd/Pp+qfqQq9jjzfVlMGphAidPMansz/d0P0OEvJE5/mJkXTtK934SjVU152ggeue4hti5ciG7IRVFXDdIwK9cNlXIucA/CoED4YC07UyfTPeVm5hS2gv4U9ZGRvG8tI0ITySdzP2VczPifJ0JZRAS6OQvxd4s4j+zCc64EX+1xJIZ4VOPux1MdxFnaib/HiCymkEBvLYhBdPMfRBahRxEfhjo7grDp8RgWp6EvTkCTb0adE4k6OwL1yAhUGSYkCun/Q9N/HWaFnKVZacyaVERiXBwDAwOcO3eO6upqBgcHiY+PJy9uBD2OAXwqFZ4eG3q3hMumSl4bezVrqt/lptNPs7hnP/nhEZBYNPxgUYRt90PsKIJpS5Bs+yPO6cv4PkzgyvxZGCu/hsbDMOp6BI0Jb3sU4bfcgDIxAn8wxO6qHgqt9WTIvWjHj8N5+DASg4Hop57CvmsXzsOHAZBbLGjGDR82ItVp8dU3MLhzJ43hUdSWVpA9YRJbewfxhEKsiDLxebuVAa+d4/pRNLoVJAdqWSX7I4eEmfQRzjTnIG1nBKavXoGntRy9pRJRDDHkVZJvqiBa6OBH5UJGV5xEbRSIyxxNWFgOXd1b+bh3EQMuIznJ1cTlZOEPWpDK8zAtOc4uySLG60+QZK/j8uEK5o3czhHFNAaFcKQhP1G9vSwrLSd09S0Ur5qF1bMDr12BTBWk63wsAy069Cl70FmsOH2H8DRNQpWsJWdMFDv6nVQlKvmFsobYMBOt6nlUb7sGozwJnzOAJXYMqUovtsRqgmEygjKR/rmtxJrLaRHTccT+kseHlrD43CE83zUgiYvhZMQqgoIErfkTiv0lZDecJVO2j2jhIh67j8tiDLkjFqC9XE6vIox31P/EN6oejtim8n3wEcK8Js6nJBIyRpHbuZXXZ7o5GyikKSaV2/RR1Jb3URUTQuPYyYTukSweLEaHijNDfnxj9hOZ4uJipJG3fF+hdRTyUcqXfKnfTnHedcRPTcBzrgeZUsqUNePxB72caj9GT4SDNDGRJd3TORxxngvyerwB6IqQcqJAT+loJafiYUa5G4kI78wN8skUKyaHQP9QNwfyBKQKHY/3P8CitWu46tpb6CrPYHziFXjs1eQpxrH2uIKFJd3EOz3k1/Tz/gwLI4rmYji+kwfTEsmMMFJY46WzthRveCn1oTZyLy9nym0rGNq6mcGNG1HYHAxWXaTFAiv2KIneVIJXoeZ8wWoc/nrs9hpkqmTSxiWROk7J5td+Q58QQtTpqA+46Sg9TtasuQiCwI9vv4bBEs3kq1ch2DuQH/gVbZqx+NvaKHemI+t084zjY8IMMjlCAAAgAElEQVRz53L20DFO/PA1UZPm8oe+JO6ekc6igljCIiKJSk3n3M5tNJw7BVIJR46X0mcykJmUiOTYboz6CLJvv5dxBi03x5uJi43F6/XS0NDAhK4uMqRSxvz2FSYsu4qk/NEoLBaG9u7DW1eH6aq/PAdg8IdNuNZ9SeLS5RTdeQ8jJk8fDhQ3Gv9LCQD8I2Pg/3ioIiJQSoYIqMwktPehVguYXRH0xpZS4x5DQo2HhLZBvu1T8etMGbX5Uxl/dh8KVyJZOXeTKdPyZoKWzthDyPUVjFXDxPalVPnL2ZVxGKkI17ZfjUPZSpr3OMr++QyKKkpTCjjbu4JrDu/EEy5j7/QpvLH0RgJqJeO7zzO6pRG12km+Azb2/R6JXEpvlJqqhCVsjCli69J8NLLneGbf1eyxWZkQM4HXpr+GQWn4uW0hXxBnaQf2/a0gH4flsYm4Tq5HqlVjefJpAt1+PLX9hNwB5NFa5DF5yKKWIFWA8K8CBf+W0MmGCURWVhZZWVlYrVb8fj8WiwWJZDhSN9c6ms8++wwxLpmadph5vBl/bQ4KvwdhzA3gssLeZ8CUBDnLofMC9DciTH0Qy5g1hN94Aw/3hdjS0spLTR7eX/wGfLMKDv+OIdd1CPI4PFUOdONg+eg4frerBklOHr5Dm0l452089U5UOSkIMhnO46XI4+KQRkYwtHcfkXfe+XNbtFddyYGKs3Rv/haA1NFjKYhM5ZBtCGcwyFm7i+W6fg7ZZHQrLNzfsJfitj5WJ2/nDwk3cPrANgzRDtocr0M0hAZVLEotQSqB2v40JkRWURbZRL8+nNJD32POcxKmy2ZfSxR7LItI7q1lunAQn7CdmLEghiRUMRKAPdUTKFVm8vD0z5BpvTjEMCShIEGpnPKsbFotejoO6NAl7UIq1THUNA9l3vf0t8UT9J2n60yIH8/tI22Bj15JiOrdbfhzImiJlqN1uYjqPsSoaw5ire+jz16OdnIkoWPddNYPEt+VhrFLSv91wBQJbYPxfMpa0utieLa7g12DPQi7fBBtoWRcIUKvns25r/DFwGmkfiiL1rDZfg/yoqVs7XCx6IyTiVMnEfr0EEmjGvBNAlSjwesnb3w0u06VUxaewnKhj1+8e5Ddm1ZywfElSncigz+GyHR4uWz4mG+EalaqitFEGdAtS6fr+VPk+Z9gbGEm3etPUxI8wrH8r6l31nAFV3J0Wwv2mSGkvhApSgn+niEsWztYXGNGKldyRexcBqVu9qs1FMTeiGy/n1k5iaTEqnhTF6KrcTsCn/HG7ffRNSGZu1or2ezZwsWU4QDMV6MeIapWyzSlikWpZgL6VhLOulgtf5ToR8ciXC3SduedTDleiluv5mBqPQe2rOCmcwK1o2dwnUpG7anj+IZ2wxmRZcQike1h98FpzP34I7ruu4/+9euZmxJPSp9AXnU9PoWO2lnPcPXjM/AOLuG7R+5hkBKkFz5h06FENKZwrn3uVSIjLRy6ay3nO1v57u7bGH3jrfR3trPg3keGFx2Xd3E8mM16oYgpoW0Ueds5L0ngRvExfrVhA+Wl5zEPuni7Tk88fcx5/hW6z84l6oknSC4Yw+IHn+DA+s/ZtmsPQYORWLcD+8mD6FUaJpw8zwh5CHlC9M9jbU5+LGMv7ca21Yb2huExKEj+JbLfsHQpPS+/jKeyElV29s/3A1Yr3b/7HeqxhYy4/6E/kyEYAOnfZzr+hyfg7wVBoGFvKRKnC3NXA/vyvdwY6+VgXwpDlhoiBxWYAn2MFgoIt9YzTjuRQMd5LIODtKbM4FnDJQZTNyBXdrFQ7efKQBzG5jk8F/MRcjGMVaQxyjoNAvsJOdPp8OcxUuvlg3w/T3zyLr4UkR2TFxHsbmNa9UHu8m0lr7OZrmA0kb1Z2AaLMGlrqLKfwBvs5sOYhfz6yjEotK3cd/Axzgx0cU3WNbw09SU08uFvc8VACOfJTqxfVeOpsKJKNxKxJhvdpBQMC+YTdsUVSFQKZBFqVJkm1NkRKBP1yMJVSBRSBOl/bFX/XwWNRoNOp/vZm/HP99LT0zlf24DEMYDdpoSoPlSrvkE74Q7IWgBNR+DUx5A6HSq3QPtZWPI2yNVI1Gr0RhVdx9r5VhtiYfZ4zK5OxFMfMtSSSZBIggNewqbGIcgknNeJjDApMO/fg276DAL2PJSpeWjyI+h69lnCZs5EPXo09i1bMa5ciTQsjMGeLjZ/9BZ9Hhd5XhHS02g4fxZL8Ry299lJVinY2WdnzaZ1TI3Ziddl5O7uz7HHGFCa+timmI9NMHKTtI6CFevQaTOxOfciEaBlIJYXTz/I6KQ4Hpl2F99X12KsaydkOULl7lK2iMvpiYzFpzGS61Ngkl3kYMMUYhQ9XJZncVYYj6TOSbisn3kFuznpmEe1MoNrDnyGxeqkPi6FfeMnk9p/gUTzt/hts2k/vZCmliko/ZMoSvERtUDE2mKl/7KOo7o00pwq+jucHByvI+vyRSZ17SR64hpsFU46LtkYKjajmmzB1+WmpU2PqidI4aKFSE+7WBP3HH0SCwuPDJD61bNMO3mMVksMRxPUhHoG6Y6UMUZsY06wiVfNkbwXFoZCm8uXYekMaqUMqSWot7agPrGLp+dK6VOkIleO4A9db/NZcyQV4dk4443c07KB7IJFFJ/7lj9KQihdpcRVZdGauYPe4EmyUm/n5muXoZ0QjSJMQVfDIF0NQxgi1Zz+vpXkDAuHPXuQCBLeXfl7RLuMyqMdDARF0sPkdJyp4kLNLs6Pm0WitoBRoVhKB/airTmCrOI0EtdZ6tuPc9rTyFexMdy9+XsskUaa7nuIHf1S/jB2NpHHghw0nGFFxgrmW66C8j5kcik5MXoUIRFjwyBiTgTGwmgEmYywOXNwt7QTtWoN+vHXcLT9EBdSepH52hh59gTe6rMojUY2TLzMpMwZ0GXF1nqKc4f30aCSYHB7iey2EdM3hE+hp3HGoyx+dj5h4SqorkH7xVc40iOpHdCRoLVz5ZO/wZQyEolSSfLipQSOlVJt7aT2xFF0pggyVt5EaUM/n+05w7POFWjMUeQ5q0kOeVk6bSp95fsR6y9itnuoGb+KUqmZlw3tDBmVnO7upqWvj06bjUDDfpp9EtwyNXG1l3A7+vH7vCy7+2H8P2xGolGjnTDhZ5sgXPoeTeUGPFYZhhsfQh4X92d2RBEXg7T8A3rXbUGUalDn5SFIJHQ+/Su81dUkfPD+z1t5P+Pra6G5FDL/+wMD/z4fJv4DABi1TpyqRAB0PRKkUjdjbZmEPNHsH9PLScUgzuAQMSETm2xfcjJ7FoLXSVXL7/Elfk6MV83v+lcw2+zD0j2PY77DzKh7lIV1NzOzdw5OfJQMLKXbn0++epA/Jg/wxO7XkblEyseM5JvAGCKvEFB4vJytz+acWIDKFYc8qGCC8TV26iSYnfUkjJtMyYNF1AW/ZM3ONTgDTt6Z9Q5PFT2FXDK8H+8q66Hr1TMMbKlHFqnCfHs+kTflIrdo/m8q+F8Bi8XC6jVrCMQkExQlfOrN5anarxBFEeQquGYD6GNhw7VQ/i2kzQJN+M/yglTCWqkGbVDktw2dMO+3hORRmKSvYpgbhegL4m2y81RtGyUuF0+oh2WH9p2AgIi/y4W7/CIhhwPt5EmEzZo9XL5/Px3HtvDlo3fhsPYyb9YCEmoaGFswDntvN+ozxwB442Q5cr+fsQ1WEgy9rA17herRGjRL/oigH2B6bxmVmQVIhE58P95Nc8uHwDAhs7eZ0UUH+fB8DkpgxcxZSEMhLm+IobEqisqMUWhCIi5ByhXTn8RgnMGM5KPktVvpkyQhiCEeL9zFA+M24A4okKsGeFNcyxUz97Es4gxjNH60wQDOyf0IkiDNJ4sAAbXDhFTqp6E3mdGj15CzXIlEUFA4WEJA4iEYCjEgioxqrEXeJmC3l9FfN8iFVCV/cAzwWGsXX2W4sAyepi5mKSeOTmZjyo2EpDKyeq2kN19A9HpRGoLsmFSMxC2C6MPSWcN11CLGFLBw/ut0qOewPWERM3pPkni5nup4BQdMcHjKg3T5IlnkOEa30oIjLIxtiqeYlDyAgMiUpk1w6XsUjSexRj2KTBLkh9Gvck5ymLiYa6mWTgW55GfCmVJgxt7rZvenFUTE6XhkxV0kGkaQbp5Ch2igaFUmhfOTiJ2XwGlNK0afiYFRVxFevJhFYgZCmoFV773AnR99xeTHfk3b2MVUpuUTamvijq/eIq2pBuOC+Sw2G/GLIvsDbrQuF1PLzUw7Es3mQw0AjK5xYN/djLHdgV8UudjbS8O505zeto2vX/yQTVYZJWVWVutSuH1vIm7dPDTOywzW1OOXuvl+VCV+rYSrVj3I7e99jDl1FTJ1MYJ+GeX5D9KWMgOXNo7G9JWMU5eh0Q97/pylpSgFCb8odLF8pJWV6Y1odt0N/uFkRYJcztQ33iE7awwisFfIYNbrR/mn9efY2J/G6tgOdtw7nRFTZ9ATrqT+4mayHZcp0+fxxwn38XUgimvHJ6ApHs0Jk4mBiAhqGho4cuQwOxtEXEEpN/Adt2bs5Y7Jdm6+czlxEyaimzaN/m83Ivp8/2IQrLUAqCyg/iv7/jJfG5EZVhJn9NP32ks0XX0NX23cwvb2HsS77kaZlvbnAi0n4fIuMMT/h23Ufwb/IAF/RxiNQazqLEJAaht0hgTmZh7D3XIjgUAkp7IbeFbZSFUojBLzPJ6NT6ckP4wFlzooro6noDKPAUsZgk/NQLOWMbKxjDd5SQqa0TqSaHQP/71eQmyXusn1HCHraAu2XA2NFHCl8hJCuwllwni8kUlIQgqCWj0v6gxsGPMi94yNRhRC6KaouefIdWyo3sA1I65h89LNTIuf9nM73BV92DbUINHKibw5F/PafJQphn+j1f87ERMTw6o7/gnUWjKbDfjKfXx96evhQm0EXP8dhALg6ILcFX8hH5URzpoGHyVWO991eLC67kMmdKIbeAekAuvquviq08Y9iRaWZCTTaonmXNlZAgKEhnw4Dg4fvqKZMAFlagqK1FQcu3Zw9NPXkfmHuD7mKCPVuzHlCSi/+IhIb4Deb79AEgzSbAxnlOhj5Ddf01uWw4VPMqj5JodTX58k1D6T/L3bUQU8vJBzG+GVJ4nv8FE4ZgOX7VNpzY2ntyCZxhQTr3+0ibHJdoaizDQnpNF81UhCUim/ShteCV10eMgb+TyyYIjaLA09ohG9OEC6egdGeQthChejZKc45ZmBRnkV+qST3Ou8nVGyYyz0bqOMUWzLSsWhCKJWtDF6hhFbIJG+o80Uz9nBgnsfQefsITR0AFEMsfK4g1GeIZoHY3nnj3t4StvOtnFadNYebtnyDXU6A4dTA4yxf01Yw6cc9w5PKHMOHiCn+guc+gROZ99GWu0ZQop4Bs2FjNBewBLspGHcfewKjMERfgMK1xlWd71DaeetTPc3sXOUii6DkWsvPkzhmSIEUeSdmFfYOnQnA3IPBQxhkoiw5W7OGHLwy+NZO/YFAlIfV2ddzU15t9Pl81M+5P65f6QURIIAoYDIrBuzKLtcjbp+Er6qTG7afZj0Ixe5P8rLW+2HaTy/HpvUya3+VJ480IgsIGJZmo4gCGj0BorGjOWOqUsosE7BPO1ukqwOBET6zOGM1mvIHeyh9uVfcqn+IAVdcVw4t4NK7wW61RLMBiXui314q210qaxUHX+VTS8/y+EvP6Dz8l7EQB0dVT/w2aP3kV9Zzocjb+PRnnmYB5XYozMYlz2du0bdhUFpQCaXcdVTKxgrdTGyp5rCuWNQrL4P8VcfMCF9AM+enYS8wxkEncdL0RTkoegtI7VoBpLl70NnGex+6mcdVXbaeUY5jW8SryOmb4hfpwXZvsBHhfJmnlsyEokYoHrAiSiR4giECKWmsyKulUaflHCtghkGKwcOHKCgoIBb8jK41/YBT/MGDxdHcO9dD+D/MYRDOQuFvx/93vvA68B0/XUE+/qw79nzL4O5b5gEaBMUf337sv0sADK5i7SbzBwwRvBQZBLP3P4gM0aMp+hEJfdUNXNm0Dlc/8DzoDXDhH87L8rfEv+ICfg7whApJyDX0hIeQV6TlXq/jKjIHl4+9QXfuQupGnmM8pR1nGi+HbXgxxz/RzbGuZh8WcatW1tZPyYLQ1QF7qZMSiQXSbB0scg+kUStjBAiL0xSIKnqZ2qgAqO2j6mVhyEk0DDzDqINzQR7rFitKfjUPhBcqFsbqDTIiY0u5OlFWfz29Rc4PquP/orfMzJ8JC9Pe5nRltF/1gZ/jwvbt5eRJ4RhWZuP8HfKevXfgbi4OCYtXs7xb78kxZZE2ZYykkPJjM8bTzVe6iasIvnyXlLTivnXIT6qLBPXbq1jS7yTu5vhptRCnou8A9m59+iPz+Q5+USmm/Q8nhqDBNidm4fxzCmeuFbDc2dd+I4cQ5WTg8xkAiBs5gx6P/uEzrwU8ieMwpQ3GSo2EZ3TDrSjchnZ0JxHgquX5rBoijOS2fPJuzSd6MeY5sSoz6f+3Ck8Q3YkwLWOMj4zTeRE7m0UXfoYxge4ILuPbYQw001vZBTv9RhJPvU4pmXxvC/ch0Z0khlq5drEfH7Z1EH5kIvFEheFFwbpi1DQmRiHSTKIRKpCIlGwzbaAH/TzEctcbAqARZrKlTnfcIf+bVBCT1UCp7NVhCnKWNfwOBQdoOZQG2dOiggLPZzWJHCyaDVd+gC90Ro8UiVfKm/7Wccal5MFh7Zx37df06fXUJEYz8bZCyl68zkW9R0jqSeBKm0yV5TupjZ1OW3xM/C6fkQUgmwuOoct/hXuOvcp3R4tS+s19EX2IsNPasdGSpqiaR5KQ1H+GhQ8y9bpAo+frEXbriSp388ltZQC/2zO6w3c3fwVRKRBZxknUpcjAa5PL+b61MPo5Dps/iASWinpG2SUfthTJpF4GWHZTO+Qm6+ffhef28XEf27YyT2g02NPSCOspgxzbj6xSUE8lRBwqVCNUPyFxy1+ZDjKAATPBklwSXGbDBz47ktqmmqZd+40LpWGuQ/9kjRLFts2vAEntuEZlQxBEyIiQQKcqlmHRJ6ETDWBxJwkplxVgOdwOz/sP4rXvptzydGEf/w6tvZWFMoxjG/WsqTwn5D+SSZQ/9EDhB/bwMgnnyT8F/+yP+4IX4Bjyw84Dh1CO348nspKou9YAv0eSJwAIxbApHvg+FuQOJFj6mJuX3eWMJWMz+9fgOqxnbjfe5aMe9OQao2E4ifw/bcbsdps5It+hNPnqCkaRw3xvLs0Eae1i+NHDpGfn8/S6WMQ1l8JkX56GrKwPH0Xg9u24bcLSBc9C7Km4bid3hq0U6YgT0zE9ulnEAoher3oW8qQAAqVHUIhkPwrm9d+BnTRCDOfwrXjcd669mUy3A5eio+g3BjB6UEne/vs/NDdz2MGD3c3HkEy90VQaP9jhuk/iX+QgL8jjFHDg0XMKCDj9H4qPArQ+0gYW88CXTsjSmPZOslGdNLHeCVupD4oPp3GqaVtjD4Y4sbTJTgVIQ6MiuLsmKNckvmI95/EfXYcmkEfHnEa05QVSAQn+eEH0J2A9uQJ+FvM6EydDDZeRYK0k4nLLLijo9n6yRfktB9h+bJCVv94JU3xzSRIo3lm2ovMTJj5Z3vlMHy4iHVdJYJcQsSqkf9fE4B/Rm7xbI5v/Iq8BDPH+zsp2VTCe4ff43zYeRBAUAlMO/k8b858E4kgwe12o1arcWv89Ct6eeW0j29TtXyWoqTdcAMfdRwntfc3jDO/w1v5c5H+pOPRmQVY9++hOmTl/jw1r2y+RMStt/78HmFh9dQrlQRECXETF0DRFJj1zHBgYnMpsf2NZO25jKGjDbKikXz3DpfOllO08homrLgSmUyFWH8A28fXMuBTEx2M4UfFVF5MvpUtNevpK/+Bg9rrwOXnrZg9vDA0m4uZFr4qWcPvG3fyxp0hXFItS4U3qG3LIE2l5OKQG/fgXrTuINo2Nz2xZtK14RRPuwTAI4cu4bZ7+P0YLfUVDTRJcyg59DAxCy8SHqxl5UcHqbozl/2ZE1ir+jW66kYuLIimQabGf7IaAKEgE71zALtKRVpzDVHWAWIGvIxIbCaxNpyowXaQSDG98Q6/2fsma4cS+d2aO0h+qZ09V01mSsVJzNo+TL++C8XOL6morKU+w0EgzMCi/lKihQG2+iej9XuRSETmHf2OyIsKQpIg3Qo3o04bSBr4lE9mPsDBApHnz7zHEqueNzPyqc3REhQkTLNEwqkykMg5EzGWXLmaMJkUfqKGEQoZ4w1a9vTauGqgjYqDe6k/U0owGMIgdxNrUbMuYz6r5yxmrklL88ULNJWdo7n8PGGJKVwRm0rviw+jnfMwSMw4928h4oZxfzY+tQYlEXE6nHVN6PqbiXzwfnKCbioO7iVqwlSeHjmV3KQscqNMyFbfRb3tZUY2niYYPh0BgUu2oxQuWkpE6mwMZi2xGUYcpR24y/tIC0uhUbiZcePaKT9/hJiMPGy90zA1fkb/+g1Err0NURSxffEFPa+8inLECEzXXvNn40hbNAFpRAT27TtABEQRbawA/UDCT/vvs56B1lNs+eErHvZqSDXr+PzmccQY1PhffYWmFUsR6vciFl7H7r37uHz5MhMHBkjcVULYvHlMnRTB+uPNnCz5gVAoRF5eHsuWLUPyxWIY6sKZ80ts336Ccus2hvbuRRYdjSo3F6w/JSnrrUKILyR81fV0v/gSHY88ikQWwnilHZ9DhkLngf7GYcL3p2g/C3GFMGYNL9g0dAsqPomoY0z+FKb8VGUoEOTh6lZe7B2gdNQbvJm/EvN/2jr9x/APEvB3hCEuEoDorFHITu5H3uAFCzjnhIgWXXQ2KRhzPouywlribArGXzDhsIwgKq+PJ/y38Ku+94g9MsTM2qP40gUm1KmI62kEhg/Veb+shMujU1DM7STm+yH8CiWe5X0Ea30MNk4hL7KUidG7kc8+yI6LXayTF3Gbup0vzz9Pu9FG8XkzLz7zNWGmiL94dzEkYvv2MgGrG/OtecgMyv9O1f3dEBYRSVLeKGwVVUy9ezG7S3aTak1ljGYMV195NQfa9vPS6d/yh4N/wNJuoa6ujrlz5/Kt51tS1UaW22byaJWT9NFa3rD6mJTyND/abmfdpScJWUaC+afVkmx4f/B1bz/v97ZAKERj/igsANU/oupYz0B4HgBxI3KGZQQBYkcPX8DkMR3sfu1VHFoD/vOXmLmgmLG/WDVc1+dE2HYfETGxRMSOhtpdPFT0PI/WdbI79w4+CSThQkR2YQBp5mN8lm1gcmklZyeOZ1fVedy+EKglaPCw+cjzNAl30REjp7PpeVKAAZkJp0pDUYwBQRBodHlpEYNoOhykbniRUbZuor7ewoa3vMgCy3hW6WLfA428t+cZ3lKsZlvSLMz+QTKUEkYcOUR6Sx2pbS2k+Xv5cPRC9hYX40tI5dZLpyDoYn7nZ7i9cpqOmPGMVqNr/5oM33beuljHkonvcuOvXsWp0bKK7RyLSGA+ZznUdAyt2suJ1D6Sg7n8dmgjWHIYd/M7tNf0kV9WSkxFFcZsGy1TV/BDawnF9VkkVdcwzbKXnXlzmTzOz4Qj+yEjn32ZSuSBEOn5a7H7nQRPfsTY2o04Jt3/F/1otquP7s/fYdPQAGqtmgJDG9l5aQSzZ2M8/BILrOdQ25SQcjM502eRM30WoVCI3jffxPbKK4RdMZuY313PwMYf6HnhOI5DhwgrLv6z30jIDqf/+A8AGBYsYuLFclLU54mfOZfXnHK29wywIspEyaCLk4tWsfzQYXCBJ+gkUhlHeiANufUcKstIAlYlgzsbQSaQGpDRKAExspi179zMqe0NDOxsIX6kCdvnn2NcuYKu559naOeu4fd88UUE+Z/n8hBkMvQLFjDwzTcIcjkSrRZ5sBWMSRA2HIkvSmS8G/MSr9R2McFg48M7rsDwU1ZQeXQ0cQ+sQFLxIgcvSDjBCTIbGki6eAnLU09huv46hNoSbj3+WzbH/RqdOZ6FCxci6W+E5qMw61doJj+A6tsT9L75JkGbDeNVVw0TqfAUkCqhpwoA06pVaCdNAqkUqb0WNl2FfO69cOz3w6T7T0mAux+sdTDqOk4MOPhCms7tjhOMOfoUhKkhe8mwHZFJeV9Rx+TLn/N05oPMvtDEe9nJTDL99fNU/pb4my7dBEGYJwhCjSAIdYIgPP5Xyh8UBKFSEIRyQRD2CYKQ9CdlNwiCUPvTdcOf3C8UBOHiT898U/jXy9P/RVBExqKVWOlXxeKTC5irBexeHYNuDTIBNAk2smx2Vm7K5PofZSh8CrSmEJcqZyBV+RCusdJ4TR64RZaVikglFj5aejVvLr2BI7MnETCLjDpeSdYr/ajLJVyeMpdZq97iphdXsvoOBdNkv0M+8WYarS6e3HSRrOQYMm9dSo2xl+xaHdPNk/8qAQAYOtCKp9KKYUEqylTjf7Pm/r7ImTYTe283haE03rn3HebNm8dg2yAbX/kDXS98yw07kwh9cJCund9haK7i4BcfYjtST+KoLABKwo8zaP+G70eloTUmUL7wY9TYUB6/EwI+xJCI36YDuZIRzfU8caESr0LJ1aKOdRXnEDffgRBbgD0pCY0vgFo97Aru8vp5sb6DB6tbcAaDmKJjWZadxcodf2Re6gBje94He8dwI/Y9BwPNsPRtyF0JXjvXeitJUSu4Q7+Iw4YCnglzIBnyU9vtIF6l4PnMeELhSn573S2IahkKAbaFbmSh7DC/UG1lCDk2bzxBYzJbhEmEBCnpWhUA33f3IwCPnt2FvrsNQiF8P3xFXJYR+eFeJp5toz06hlXLX2P+2GXM37ud/Z+u4vl7buXezX/E6A4jSQFqFNyzYz3fPX4nyzeuJ/r6Isarv2LAH031hQwkYXJk+QKZ5Z/g9MqQ7HajlEoY0uowe/q5Yug0SdEDfP7aRwIBuSgAACAASURBVAy6RFyFAwSkAk/1uJDa6mD6o7TqzQRkcqaaw7nyN/eSOKWLu3ILeOqKr/m2eDXWyUlMLDtCdE8bLxRO45jERfiglSFBJL6jli8fuoGP1l/g0/pxJB48RVFn+c99RxRFLpTswPf2iwC0jcjhhrjDTI62oxx7P6s081gxaR2yhLGw4yH4ZDY0HibkdNL15FPY3v8Aw5UriXv9daQqFeHXXIUiKYmeV19FDAT+rJ/mToslyV2OMieHntdepeOBBwmdPU/r6jXMtvex32bH5g+wz2pnliWc/PgIgkEfnqqtRDt8uC4M0PHYkzQsWkLHs5sQAwEU0d3oZFISzRIqDrfj84ZorRrAkqwn9o6bCdps1M+dx1DJbiwPP0Tcm28i/Te+fzcsWojo82HfsQPNhPEIbad+9gJ4A0Ee2ljGK4e7WCit54vA4xhw/Jm8RtbEeQo4FDIS097BRImU1G1bCV+9avjzu4gMNHi5rtDIkiVLkEqlULYBBAkUXIsgkWB56EECnZ2IXi9hs4cDbpFIwZz5MwkQJBKU6ekoU1KQCQPD93KXg0Q+HLfwp2g/B4AntpCHa1pJUCl4dObVEJUL366GTXeAewBEEeHAc6xxl/Hj6HR0UikftPX8u+zPfzX+ZiRAEAQp8A4wH8gGrhUEIftfVTsPjBVFMR/4DvjdT7LhwDPABGA88IwgCKafZN4DbgMyfrrm/a3a8DeHPg6DtJPBAbBmmkluAJdfjSeoRt8XIi5xCKkYoqinilZTJG2qWL51TsAXVHBdwm5EUWB/UgS/vEfCnXdF88T9v+RCXj4j4y+TtOQYg486qL/OjE1twa6LZuLTT6DRpCCTS9Ff/hBURnZLp7LkraMIAvz+F/l8ObAJI1pyG/SMnFL8F68siiL2g63Y9zSjGWVGNzn2v19vf2ekj5uIXKWm4tA+BEGgqKiI2WNH4autwK/UEDDHMRQfRmOsE0WCCdlAH/kVIZo3bOKi/iT2QtjRsINUpYfDE0ZwRcFMnEnPIPdcQNz+IL6mQURXCGXGSNwXLqBpvoTSlM5ss5ERJXfjCgR4e/zLdPm9mBwuag4c4r6qFsaVVvJ2Sw9fd9r4xYV6+v0Bitfcyi1vfET+/R/B/2HvPcOkqtL179+unLqquruqc86B7qbpJkfJGUQJJhQDxpkxjWEYHfOYcxpQFHFQEBFRcpQM3UADnXPOuasrdIX9/1AckGHmOO91HUffc7w/1d619qpVe++11r2e9Tz347TBhpuh6hCc+BCGLYfIURAzAWRq5KXbeDQ6GBsSlrTs5LbmbzBq5JS1egffG0P8yVKrcIdokTmczPE4OEMUyu/0zM05CkDxQDQ/9ARxWDEIgHB3D6Io8nVLJyNEJ+MPbeHr2HH0T5hG14avON/fiqPTwjtdT/HJrscZkMp5vqqRebmnaTurxyfJSMXjWbw9bSvWxRIefHkVd/zpBfYlDmXO4b0Iy5bjKeuluiASVVs3HfNt3DHiz1wz5g3KSvz4dPbNOFwOIp21jDn8DRaPkpF+tUT79JFubqQypI/RVjuZfQcRA1IheS7Hur0OW8uvuZbgKO/OvMVSzMJAI1cVnGbNoGVE3jmBZ0wqnEo1J7KnkdDvnRziut34BExi8h33oZ46kw6HhpL33mPPR+/T297G9ndfY+/qDzD1WJBnjOQe7XYcSgXT0l5kfkEThf127pZqKJy/jtsnf8dr2pGwZg72Fck4Dn6F6d57CX72WYQLGSEFuRzzgw8yUF5Bz+bNl72niuYKZM1VDFRV0bdnL+b77yd+/z7U2Vlkv/cmdo/IM6X1WNweMle+R+fLz0P7F4QsGoF+SiwSlYHglz/H767nkGjCsZ/6Ox3vPoHo7Cc5wsSA3c2p7dW0VvcSnuKHZsgQtKNHIygURKz+GP/bb79iC/HHUKWnI4/wRkf5ZCeApQXCh9HZP8CNH51g0+kG7o4y84TbgMrdB6fWXLrY7SS3oIJvmUiIIHD15ElEfbIaRdiPPOx9I0GQelfmAB435H0BsRO90TyAdtQotKNGIfX3R5OddelaczK0FV/Z6PZSL4kwJ0JgCjTmXf59w2lA4E13JOVWB68khqHV+sJtu2HcI97oofdH4v5uhdeKMP4xUo16dmYn8GZSxL+8Vz8nfk5LwDCgXBTFSlEUB4AvgXk/LiCK4n5RFK0XDo8D//UEpwG7RVHsFEWxC9gNTBcEIRjQi6J4XBRFEfgMmP8z/oefFxp/jPJmunukOLNTCWkHtaufQE0HUVVWdCFWBESaDVoEqQuDKpgbBRUhA6mEBpbT2RWMjBrqRSlmMRWpo5txFWeIjcuhWQjimPAMuZ6JqCYrkL3+MGFCs3e/qnQXYtH3HDXMYvmXRcQE6Pj+d2M4172Hwo5C/jjqcebf++gVJED0iHR/W0HvjmrUGWZ8r034bzv5/1bIVSoSRoym9PgRnHY7LVUVnFq/FlNEFFnXLeOu517i3mfeoGiomw9jj3Bwvgf90FFYpQoKzx4gqycMl8fF+pL1F+uUjriObtdizuXl0Ln7bZAJaEdkYS8owNVch9Kcwgc1XzO0t4D30h5jZXU/LocdzYCH77/azJbWLm4K8efoiGRWDYrifJ+Nq8+U01RWgeubbxH94mDuO1B/EtZeDYZw754rgEIDsVdByXbmmQ18mxnHy0IhQtEWEs1qKi6QAEEQ+DgzFqNEwqIDO4n66ntEiYS15rno9/UjEd006IPQuXvpNHuFgsI6znOm10qVbYDxX3+BIimJ74fN48+aIbidTjQnNzPJ921C5GUw6FpeffM5Hln1JlGNleSOSSU4o4xvZW0AfOgfxak+Gy1+QbwVv4A/X38/x1MzaC/wQVlch9zXTbyqh0RPBwWSaFqdoWxOTyaq+S9Ym1aQH3aAntirkSk9TA4uIHJYM8HtDt5tbcNpkdJjXAYSCce6LSRpVfgrZMhkWtTqCCz9JTira7j72LsY6OYl10QmTbiKZcF+nBqUxfGQWASgUR+D05mBPnYEx4dOp3f2GAb7NnJuz3ZW3buMosMHiG/qZEr2MJ7w3UecrZ7aOSsZHJdJU0Q0E4rO8lleEdNOl7Pd6cMrwQvZ3DkepdZC9NQ2zCmdF/ucx2ZjoLYW7bixqDMyaHv7Hdx9ffQdOEDVosVUL1zkfbyhoURv3IjprjuRmUxErFrFuLEj8e3p5svWblR2O4PPniL0jdeJWL0Kv6VL8b1uCvJgLbbCAVydQSjjjIS98zCme+9BGWdA09xPeLIvZ3bXIooQkeK1GAY98yqRf9+CdsSIn+xHgiBgmD0bAG24NyS10ieL+e8d4Wx9D28vHszSbnARw4A8E06uBLcTgOPbv+B71yjiQwzc8uc/E7B48ZVjkVQOvlGXSEDVQeith8HXX1Ys9K03iVq//iKxAiAgGXobwN5zeZ3tZd46ZUoIHuy1BIjipe8bTlEVMpp3G3tYGOTLBD+997xMARNXwO178AgapKffwyWPgPTFgFe4zFf+y+zO/5wkIBSo+9Fx/YVz/wq3Adt/4trQC5//3Tp/3ZBIMGr7sTkUqIZ6VxyKBjtIoLnSSFNrBAHqbiyZIppAK7HB7XSFfkqzfxlKlYWW1lgUNVnE2KLwlY5iUlEuKnMTKqWVz6U3o6kZQK1SkWnoIGvf9fDBSFg1EdYtxC3CI7XDuGVUFF/dORKj1sNbp98i3ZzOnLi5JI0ef1GnG7wqgB1rC+k/3oRufBh+ixMRZP/7HQH/FVLHT8Jpt3Fm5/dsfulpVDofrv3TM0yeOhWj0UiAJoA3r3qTwebBvDL1NZbd/wgRE2fgkSsoO5TDRL+JrC9ej93lDVtrlvewRhrPN8zgq6YOFEFFaLIyvd7HgDLAF9nZ1yBpNo/M/R2f+HhNv5KkQUw/c4Kc5BBeSAgjSq1kltnIuowY6mwOcv/4KG1vvkn7Bx96QxdH3OMNZZz7Fih/tP+YOBN66hBa8hlu1KFInQv9rUzUVlPa2ufVRACClHJO+Eu4/cA2Zu/fyNCyc2ydMhmJ1UV0XzfndfEMlxQywsc78Fqb8nmuohGly8WYU8cJe/01rh8TT5s+gJah45lVdYgY8ShHe5eSOvMWRLmctLJi1txwGyuu+SOdUjVhjecwqvw5afW+bwu3bEEUJLg8Tp6+4w/svs07kDoefolDPcMZVXmcbsGXZ6+eiKHlL3gsDSw5qaBbI7I7Mpa+ehUaqQu308PjTZ20+UXRXDuCzq+24/SInOztZ5Tx0r3R6ZKwWIqxnjyBPL6PP1jfIyTnDH99exWftnQj8XjQOAfIGZHCpGEhuCTw8pZijnZbaMu8iYkjw7gpoZgYvZ6hFY2MnZpCkO93CBX7EGa9xuCMGbyRHsu8sAAOJGdwLn0It+7bxoZH7iayqZ4npz9Kz72nIXEW4tH36D96iMY/raBs9Bgqpk6jNHMIjspKnK1tlI67ivq77sZ+7hyCRoPp3nuI3vQ1qsSEi/9HkMkIefQRpqu9/XustYfkLVvQz5hxcSIVBAHduDDcnd7303dBPKqEBMy/uw/dyFg8VhdpmWYQQaGWERjl4/UT+qKcto+KsJd3/fOO01UDZ7+8eOh/+22Er1qJ3FHFGUka920oIduawxvTzEwz6nB3O5CZ1fRaZ0NvA2LBZg4dOsSO3EqShSoWL70Dufy/yR1iiof2CyQg7++gMkDirMuKSH18UIT9wzQS4CWxtBbTXt/Hob01eDyil1D4x3u/CxkM9m7c7VWU5bbgdLig4RRvR9yEVBD4c8yVVlJbXxSNHa/Q47mNTssfcLY7/nXb/0P4VTgGCoJwI5ANjP8frHM5sBwgIuKXMbP8OzAY3dAGhuAsujUgzxcgFVrnuAlT1yAsvVRWFGvAEoxM+AaXU0mNrIUBhZ7BzVlAKY0qX8aF7aLGE0mVI56+mj10+0Sze8SnpNlPcbrBypHafur6oEdm4tElU5mT4X1R3zu1ig57B+9MfOcKRj3QYKFrcznO+j6Mc2PRjfq/twXwjwhLSkVvDuTQuk9RqNUseeYVdL5+l5VJN6ezdubai8eLFi3is6I8OitKMeZmkKhN5MujX+LT5sP58+fRyTQMdUWRi4cDHYe4OtTr+Cf198cUsA5RUCPMfgMEgbbSYtQ+eiY//BBV8+bjXr0aHnv04m+N8fVhk60VRVkxzeZAeP99NEOHop32gjf0Sv8PzzBhGiBAyTYITof4qSBTMcZ5hL9a59DRP4BJp8Sam0vTrbfhkCn5NHMuv7N9wVL1X9n08ArMNTWcjU+ECSsobFWi8gwwRTUTVVcvy7/+nNgH7kcZE8PvY+D3E+NwrP2Oyhw3bX1XEXLXX9BUFxBdX+O9VxlJfKlQsDTlBZ7Je4Q2zyQqk4YQLFqYd2wnZddk81r7a/yl4yHez57LmLWbSYoI43TIO2w4sh1t15f0yLbi5zTzSdaLMCmCuoJX+bRpC6OLfUgKs5NcZ2OfRo352lWEGktoef55cgqKsbo9jPwxCdAm0VG6h/ZPPkJnlzLuy2LGcSFa4a0Uhp0/w90Zo3mivJ6bQkxsHeVHd6eNfqebNB8NzHkL0zvDmcweZPOTUbu+AmUSLFoLYV4T9IluC581dnBjsD9PxAbjMzqV7vhwXtPLWKzWsqKik6cLTPRu1+P8+3IkGg0+06ejyRqCq62NzoJquk+V4EaCLSic5GuHE3rjAiTKf+2wuyhrEM49K5k6dilS3ZXhaZp0E7bz7ajTTTjVIn0d7dhrz+DvsaCSluJbX4yvxh9UehAE7EUduNptSDQyOj4rwnxHGorwH/kDeDx41i1F0paHqDUjxE1CotGgGzuW/a9/xKuOWxgqL0Emk5Gz93vc5mQy5SEYZsXQ8Wk/rYZBbN96mCqHL4OkVVydAFLVTzjS+cdB5QGvw17RdzD4Bq/A10/BnIQowrn99bzV4WbbYDVzjth5sacN/5gJ3jLB3ox/BbuLOHRQTcpQPbEuCV8pE1ga7E+g8nJyYi/touPzQuRBvmivfx7Lm6fpO1CP3+LEn27Pz4ifkwQ0AOE/Og67cO4yCIIwGVgBjBdF0fGjayf8w7UHLpwP+4fzV9QJIIriSmAlQHZ2tvjPyvwa4GeWQBnUHXDQGiUh45SH1pk63BZfzPubGLBKKZAGIwu20hZlJERix+TbRVNzDCfVNajDGjH13gdAv9hJiK6F456HuLm/HbcgUOQys2VzHRCAVCIwKtafBVNCmJoadNHTtryrnLWFa5kbO5c0c9rFtg00WOjdU4O9qBNBLcP/hmTUg0y/xG361UGQSEifNI0jGz5nzv2PYY6I+slrZDIZwydPY0dpIUMHpeAu9lC9rxqpVMq4ceMYLI2l+dszoAogRyEh6tuXMMXHoQ6Ro2Qv3Yo/Y9QFANBQXEBoUgqq+HgM8+fTtW4dfktvQh7indxFUUS/8kPsISE8/uhzPP/CCnjoYeK3bEbm909InC4Awod5ScCEx0DpA3GTia/exV7FfjpP/AmfyNHU3XMvkuAQ7h58G3db1jOp6zjpKvgg4tJKM1U6gw6zG4no5rYzG5n1xR4ixo3FuOhHCVV+eBll5Rp8BmfTe6yGqId6qbnnIWyhYVgtFkK+XMed42fyQUwqa1z3kH2wgE1pczC1r0fvtPHFAh9km9q5seI0202j2DViHMb163Ddkk6n/6do+qxIpMPYOOhOjGmDeeWVV0gLSuOI7AjrE3Tc2WPnfKyEp31DOBCYCbNiaXnpJQ6cyYfweEYYL02KOl0SXTsSyE1LZkizlejZQ/CNnkDzn5/gYVcfYnQ4N2/9mo/nLWZ7e+8Fm6U3zGxTSxfXhhiwFxoISG5DdJ+HsQ/B+Ee9JuULeKO6BZNcxjPxoWikEpDLcAWEE/bdN9xoMLFmyhwyK3uZrhcxz0vH5+FPkGg0WHsHOLmhlDJnAr5T5hJitFNVKaEyD4YENJA5LRL5v0iyNTLvbUYWv44Ya4bQW6/4vqmlmW9699L+bcdlFu9I6lkq30hbfgJd1hfBCjmvvE2cJhKpbwjmOzNoW3mOvI/PsiZSSa3FwYykAKZW7iGuLQ+PqET8+lEkDx9HkMrYcLSUv3eMZqi8nojoGK5btJC9e/aSeyqXZl0b1/glc0pRzTnrFGTYmZWkIqt4M5LU1T/Z5/CPpc+hQ7J3JVqXHTJv+OlrAKskmL09T1FzzJfc+Rp8nCJbRSuHhnzEY7oebhJFpAEpONGQe0KKTCGhMKeXDSP/gIDAvREBl9VnK+2kY00hEpMa9TXxdPW76I8z0pLbTFeED6hkaHwUBMf9552sf04SkAPEC4IQjXeiXgJcthkjCEIm8DdguiiKP3aN3Am88CNnwKnA46IodgqC0CsIwgjgBLAUeOdn/A8/O4xBesYYPuVowS3UhegZVdiNrQkqyrOI27qNmmkuXIgodE5OWtpZJFNzvGQhneGH6ZLB5P4BPooSEO1xPCF5nm6HPw9edQvvvP0uEUmJPLloBserOqjvsjExKQCT7vKVwfm289yz9x50Ui3LVTfQd6QBj8WJs9GCvaQLQS1DPyUS3egQJKpfheHoV4Nh865l0FVT0Bp9f7rwBYSneElWsE5N1rVZrNq7iumDpzNi+Ag8TVZ2Na4h1JRIfGY4O+oGceukMwR1H8LpNxlL03D0A26s/T10tzSRMWUGAOb77qX3u+9oe+89Qp5/HoC+PXuwFxYS/MILfDpmMA/c9QAvPr+C4t//AfGPDxMRFYV2YICuDRuwHjtOyEsvIk+c6U2G1FPvlTCNnYii+HtiJdCy60ny9oWhFKRsWvAgLdUDzDecw9WvYMvQQVTYnWxe+wbvJM0kwW6hUKlhWOkJblj1DfrxWYS89KLXwuQagAN/hcOvQ8b1mJb8gb75V1O9aDGi04n043fYtfYLbti5hUUnT1J5w3I2Tp7FD0NHYurtotmyje7YAGSFa/CICiJ3FJExWc3n11zD1rL76D61h/ROHyY4Yog+VUlhgi8B5eUMOJ10NHQi+CWwY3g5i06M5Y3gLjKN8cgkMuwaDfIJEzhhd5KgUWJWXFrF2fJtFARm4pZKORw/CePEaUSnDaP5qadxlJRimDeXG1asYOJVY/AZPx6jVMqu53PpTDfwAVbuKsxnRZkPfjdej2zIfMSQTGoLOjm7r4j0CWF0RKo50NXHE7EhXgIA9B06RNsD9+FWarln1hRyPU7euvshrm6S09tSyrH+AY7mt5Bb1IZLJqK/JhBdoJoApZy7jb6UfldNztZqSo7WsvjJMSjU/9B3qw7C4TcAEEq2wdDLScCpU6fYtm0bOrGPseI51FIBVXA8fYZk9hXAzoBXcBSFoFQJRAY0k1uVhtn4IuERBrp7nuK9CDlf5LUiL4E4o4aX95bxDkHMUDyKXuLC0z9A93Mf0CAPRGLtIFPeQnKEmWtvvAGpVMqkmBH4HLNxWFbKO++/CxJIkAUxV/o6upI2bwhf/NSf7G91vbFsb38b9/cyUvweIUudwk8F4VWfaeXouhJ6HSloMwpoVY7lL2pfmjfVkDOsg8fkMXy6PY+P48LplSzF5lAw7/50vl93lC2hI1nkbyBU5VUSFD0iLd9XYj/SQL8HKqt6qX/mJJ4f/+Aar1UpOsP0v4sEiKLoEgThPrwTuhRYLYpigSAIzwC5oihuAV4BdMBXF0zQtaIozr0w2T+Ll0gAPCOKYueFz/cAnwJqvD4E2/n/M/ShZKjfITBEwp96g4FuQqtt+DTnIEpEdkZrqQ1o5Z4gG2l9Mj5u1TJVb+espJFoBYzdrGDT/PcJRUtseCPnXCP5ZN+nWK1Whg0bhkQiMCr2n6/efyjax8MnH8Ho8uG56vuQnuughw6QgFSv/G3y/wkIEsn/JwIAoDcHYAgIpK7gPLOmPsLOhp2srFjJhvoNLHaOxy06qW3LZ8KgqTS0trGxO57blCXIRj0PG9twNvfT2FgIXNIHkIeE4Hv99XSuXYv/rbeiiIqi/e23UURHo5o2FUlDHderPORmZTHqxHFKn3iCescAEXV1SDwePIJA4TvvkfHQLV4SULIdhiz1hlMBbfos+nfUorX18NzYm5hQ9ymPRo/C0NhMW4kPuqJiUtMGEdG/jneYSfLB/eRMmI65rBVDtJXg4d3eOPHm8/DN3dByHjJvhNlvoZLK0E2ehGXPXoKefQbdkAyWtfYTHxzIFtW3nHa5SO4up8gYx52b/s5QeRdxw9qhOA+HaRbO5jMMtp/nrCKOIMM4nvpsH4OaOki8toB2vQ8jvy3jvphOvh08FoPVQkCFDy0RpawJqqLO0s91yd6V4caNG6kNCuJceAxX2/ouPi9RFNmz8xjIZQwZtJXqxnF8990eursdREVH4ygtRREdjVSvJ+XUSYLnefebWzIDyT/UwL0TpbwbFkPoky/xypyp1Jd0ceKV0zRXeh3OnHYXm6b54SeXckuI17nOdv489b/7A/3aYE4Pvp/pi4fzXqyWabmlZJrvwWUWIL8aQRTxCZSj18mxyiXI7APs7+rju9ZuXpgVzHTrWnYUTqNszd9IXX6XN/QNwNoJm+70msqjRkPeOnD0gdIHp9PJtm3bOHPmDDGBeq5peRft7L/C4Bu9zm1Aj+o7Tp46hV5iZGhyBCNvHUf7YwfZ3fMQqqavePmDYuyCikVpIVxXasW3281Z3QlyneARpFS4ffEVbBg9HfgNdIAMssWzzLzu04t+SNa8NuI14aTcMYHDRw+TIIRiOO5AM2Yh5L7r9fBXerca3G4PEolwxTZmyYlm9m10EyjrwCyrIr9rDIVPHid1bCiZUyK8iYt+hAGbi9OfFOBb1cM4qYAk1MJjAf74y2Usyw5n1+ZiFp3QczLExvODVCwsr+UPtqmEq/MJS7yK8vRWPEIog0/2IaaJuLscNK4pQNJipcctotPKyZQKZBgliHG+SFL86T/diquyG/OtqWhMv0yelZ91dBdFcRuw7R/OPfmjz5P/m2tXA1fYe0RRzAUG/Q8285fFhb3ZoK5vyMxYQL0/+BcKhDS20hen54hWRnBzKs3OXsaHFXDO2sp62U6cEimLpU4ejHwUW+sZpiRux+IW+LI5nzG1gYhykY/qP+KPIX/EV3X5ROVss/LV92t4WfiQSEcIr6ieIHxJIjKTColOgUQtQ5D83/P6/08hPDWd8pzjyAQpH0z+gLzWPD46/xHl3xzFX6VEQGDjx3/lyBAHVzWP5zVhPvf4GYA2nI39NBQXIlMoCYiOuVin/1130r1xI82vv0FvSjKysnIKZ8zg81dfRRRF5HI5psmTONtnIaMwH7tCydmUVBoiw0kqKSFqyxYK71hOin8cFG+F+lyoz8ETkE7/xgYcvQqixrXzRfArCB4nbmsBAD11WsTdu1FHB+JjqSPa1cfh2CRcEgkxMVEEGzwItYdh2x8hdzVo/L0Jl5JmXmx78NNPY509B59pUxEEgeTQIJ4W/NG2dpJljiAw5xxzQ/dz1YmDGLRS6qd5MI34E5KQ2VR/dS27K15EE/4aJN5Huqwaqa4EAH2ghyHBOo46Wmg2+NNs8GewXE12dwhbE716CcODh9PT00N5eTktPkZsKhXJuQdhwjAA8rZupU6tJqXvNFr/LmYMDqewMIZDhw5Rl5FOZm4u4RIJ6vR0bGcvxYwnjw6h4FADvrtcDMu0szYhgN5VOaSf6kNrVDL++kTslgG+OVTL3k4Zf4oJRiuT4qiqom75nbjVes4Pug+1ycipHTUs+OMQ3ogO5Xh7G4Nynketm0v9URML7s4gctAlLY/Sfjv3F9Vyd3E9M4NCGN7YTVGBhNQNS2HBKpCrYcvvoL8N8bovyOm1knH67yjL99IfNYXPP/+cpqYmxo0bx4T2z5D06SBz6WVpbqdPn05JfiV9hhJMskjEbgfZMilblbBXzGaKspRhkmIC1RPpHRVFbnE+tV0SIjVWZt/6RzR6XzRNubg/mUGe/S7633dbnAAAIABJREFUNS6GGfuQqL35Rjx2F7aiDnTDgjEGmrn66qsZaLTQevwMduNCNKq1uNNvoPZcO8VHG6k+245WLSNpXCiJo4PRm9Tk7a7j6KZy4qN9SO0KRCSauHAFTYKcvIMNnD9QT3CsgdghAcRmBtBd20PjFyWEAU6tDN3wYCpOu9nja+DWZif2XTVkomZAEBgd5MsaiZxbZL28MdaXlbndtLaUs9GYyuSeNpynZFQoi1AUdeJ2eyhzuEmaEEbIvDgcFT1YDtdhL2hHLGhDr7HjsjtRVvbgk3C5T9F/Cr8t8X5p6C94pfrHkZB+LeeiTzAz12sSPGmKxKYoRtOgZ03HeB4KLuUus4O/1MuJUbpp6B+BRWvEZE8iTbcJj/ZWXlWNY2/lXvQj9KytXsvhxsM8MuwRZkXPoqq3ikOVBzmQs5NcZT5DFOm8NfttjKZ/Lgj0G34ehKekkb9/N2211QRExTA4YDCvDn+R9z++AUeGCY9Zg2lnFY+ELqY4vJvOU25WfbmaMapk0huDaCgpJDg+Eansksla5uuL77JldLz7Lq7Dh+n39cWSlk5mg4wAm47k6UMxjAjl7NTp7Pp+Jz5jxjAmLJCrJSKbP12D5O23OfzcC4QunIrh5PsAOMet4PwXh1E3thMwtAdtkA3BEAXxU5GeXAkBKchTk+jbtQvzvEwEIEOvZLPMS05Sr12AcPCE16JwciWkLYQZL1+WYRFA5u+PfvqlFKqjjDpOFe9GIffl8ynzmVtkJtJyGvNQO717j7JCpuWN9PmEaEN441oFPk64Ny6aFRWdHBoynKm5XvOqXGnl/qY6bh4VT1Sfg5CeLo6GBTG+8wkWV5dx2JRHvDGeo0e9Gge+I8eBA7obqnH29uJRKtl9/DhGi4UoXS/yqhmYM69i7twMzGYze3btoi47m5atW0mMG4PMx0zbqp2oYuWo1WomsY2Wwjqyxj/CC1YJW2Jl6GNC+cuYGHRKOZYuO4c629CJsCzUhLO1lbrb7wBB4Nzg3xOSEUNYoi8Hvyyl8UA9Iw7VM9wlYjDo+TpfQXiEnojUS/fS1WUnosXKlrZP+LCxi5djlnN0qpRl3/rSmf8ufr2zvOSr+HuY+jzfyaJY3lTNyMFv8n7hXjYfbKKjo4MlS5aQFB1G1xvLeWfIMyywDjDI59JU4bSJqJoSsPmdYm/dYYSdHk4pi+hSN5MkisgFDXWEUXauApEqlFIPs4UDDLltNYKfiaaKHs7k+VPZ8yl9dh/ohoLGaUS8m0fiiGACnG5wiWgyAxBFEUdFDwMdVuwSgdr9dlzqTTR9ZqOt/zx2mUCEXIJlwE3OjhpydtRgDNTQ3WIlNdFIXLsVQXCgVp/BKZtKQGM/U31kuNQyrJ02bFsryf++EpNMIEgiIGSYibo2AUEuYad/I1hE5ldYsXRZ0OiLyWnX03cSxsjhJqnI2gk+3JE9m6xDjQz4+3BftZJQgwQKOmh1emiRShhk1hA8MwZBEFDFGele/z6W3dtRpkxD9E9Hovald1cxtlM5BK9Y9D851Pxb+I0E/NIwJXhlXqc8S4wxiC+iBGbmish9RGrnGZB3yhhjGaBXVUNF/ggSBx/iyRAbUomb6rowdtzp5ti59Tg9CrLjbuBvH/6dxMRErpt+HbO7ZvP00ad5/NDjvHTyJbodXkGTMCGQWyJv4ndj70ch/SdZsH7Dz4qwFK8hq77wPAFR3gmzPOcYotvNsmseJTAmjr+XPUTDtkMseu4pFjYtYZ51Hvs7z9FQ2EZrVSXDF1w5WORFhGNWKlE5HMS8+ipxzSHY7Z3ITCr699ThMziQjEATGbdd7hy18I7bObhvLyNPHuXZUct5FXCkXsc3Z+UMOlqBOtxDa0wgp/2uYXLnGgS/CzKpukB8pkyh5ZlncRceRAak+ZnYbO0FIEKtgJjxcHYdzHkLsm75t+7PROsJ6tuPETbyflRyJfOzInh5h40zKn8ek5xg5g8hvBhxCIN/CS16kad3qJh9axif1Pfyt9Qs5vXtBdoRBJGzUfX0alKZ1uRklEtCY3sjb8cH8ydLAMvrrsFR0c3Zs2cJDQ3lB52RUGsH/QY933/6KTK9HqtUyqjTZwke8zhCmQbXVgUsERk1ahQRvb3s+nI9R3NyOCXKSFe6SauIpW/PIRznvgTRTdL992O6bgjr3R7uL65lbWs3B0+X8Ux8KCFKOaWhCqZWDKBK7aD21ttwdXWhevodurbaGT40kPBkP7q2VSHurEYWpAGZhO766wiRuEmaakIQBESXh76D9fTtr0N0evCR9nPvGF/GZSUy41QZR1PUjJW8wajWm6HxNMROxDP8bl4/VUagQkauTzJTraFM7zvFnUuWEBcXx+FTW/nd4PdpkgdQV9PKqkFRF5/P+R/qEQaUTEqdwK6CPXxZvgOpVEqZOwAfcwJZFTI8Lg8T/HaTLNuAyt2DOOQuzuUpOP/DcXrbbEhkAuGxAWQ1v46/tIYC631UF0mpye9EIoBMEJC/m0eKRCDkgleiCqDfidsygFEikOwjQwQkSinqVH96KrupbrbRYnMyOERDRIsFEPgqMYi+ARMPzI5HoZBiO9eOs6Ufrc2Fs2eA4n47p+UwrMuNtLCD9s8KkA4ysW5Ax5SOQ2SNV+NOuAHZJ8vJjF7ItoJAjkvl+Pe6eLcN7jc72GYyML3RRoxKCeMDOZnTgilEy6CyLvznxCC54JzZs3UrXWvX4nfzzQQ89igDVdV0fX0CR6kdl/DPHTh/bvxGAn5pqPSw/AAAke4BiiKlOLVS/O64nUP968jSDaEtOAyJ28PIfCmO+DDQ1gMyYkI3Ul3+BREGE1FRT/HDgVN4PB6mTfOuqhJ8E/hsxmdsKN3A6ZbTpDZEklYURvK1o9Fk/FLpKn6D3hSAITCIusLzDJnp1c8qOXYIQ0AggbHxCILAhKW3sf6px2jYf5yk0CRO2k+yXHkTp8qOoBE9aAMv9/AvLCzk6OnTTFi8iCC7A4kuBXtBBYZZ0SijDLS+l0fv/jqMM6KvaI9MJmPoc89RN/9qhm//gXuve4+0zn5SNv0diUpN6OfbOFpcxJH9+zEoxzDsv9K7thXhc/1VtDzzLM78A8g0JjJMZqj3koBQpcIbcQAgeq743cvgdtF4+iOsR94itbuRl4Aurbet1w2NoLq9n5KDTRyKyGJc+SlWH9HgierhdtM4EvP24mls5N62Oh4IDqVJacXoFJDKRfqFRsJdDt6+bhgOh4OiV19l37BJvJwWQHiRg9h1ubR6Wpk2YyYvd1uYHxZESmMTZwE6O4mtrCQsYQmCoEU3OhjLkUY61hXjf30SgYMHM/L+B0gnhnPxfuQItdSqehkfMwy/7AnoRqvRjhwCgFoq4W+pUdwY3MeKsgZuPl+FUSZFi8DwEzVUrnkMT1cn6uH34s6BDJ2MQEGk+7NCYiRQ4/CQMC8OY4CGM08fJVktRXWkDJvSh55tVbjabahDLQjNR+hzL8RjDSRNp2FRsB9feTo59YOL5ORNWPOtyNp82P9dCcWGAV41GiksOs7nkelszZ7AdNHAB8fKWWcLIcTVyyBRYF9bD5b+AXRaBc4BN/kHGohKNzF0UjzWvHocODkcGMGJJgt7Fw3DrFJw5KsycnMnU6bIJFRZQOmeCbgGygmONTBsdjTR6Savs+LOBDi2G9/rs0jZZaO5oZ9Wl4g0VEuoy4NP7wDtRhWuGANqpwdpXitRDw5BppHTtbEUR3k38iAt1jOtyEVICtYQ3+0AqxNBKcNwcwrv1NdicXvYn1/Jh2MSiZ/kDRm3uj28fKyCVQ4JbonAMo2OB1rAXdbNt8eraU9Xc0vrLgRNAjKtC/oaMRts+MoFuixOYoeYmXZjGps+voYX9VN4omY1Ttdb+E/3Zcb4MJpfzUUWY0Sd5vXJclRU0PTEk6iHDCHg4YcQBAFlTDRBf4ymbeU5JPpfZkH2Gwn4FUEhVWDyD2fti3FMjU+i/4d+bh67jKrWYgLrFMTdeieq4ToOHxmFKLqx25Oorw/lhuufoafHwvnznzBu3Dj8/C6ZCKUSKdclXcfs1rH0nKvCZ1LEbwTgV4DwlDTKTx5D9Hiw91uoOZ9H9pwFF52bwpIHkTB8NCe3bGTavbN4qeANYhOjsJzJoxbY+sMhpH5m0tLSaG9vZ/PmzYSGhjJm2TLEdgct7+ahTPBFNzoUQSKgyQrEcrgB3bAgZP7qK9rjk5iIZsoUkvbvp+x0AdraOsxtbQS/8ALywADGmk3U19ezoxyCxQrCTXpoL0HeX4hu/Hho3oQndTCDdN66AxQyVFIJ+EaDNgBqj0P2lWFoAOc3PEl44WpC6KMbH/ZKRjPOc5KunauotoYSExPDX6fHUfrk9RgXX093TQ4LK4+QGzCJ24ZlUMNerCdzGLl9O3ET5mAzyxnoCKBfYifZVs5dJq3XFKtSERsejk/FWTYYw7krPZQhrU6SqnUIkTH0FdUzylfH6MzB9Obm0unnR2ajE9nQFHznx6EdGoTMpKb72wo6Pi/CZ2I4KDT4djdz8x8epbimjC1btrBZm8uYvkTi9oehiOpHEXLJH32snw97hyayuqGN16qbuVsjMObEq3jwoJv+KPpZo6nYVk2EXKB7fSmCXILPvFgK1pfRv6+egEgfcnrdzDfvpagxndZ13zLKkIZpFqj234iYNAGp+Vb6DjTgsbt5YG4UXzV2cj5WgeWsA01aCC6Hi/dkdsL7RXr3b0Yp9PBccwCvDAnjhnpvxHV2pYMpZ1zURvSTP0zDs6+fZGqkP0qVDHu/k8Exeto+OEeSO5RmicjGxj5mIkf2Vh49ajmpTg/JvnIEMYh+TyDSNF+Sp0Vhjrg8j4A44UmcpvnIYxII+r0U7Q/1BJ1pQWZQ4qjowTAjmrDx3qhwV6ed5vNtuCp7kMYZcZR3oxsZgnFuLO4eB/2nWujPbQERpEYl5uXpnJO6sdR4uNatYDd2JueU8GRcCOEqBX8qrafe6WRer4Ap1cTHDe3khWj42+Q0vv6hiHCrh7FYvDkELqgOOtr8GToulMM5rQyb47XiJfsHsSbvUTwRV9HaJafto/MoQn3w2FwY58YiCAJuSz/1v/s9ErWa0DdevyKhkv8tqRetBf9p/EYCfmWIMcRQbqnFVbUdf5U/I0NHMvqe0bR/UnBBrz+bsWNOIghSenqsfPDBB3z33TYsFgt6vZ4xY8ZcUaetsIOe7VWo00zoJ/16hZP+LyE8Nf2iX0BzRSmix0PiiMuf3dgbllFx6gRNr29iKZF8j1fm188chhgaxtdff01NTQ21tbVIpVIWLlyIVBRo+aIYiUqK38KEiw6ehmlR2M630721CtPSf0zh4UXQvfdi27WLoWUVmEpLKEofQvAFWVeJRMKCBQtYuXIlGywLuW3UEIy7H4Qzawl64lmkH36JpbgDg0xKhEqBSXFhaBEEryTxuQ3efOkTn7jkE2Drpm/DnaRV7aBG8Gd/4DVIw2Yjk6hoKn6doM4TfP7tJjxIMarVSCZNRCXoYPIs/Ow9hNvrWHugm765c/CcOU1ySzO3bv6S4CFt1IRlUuqxM7z3PMaU+Iv/MTExkaodO3hj6zZ2XL2ENZEJ5JkmcTq/EaQw0qhDHRfHqLfexiNTYpjxGprsALRDvZntdCNDQCLQ/U059pJOpL7hSOQdSHUKUlNTCQkJ4euvv2Zf/Xka3F2M/shJ8PJM5EGXdAfkEoE7wwO4oaWO+rvuRpTKkI98EPNDs2hstnGsz8Wce9KR0o/SqMYQEcCgRit5e2qpLewgLMkXTXAHB4vO4kRK7MgIgo/cAb7RCAtXY1AZkGgV9GytQlrWxYIoGRvD5Uy0yVlyQzLb27opy69mclEerUIPGYoMkqxuPj7ZwAcJQUxqcjGhbQB5jBJ3ciBfiX10J2npO9pKl9PDVSYl4oE6ZGE6/G9K5p2TVXDGwv1zU/HpceKxuhBkEm9qcYmAcKwRn9Z+jIrLFUZdHTY61hXjbLADx5H6q1CE6pBq5DgqezBeHYduePDF8jI/FVI/Ffbybuxl3QgKKT4XxjOpQYl+YgQ+E8IZqOlFZlIj9VFwuKYFgD9nRXH7u3k8P1THijIv0YkTpKw8aWXqgmRU8b6MNOp4oLiWSbkl9KngwVoPAx1mpJYcaCtDAERDDHFXxxG/8JIuBsEZkPc5kuhhBFw/mM4NpdgLO9COCEYRrEUURZqffIKB6moiVq9GHhh4Rd/7pQgAgPSpp576xX78P4WVK1c+tXz58l+6Gf8WiruKOVh/kNreWubHzWds2FgEQUARqsNytBFPvxPtoGAkEhlqtRqVSsXJkyfp7+9n7ty5BAcHX1bfQKOFjk8LkAdp8V+aguT/sNTvrwlKrY7T277FLySM8pzjCBKBMdfdfFmYk0qnIyx5EL4hoeRpaqj1tTDRM5GM7ClcdfM8nE7nxWe/ZMkSzFLDhUHVgv+NKZetQCVK7yDTf7wJRZQBmd+Vqmkykz/24mJUx48jUSp54J5H2GH3MDfAiFIioc0tck5joLukjBMlzQRqRPwb9kDaXKTn1tJYJKO0X4NSoyS6vwdZewsWiwVP1DjUCglC7mo485k3QsDejeez+Sha8tghyaJ50ZPMm/EoiQnJxMfHY/D1R56/nrSZt2GIHoK9qgrcOjwSOW5/LTanHb2tF7XaB4Pdiqe7m4q4OOKbahliKuSzgLGUa8OZ2/4DsmG3Xgwn02g0nDhxAn+5jPTKMuTWbkJ9w8hRSIkRZFx/4Dgtz65AkKvRjnoQeagZ87IMBOml56II80FqVOLuciD368GWexz/O7zJctRqNRkZGYiiyOmafFrpIfC0gCbJH6nukrnX43BQveAaBKkO9biHOeb2wxDvS1luKzaLA1lkO1/v2Ex+aaGXXET7c+5APS6Hh8nLUth+voq+fitmXz2FRUVkSoqR37z5YrSRMlKP1KjC1WFn2LAw1tj7qe0fYFaIllvPloDdzlVFpcyZsoCJN43BbDhOaOly5l17J0mVHyFz1eL2zcaV38FZvYRircADDS7CFRKUCgnGObH4zo+j3uXmsU3nuXFEJAsmxaKKNaJO8kOV4Isqznjx2Hq6DWtuM8pYI1K9ElthB+2f5OOxuTHOjkERqUcQRQbqLLi77PgtTECbHXTFO+pqsWLLb8fVZkM/JRJ1wuWRT4IgIPNVXXzfX69uQS2VcF9cMKo+J1cdbiNpfCRj/H14ZFsr0X4a9FMiEQSBBK2KuQFGDnVZsLk9vJMZAzl5qN2HcfapkfQWIZn7EvJg/T90HAXkfgITHkMwR6NOM6GM1KMbFoQgldD29tt0f/El5gcfwDhv7r81PvxP4Omnn2566qmnVv5Uud8sAb8yxBhicHm8uvAzoy+FUckDNOhGh3hNusODL8pxZmdnU1VVBUBKyuUrPHfvAB1rCpCoZZhuTvlF2eZvuBx6kxljYDClxw/TVFbCsPkL/2kyprCUQYSlDKKzSscjBx/hUf+RKEs8dK4pYtyooURHRTNgc2AqldJy+AyCUorvwgRUCVfqF/iMCaU/p5nu7yow35F22aT0XzDdfTf9R48R+qfHeWFsNrcXVLEwrxx/uYwDnX14gOHjZyJUFGNs6iHFs5+6z+4gEtgzeBIN9fVIGxsRpVJ2OJ0X69XpTMyb9DFxJR8gfHsvAL0yE1+ykPIhBl5Jmnd5Q+Img8qAX/1eRs7/G+EbShFUsRine2WrT3+1k84XnyN0105U6en05+dzdPQoqjMikCBSoQ6l1+MlQe6SH5AOvQ4APz8/zGYzjRIJ7VVV+ErguSlDKP68iP5jO2k7uhqJMQL1yN8hUakx35HlXdH+A7TZQWizg+jaUE7PpvU4GxsvZrCTSqVMmjQJf39/Nm/ezE5OM20lBN+ZiTxAg6vbQc/mfXgsfahH3ox5+RicnxRy/ocGGqpbcIZUsndfKwkJCVRXV/PFF1+wbNkysmdEYe0ZoKmnkspWC7OEI0T0dfA38Wp2hT3IfFPcP7QxEG22d9W5OKePtREid2zbTX1kAtPya7h6ymLSxl0QdU2cQdOu53gyv4IHLCdJGTkf/aQMRJeHWTWtrKhtpm95CrFIkQdpkWi85uzXd5cilwrcc1XsFfcIoG/ffuz55zEvv4321QW0rTqPOs2ENbcFeagO/xuSryCkoke8aMHqam3j2W37uT8+jIjRo1DGGek/2YzUoMTnJzKYOjweTvZYuOGC/oLPuFAsxxuZeb4PmUlNT68Tw5Lky/pdlFrJtqwEel1u/BUybKNHwfFVSOt34ZEFoUoLvvKHgtJw3X4CaWgCAiBIhIv9r2v9Bjo++BDjwmvxv/32/7a9vxR+IwG/MsQYvPtM4T7hDDJdLoegnxSB9Uwr3VsqMN+dgSARkEgkLFrk9RT/8cvsGXDT/lkBHpsL810ZSPX/WkP8N/wyCEtJI3//LgASR165jfNjjA8bj1qmZkPKfu5NXIrleBMdnxbg468ClwdLTzea7EAM06P+6eQOIMglGOfE0LG2kOZXcvEZH4ZuTOhl5FCdmkrCsaNIlEqmA6tSo7ijoJoAhZw/RAayJNiPSLWS4uwUHi/JZtru/aTYKhERyBg+k9SX3iA4MYHIDz7AZrPR1dVFZ2cnx44d4+97zhIdsZhxpa3YfOEb8yzOBZfzweSXriRAMiUkz4GCzdjO1CKoYhFkFehGjQVg0NVTyMqx8+fSfaTn70Hq8TAmP5/6kCEgQJBNQNPeh8cDztytF0kAQEJCAseOHkUSEkJyUBByqUBg5246j65GM2I0QU+9SNvbb2PZsQPh8T1c8Ev/p1AlenXfHaWll6exBQYP9mrLb968mZ2e00z7Gyi0KlytVmyFe+gxGBCvHUItrejirZQVVWA11CJzSpg3bx6DBw+mvLycdevW8fXXX7NkyRIsFgvvvfcekZGRZAl6JNV5jIr24XBFCxlVVURHX3L89Hg8lJWVcfr0aWSVVSiGTeFoZALGfhfL4waRNv6SqnuTwo8FWR9SJTOjDFvMu2lzvO+MTMK0UD9W1DZzQOYmJeJSOPH+klY2V7Zx09goAnyuvEf2khK+/eAjzkbGcN9bfyX0oRW0ry7AmtuCdkQwxlkx/5Rg/RcBEEWRVzZ8y7rUbLTr/1979x0eRdU2cPh3tmY3vWx6TyAQQi/SQXrvRcUCqCivomIvr6/dz4piFxQEGxYUEJCOoCC99ySQQHojvWx2d74/ZgmEhKYoIue+rlzJzk45O5lknjnlOV9z17ffYrn/IbReRjwHRiP053+o2VlcToVDoZNzHgithxHXNoGUbc1CY9RibOCFMdqzznZ6jcDHuW9Txw6wCbTiJI7glvUG6vmffkrO62/g2rED/o88gktjdfKhkrVryXruOVy7dSXwmWf+sTOuyrrhf5hoz2gMGgODowfXuWg0Ljo8+0dhPVFC8apU7GXqk5YQtbNlKQ6Fk98doTq9FJ8bGtWqFpb+OcKaqCmEfYJD8bvA3ANmvZme4T1ZnPkzLt0DCXq8LT43NkLrbkDr5YJlcnN8RjU8ZwBwiqmxLwEPtMYY40XxilSyXt9G2dasmlkCgVqTzvS3eLGrYwJbO8TzWHQQESb1vUauJn5o2ZCqNhMAOG4KIaB7XxpNnEDluvUUL1qEq6sroaGhNGvWjDvvvJMBAwaQfiKNubFD+MYylES3DCb1m4SPyzmSpCSMAmsp1eu+wVFVjGvb0+sZdBoaBXozq1E/gt/9DGNcHIFTn6GNTS2fS2ouLYNDsJa4IDK219ptXFwcDkXBptcTnZtLyo03UTB7Fl43jCV85ocYInwp37wGpaKEkpWrAFDykqj6/aM6RTTGqk/fVYcP1/sRWrRowbBhw0hX8lkmdrKNRFYEHeTb5maW9e/Ht1uXM2/ePPalbaTM/RgG3Lh78t20bKnecBo0aED//v05cuQIK1asYPHixdjtdoYMGYKmx1PQ92W63vgAXl5eLF68GJvNhs1mY+fOnbz//vt8/fXXpKWl0aNdW4Yr6rkZXeVCx0GnE01lVlkZuTOZXIM37Qt3sdTSlTLf023eoS4G4l1dWJF3elrd4spqHvlpP7brLKxyV7ArtadnsZeWcfyBqbx5wwQ+HziS+/2jOfHBW1gmN8cyuTnew2LrDQDOdHTeN3wdo2bF3NhvMKXr1nFs5FD0PrsxNap78z7bbydLEVBrMij3bqGggKPchkfviHq3OzlvHkk9elK+fTu4B6K4qMfShDSqtZ6iKOS+8y45r7+BuW1bKvcf4NiIkWQ8/gQlq1eT/uBDuDRuTOi0abWnKf6H+eeW7BrlZnDjx6E/EuRWT7UTYG7pT/nuXErWnKDklzRcGnpjbm5B6+NCdXYZtqxyrOmlWFOL8RwQhSleJgL6pwpr0hQhNDTq1O2inhIGRA1g8dHF/Jb+Gz3Ce2BubvlDIz30/mb8bo2nKqWIoqXHODk/ETQC19Z1OywBpzv5nUUIQcuOt+L4/SUOu0Xz/J6jLBp7A6blK8h+6WVcr7sOvbOPikajoXXTpqz8bhGHoyIxW6vYGtWK+7zPM+98VFcUswV9wSrseeDW+fZab7dvbOH9nBJKijyJXriAomUpaDWfoxg9aNm6J/FNmmDbH41JOYRiq0Y4kyuFhoZiNpshPx/jd99T7eZGyDvT8eij5qKvSk7Gnp8PQPHSpVQNGkziwv/S+cTP9C2JxOAbQ6yrkQZmF1p5mPENC6Py8JFzfowWLVoghGDBggVkluTjb7EQnpJCRNOmhI0ejdFoxGAwsOmHVMIb+OPrW/tvtl27duTn57Np0yYA+vTpo67j6wvh7TEAgwYN4osvvuC7774jMzOT4uJiAgMDGTVqFI0bN0ar1dKp2kaT3RmM7xJSc72dCgCyrdXMizZj/WE2I1tMZ2VeMcMCTjcp9fHz5N3j2ZystuGt1/HSkgNkhLvg0ApSK60szS1isL+a917tCPc/1vgEkOl+OX6/AAAgAElEQVTjx3B/LxYktOTO5MN8NOMDYu6/79y/c6eqxETe3X+UqusbMibAm2+zwfDjQvRvvkbutGkolRVY7jv/fn47WUJTdxNe+tPXr87bBffuoTjKbRjDPepsoygKBZ/NwZaZSer4CQQ9+yxe/vFw/Hd1WuIz1st55VUK5szBc8QIgl54HkdpKXkfz+Dk559TtGAB+tBQwj7+CI1r3Rka/0lkTcA/ULhHOHpN/XNkC43Ab0IT/Ke0xK1zMNWZpRR8c5jcD3dT+EOS+lRnd+DRNxK3LiH17kP6Z3D38ePmV96m7dBRF7V+++D2+Lj4MGvfLIqtxX/6+MZITyx3N0cf6kbR8hQcVvul78TkheaGLwno9xzHK6xM2J+Kz0svodjtZDz5JIpDzQ9QYrMzavU63h0wit8iNOwMSURxuDNweyKPH0mj2FbPsTVayqviMWl34NW3Abqzb46xfjiArXuyUOwKlYcL0JtzET5R9O7Th5CQEERMJ7Q6B9atK2q2E0DHkydps3kLGq2WqEULawIAgPItWwBw79+PVaWV9Nu4ixYZvwBwl3UvOg2syi/m+eQMhu1M4hffQBL37ON/iemcrLbVe5qaN2/OQw89xOOPP87NjRrTZus2WnftRlRUFMHBwfj5+TFoUmuaXR9W7/Z9+/alSZMmxMTE0L593cApNjaWhIQEDh8+jKenJ+PGjeOuu+4iISEBrTMfv1mvY1KbcAw6Z+KaahujTgUAzWNoGxFPo4GvEmjQ8UP2yVr77+3rgV2BtQUl/JqYy1fH83BYTg81feNYZk1tUuG8eRQvXcqP424n0mTgvfgIPm4SyaHohtzqG8nBmZ/U+xlPcVit7P7fc/zYpRfDfdyYGql2EFypcyHsvffwGDCA/Fmzqc7KOuc+yu0OdhSX1zQFnMmzTyTew2r3nzhVk1G5dy/WlBT8H3kE17ZtyHzqKcoznJPb+jZAcTiozsgg63/PUDBnDt4330zQiy8gtFq0np4EPPoI0T//jO+kSYR/+gk6v/rnbUmtqKK0vmv+CpBBwFXo1GgBrwHRBD7WDsvdzfC9LZ7AR9sS/FxHAu5ticf1Yf/YNijpNP/IaHT6+gO+s+k1eh5u8zD78/Yzbsk4jhYd/dPHFxqB16BoHMVWStal/bGdxPaieUwr3mkczuaiMh4pU7A8+ijFm7ey89v5fJy8h5brf+V3sz/e+d/weIiVle3vZe5zDzOuIJO56Xl023KIw2WVtXZbvm0bRamxCFGNV3xZncO2DPdGI2BXZRXlu3KozixDr8lE8Y7mtWWH2Jich6HTCACsmxfUbJf71tv4/riA2NhYFKsVzqrKLtuyBXtoGO/eeDtP3v0wA7PW4WavAI2OEaW7+LFlA/Z2SmBfpwTmNo3CL74x/pkZfHksg8E7EkmpqKI+bm5uGI1Gyjb9jjAaMbVscdGnWKPRMHr0aG655RY0mvr/bTfs1RfXoaOZMHEiDRo0uODf//vHc0iuqOKLZtG09XQlObeUDnNPUpRcxMq8Ij7ceJTk3FIURaGlhxlfvY6fcwp5ZME+HE280QmIMxtx02o4XF7FL0eOUbxyJdkv/x/JI0az2+TGnaEWtEIwJMCbL5rHkBkYzC2eoaT/vvmc5cqd9hazGyRgM+h5pFEEUWYj8a4uLMlVmyMsDz4IDge5b719zn1sKyrDqih09nY/5zqgPtHfcyCVnlsPU2F3ULRgIcJoxGvMaMI+/hjvm26ibNcRFAVOPPECh1u1JqlHTwq/+w7fSZMIeOpJxFm/D0NoCP4PTsUQUX9zw5r8YrpuOcSgHYkUnCNo/DvJIOAqJzQCY6Qnpsa+6Hxc5MQ//3KDYwbzSd9PKLYWM27JONanrf/T+zRGemJq5kfp+jRsRfXfwC7GsABv/hsdxMKcQnqHJ9Dv3TkMCGjAM8cdVDgEI5e/yLrgfvynxd34hMXi1yiO/3w+g6WtG2JXFIbvTGR/aQUA9uJi0h97Erv3AOz6YMT++eBwqIlbtn8Gy5/CzVZEkyAP9ggHRUuOAnZEVQZJNgsf/JLMXXO3k+bbFLtdS27iRkbvSuLYvG/InzkTr7Fj8btvCgAVu3bVfAZFUTi5YxeP3f0Qc8psjN2+gUdPTXzU7AZ1Cl672hfHz6Cjj58nPa9rjUZx8LUH5FttDNh+hG1FdYOWU8o3bcbculWtvheXw6upubxZWM1n6XkXXDfXWs3MtDyG+XvVtJlPX5WIVgh6uruhCMFLO1Lp+eY6Gj29jF5vrsNYUMXS7EJOBBqw6zXYFHh623ru/XYOAE9s20/6lPvQWvyYP+pmvHRaGppdWJSjpivv7ufJ182jyfGxMPlACtXl5XXKVbJ2LYcWLmJxt97cEORLpLMPykCLF1uLysiuqsYQGoLPbbdStHAhFfv21+rPcsqGwlJ0Aq7zdGVNfjGbC0vrPQ/TU7OZn32SQ2WVfJiSSfHSpbj37IHW3R2h1xP436fwbu2NEBAQcwifMUMIfPZZIr+Zh/+DU+sNtOyKwm8nS8i31r3Br80vZsK+Y4S7GDhWUcUNu5PrrwX7G8kgQJKuMq0DWjNv4DzC3MO4d/W9fHnwyz+9T8/+USiKQvGylPOu57DasRVWoTjq/uMFuCfcnyei/PFWcnAtW45n7gyGbXubH958kUfSzFg6dK1Z171fX6oOHSK+IIcFLRvgotEwcmcSu4rLyXr+BcCC0BpRGg6Do7/Aa5HwQXv46X74/T3Y9SVto3w5gJ2q8moMHkUIh40fUgxEW1zRagU3/bSXVEcgQbps9OvXUfrCC5S0acectiOZk+sCRiMVO08HAWXJyTwz4mZ2+PjzXuNwnjbbcHPJwB7RCxr2gapiSK/d0dAlTu1E1zAjjcWtG+Ch0zJyV1LNze8Uu0PBlp9P1ZEjmNt3uOjfzSmLcgpZcFY1/SlplVbWFhRj0gheSM4k9Ry1Eae8k5qNVXHwSJRa1X4ku4Sf9mQwvlMkM4c1I9ZspGm7YP5vRFPGd4ykcZAHriet2LUCe6jaxn1HgBehH73P0LwMQq0VpASHkTbzUzTffMeyonJaeJi5YU8yd+9PIalcreVp7+/LsyaFLdFxvLBgWa0yVR45QsZDD/PVTRMRWl1NMwDAQH9PFGCps3Oi76RJaL29WTL3K1pu3M9zSem1goHfTpbQwt3MwpxCbtpzlBG7kvg8o3ZwtDKviFePZTEiwJuBFk/eTc0hCw2eQ88YrnpwIbqqE9BmIgaXCvz9N+A9fCCm5s3rPa+JZZUM3ZHIqF3JtN90gHdSsym3q01ivxQUM37vUbqSzzLdNhYZD1CYl8LNu5Mps1+5QEAGAZJ0FQpyC2JO/zl0DO7I9B3TqbBV/Kn96bxdcO8cSvnOHKwnSgBQqh2Ubc8md8YeMl/ZQvrTG8j430ayXtlC0eL6myKEEBw9+io5SffRzy2LH00duP/TzXgcS8Nyz39qPTl5OOe4KJi3HdfZB5nfMAJ3nZZRWw+y8cBhNNffSJGHjtxOE6kMbY8tfhgM+xCm7ABLY0haSdtIb6oUhcPYMYWp5d5R4s1/BzSmx8BYjkWa2O2RgItnNf+b+Sa5gSHceNNdvFNcwiu/JDG/w5iamgCHojD1SDobm7XmBYsrowJ98GziikavUJrnA1FdQWggeU2tz6wPC0OYTFQdPkyM2YUlrRoyOukgmhvH8P7CZVQ5HOSWVNHy+RVs+E698bl2OE+HyLNUOxSeOJLGpP0p3HfwOJlV1jrrfJ2ZjwP4unkMeg3cf/A4jrOekKtsdn7ancGxsgrmpOczJtCHGLM6tG/6qkTMei2Tuqiz3Y0I8GZnWQVdmwXyxIDGvD+uFT+Pa4dBCHQCggw67jmRiFJdjf+DU5nRvhkAT+m8mFlQjgB+KSihq7c7Ro2Gt1Oya8pxe+e2DE8/yoygaBbu2AuALT+f43f/h296D2JhQmviXF0os5+ebyLO7EKs2cgSZ2ClcXPjp8efYUrfkeRWVfPhiVyeTVKnhy612dlVUo6nTstDh09wvY873bzdeeRwGi8kZ+BQFI6WV3HPwVSauJl4Iy6MZ2KCcTjszLhhAq6dOqkHtdtgzUuU+DTkjoh7KBv+CaTvgHk3ga12kGVzKLybmk2vbYdJLq/ixQYhdPBy4+WjmXT7fS+LVn9C3rd3smXzWD5fOxzXn+6l+bK72bJpDJ8u68PBGUOp3jrroq+Jy0mODpCkq5RJZ2JiwkQ2rNjA+rT19I3se+GNzsP9+lDKtmVRuCgZY4wnZVuycJTb0FlMGKM80bjq0bjpsZ4oofT3DFzbBdZKhwtQbC1mXdo6bom/hUfbPgpA1q5UbLm5mDvUfvrV+QXg2uthbIX+UFSC63fJzI3O4+bCaqY88vzpFQ+XQfT/ARBQpiM0xc5Un3b0TPyKNoPUIZGHwl3pGlAIyeAZHsd8pZL5xcU0RsfyokYMNyzHGGLgzVa3Y8+0Q7Q71YFmPsjx5thWHW9XVPLyiTx+Mnly5+ol3P7CkwDos3/FbjNQsPownvd4Q0hrSFpNddx4yrdvx2PQIIRWizE2lsojh9Wn0a++4PY3XweHA/2brzHYN5hewpXiShsFv24k0N0dl/j6UzefLddazZ37UthUVMa4IB/mZRXwwfEcXmhwOieBXVH4OrOA7t7utPdy47nYEKYeOsGs9DzuCD09emTm+qO8seIIgZ2DUNy0POh80j6YWcySvZlM6RGLt6t6Pof7e/PasSwW5BRyT7g/AK5aDb18PViaV8QbjcJRXvscracn5lataKXT0dLdzM6ScuZk5KMAd4dZeDommJeSM/noRA4PRAYQ6ww63hh4PQcXr2eqNZC4vJOsnf4hc+6YSkpQCALYX1pBty2HaOZuYnSAD83cTVzv486stDxOVFbxYnImCz0C8Cwvo9xgxKHT8XFaLicqq7ghyBe7AqsLSujp48GnCZHohODJxDTeP57D8Qorh8sq0QnB7KZRmLUaQqyVjF25mLn9hrGltJLrvNzU2S/zE7m/yYsszStFsTTjk6HvIRZMhu8nwqjZoDOQXVXNrXuPsrukgoEWT15pGIrFoOeOAHeObvwZ1w3vElCRSbHeA5eYburMmpGdoboc0ndQmvQ7Hmnb2LxvLZ3b1j+/xl9JBgGSdBVrHdAaP5Mfy1OW/+kgQGPU4dk3kpPzE7GmleAS74tbh2CMMZ61E1GVV5N1rIjCn5Lxu6Nprfc2ZmzErtjpHdG7Zlng0/+tcyx7WTX5cw+gcWtI1f4fsEydRPGKPFx+28YM/RF+uetxKvYU4Ns2EPdANzQCsqqqOVFp5USFlc/NrejlmMOhI6uI9gtgn6vgYOpBmqBnT0IkqdkneSwqkPvC/Hn4aDqkTWdx81YUevixtH9z8NDzeXoeX9lyWDKoD8t+P4hdCG74dRV3WYvUz2QtgyPLqfZuR+WBQ1QdO4Yh+npY/zopIwdhO1mBzuKPa/vrMMY1pHT1GjKffpqi7+fj3rsXnsOGwT330mXBt7zVfyTaSDd8V+/G3K4dQnvh7J17S8oZv/cY+dU2PoiPYESAN3YFPs/IZ0p4AP5GtUPpmvxiMqqqeS5WHQ10Q6APi3OKeCk5g54+HkSZjZRbbczakIKvxUyKSdCwXCHEoG7/1sojuLvouKPz6dwBUWYjLd3N/Jh9knvC/dleVMbzyRlsLipjVIA3PTzNJP6yDrfu3WrGwL/bOJzOWw6hAA9HBvBwlDo8dHK4hdnpebydks178WpnOVdvbz4OcGVIZRU9dh/D0WMQYc5MqY9HBXJTsC8Lsgv5NquAp5PSa52X67ccpszuoKmbib3A/2ZOp1HrFtzbrgdL84pZla/WCPXwcWdW00hIScUu4NWGkUSYjLyQnIFWwDfNYwhzUYOe4p+XccPPC1g5YBj/TUxnWYtwyle9xBH3eCoa9OdRLzdeO5bFZw37MKH/a/DzozBnMEXDP2VsUinHK63MaBLJEH8vqK6EjR/DxneJLs1CCW3LwZb/R0izQRjO7gQc0pqodnfyeUYeQecYivtXk0GAJF3FtBotvSN680PiD5RVl+Gq/3Njks2tAxBGLYZwd3Re9WfK05j1ePSOoHBhMpUH8jE1OT0M6te0X/E0etLMr1m92yqKgvV4CQXfHsZeVIVnvwDSFiyjdLkRa4oBQ1RvYnuPJCrVRmW2g6DmYQht3VbL7LggKvY8TvLeJVibPMimrdmM1SWSYg6hRAjmNY+hm4/aM/zZm3qS/bqFDt6ZjJvSGR/n0+7/xYXxhLueYe/8TELYCfobM4ic9wtuz7+oHuTIcrBVoOtxN3zyGIXz5iHy9+PvpuDZ1JOT2zUULVqEa/vrcGkYR9H38yn6fj6+k+/GMmUKQqO2L49avICfw5pTHuyJpSSfNy1hHNh2mCiTkSnh/iS4m+s9T5MPpOIAFrVqQDPnOvdHBPBtVgEfnMjhWedN/8vMfPz0OtqtWU7SrFnELP6JNxqF0n3LYSYfSOU/4f4cPJxHfpmVjn0jyC4tJ3VTJi/aDQxvGcKKA9lM7dUQT3PtG9TIQG/+m5jOjbuTWVtQgr9Bx+txodwY6Ev5tq3Yi4pwu75Hzfqxri7cGuxLrtVWEwAAWAx6JoT41akNiOvTizeefZHZ3kGM9TbzQ9O2lJVVcEeoBVedljvDLNwZZiG1ooqk8iqOllfy6rEsTFoNQyxefJVVwCORAYxs2pCCmR+x6PAB/jPxfvZUWPHRa/m0YTBF06aRP2s2OBy49+7FxLvupknzaKyO2iMHihYuxCsijP/FhTP54HFmL3iNO8qzWN/teeY0i0YnBNuKyng2KZ22rW4hwdWCsvAebB93wyv+eZ7vMoSuXq7qRFmrn4eiE2rz0YgZiKiuNL7ASI1bgusfSvh3kEGAJF3l+kX24+tDX7P2xFoGRQ/6U/sSGoG52YUTELm2C6J0UyaFS47h0tAHodfgUBz8lv4bnYI7odXUftK1l1op35lD2bZsbNnlaFz1WO5shjHCA5fmzShauBBdQCCGHkMpWZ2J0GowNbfUGwAABJhdUWK7Myx9G08YFZR2foTtyeGkWxir28YRaDx9Q/M06/FoM4yAnZ+DzgqczqroERzI9B3fEGw4gK+miLKeBvQJztS7+38EtwB0zQdgbvMdBXPmgl6L3ygXLAMTsPm6U7J8OY6n/4trp47ow8OxTJmC5+DTvwP/xx8jb/VaHvrmUyqGqKl47Qmt8dHpWJFXjF1R+OTU8c6QWK7e+P6vYWhNAADqE/qIAG/mpOdzT7g/dgVW5hdzd6iF0hc/o/r4cSr27SOoVSteiwtlyoHjTNqfAoCmdzC/lJUzOdyC0lbPrA3HWLQ7A0+TngmdI+uUYYjFi2eT0tlSVMajUYHcFWbB1VmDkb9mLUKvx/WsWUtfi6s/z0F9tQEAAx66n+6bN3OwTXvW7Uzi6ZhgXHW1r50Ik5EIk5Gevh6kV1UzMy2Xr7IKGO7vxYORgYgnnsAQE0PWCy/yTlo6nz//Kp2xkTF6NNakZLxGj0Zn8aPgiy8pWbmK6C5d8Bo5ksqoSAwhwTh+fQcf82p0bToTlbuWXxU9w498SmJgB+7rPgat8wb+TuMIem49xN0HUlncagj/18XM3Rsf5Ifd96PxOA5HlkHmLghsBkPfV6v9rwKyY6AkXeVa+LcgwBzA8mPL//S+iqqK+Hj3xxRVFZ13PaEVeA2Oxl5QSckGtbp2X94+CioL6BqqjgBQHAqViSfJ/+IAmS9voWjJMTQGLV7DYwl8pA3GCDVjm/eNN6ILCiL8kxn43dYcnZ8JpdqBuen5n45EbG+8StOZ5WtFU20jsjKD66Kb1QoAatZtMhxslZC4os57gS198dUUMc/WHYOXA/2ScepQwMQVED8UNFp877gdc7t2RH79DZq4Xoijv+A5ZDCOsjJK1qzBGBND7IrlNQGAvbiYrOefx15QwMKOo4kvSKXtwi8pcPHAzxDIvBYxjA3yYXV+SU3v8TMtd/aC7+tbN6vdA5EBVDocfHwil3mZ+dgVGHEyB2tKCgDlm9Ux+EP9vTnSpSmPmDzQ7z1Jfw93RgR4MyUigKcHxjOqdSh5pVVM6hqNh0vdc+Zv1LO8TRyb2jfmwcjAmgBAURRK1qzB3KE9WreLq3k6VRvwQ/bJmpECAFp3d9x79eKNlCz89DrGh5w/w+kgixd2BVp5mJnWKBxRcRLea4d34QfEPt4FsyONWyfdQuRt43CUlBI2cyZBLzyP5b77iF29CsvUqVTu20f6Aw+QfvMgKh+PQrf5NUw+1ZhK1yLmT2Ta+lvwrS4idtBLNQEAqENC34+PILm8ii5bDjHHHsi2sYvRRHeDda9AWR4MnwGT1l01AQDImgBJuupphIa+kX356tBXFFUV4Wm8cF71+uRV5HHXyrs4clJNgXtX87vOu75LrDcu8b6UrDmOKd6XzYkbCbUG0EHbmuJfTlC2JQt7QSUasw63jsG4tg1AH1D3puE1bBieQ4fW9C3wG59Axf48jLF1Z0KsJbYXAP3Lt7Mwoisu26vAp+5TNQDh7cHVHw4shIQRtd5yDyjEUSD4oGQoW00deFP7JcxRn9ppoq7r1q0bbt2c/9gresChxZhjfNAFBlK0aBGeAwfW2mfh+//DPfNLkh9fxqfRT3J9o+b4HtpNWqP2bEtVe7gP9HHjs/Q81hYUM9DiVWv7n/OKaO5uItil7lwQsWYXhvl7MSs9D2+dlk5ebnjP/4xisxm9vz9lm7fgN3kyAHoh+OnXVJq76PikTUyt/huvjGjKwGZBdI49d7DVxM1UZ5k1KYnq48fxnTjhnNvV51RtwKtHs/ggPgK9M6fJpsJS1p8s5ZmY4JpA41xae5j5LCGKdl6umLQaWPoIFCRDcEv0SV8R3t6B3a6nSkRjHD4FbdO2Ndtq3d3xu2sSPrfejG3ZK+j3foii6Dhpux57bG/8Jt4K+YlqLgqtARHaus7xO3u7MzUygGkp2TwVHcToiACI+BZSfoWw60Bf93z908kgQJL+BfpF9mPugbmsOb6G4Q2G17tOpa2SD3d/yNoTaxkWO4ybGt2Ei05tn80ozWDSyknklOcQ4hbCytSVFwwCALwGRpE1rYDsadvpTxP604TyDxMBMER54tknAlOCH0J3/krHM29OOh8X3LuEnmdtJ+8I8GuoDhXs4hy37RNd/7oarTor4e6vwVoOBmcVu70aY+VeitNd6Fqwiy8a9+XB0UsJWXUPlOao/9jPFqO2g4tjv+A5eBD5s2Zjy8urSRFb/fvXeJd9hvBXaOR/gFtsK/F/4AF48iGqO3XnQGYx6V/Ow+etN/F89i2+W7uB7pEWzK1bI7Rasquq2VFczmNRgXWP7XR/ZAALcgoptzt4MtSXkqU/49G3L1oPd07O+waH1YrGYGDp3kxS8sv5cFyrOoltdFoN18f5X/g8n6VkzVoA3K6//pK2sxj03BVm4e3UbH7fWMrYIB/GBfny+rEsLAYdt4VcuF1cCEE/izPIPbAQ9n0P1z8F3R6F8gI4uhZt4krMh3+GhRNhmQfE9QePEChMhcLjaAqOYSjPgwZ9EYOn4+1xxjwtgU3Vr/N4JDKQUQE+RJmcAZpGC9HdL+lc/JPI5gBJ+hdI8EsgxC2E5Sn1NwnsyN7B6J9GM2vfLAwaA29tf4uBPw7kh8QfSC5M5rZlt1FQWcCM3jMY13gch08eJrU49YLH1fmasExqhrafP28HfsHujhn43tyYgIda439XM8wt/C8YAPwpsb0gZQNk71dfnysIALVqv7ocklaeXnZ0HcJaREmmB31St6AR8NW+MrhtEUzeAM6UsEXl1WxPLXAeIwq8oyB5DZ5DhoDdTvHSpep7O+aiWzYZa6ke200r2KprzQv6zwj4ZiLRPy0kuEt77A6FdR9+iVtCAj1y0ljn7kPSxDtI7NqN4hUrWJGvNgX08zt3jU4jVxND/b2wGHR03r4ZR3k5XiNHYL7uOpSqKip27UJRFN5fm0SMxZW+Tc4dUNQozYGvboCj62oWWY8fx15aO/thyZrVuCQkoA+of8Kp83k0KpDPm0bRxtPMRydy6Lj5IBsKS5kS7o/5HP0/6i9rLiyeCkEtoPNUdZnZBxJGwvCP4OFEGDcf4oeoHTw3vqOO8debodEAGPkp3PQNeNQ/Udv5CCGINhv/NWnZZRAgSf8CQgj6RfZjU+YmTlaezipXbC3m/zb/H+OXjafaUc2M3jP4fsj3zOo7i0BzIM9sfIbhC4djtVuZ3Xc2Lfxb1AzvW5m68lyHq8UY4cHG4H0s995Igy4tMSX4obfU7fH+l4jtBfYq2DkXNDrwrL9jGgARndT0vwcWnl62bz4YPbH7tyPIy0T3OH++25ZGtd2hPuEBVpuD22ZvYeSHv3MgwzlxU0wPOLYeY+pXWLq4Ub32E7VX+KIplGUZKAl7iCxLU24se4CdHoPwDEin6oV2RL86gls0KwgcFEj4hMZM7BxFhYuJo9Omo/X0JOfNN/k5t4gIFwONXOsfnXHKW43CWdM2jsof5qOPCMfUujXmNm1Ao6F88xbm/p7KoawSJnePRXOhdOK2KvjmFjjyM3w3HorSsOXlcXTQYI4OGUyZcwZDW24ulbv34N6zx/n3dw4aIejt58lnTaPZ3qEJT0YHMSrA+/y94/OTa1I1A+pcD0sehKoS9YavrWfuDZ0BGvRSO+g9ehT+mwP371KDuyHvQtNR8C+5if9ZsjlAkv4l+kX149N9n7Lq+Cqa+TXj60Nfs/TYUiptldzY6Ebub3U/Zr16c24b2JYvBnzBmhNrWHZsGfe0uIdIz0gAAl0DaWZpxoqUFdzR9I6LOvb6tPUEugbSwKvBhVe+nCI6gc4EWXvVWgDtef6laXXQaJB646+uAAQcWgyNhxA45kEcZWXcqAvgzrnbWHMop+bp+eWlB9l1ohCDTsM7qxP56JbW0PwGSFwJG6bjF+JM+frrbrwg+LIAABUwSURBVEpLwsnY60bMG/fwyY5MHGjwvW0mFUv+izn5UyKbwwt8BpXAWmijeY3HoibwS6u7uf6OO0h+7nl+KyhmQqj/BZ80TVoN2vQ08rZuxfLAAwgh0Hp4oGscz8uHq/kxfT9dGvgxtEXw+c+hosCSh+DEJuj1LKx/E74bTxFjUKxWhEbL8fET8L75ZgzhapDl1uOPBQE1bFUEWgu5z1wEniY4Vy3Alpmw9GFw8YK4AeqTfUUhHFykltW/8YWPpblwToZrmQwCJOlfIs47jkiPSF7f+joVtgqMWiMDogZwU+ObaOTTqM76Qgh6hvekZ3jPOu/1iejDG9ve4ETxCcI8zvN0DVjtVn7P/J3B0YP//ipSvQtEdVF78nufo1PgmZoMgx1z1NS/iqLOBZAwAmNMDADX2x0EeBiZt+U4fZsE8tPuDD7bmMLETlG4GbW8syaJg5nFNA5rB1P3gsOB7fghTtw0FJe4WAp/P0bAU/egdXdnyd7dNAv1JNzXDLdOw3ZiElqTjjd+SeebPQVsergTuuWPMnX/DHbmbsA08kO2tmyLFbXd2+FQSMotZfOxAjYfzWfLsQKq7Q7aRvrQLsqH66J88fvhR9Bo8Bym5rsvKLPyWOPR7LC5cnv7MJ4YnIDuQtXsW2bAzs+h6yNq1bp3FHx3G9qsdEwtWhA+exY5097i5Oefq6c8JARjw4aX/rsqyYJVz8L+BVArzbWAgW9A27MCzqRV8PNjanu7exAcXqJm8QMIaQMdplx6GaQ6ZBAgSf8SQghuib+FeYfnMTRmKMNih/3hkQK9I3rzxrY3WJG6gtub3n7edbdlb6PCVlEzNPBvF9tbDQLO1x/glMguYPJWmwTs1WD2g6jTw7l0Wg1j2oTx/tokfk3M5fH5e2gV7sXj/RvVZN17d00iH4xz9hzXaNBFxqNtcj2Fv/6KPjwC77FjWLYvkz1pRTw54HTwpQtTf27UwEzetp0cLDbSdPRn7AnpSeSaJ9B93gdrx7vwLCuhtV4w6fPtrDqo5twP9HChQ4wveq2GrSkFrDigLtc5ovAf+Azhi44R7JXF5qMF5DpceXj7V0wYcs+FA4Cjv8CyJyBuIHRXUyXTZBjV20fixXz0bYeiMZkIfOpJ3Hv2JOu552qN5KgjPxnyk9S2endnnwGbFTZ/COteA7sVWtwEXuHg4qk+4e/5Vq2JqCyCzg+q1fQ5B+G7CeAfD2O/BKObup9j6+HoWmh35/lrfaSLJs+iJP2LjIkbw5i4MX96P8FuwST4JrAydeUFg4Bf037FqDXSLqjdnz7uH9KgF/wswBJ34XW1emg0EPYvBMWu3pDOupmMaRPGe2uTmDB7Kx4mPe+Pa4VBp8GgMzC+YyTvrU3icFYJcYGnM855jRhO2a+/4jf1AaavT+HtVYk0D/NibJvwOkVoE6kOfdyaUkDTUE/i2o+jR1kI3+17hIGFP7Ijx5tNJwtYdVDHhE6RTOgYRZiPCVt2NuVbtyKa6sl2uFCx51NMuTt5K/h1ch0Km48W4KLX8M34VrgsfIyyzVtw7djx9IEri9Xmj8LjUJwBJZlwfJM6wmLExzWdIAHyEgPxKjJiNnwB+XeCbwyu7a8j5uel5z63JVkwuz+UOicLcg+G4JaQd0QdetewH/R9GXxjam8XPxQWTFb7VFQUQscp8NUYdbjdTfPUAABOt/M36HXh37N00WQQIElSvfpE9mHa9mmklaQR6l7/kL20kjSWHltK28C2mHRXaIy0TzTcuRr8m1zc+vHDYOcX6s8JI+u8HeZjpksDC78m5jL9hhYEeZ7+XLd3jmL2hmO8syaR929qVbPcvV8//MMieXxnOcv2JzKiVQgvD2+Ki75ue3SQp4lQbxPbUguY2DkKo0ZDy5AYXs8byVuHX2XUya18kmvG0yeKh/vE4WrUYSsoIGXMWGw5OQAYvapp2icX4Q7vjQ1DE1p7atuUhISapEFYy9Qq/w3TocLZadTVHzyCUCK6Ivq/BMbTAY2jvJziJcvR9B2LSbsYvhgJt68At/MMJ7Tb1El1qkpg9Bw1yMjYCRk7QGuAm76FhueY20KrV5PsuHiqvfh3fq7m35+wBDwvYqio9KfIIECSpHr1jujNtO3TWJW6ivEJ4+u8n16azsTlE7E5bDzQ6oG/v4BnCqmb2OWcorqB0RMMrhBW/5S+b4xqRkp+Oe2ifGot93Y1cFvHSD5cl0xidgkNAtypstlZeyiHt1bmkphTwtOD4pnYKfK8/SPaRvrwW1IeiqIghGCQxYv/WLrzfNK7tAvMYUphMHfFe+Nq1KE4HGQ8+hj2wkLCPv0EnZ8v+hW3Q3EVVBejOboSzgoCzNddR/7sT3Gsn45m87tQlgsN+kC3x9S0tjoD5Tt2knrbbVhKVuB316SabYuXr8BRXo77qPHgfyvMHaIGAuOXgEvdDIYArH4OUjfAiJlqv4tLpdHAgDfU5oENb6tD+C7ldyr9YXKIoCRJ9Qp1DyXeN54VqXVT7WaUZnD78tspqy5jZp+ZxPlcRFX8P4XOAIOmqZ3RNPX/C/T3cKkTAJxyR5doTHotzy8+wBM/7KHti6u4+4sdnCy3MmdiO27vHHXBDpJtIr3JLanieEE5AN183BEGN7aF98fLugcvRwlD07cBkD9jJmW//UbAk0/g1qkTLqWb0ObvQwx8DYJbwaEldfZvvq4dPtFFaNb8T+1BP3EFjPsOQtuonx/Ie/99qK4m9623KJw/v2bbwvnfY4iMxNSqFYS1hTFzIecAfDNOHUp4tgOL1Cf4tndAsz/RFCUE9Hwankj7Y4GE9IfImgBJks6pd0Rvpu+Yzp7cPYS5h+FmcCOvPI+JyydSbC1mZp+ZxPvGX+liXrqmo/7wpj6uBm7tEMlH65Ix6bX0SwhkWMsQOsX4XrgjnlPbSDXA+C0pjwhfNQXudy1i8PCbiOHYfB5jGfpF6ZR1aE3uO+/gMWAAXmPHqklyVj4DEZ3VYYrF6bDmBSjOrJX4xtyyJfrYcqyaMAy3/VTn+BV79lC2YQOWB+6nfNt2Mv/3DFpvHwxRkVRs247loQdPBzINesPQD+DHSfDDnTBqNgiN2skvPwkW/Ed9au/78h8+p7Vchal3r2ZCUZQrXYa/XJs2bZRt27Zd6WJI0lXnRPEJBvw4oNYyjdDgqnNlZp+ZNPG7yHb4f5nKaju/H82nXaQPrsZLf5ZyOBT6TV9PSn4508Y0Z1AzdSz/tOWH6L9hNBFmLamfVSGc8wFEfv+9OlnPj5Nh77dw9wbwb6T2ov+gPQycBm3P6MCZuhFm9yc3LQHLJxvqHP/E5P9QsWMHMatXIwSkjp9A1ZEjuLZvT+lvvxG7dg16/7P6AGx8D1Y8pbbx262nl5t84K714HX+oaTS30sIsV1RlDYXWk/WBEiSdE5hHmHM6TeHEyUnKK0upcRaQoWtggFRA66uJoDLzEWv/UN590/RaATzJnVg0txt3PvVTo4XlDO+YyRzNx8n0DKUxvnvYgqJoDLPTsj0t9UAIGWDOk6+81Q1AACwNFI7Rh5aUjsI2DEXhzCSv7kA9yNHcDljXH/lwYOUrl2L331TamYBDPv4I1JvvInSdetw6969bgAA0PFeNeNi7kHQuYDOCFqjWlMgA4Cr1l9aEyCE6AdMB7TAJ4qivHLW+12Bt4FmwA2KonzvXH498NYZqzZyvr9ACPEZ0A04NdfpeEVRdp2vHLImQJKkf6LKajuPfL+Hn3Zn0CjQnUNZJfw4IZ6W316HNbAX1U3vx7X9dXDwJ1hwD5g84T+bT0+ABLDiv7DpIzU9rouHOszuzUbYGwzh6PuHURwOIubOwRit5lFIu+9+yjZuJHbNarQepzv6WdPSyHzyKSwPPIC5Vcu/+1RIl9nF1gT8ZR0DhRBa4H2gPxAP3CiEOLvx8DgwHvjqzIWKoqxVFKWFoigtgB5AOXBm76RHTr1/oQBAkiTpn8pFr2X62BZM6RHLoawSWoV70TIuCuKHYsj7DdfmcbD0UfjmZvCNhlsX1Q4AQE3046g+PTHS3u/AVoG2y2TCP5sNwPHbxmNNSaEqMZGSFSvwvnlcrQAAwBAaSsTcOTIAuMb8lc0B7YAkRVGOAggh5gFDgQOnVlAUJcX5nuM8+xkF/KwoSvlfV1RJkqQrQ6MRPNQnjg4xvoT7OG/wrW5V2/7fawtlOXDdZOj9nFoFf7awdmrmw0NL1bwHO+aqwwCDW2IEImbPIvXW20gdPwFjTAzCbMbnttv+1s8o/XP9lUMEQ4ATZ7xOcy67VDcAX5+17CUhxB4hxFtCiHr+KkAIMUkIsU0IsS03N/cPHFaSJOnv0zHGj1BvZxAQ2VnN5GergrFfQP9X6g8AQJ0gJ66fmjr5xFbI2qMGEU7GBg0Inz0LpaKCsg0b8L7xBnTe3n/DJ5KuBv/oPAFCiCCgKXDmJOlPoPYRaAv4AI/Vt62iKDMURWmjKEobi8Xyl5dVkiTpshECblsM9+2AxoMvvH6jQepkSIumqJ32mo6u9bZLo0aEzfoUj8GD8b39/GmgpWvLX9kckA6c2WU01LnsUowBflQUpWYyaUVRMp0/VgkhZgMP/6lSSpIk/ROdmoDnYkR3B71Z7bnf7AYwedVZxdSkCSGvv3bZiif9O/yVNQFbgQZCiCghhAG1Wn/RJe7jRs5qCnDWDiDUTBbDgH2XoaySJElXL70JYnqoP5/RFCBJF/KX1QQoimITQtyLWpWvBWYpirJfCPE8sE1RlEVCiLbAj4A3MFgI8ZyiKE0AhBCRqDUJ687a9ZdCCAsggF3A3X/VZ5AkSbpqdHoAvCIgouOF15UkJ5kxUJIkSZL+Za54ngBJkiRJkv7ZZBAgSZIkSdcoGQRIkiRJ0jVKBgGSJEmSdI2SQYAkSZIkXaNkECBJkiRJ1ygZBEiSJEnSNUoGAZIkSZJ0jZJBgCRJkiRdo2QQIEmSJEnXKBkESJIkSdI1SgYBkiRJknSNkkGAJEmSJF2jrolZBIUQuUDqZdylH5B3Gfd3rZLn8fKQ5/HykOfx8pDn8fL4s+cxQlEUy4VWuiaCgMtNCLHtYqZolM5PnsfLQ57Hy0Oex8tDnsfL4+86j7I5QJIkSZKuUTIIkCRJkqRrlAwC/pgZV7oA/xLyPF4e8jxeHvI8Xh7yPF4ef8t5lH0CJEmSJOkaJWsCJEmSJOkaJYOASySE6CeEOCyESBJCPH6ly3O1EEKECSHWCiEOCCH2CyHudy73EUKsFEIkOr97X+my/tMJIbRCiJ1CiMXO11FCiM3Oa/IbIYThSpfxaiCE8BJCfC+EOCSEOCiE6CCvx0sjhJjq/HveJ4T4WgjhIq/HiyOEmCWEyBFC7DtjWb3Xn1C94zyne4QQrS5XOWQQcAmEEFrgfaA/EA/cKISIv7KlumrYgIcURYkH2gP3OM/d48BqRVEaAKudr6Xzux84eMbrV4G3FEWJBU4Ct1+RUl19pgPLFEVpBDRHPafyerxIQogQ4D6gjaIoCYAWuAF5PV6sz4B+Zy071/XXH2jg/JoEfHi5CiGDgEvTDkhSFOWooihWYB4w9AqX6aqgKEqmoig7nD+XoP7DDUE9f3Ocq80Bhl2ZEl4dhBChwEDgE+drAfQAvneuIs/hRRBCeAJdgU8BFEWxKopSiLweL5UOMAkhdIAZyERejxdFUZT1QMFZi891/Q0F5iqqTYCXECLocpRDBgGXJgQ4ccbrNOcy6RIIISKBlsBmIEBRlEznW1lAwBUq1tXibeBRwOF87QsUKopic76W1+TFiQJygdnOppVPhBCuyOvxoimKkg68ARxHvfkXAduR1+Ofca7r7y+798ggQPpbCSHcgPnAA4qiFJ/5nqIOVZHDVc5BCDEIyFEUZfuVLsu/gA5oBXyoKEpLoIyzqv7l9Xh+zvbqoagBVTDgSt3qbekP+ruuPxkEXJp0IOyM16HOZdJFEELoUQOALxVF+cG5OPtUtZbze86VKt9VoBMwRAiRgtoU1QO1XdvLWR0L8pq8WGlAmqIom52vv0cNCuT1ePF6AccURclVFKUa+AH1GpXX4x93ruvvL7v3yCDg0mwFGjh7vxpQO8EsusJluio4264/BQ4qijLtjLcWAbc5f74NWPh3l+1qoSjKE4qihCqKEol67a1RFGUcsBYY5VxNnsOLoChKFnBCCBHnXNQTOIC8Hi/FcaC9EMLs/Ps+dQ7l9fjHnev6WwTc6hwl0B4oOqPZ4E+RyYIukRBiAGq7rBaYpSjKS1e4SFcFIURn4FdgL6fbs59E7RfwLRCOOtPjGEVRzu4sI51FCNEdeFhRlEFCiGjUmgEfYCdws6IoVVeyfFcDIUQL1A6WBuAoMAH1wUhejxdJCPEcMBZ19M9O4A7Utmp5PV6AEOJroDvqbIHZwDPAAuq5/pxB1nuozS3lwARFUbZdlnLIIECSJEmSrk2yOUCSJEmSrlEyCJAkSZKka5QMAiRJkiTpGiWDAEmSJEm6RskgQJIkSZKuUTIIkCSphhDCLoTYdcbXZZtARwgReeaMaZIkXXm6C68iSdI1pEJRlBZXuhCSJP09ZE2AJEkXJIRIEUK8JoTYK4TYIoSIdS6PFEKscc5xvloIEe5cHiCE+FEIsdv51dG5K60QYqZzDvoVQgiTc/0YIcQyIcR2IcSvQohGzuWfOedR3yiEOCqEGFVvASVJ+kNkECBJ0plMZzUHjD3jvSJFUZqiZi5727nsXWCOoijNgC+Bd5zL3wHWKYrSHDUn/37n8gbA+4qiNAEKgZHO5TOAKYqitAYeBj4447hBQGdgEPDKZfysknTNkxkDJUmqIYQoVRTFrZ7lKUAPRVGOOieCylIUxVcIkQcEKYpS7VyeqSiKnxAiFwg9M12scwrplYqiNHC+fgzQowYUucDhMw5pVBSlsRDiM+c2Xzq3KVEUxf3yf3JJujbJPgGSJF0s5Rw/X4ozc8jbARNqjWThefoinLmN+IPHlSSpHrI5QJKkizX2jO+/O3/eiDqjIcA41EmiAFYDkwGEEFohhOe5dqooSjFwTAgx2rm+EEI0v8xllySpHjIIkCTpTGf3CTizDd5bCLEHuB+Y6lw2BZjgXH6L8z2c368XQuwFtgPxFzjuOOB2IcRu1P4DQy/T55Ek6TxknwBJki7I2SegjaIoeVe6LJIkXT6yJkCSJEmSrlGyJkCSJEmSrlGyJkCSJEmSrlEyCJAkSZKka5QMAiRJkiTpGiWDAEmSJEm6RskgQJIkSZKuUTIIkCRJkqRr1P8DraR1y9T/HAoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if os.path.exists(path):\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename[(len(filename)-3):len(filename)] == 'pkl':\n",
    "                #print(\"file: \", filename)\n",
    "                with open(path + filename, 'rb') as input:\n",
    "                    ann_net = pickle.load(input)\n",
    "\n",
    "                    plt.plot(ann_net['history_val_loss'])\n",
    "else:\n",
    "    print('FAIL')\n",
    "\n",
    "plt.title('Verlauf der Kostenfunktion - ANN - Val_loss')\n",
    "plt.ylabel('Kostenfunktion C')\n",
    "plt.xlabel('Epochen')\n",
    "figure = plt.gcf() # get current figure\n",
    "figure.set_size_inches(8, 6)\n",
    "\n",
    "pic_name=create_file_name()+'_bild_val_loss'\n",
    "plt.savefig(path + pic_name + '.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean(arr, start, stop):\n",
    "    if start > stop:\n",
    "        tmp = start\n",
    "        start = stop\n",
    "        stop = tmp\n",
    "    sum = 0\n",
    "    #print('laenge:', len(arr))\n",
    "    j = 0\n",
    "    for i in range(start, stop):\n",
    "        sum = sum + arr[i]\n",
    "        j = j + 1\n",
    "    return (sum / j)\n",
    "\n",
    "\n",
    "def calc_min(arr, start, stop):\n",
    "    if start > stop:\n",
    "        tmp = start\n",
    "        start = stop\n",
    "        stop = tmp\n",
    "    min = 100.0\n",
    "    j = 0\n",
    "    for i in range(start, stop):\n",
    "        if arr[i] < min:\n",
    "            min = arr[i]\n",
    "    return min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'units1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ae92f7fd66b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                         \u001b[0munits2_min\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mann_net\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'units2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtemp_mean\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0.24\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#ausschneiden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                         \u001b[0mpointx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mann_net\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'units1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                         \u001b[0mpointy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mann_net\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'units2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                         \u001b[0mpointz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'units1'"
     ]
    }
   ],
   "source": [
    "points=[]\n",
    "min=100\n",
    "units1_min=0\n",
    "units2_min=2\n",
    "if os.path.exists(path):\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename[(len(filename)-3):len(filename)] == 'pkl':\n",
    "                #print(\"file: \", filename)\n",
    "                with open(path + filename, 'rb') as input:\n",
    "                    ann_net = pickle.load(input)\n",
    "                    temp_mean=calc_mean(ann_net['history_val_loss'],15,100)\n",
    "                    temp_min=calc_min(ann_net['history_val_loss'],15,100)\n",
    "                    if temp_min<min:\n",
    "                        min=temp_min\n",
    "                        units1_min= ann_net['units1']\n",
    "                        units2_min= ann_net['units2']\n",
    "                    if temp_mean<0.24: #ausschneiden\n",
    "                        pointx=ann_net['units1']\n",
    "                        pointy=ann_net['units2']\n",
    "                        pointz=temp_mean\n",
    "                        pointsrow=[]\n",
    "                        pointsrow.append(pointx)\n",
    "                        pointsrow.append(pointy)\n",
    "                        pointsrow.append(pointz)\n",
    "                        points.append(pointsrow)\n",
    "else:\n",
    "    print('FAIL')\n",
    "\n",
    "   \n",
    " \n",
    "print('minimales Netz')\n",
    "print(min)\n",
    "print(units1_min)\n",
    "print(units2_min)\n",
    "print('--------------------')\n",
    "    \n",
    "points = np.array(points)\n",
    "plt.scatter(points[:, 0], points[:, 1], c=points[:, 2]) #scatter = punktdiagramme\n",
    "plt.title(\"Kostvergleich ab Epoche 15-100 abh√§ngig der Neuronen der Layer\")\n",
    "plt.xlabel(\"Neuronen erster Layer\")\n",
    "plt.ylabel(\"Neuronen zweiter Layer\")\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(\"Kosten\", labelpad=+2)\n",
    "figure = plt.gcf()  # get current figure\n",
    "figure.set_size_inches(8, 6) \n",
    "pic_name=create_file_name()+'_bild_Neuronenvergleich'\n",
    "plt.savefig(path + pic_name + '.png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
